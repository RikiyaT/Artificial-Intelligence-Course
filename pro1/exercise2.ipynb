{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iVIpquHhb-n7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKHmfeEzcpns"
      },
      "source": [
        "**Preparing data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouFA5aQtce7p",
        "outputId": "ece1381e-a545-4c56-cfc0-08881ed69cf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0200],\n",
              "         [0.0400],\n",
              "         [0.0600],\n",
              "         [0.0800],\n",
              "         [0.1000],\n",
              "         [0.1200],\n",
              "         [0.1400],\n",
              "         [0.1600],\n",
              "         [0.1800]]), tensor([[0.3000],\n",
              "         [0.3140],\n",
              "         [0.3280],\n",
              "         [0.3420],\n",
              "         [0.3560],\n",
              "         [0.3700],\n",
              "         [0.3840],\n",
              "         [0.3980],\n",
              "         [0.4120],\n",
              "         [0.4260]]))"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "\n",
        "X = torch.arange(start,end, step).unsqueeze(dim=1)\n",
        "\n",
        "y = weight * X + bias\n",
        "\n",
        "X[:10], y[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtmDKpTOcjDK",
        "outputId": "21246d4b-42fd-4457-b30c-f6f833f0f018"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40, 40, 10, 10)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_split = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bmnBjdiKcovA"
      },
      "outputs": [],
      "source": [
        "def plot_predictions(train_data=X_train, \n",
        "                     train_labels=y_train, \n",
        "                     test_data=X_test, \n",
        "                     test_labels=y_test, \n",
        "                     predictions=None):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
        "  \n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
        "\n",
        "  if predictions is not None:\n",
        "    # Plot the predictions in red (predictions were made on the test data)\n",
        "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "  # Show the legend\n",
        "  plt.legend(prop={\"size\": 14});"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "QNgMehH7c0Ot",
        "outputId": "7a862036-96b2-4c02-a2a1-4421b0a26dd1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_predictions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Y-Is0utpc2Jh"
      },
      "outputs": [],
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LinearRegressionModel,self).__init__()\n",
        "\n",
        "    # self.weights = nn.Parameter(torch.rand(1,\n",
        "    #                              requires_grad=True,\n",
        "    #                              dtype = torch.float))\n",
        "     \n",
        "    # self.bias = nn.Parameter(torch.rand(1,\n",
        "    #                              requires_grad=True,\n",
        "    #                              dtype = torch.float))\n",
        "    self.linear_layer = nn.Linear(in_features = 1,\n",
        "                                  out_features = 1)\n",
        "\n",
        "     \n",
        "  # def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "  #   return self.weights * x + self.bias\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    return self.linear_layer(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2Q8uPijc5zq",
        "outputId": "59888404-4a67-4e4f-8d68-7637ec125841"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[0.7645]], requires_grad=True), Parameter containing:\n",
              " tensor([0.8300], requires_grad=True)]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "list(model_0.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxs5HSTgdBI5",
        "outputId": "630a9789-2b84-497a-9018-53e61c1c4280"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('linear_layer.weight', tensor([[0.7645]])),\n",
              "             ('linear_layer.bias', tensor([0.8300]))])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_0.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Cpq5yRadDTk",
        "outputId": "0a177474-c75c-4413-ab08-ca445dc2c3aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.4416],\n",
              "        [1.4569],\n",
              "        [1.4722],\n",
              "        [1.4875],\n",
              "        [1.5028],\n",
              "        [1.5181],\n",
              "        [1.5334],\n",
              "        [1.5487],\n",
              "        [1.5640],\n",
              "        [1.5793]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds = model_0(X_test)\n",
        "\n",
        "# with torch.no_grad():\n",
        "#   y_preds = model_0(X_test)\n",
        "\n",
        "y_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "7baq9EKbdFgH",
        "outputId": "ee9aaa8f-b9ee-4460-a172-00ae798b9c53"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_predictions(predictions=y_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZFAf5y7dLAL"
      },
      "source": [
        "**Train data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "abnzAU54dHfI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "criterion = nn.L1Loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IxITQw6dNHJ",
        "outputId": "29971f9a-025f-4181-8e6f-476cb2b62a66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 10 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 20 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 30 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 40 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 50 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 60 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 70 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 80 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 90 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 100 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 110 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 120 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 1/100 [00:00<00:31,  3.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5551779866218567\n",
            "Epoch: 130 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 140 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 150 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 160 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 170 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 180 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 190 | Loss: 0.5551779866218567 | Test loss: 0.5874472260475159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5874403715133667\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551720857620239\n",
            "Loss:0.5551662445068359\n",
            "Loss:0.555160403251648\n",
            "Loss:0.5551546216011047\n",
            "Loss:0.555148720741272\n",
            "Loss:0.5551429986953735\n",
            "Loss:0.5551370978355408\n",
            "Loss:0.555131196975708\n",
            "Loss:0.5551254153251648\n",
            "Loss:0.5551195740699768\n",
            "Epoch: 10 | Loss: 0.5551195740699768 | Test loss: 0.5873722434043884\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551137328147888\n",
            "Loss:0.5551079511642456\n",
            "Loss:0.5551021099090576\n",
            "Loss:0.5550962686538696\n",
            "Loss:0.5550904273986816\n",
            "Loss:0.5550845861434937\n",
            "Loss:0.5550786852836609\n",
            "Loss:0.5550729036331177\n",
            "Loss:0.5550671219825745\n",
            "Loss:0.5550612211227417\n",
            "Epoch: 20 | Loss: 0.5550612211227417 | Test loss: 0.5873040556907654\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5550554394721985\n",
            "Loss:0.5550495386123657\n",
            "Loss:0.5550438165664673\n",
            "Loss:0.5550379157066345\n",
            "Loss:0.5550321340560913\n",
            "Loss:0.5550262331962585\n",
            "Loss:0.5550204515457153\n",
            "Loss:0.5550146102905273\n",
            "Loss:0.5550087690353394\n",
            "Loss:0.5550028681755066\n",
            "Epoch: 30 | Loss: 0.5550028681755066 | Test loss: 0.5872359275817871\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5549970865249634\n",
            "Loss:0.5549912452697754\n",
            "Loss:0.5549854040145874\n",
            "Loss:0.5549795627593994\n",
            "Loss:0.5549737811088562\n",
            "Loss:0.5549678802490234\n",
            "Loss:0.5549620389938354\n",
            "Loss:0.5549562573432922\n",
            "Loss:0.5549503564834595\n",
            "Loss:0.554944634437561\n",
            "Epoch: 40 | Loss: 0.554944634437561 | Test loss: 0.5871676802635193\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5549387335777283\n",
            "Loss:0.5549329519271851\n",
            "Loss:0.5549270510673523\n",
            "Loss:0.5549212694168091\n",
            "Loss:0.5549153685569763\n",
            "Loss:0.5549095869064331\n",
            "Loss:0.5549038052558899\n",
            "Loss:0.5548979043960571\n",
            "Loss:0.5548920631408691\n",
            "Loss:0.5548862218856812\n",
            "Epoch: 50 | Loss: 0.5548862218856812 | Test loss: 0.5870994925498962\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5548804402351379\n",
            "Loss:0.55487459897995\n",
            "Loss:0.5548688173294067\n",
            "Loss:0.554862916469574\n",
            "Loss:0.5548571348190308\n",
            "Loss:0.554851233959198\n",
            "Loss:0.5548454523086548\n",
            "Loss:0.5548396110534668\n",
            "Loss:0.554833710193634\n",
            "Loss:0.554827868938446\n",
            "Epoch: 60 | Loss: 0.554827868938446 | Test loss: 0.587031364440918\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5548220872879028\n",
            "Loss:0.5548163056373596\n",
            "Loss:0.5548104047775269\n",
            "Loss:0.5548046827316284\n",
            "Loss:0.5547987222671509\n",
            "Loss:0.5547928810119629\n",
            "Loss:0.5547870993614197\n",
            "Loss:0.5547812581062317\n",
            "Loss:0.5547754168510437\n",
            "Loss:0.5547695755958557\n",
            "Epoch: 70 | Loss: 0.5547695755958557 | Test loss: 0.5869632959365845\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5547637343406677\n",
            "Loss:0.5547578930854797\n",
            "Loss:0.5547520518302917\n",
            "Loss:0.5547462701797485\n",
            "Loss:0.554740309715271\n",
            "Loss:0.5547345876693726\n",
            "Loss:0.5547287464141846\n",
            "Loss:0.5547229051589966\n",
            "Loss:0.5547170639038086\n",
            "Loss:0.5547112226486206\n",
            "Epoch: 80 | Loss: 0.5547112226486206 | Test loss: 0.5868950486183167\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5547054409980774\n",
            "Loss:0.5546995401382446\n",
            "Loss:0.5546937584877014\n",
            "Loss:0.5546878576278687\n",
            "Loss:0.5546820759773254\n",
            "Loss:0.5546762347221375\n",
            "Loss:0.5546704530715942\n",
            "Loss:0.5546645522117615\n",
            "Loss:0.5546587109565735\n",
            "Loss:0.5546529293060303\n",
            "Epoch: 90 | Loss: 0.5546529293060303 | Test loss: 0.5868269205093384\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8295]))])\n",
            "Loss:0.5546470880508423\n",
            "Loss:0.5546412467956543\n",
            "Loss:0.5546354055404663\n",
            "Loss:0.5546295642852783\n",
            "Loss:0.5546237826347351\n",
            "Loss:0.5546179413795471\n",
            "Loss:0.5546120405197144\n",
            "Loss:0.5546062588691711\n",
            "Loss:0.5546004176139832\n",
            "Loss:0.5545945763587952\n",
            "Epoch: 100 | Loss: 0.5545945763587952 | Test loss: 0.5867587327957153\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8295]))])\n",
            "Loss:0.5545887351036072\n",
            "Loss:0.554582953453064\n",
            "Loss:0.5545770525932312\n",
            "Loss:0.554571270942688\n",
            "Loss:0.5545654296875\n",
            "Loss:0.554559588432312\n",
            "Loss:0.554553747177124\n",
            "Loss:0.554547905921936\n",
            "Loss:0.554542064666748\n",
            "Loss:0.5545362234115601\n",
            "Epoch: 110 | Loss: 0.5545362234115601 | Test loss: 0.5866905450820923\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8294]))])\n",
            "Loss:0.5545304417610168\n",
            "Loss:0.5545245409011841\n",
            "Loss:0.5545188188552856\n",
            "Loss:0.5545128583908081\n",
            "Loss:0.5545070767402649\n",
            "Loss:0.5545012354850769\n",
            "Loss:0.5544953942298889\n",
            "Loss:0.5544896125793457\n",
            "Loss:0.5544837713241577\n",
            "Loss:0.5544779300689697\n",
            "Epoch: 120 | Loss: 0.5544779300689697 | Test loss: 0.5866223573684692\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8294]))])\n",
            "Loss:0.5544720888137817\n",
            "Loss:0.554466187953949\n",
            "Loss:0.5544604063034058\n",
            "Loss:0.5544546246528625\n",
            "Loss:0.5544487237930298\n",
            "Loss:0.5544428825378418\n",
            "Loss:0.5544370412826538\n",
            "Loss:0.5544312000274658\n",
            "Loss:0.5544254183769226\n",
            "Loss:0.5544195771217346\n",
            "Epoch: 130 | Loss: 0.5544195771217346 | Test loss: 0.5865541696548462\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8293]))])\n",
            "Loss:0.5544137358665466\n",
            "Loss:0.5544078946113586\n",
            "Loss:0.5544021129608154\n",
            "Loss:0.5543962717056274\n",
            "Loss:0.5543903708457947\n",
            "Loss:0.5543845891952515\n",
            "Loss:0.5543786883354187\n",
            "Loss:0.5543729066848755\n",
            "Loss:0.5543670654296875\n",
            "Loss:0.5543612241744995\n",
            "Epoch: 140 | Loss: 0.5543612241744995 | Test loss: 0.5864859819412231\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8293]))])\n",
            "Loss:0.5543554425239563\n",
            "Loss:0.5543496012687683\n",
            "Loss:0.5543437004089355\n",
            "Loss:0.5543378591537476\n",
            "Loss:0.5543320775032043\n",
            "Loss:0.5543261766433716\n",
            "Loss:0.5543204545974731\n",
            "Loss:0.5543145537376404\n",
            "Loss:0.5543087720870972\n",
            "Loss:0.5543029308319092\n",
            "Epoch: 150 | Loss: 0.5543029308319092 | Test loss: 0.5864177942276001\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8292]))])\n",
            "Loss:0.5542970895767212\n",
            "Loss:0.5542912483215332\n",
            "Loss:0.5542854070663452\n",
            "Loss:0.5542795658111572\n",
            "Loss:0.5542737245559692\n",
            "Loss:0.5542678833007812\n",
            "Loss:0.5542620420455933\n",
            "Loss:0.5542562007904053\n",
            "Loss:0.5542503595352173\n",
            "Loss:0.5542445778846741\n",
            "Epoch: 160 | Loss: 0.5542445778846741 | Test loss: 0.5863496661186218\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8292]))])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|         | 2/100 [00:00<00:33,  2.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5542386770248413\n",
            "Loss:0.5542329549789429\n",
            "Loss:0.5542270541191101\n",
            "Loss:0.5542212724685669\n",
            "Loss:0.5542153716087341\n",
            "Loss:0.5542095303535461\n",
            "Loss:0.5542038083076477\n",
            "Loss:0.5541979074478149\n",
            "Loss:0.554192066192627\n",
            "Loss:0.554186224937439\n",
            "Epoch: 170 | Loss: 0.554186224937439 | Test loss: 0.586281418800354\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8291]))])\n",
            "Loss:0.554180383682251\n",
            "Loss:0.554174542427063\n",
            "Loss:0.554168701171875\n",
            "Loss:0.554162859916687\n",
            "Loss:0.554157018661499\n",
            "Loss:0.5541512370109558\n",
            "Loss:0.5541454553604126\n",
            "Loss:0.5541395545005798\n",
            "Loss:0.5541337728500366\n",
            "Loss:0.5541279315948486\n",
            "Epoch: 180 | Loss: 0.5541279315948486 | Test loss: 0.5862132906913757\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8291]))])\n",
            "Loss:0.5541220307350159\n",
            "Loss:0.5541162490844727\n",
            "Loss:0.5541104078292847\n",
            "Loss:0.5541045069694519\n",
            "Loss:0.5540987253189087\n",
            "Loss:0.5540928840637207\n",
            "Loss:0.5540870428085327\n",
            "Loss:0.5540812611579895\n",
            "Loss:0.5540754199028015\n",
            "Loss:0.5540695190429688\n",
            "Epoch: 190 | Loss: 0.5540695190429688 | Test loss: 0.5861451029777527\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8290]))])\n",
            "Loss:0.5540637969970703\n",
            "Loss:0.5540578961372375\n",
            "Loss:0.5540520548820496\n",
            "Loss:0.5540462732315063\n",
            "Loss:0.5540403127670288\n",
            "Loss:0.5540345311164856\n",
            "Loss:0.5540286898612976\n",
            "Loss:0.5540229082107544\n",
            "Loss:0.5540170669555664\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5874336361885071\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551663637161255\n",
            "Loss:0.5551546812057495\n",
            "Loss:0.5551431179046631\n",
            "Loss:0.5551315546035767\n",
            "Loss:0.5551199316978455\n",
            "Loss:0.5551083087921143\n",
            "Loss:0.5550966262817383\n",
            "Loss:0.5550850629806519\n",
            "Loss:0.5550734400749207\n",
            "Loss:0.5550618767738342\n",
            "Epoch: 10 | Loss: 0.5550618767738342 | Test loss: 0.5872979164123535\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.555050253868103\n",
            "Loss:0.5550386309623718\n",
            "Loss:0.5550270080566406\n",
            "Loss:0.5550154447555542\n",
            "Loss:0.555003821849823\n",
            "Loss:0.5549922585487366\n",
            "Loss:0.5549806356430054\n",
            "Loss:0.5549690127372742\n",
            "Loss:0.554957389831543\n",
            "Loss:0.5549458265304565\n",
            "Epoch: 20 | Loss: 0.5549458265304565 | Test loss: 0.5871621370315552\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5549341440200806\n",
            "Loss:0.5549225807189941\n",
            "Loss:0.5549109578132629\n",
            "Loss:0.5548993349075317\n",
            "Loss:0.5548877716064453\n",
            "Loss:0.5548761487007141\n",
            "Loss:0.5548645257949829\n",
            "Loss:0.5548529624938965\n",
            "Loss:0.5548412799835205\n",
            "Loss:0.5548297166824341\n",
            "Epoch: 30 | Loss: 0.5548297166824341 | Test loss: 0.5870264172554016\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5548180937767029\n",
            "Loss:0.5548065900802612\n",
            "Loss:0.5547949075698853\n",
            "Loss:0.5547832250595093\n",
            "Loss:0.5547717213630676\n",
            "Loss:0.5547600984573364\n",
            "Loss:0.5547484755516052\n",
            "Loss:0.554736852645874\n",
            "Loss:0.5547252893447876\n",
            "Loss:0.5547136068344116\n",
            "Epoch: 40 | Loss: 0.5547136068344116 | Test loss: 0.5868905782699585\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5547019839286804\n",
            "Loss:0.5546903610229492\n",
            "Loss:0.5546787977218628\n",
            "Loss:0.5546672344207764\n",
            "Loss:0.5546555519104004\n",
            "Loss:0.554643988609314\n",
            "Loss:0.5546323657035828\n",
            "Loss:0.5546208024024963\n",
            "Loss:0.5546091198921204\n",
            "Loss:0.5545974969863892\n",
            "Epoch: 50 | Loss: 0.5545974969863892 | Test loss: 0.5867549180984497\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8295]))])\n",
            "Loss:0.5545859932899475\n",
            "Loss:0.5545743703842163\n",
            "Loss:0.5545627474784851\n",
            "Loss:0.5545511245727539\n",
            "Loss:0.5545395016670227\n",
            "Loss:0.5545278787612915\n",
            "Loss:0.5545163154602051\n",
            "Loss:0.5545046925544739\n",
            "Loss:0.5544930696487427\n",
            "Loss:0.5544815063476562\n",
            "Epoch: 60 | Loss: 0.5544815063476562 | Test loss: 0.5866192579269409\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8294]))])\n",
            "Loss:0.554469883441925\n",
            "Loss:0.5544582605361938\n",
            "Loss:0.5544466376304626\n",
            "Loss:0.5544350147247314\n",
            "Loss:0.554423451423645\n",
            "Loss:0.5544118285179138\n",
            "Loss:0.5544003248214722\n",
            "Loss:0.5543886423110962\n",
            "Loss:0.554377019405365\n",
            "Loss:0.5543653964996338\n",
            "Epoch: 70 | Loss: 0.5543653964996338 | Test loss: 0.5864834785461426\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8293]))])\n",
            "Loss:0.5543538331985474\n",
            "Loss:0.5543422102928162\n",
            "Loss:0.554330587387085\n",
            "Loss:0.5543190240859985\n",
            "Loss:0.5543073415756226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|         | 3/100 [00:01<00:33,  2.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5542957186698914\n",
            "Loss:0.5542841553688049\n",
            "Loss:0.5542725324630737\n",
            "Loss:0.5542609095573425\n",
            "Loss:0.5542492866516113\n",
            "Epoch: 80 | Loss: 0.5542492866516113 | Test loss: 0.5863476991653442\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8292]))])\n",
            "Loss:0.5542377233505249\n",
            "Loss:0.5542261004447937\n",
            "Loss:0.5542145371437073\n",
            "Loss:0.5542029142379761\n",
            "Loss:0.5541912913322449\n",
            "Loss:0.5541797280311584\n",
            "Loss:0.5541681051254272\n",
            "Loss:0.554156482219696\n",
            "Loss:0.5541449189186096\n",
            "Loss:0.5541332960128784\n",
            "Epoch: 90 | Loss: 0.5541332960128784 | Test loss: 0.5862119197845459\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8291]))])\n",
            "Loss:0.5541216135025024\n",
            "Loss:0.5541101098060608\n",
            "Loss:0.5540984869003296\n",
            "Loss:0.5540868043899536\n",
            "Loss:0.5540752410888672\n",
            "Loss:0.554063618183136\n",
            "Loss:0.5540519952774048\n",
            "Loss:0.5540404319763184\n",
            "Loss:0.5540288090705872\n",
            "Loss:0.5540172457695007\n",
            "Epoch: 100 | Loss: 0.5540172457695007 | Test loss: 0.5860761404037476\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7641]])), ('linear_layer.bias', tensor([0.8290]))])\n",
            "Loss:0.5540056228637695\n",
            "Loss:0.5539939403533936\n",
            "Loss:0.5539823770523071\n",
            "Loss:0.5539708137512207\n",
            "Loss:0.5539591908454895\n",
            "Loss:0.5539475679397583\n",
            "Loss:0.5539358854293823\n",
            "Loss:0.5539243221282959\n",
            "Loss:0.5539127588272095\n",
            "Loss:0.5539010763168335\n",
            "Epoch: 110 | Loss: 0.5539010763168335 | Test loss: 0.5859404802322388\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7641]])), ('linear_layer.bias', tensor([0.8289]))])\n",
            "Loss:0.5538895130157471\n",
            "Loss:0.5538779497146606\n",
            "Loss:0.5538662672042847\n",
            "Loss:0.5538546442985535\n",
            "Loss:0.5538430213928223\n",
            "Loss:0.5538314580917358\n",
            "Loss:0.5538198351860046\n",
            "Loss:0.5538082122802734\n",
            "Loss:0.553796648979187\n",
            "Loss:0.5537851452827454\n",
            "Epoch: 120 | Loss: 0.5537851452827454 | Test loss: 0.5858047008514404\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7641]])), ('linear_layer.bias', tensor([0.8288]))])\n",
            "Loss:0.5537734627723694\n",
            "Loss:0.5537618398666382\n",
            "Loss:0.5537501573562622\n",
            "Loss:0.5537386536598206\n",
            "Loss:0.5537270307540894\n",
            "Loss:0.5537154078483582\n",
            "Loss:0.553703784942627\n",
            "Loss:0.5536921620368958\n",
            "Loss:0.5536805391311646\n",
            "Loss:0.5536689758300781\n",
            "Epoch: 130 | Loss: 0.5536689758300781 | Test loss: 0.5856689810752869\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7640]])), ('linear_layer.bias', tensor([0.8287]))])\n",
            "Loss:0.5536574125289917\n",
            "Loss:0.5536457300186157\n",
            "Loss:0.5536341667175293\n",
            "Loss:0.5536225438117981\n",
            "Loss:0.5536109209060669\n",
            "Loss:0.5535992980003357\n",
            "Loss:0.5535876750946045\n",
            "Loss:0.5535761117935181\n",
            "Loss:0.5535644888877869\n",
            "Loss:0.5535529255867004\n",
            "Epoch: 140 | Loss: 0.5535529255867004 | Test loss: 0.5855332016944885\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7640]])), ('linear_layer.bias', tensor([0.8286]))])\n",
            "Loss:0.5535413026809692\n",
            "Loss:0.5535296201705933\n",
            "Loss:0.5535181164741516\n",
            "Loss:0.5535064935684204\n",
            "Loss:0.5534948706626892\n",
            "Loss:0.5534833073616028\n",
            "Loss:0.5534716248512268\n",
            "Loss:0.5534600019454956\n",
            "Loss:0.5534483790397644\n",
            "Loss:0.5534368753433228\n",
            "Epoch: 150 | Loss: 0.5534368753433228 | Test loss: 0.5853974223136902\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7639]])), ('linear_layer.bias', tensor([0.8285]))])\n",
            "Loss:0.5534251928329468\n",
            "Loss:0.5534136295318604\n",
            "Loss:0.5534019470214844\n",
            "Loss:0.5533905029296875\n",
            "Loss:0.5533787608146667\n",
            "Loss:0.5533671975135803\n",
            "Loss:0.5533555746078491\n",
            "Loss:0.5533440113067627\n",
            "Loss:0.5533323884010315\n",
            "Loss:0.5533207654953003\n",
            "Epoch: 160 | Loss: 0.5533207654953003 | Test loss: 0.5852618217468262\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7639]])), ('linear_layer.bias', tensor([0.8284]))])\n",
            "Loss:0.5533091425895691\n",
            "Loss:0.5532975196838379\n",
            "Loss:0.5532859563827515\n",
            "Loss:0.5532742738723755\n",
            "Loss:0.5532627105712891\n",
            "Loss:0.5532511472702026\n",
            "Loss:0.5532394647598267\n",
            "Loss:0.5532277822494507\n",
            "Loss:0.5532162189483643\n",
            "Loss:0.5532046556472778\n",
            "Epoch: 170 | Loss: 0.5532046556472778 | Test loss: 0.5851260423660278\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7639]])), ('linear_layer.bias', tensor([0.8283]))])\n",
            "Loss:0.5531930327415466\n",
            "Loss:0.5531814098358154\n",
            "Loss:0.5531699061393738\n",
            "Loss:0.5531582832336426\n",
            "Loss:0.5531466603279114\n",
            "Loss:0.5531350374221802\n",
            "Loss:0.553123414516449\n",
            "Loss:0.5531118512153625\n",
            "Loss:0.5531002283096313\n",
            "Loss:0.5530885457992554\n",
            "Epoch: 180 | Loss: 0.5530885457992554 | Test loss: 0.5849902629852295\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7638]])), ('linear_layer.bias', tensor([0.8282]))])\n",
            "Loss:0.553076982498169\n",
            "Loss:0.5530654191970825\n",
            "Loss:0.5530537366867065\n",
            "Loss:0.5530421137809753\n",
            "Loss:0.5530306100845337\n",
            "Loss:0.5530189275741577\n",
            "Loss:0.5530073046684265\n",
            "Loss:0.5529957413673401\n",
            "Loss:0.5529841184616089\n",
            "Loss:0.5529724955558777\n",
            "Epoch: 190 | Loss: 0.5529724955558777 | Test loss: 0.5848544836044312\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7638]])), ('linear_layer.bias', tensor([0.8281]))])\n",
            "Loss:0.5529609322547913\n",
            "Loss:0.5529493093490601\n",
            "Loss:0.5529377460479736\n",
            "Loss:0.5529260635375977\n",
            "Loss:0.5529145002365112\n",
            "Loss:0.55290287733078\n",
            "Loss:0.5528913140296936\n",
            "Loss:0.5528796911239624\n",
            "Loss:0.5528680086135864\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5874268412590027\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551605224609375\n",
            "Loss:0.5551430583000183\n",
            "Loss:0.5551255941390991\n",
            "Loss:0.5551081895828247\n",
            "Loss:0.5550907254219055\n",
            "Loss:0.5550732612609863\n",
            "Loss:0.5550557971000671\n",
            "Loss:0.5550383925437927\n",
            "Loss:0.5550209283828735\n",
            "Loss:0.5550035238265991\n",
            "Epoch: 10 | Loss: 0.5550035238265991 | Test loss: 0.5872228741645813\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5549860596656799\n",
            "Loss:0.5549686551094055\n",
            "Loss:0.5549511909484863\n",
            "Loss:0.5549337863922119\n",
            "Loss:0.554916262626648\n",
            "Loss:0.5548989176750183\n",
            "Loss:0.5548814535140991\n",
            "Loss:0.5548640489578247\n",
            "Loss:0.5548465251922607\n",
            "Loss:0.5548291206359863\n",
            "Epoch: 20 | Loss: 0.5548291206359863 | Test loss: 0.5870189666748047\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5548116564750671\n",
            "Loss:0.554794192314148\n",
            "Loss:0.5547767877578735\n",
            "Loss:0.5547593235969543\n",
            "Loss:0.5547418594360352\n",
            "Loss:0.5547244548797607\n",
            "Loss:0.5547069907188416\n",
            "Loss:0.5546895861625671\n",
            "Loss:0.5546721816062927\n",
            "Loss:0.5546547770500183\n",
            "Epoch: 30 | Loss: 0.5546547770500183 | Test loss: 0.5868149995803833\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8295]))])\n",
            "Loss:0.5546372532844543\n",
            "Loss:0.5546198487281799\n",
            "Loss:0.554602324962616\n",
            "Loss:0.5545849204063416\n",
            "Loss:0.5545675158500671\n",
            "Loss:0.554550051689148\n",
            "Loss:0.5545326471328735\n",
            "Loss:0.5545151829719543\n",
            "Loss:0.5544977784156799\n",
            "Loss:0.554480254650116\n",
            "Epoch: 40 | Loss: 0.554480254650116 | Test loss: 0.5866111516952515\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8294]))])\n",
            "Loss:0.5544629096984863\n",
            "Loss:0.5544453859329224\n",
            "Loss:0.554427981376648\n",
            "Loss:0.5544105768203735\n",
            "Loss:0.5543931126594543\n",
            "Loss:0.5543756484985352\n",
            "Loss:0.5543582439422607\n",
            "Loss:0.5543407797813416\n",
            "Loss:0.5543233156204224\n",
            "Loss:0.5543058514595032\n",
            "Epoch: 50 | Loss: 0.5543058514595032 | Test loss: 0.5864072442054749\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8292]))])\n",
            "Loss:0.5542885065078735\n",
            "Loss:0.5542710423469543\n",
            "Loss:0.5542535781860352\n",
            "Loss:0.5542360544204712\n",
            "Loss:0.5542186498641968\n",
            "Loss:0.5542012453079224\n",
            "Loss:0.554183840751648\n",
            "Loss:0.554166316986084\n",
            "Loss:0.5541489124298096\n",
            "Loss:0.5541314482688904\n",
            "Epoch: 60 | Loss: 0.5541314482688904 | Test loss: 0.586203396320343\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8291]))])\n",
            "Loss:0.554114043712616\n",
            "Loss:0.5540965795516968\n",
            "Loss:0.5540791749954224\n",
            "Loss:0.5540617108345032\n",
            "Loss:0.5540443062782288\n",
            "Loss:0.5540268421173096\n",
            "Loss:0.5540094375610352\n",
            "Loss:0.5539919137954712\n",
            "Loss:0.5539745092391968\n",
            "Loss:0.5539571046829224\n",
            "Epoch: 70 | Loss: 0.5539571046829224 | Test loss: 0.5859994888305664\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7641]])), ('linear_layer.bias', tensor([0.8289]))])\n",
            "Loss:0.5539396405220032\n",
            "Loss:0.553922176361084\n",
            "Loss:0.5539047718048096\n",
            "Loss:0.5538873076438904\n",
            "Loss:0.5538698434829712\n",
            "Loss:0.5538524389266968\n",
            "Loss:0.5538350343704224\n",
            "Loss:0.5538175702095032\n",
            "Loss:0.553800106048584\n",
            "Loss:0.55378258228302\n",
            "Epoch: 80 | Loss: 0.55378258228302 | Test loss: 0.585795521736145\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7641]])), ('linear_layer.bias', tensor([0.8288]))])\n",
            "Loss:0.5537651777267456\n",
            "Loss:0.5537477731704712\n",
            "Loss:0.5537303686141968\n",
            "Loss:0.5537129044532776\n",
            "Loss:0.5536954402923584\n",
            "Loss:0.553678035736084\n",
            "Loss:0.5536605715751648\n",
            "Loss:0.5536431074142456\n",
            "Loss:0.5536257028579712\n",
            "Loss:0.553608238697052\n",
            "Epoch: 90 | Loss: 0.553608238697052 | Test loss: 0.5855916142463684\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7640]])), ('linear_layer.bias', tensor([0.8286]))])\n",
            "Loss:0.5535908937454224\n",
            "Loss:0.5535733699798584\n",
            "Loss:0.5535559058189392\n",
            "Loss:0.55353844165802\n",
            "Loss:0.5535210371017456\n",
            "Loss:0.5535036325454712\n",
            "Loss:0.553486168384552\n",
            "Loss:0.5534687042236328\n",
            "Loss:0.5534512996673584\n",
            "Loss:0.553433895111084\n",
            "Epoch: 100 | Loss: 0.553433895111084 | Test loss: 0.5853877067565918\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7639]])), ('linear_layer.bias', tensor([0.8285]))])\n",
            "Loss:0.55341637134552\n",
            "Loss:0.5533989071846008\n",
            "Loss:0.5533815622329712\n",
            "Loss:0.553364098072052\n",
            "Loss:0.5533466339111328\n",
            "Loss:0.5533291101455688\n",
            "Loss:0.5533117055892944\n",
            "Loss:0.55329430103302\n",
            "Loss:0.5532768368721008\n",
            "Loss:0.5532594919204712\n",
            "Epoch: 110 | Loss: 0.5532594919204712 | Test loss: 0.5851837396621704\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7639]])), ('linear_layer.bias', tensor([0.8283]))])\n",
            "Loss:0.5532419681549072\n",
            "Loss:0.5532246232032776\n",
            "Loss:0.5532070994377136\n",
            "Loss:0.5531896948814392\n",
            "Loss:0.55317223072052\n",
            "Loss:0.5531548261642456\n",
            "Loss:0.5531374216079712\n",
            "Loss:0.5531198382377625\n",
            "Loss:0.5531024932861328\n",
            "Loss:0.5530850291252136\n",
            "Epoch: 120 | Loss: 0.5530850291252136 | Test loss: 0.5849798321723938\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7638]])), ('linear_layer.bias', tensor([0.8282]))])\n",
            "Loss:0.5530675649642944\n",
            "Loss:0.5530501008033752\n",
            "Loss:0.5530327558517456\n",
            "Loss:0.5530152320861816\n",
            "Loss:0.5529978275299072\n",
            "Loss:0.552980363368988\n",
            "Loss:0.5529629588127136\n",
            "Loss:0.5529454946517944\n",
            "Loss:0.55292809009552\n",
            "Loss:0.5529106855392456\n",
            "Epoch: 130 | Loss: 0.5529106855392456 | Test loss: 0.5847759246826172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|         | 4/100 [00:01<00:31,  3.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('linear_layer.weight', tensor([[0.7638]])), ('linear_layer.bias', tensor([0.8280]))])\n",
            "Loss:0.5528931617736816\n",
            "Loss:0.5528756976127625\n",
            "Loss:0.552858293056488\n",
            "Loss:0.5528408885002136\n",
            "Loss:0.5528234243392944\n",
            "Loss:0.5528059601783752\n",
            "Loss:0.552788496017456\n",
            "Loss:0.5527711510658264\n",
            "Loss:0.5527536869049072\n",
            "Loss:0.5527362823486328\n",
            "Epoch: 140 | Loss: 0.5527362823486328 | Test loss: 0.5845720171928406\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7637]])), ('linear_layer.bias', tensor([0.8279]))])\n",
            "Loss:0.5527187585830688\n",
            "Loss:0.5527013540267944\n",
            "Loss:0.55268394947052\n",
            "Loss:0.5526664853096008\n",
            "Loss:0.5526490211486816\n",
            "Loss:0.5526315569877625\n",
            "Loss:0.5526140928268433\n",
            "Loss:0.5525966882705688\n",
            "Loss:0.5525792241096497\n",
            "Loss:0.5525618195533752\n",
            "Epoch: 150 | Loss: 0.5525618195533752 | Test loss: 0.584368109703064\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7636]])), ('linear_layer.bias', tensor([0.8277]))])\n",
            "Loss:0.552544355392456\n",
            "Loss:0.5525269508361816\n",
            "Loss:0.5525094270706177\n",
            "Loss:0.5524920225143433\n",
            "Loss:0.5524746179580688\n",
            "Loss:0.5524570941925049\n",
            "Loss:0.5524396896362305\n",
            "Loss:0.552422285079956\n",
            "Loss:0.5524048209190369\n",
            "Loss:0.5523874163627625\n",
            "Epoch: 160 | Loss: 0.5523874163627625 | Test loss: 0.5841642618179321\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7636]])), ('linear_layer.bias', tensor([0.8276]))])\n",
            "Loss:0.5523699522018433\n",
            "Loss:0.5523525476455688\n",
            "Loss:0.5523350834846497\n",
            "Loss:0.5523176193237305\n",
            "Loss:0.5523001551628113\n",
            "Loss:0.5522827506065369\n",
            "Loss:0.5522652864456177\n",
            "Loss:0.5522478818893433\n",
            "Loss:0.5522304177284241\n",
            "Loss:0.5522129535675049\n",
            "Epoch: 170 | Loss: 0.5522129535675049 | Test loss: 0.5839602947235107\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7635]])), ('linear_layer.bias', tensor([0.8274]))])\n",
            "Loss:0.5521954894065857\n",
            "Loss:0.5521780848503113\n",
            "Loss:0.5521606206893921\n",
            "Loss:0.5521432161331177\n",
            "Loss:0.5521257519721985\n",
            "Loss:0.5521082878112793\n",
            "Loss:0.5520908832550049\n",
            "Loss:0.5520733594894409\n",
            "Loss:0.5520560145378113\n",
            "Loss:0.5520385503768921\n",
            "Epoch: 180 | Loss: 0.5520385503768921 | Test loss: 0.5837563276290894\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7635]])), ('linear_layer.bias', tensor([0.8273]))])\n",
            "Loss:0.5520210862159729\n",
            "Loss:0.5520037412643433\n",
            "Loss:0.5519862174987793\n",
            "Loss:0.5519688129425049\n",
            "Loss:0.5519514083862305\n",
            "Loss:0.5519338846206665\n",
            "Loss:0.5519164800643921\n",
            "Loss:0.5518990755081177\n",
            "Loss:0.5518815517425537\n",
            "Loss:0.5518641471862793\n",
            "Epoch: 190 | Loss: 0.5518641471862793 | Test loss: 0.5835524797439575\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7634]])), ('linear_layer.bias', tensor([0.8271]))])\n",
            "Loss:0.5518467426300049\n",
            "Loss:0.5518292188644409\n",
            "Loss:0.5518118739128113\n",
            "Loss:0.5517944097518921\n",
            "Loss:0.5517770051956177\n",
            "Loss:0.5517594814300537\n",
            "Loss:0.5517420768737793\n",
            "Loss:0.5517246127128601\n",
            "Loss:0.5517071485519409\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5874199271202087\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551546812057495\n",
            "Loss:0.5551314353942871\n",
            "Loss:0.5551081299781799\n",
            "Loss:0.5550848245620728\n",
            "Loss:0.5550615787506104\n",
            "Loss:0.5550382733345032\n",
            "Loss:0.555014967918396\n",
            "Loss:0.5549916625022888\n",
            "Loss:0.5549684762954712\n",
            "Loss:0.554945170879364\n",
            "Epoch: 10 | Loss: 0.554945170879364 | Test loss: 0.5871479511260986\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5549219250679016\n",
            "Loss:0.5548986196517944\n",
            "Loss:0.554875373840332\n",
            "Loss:0.5548520684242249\n",
            "Loss:0.5548288226127625\n",
            "Loss:0.5548055171966553\n",
            "Loss:0.5547822713851929\n",
            "Loss:0.5547589659690857\n",
            "Loss:0.5547357201576233\n",
            "Loss:0.5547124147415161\n",
            "Epoch: 20 | Loss: 0.5547124147415161 | Test loss: 0.586875855922699\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5546891689300537\n",
            "Loss:0.5546659231185913\n",
            "Loss:0.5546426177024841\n",
            "Loss:0.5546193718910217\n",
            "Loss:0.5545960664749146\n",
            "Loss:0.5545728206634521\n",
            "Loss:0.5545495748519897\n",
            "Loss:0.5545262098312378\n",
            "Loss:0.5545030236244202\n",
            "Loss:0.554479718208313\n",
            "Epoch: 30 | Loss: 0.554479718208313 | Test loss: 0.5866037607192993\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8294]))])\n",
            "Loss:0.5544564127922058\n",
            "Loss:0.5544331073760986\n",
            "Loss:0.5544098019599915\n",
            "Loss:0.554386556148529\n",
            "Loss:0.5543633699417114\n",
            "Loss:0.5543400049209595\n",
            "Loss:0.5543168187141418\n",
            "Loss:0.5542935132980347\n",
            "Loss:0.5542702078819275\n",
            "Loss:0.5542469620704651\n",
            "Epoch: 40 | Loss: 0.5542469620704651 | Test loss: 0.5863316655158997\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8292]))])\n",
            "Loss:0.5542236566543579\n",
            "Loss:0.5542004108428955\n",
            "Loss:0.5541771054267883\n",
            "Loss:0.5541539192199707\n",
            "Loss:0.5541306138038635\n",
            "Loss:0.5541073083877563\n",
            "Loss:0.5540840029716492\n",
            "Loss:0.5540608167648315\n",
            "Loss:0.5540374517440796\n",
            "Loss:0.5540142059326172\n",
            "Epoch: 50 | Loss: 0.5540142059326172 | Test loss: 0.5860595703125\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7641]])), ('linear_layer.bias', tensor([0.8290]))])\n",
            "Loss:0.5539909601211548\n",
            "Loss:0.5539677143096924\n",
            "Loss:0.5539444088935852\n",
            "Loss:0.553921103477478\n",
            "Loss:0.5538978576660156\n",
            "Loss:0.5538745522499084\n",
            "Loss:0.5538512468338013\n",
            "Loss:0.5538280606269836\n",
            "Loss:0.5538047552108765\n",
            "Loss:0.5537814497947693\n",
            "Epoch: 60 | Loss: 0.5537814497947693 | Test loss: 0.5857874751091003\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7641]])), ('linear_layer.bias', tensor([0.8288]))])\n",
            "Loss:0.5537582039833069\n",
            "Loss:0.5537348985671997\n",
            "Loss:0.5537117123603821\n",
            "Loss:0.5536883473396301\n",
            "Loss:0.5536651015281677\n",
            "Loss:0.5536417961120605\n",
            "Loss:0.5536185503005981\n",
            "Loss:0.553595244884491\n",
            "Loss:0.5535719990730286\n",
            "Loss:0.5535486936569214\n",
            "Epoch: 70 | Loss: 0.5535486936569214 | Test loss: 0.5855154395103455\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7640]])), ('linear_layer.bias', tensor([0.8286]))])\n",
            "Loss:0.553525447845459\n",
            "Loss:0.5535022020339966\n",
            "Loss:0.5534788370132446\n",
            "Loss:0.5534555912017822\n",
            "Loss:0.5534323453903198\n",
            "Loss:0.5534090995788574\n",
            "Loss:0.553385853767395\n",
            "Loss:0.5533624887466431\n",
            "Loss:0.5533391833305359\n",
            "Loss:0.5533159971237183\n",
            "Epoch: 80 | Loss: 0.5533159971237183 | Test loss: 0.585243284702301\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7639]])), ('linear_layer.bias', tensor([0.8284]))])\n",
            "Loss:0.5532926917076111\n",
            "Loss:0.5532694458961487\n",
            "Loss:0.5532461404800415\n",
            "Loss:0.5532228350639343\n",
            "Loss:0.5531996488571167\n",
            "Loss:0.5531762838363647\n",
            "Loss:0.5531530976295471\n",
            "Loss:0.5531297922134399\n",
            "Loss:0.5531065464019775\n",
            "Loss:0.5530832409858704\n",
            "Epoch: 90 | Loss: 0.5530832409858704 | Test loss: 0.5849713087081909\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7638]])), ('linear_layer.bias', tensor([0.8282]))])\n",
            "Loss:0.5530599355697632\n",
            "Loss:0.5530366897583008\n",
            "Loss:0.5530133843421936\n",
            "Loss:0.5529901385307312\n",
            "Loss:0.552966833114624\n",
            "Loss:0.5529435873031616\n",
            "Loss:0.5529202818870544\n",
            "Loss:0.5528970956802368\n",
            "Loss:0.5528737306594849\n",
            "Loss:0.5528504848480225\n",
            "Epoch: 100 | Loss: 0.5528504848480225 | Test loss: 0.5846992135047913\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7637]])), ('linear_layer.bias', tensor([0.8280]))])\n",
            "Loss:0.5528271794319153\n",
            "Loss:0.5528039336204529\n",
            "Loss:0.5527806282043457\n",
            "Loss:0.5527573823928833\n",
            "Loss:0.5527341365814209\n",
            "Loss:0.5527108311653137\n",
            "Loss:0.5526875257492065\n",
            "Loss:0.5526642799377441\n",
            "Loss:0.5526410341262817\n",
            "Loss:0.5526177287101746\n",
            "Epoch: 110 | Loss: 0.5526177287101746 | Test loss: 0.5844270586967468\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7637]])), ('linear_layer.bias', tensor([0.8278]))])\n",
            "Loss:0.5525944828987122\n",
            "Loss:0.552571177482605\n",
            "Loss:0.5525479316711426\n",
            "Loss:0.5525246858596802\n",
            "Loss:0.552501380443573\n",
            "Loss:0.5524781346321106\n",
            "Loss:0.5524548292160034\n",
            "Loss:0.552431583404541\n",
            "Loss:0.5524083375930786\n",
            "Loss:0.5523849725723267\n",
            "Epoch: 120 | Loss: 0.5523849725723267 | Test loss: 0.5841549634933472\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7636]])), ('linear_layer.bias', tensor([0.8276]))])\n",
            "Loss:0.5523617267608643\n",
            "Loss:0.5523384809494019\n",
            "Loss:0.5523151159286499\n",
            "Loss:0.5522918701171875\n",
            "Loss:0.5522686243057251\n",
            "Loss:0.5522453784942627\n",
            "Loss:0.5522220730781555\n",
            "Loss:0.5521987676620483\n",
            "Loss:0.5521755814552307\n",
            "Loss:0.5521522760391235\n",
            "Epoch: 130 | Loss: 0.5521522760391235 | Test loss: 0.5838829278945923\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7635]])), ('linear_layer.bias', tensor([0.8274]))])\n",
            "Loss:0.5521289706230164\n",
            "Loss:0.552105724811554\n",
            "Loss:0.5520824790000916\n",
            "Loss:0.5520591735839844\n",
            "Loss:0.552035927772522\n",
            "Loss:0.55201256275177\n",
            "Loss:0.5519893765449524\n",
            "Loss:0.5519660711288452\n",
            "Loss:0.5519428253173828\n",
            "Loss:0.5519195795059204\n",
            "Epoch: 140 | Loss: 0.5519195795059204 | Test loss: 0.5836108326911926\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7634]])), ('linear_layer.bias', tensor([0.8272]))])\n",
            "Loss:0.5518962144851685\n",
            "Loss:0.5518730282783508\n",
            "Loss:0.5518496036529541\n",
            "Loss:0.5518264174461365\n",
            "Loss:0.5518031120300293\n",
            "Loss:0.5517798662185669\n",
            "Loss:0.5517565608024597\n",
            "Loss:0.5517333149909973\n",
            "Loss:0.5517100095748901\n",
            "Loss:0.5516867637634277\n",
            "Epoch: 150 | Loss: 0.5516867637634277 | Test loss: 0.5833387970924377\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7634]])), ('linear_layer.bias', tensor([0.8270]))])\n",
            "Loss:0.5516635179519653\n",
            "Loss:0.5516401529312134\n",
            "Loss:0.5516169667243958\n",
            "Loss:0.5515936613082886\n",
            "Loss:0.5515704154968262\n",
            "Loss:0.551547110080719\n",
            "Loss:0.5515238046646118\n",
            "Loss:0.5515006184577942\n",
            "Loss:0.551477313041687\n",
            "Loss:0.5514540672302246\n",
            "Epoch: 160 | Loss: 0.5514540672302246 | Test loss: 0.5830666422843933\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8268]))])\n",
            "Loss:0.5514307618141174\n",
            "Loss:0.5514074563980103\n",
            "Loss:0.5513842105865479\n",
            "Loss:0.5513609647750854\n",
            "Loss:0.5513375997543335\n",
            "Loss:0.5513144135475159\n",
            "Loss:0.5512911081314087\n",
            "Loss:0.5512678027153015\n",
            "Loss:0.5512445569038391\n",
            "Loss:0.5512212514877319\n",
            "Epoch: 170 | Loss: 0.5512212514877319 | Test loss: 0.5827945470809937\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7632]])), ('linear_layer.bias', tensor([0.8266]))])\n",
            "Loss:0.5511980056762695\n",
            "Loss:0.5511747598648071\n",
            "Loss:0.5511513948440552\n",
            "Loss:0.5511281490325928\n",
            "Loss:0.5511049032211304\n",
            "Loss:0.5510815978050232\n",
            "Loss:0.5510583519935608\n",
            "Loss:0.5510351061820984\n",
            "Loss:0.5510118007659912\n",
            "Loss:0.5509885549545288\n",
            "Epoch: 180 | Loss: 0.5509885549545288 | Test loss: 0.5825225114822388\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7631]])), ('linear_layer.bias', tensor([0.8264]))])\n",
            "Loss:0.5509652495384216\n",
            "Loss:0.550942063331604\n",
            "Loss:0.550918698310852\n",
            "Loss:0.5508954524993896\n",
            "Loss:0.5508722066879272\n",
            "Loss:0.5508489608764648\n",
            "Loss:0.5508256554603577\n",
            "Loss:0.5508023500442505\n",
            "Loss:0.5507790446281433\n",
            "Loss:0.5507557988166809\n",
            "Epoch: 190 | Loss: 0.5507557988166809 | Test loss: 0.5822504758834839\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7630]])), ('linear_layer.bias', tensor([0.8261]))])\n",
            "Loss:0.5507324934005737\n",
            "Loss:0.5507091879844666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|         | 5/100 [00:01<00:31,  3.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5506858825683594\n",
            "Loss:0.550662636756897\n",
            "Loss:0.5506394505500793\n",
            "Loss:0.5506161451339722\n",
            "Loss:0.5505928993225098\n",
            "Loss:0.5505695939064026\n",
            "Loss:0.5505463480949402\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5874131917953491\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551488399505615\n",
            "Loss:0.5551196932792664\n",
            "Loss:0.555090606212616\n",
            "Loss:0.5550614595413208\n",
            "Loss:0.5550323724746704\n",
            "Loss:0.55500328540802\n",
            "Loss:0.5549741983413696\n",
            "Loss:0.5549451112747192\n",
            "Loss:0.5549160242080688\n",
            "Loss:0.5548868179321289\n",
            "Epoch: 10 | Loss: 0.5548868179321289 | Test loss: 0.5870729088783264\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5548577308654785\n",
            "Loss:0.5548286437988281\n",
            "Loss:0.554799497127533\n",
            "Loss:0.5547704100608826\n",
            "Loss:0.5547413229942322\n",
            "Loss:0.554712176322937\n",
            "Loss:0.5546831488609314\n",
            "Loss:0.5546540021896362\n",
            "Loss:0.5546249151229858\n",
            "Loss:0.5545958280563354\n",
            "Epoch: 20 | Loss: 0.5545958280563354 | Test loss: 0.5867326855659485\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8295]))])\n",
            "Loss:0.5545666217803955\n",
            "Loss:0.5545375347137451\n",
            "Loss:0.5545084476470947\n",
            "Loss:0.5544793009757996\n",
            "Loss:0.5544502139091492\n",
            "Loss:0.5544211268424988\n",
            "Loss:0.5543920397758484\n",
            "Loss:0.5543628931045532\n",
            "Loss:0.5543338060379028\n",
            "Loss:0.5543047189712524\n",
            "Epoch: 30 | Loss: 0.5543047189712524 | Test loss: 0.586392343044281\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8292]))])\n",
            "Loss:0.5542755722999573\n",
            "Loss:0.5542464852333069\n",
            "Loss:0.5542173981666565\n",
            "Loss:0.5541882514953613\n",
            "Loss:0.5541591644287109\n",
            "Loss:0.5541300773620605\n",
            "Loss:0.5541009902954102\n",
            "Loss:0.5540717840194702\n",
            "Loss:0.5540426969528198\n",
            "Loss:0.5540136098861694\n",
            "Epoch: 40 | Loss: 0.5540136098861694 | Test loss: 0.5860521793365479\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7641]])), ('linear_layer.bias', tensor([0.8290]))])\n",
            "Loss:0.553984522819519\n",
            "Loss:0.5539554357528687\n",
            "Loss:0.5539262890815735\n",
            "Loss:0.5538972616195679\n",
            "Loss:0.5538680553436279\n",
            "Loss:0.5538390278816223\n",
            "Loss:0.5538099408149719\n",
            "Loss:0.5537806749343872\n",
            "Loss:0.5537516474723816\n",
            "Loss:0.5537225008010864\n",
            "Epoch: 50 | Loss: 0.5537225008010864 | Test loss: 0.5857118964195251\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7640]])), ('linear_layer.bias', tensor([0.8287]))])\n",
            "Loss:0.5536934733390808\n",
            "Loss:0.5536643266677856\n",
            "Loss:0.5536351799964905\n",
            "Loss:0.5536061525344849\n",
            "Loss:0.5535769462585449\n",
            "Loss:0.5535478591918945\n",
            "Loss:0.5535187721252441\n",
            "Loss:0.5534896850585938\n",
            "Loss:0.5534605383872986\n",
            "Loss:0.5534314513206482\n",
            "Epoch: 60 | Loss: 0.5534314513206482 | Test loss: 0.5853716135025024\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7639]])), ('linear_layer.bias', tensor([0.8285]))])\n",
            "Loss:0.553402304649353\n",
            "Loss:0.5533732175827026\n",
            "Loss:0.5533441305160522\n",
            "Loss:0.5533150434494019\n",
            "Loss:0.5532858967781067\n",
            "Loss:0.5532568097114563\n",
            "Loss:0.5532277226448059\n",
            "Loss:0.5531985759735107\n",
            "Loss:0.5531694889068604\n",
            "Loss:0.5531403422355652\n",
            "Epoch: 70 | Loss: 0.5531403422355652 | Test loss: 0.5850313901901245\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7638]])), ('linear_layer.bias', tensor([0.8282]))])\n",
            "Loss:0.5531113147735596\n",
            "Loss:0.5530821681022644\n",
            "Loss:0.5530530214309692\n",
            "Loss:0.5530239939689636\n",
            "Loss:0.5529947876930237\n",
            "Loss:0.5529657602310181\n",
            "Loss:0.5529366135597229\n",
            "Loss:0.5529075860977173\n",
            "Loss:0.5528784394264221\n",
            "Loss:0.552849292755127\n",
            "Epoch: 80 | Loss: 0.552849292755127 | Test loss: 0.5846911668777466\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7637]])), ('linear_layer.bias', tensor([0.8280]))])\n",
            "Loss:0.5528202056884766\n",
            "Loss:0.5527911186218262\n",
            "Loss:0.5527620315551758\n",
            "Loss:0.5527328848838806\n",
            "Loss:0.5527037382125854\n",
            "Loss:0.5526746511459351\n",
            "Loss:0.5526455640792847\n",
            "Loss:0.5526164770126343\n",
            "Loss:0.5525873303413391\n",
            "Loss:0.5525582432746887\n",
            "Epoch: 90 | Loss: 0.5525582432746887 | Test loss: 0.5843508839607239\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7636]])), ('linear_layer.bias', tensor([0.8277]))])\n",
            "Loss:0.5525291562080383\n",
            "Loss:0.5524999499320984\n",
            "Loss:0.552470862865448\n",
            "Loss:0.5524417757987976\n",
            "Loss:0.5524126887321472\n",
            "Loss:0.5523836016654968\n",
            "Loss:0.5523544549942017\n",
            "Loss:0.5523253679275513\n",
            "Loss:0.5522962808609009\n",
            "Loss:0.5522671937942505\n",
            "Epoch: 100 | Loss: 0.5522671937942505 | Test loss: 0.584010660648346\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7635]])), ('linear_layer.bias', tensor([0.8275]))])\n",
            "Loss:0.5522379875183105\n",
            "Loss:0.5522088408470154\n",
            "Loss:0.5521798133850098\n",
            "Loss:0.5521507263183594\n",
            "Loss:0.5521215796470642\n",
            "Loss:0.5520924925804138\n",
            "Loss:0.5520633459091187\n",
            "Loss:0.552034318447113\n",
            "Loss:0.5520051717758179\n",
            "Loss:0.5519760251045227\n",
            "Epoch: 110 | Loss: 0.5519760251045227 | Test loss: 0.5836703181266785\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7634]])), ('linear_layer.bias', tensor([0.8272]))])\n",
            "Loss:0.5519469380378723\n",
            "Loss:0.5519178509712219\n",
            "Loss:0.5518887042999268\n",
            "Loss:0.5518596172332764\n",
            "Loss:0.551830530166626\n",
            "Loss:0.5518014430999756\n",
            "Loss:0.5517722964286804\n",
            "Loss:0.5517432689666748\n",
            "Loss:0.5517140626907349\n",
            "Loss:0.5516849756240845\n",
            "Epoch: 120 | Loss: 0.5516849756240845 | Test loss: 0.5833301544189453\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8269]))])\n",
            "Loss:0.5516558885574341\n",
            "Loss:0.5516268014907837\n",
            "Loss:0.5515977144241333\n",
            "Loss:0.5515685081481934\n",
            "Loss:0.5515394806861877\n",
            "Loss:0.5515103340148926\n",
            "Loss:0.5514811873435974\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|         | 6/100 [00:01<00:30,  3.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5514521598815918\n",
            "Loss:0.5514229536056519\n",
            "Loss:0.5513938665390015\n",
            "Epoch: 130 | Loss: 0.5513938665390015 | Test loss: 0.5829898715019226\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8267]))])\n",
            "Loss:0.5513647794723511\n",
            "Loss:0.5513356924057007\n",
            "Loss:0.5513066053390503\n",
            "Loss:0.5512774586677551\n",
            "Loss:0.5512484312057495\n",
            "Loss:0.5512192845344543\n",
            "Loss:0.551190197467804\n",
            "Loss:0.5511611104011536\n",
            "Loss:0.5511319041252136\n",
            "Loss:0.5511028170585632\n",
            "Epoch: 140 | Loss: 0.5511028170585632 | Test loss: 0.5826495885848999\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7632]])), ('linear_layer.bias', tensor([0.8264]))])\n",
            "Loss:0.5510736703872681\n",
            "Loss:0.5510445833206177\n",
            "Loss:0.5510154962539673\n",
            "Loss:0.5509864091873169\n",
            "Loss:0.5509573221206665\n",
            "Loss:0.5509281158447266\n",
            "Loss:0.5508991479873657\n",
            "Loss:0.5508699417114258\n",
            "Loss:0.5508407950401306\n",
            "Loss:0.550811767578125\n",
            "Epoch: 150 | Loss: 0.550811767578125 | Test loss: 0.582309365272522\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7631]])), ('linear_layer.bias', tensor([0.8262]))])\n",
            "Loss:0.5507826209068298\n",
            "Loss:0.5507535338401794\n",
            "Loss:0.5507243871688843\n",
            "Loss:0.5506953001022339\n",
            "Loss:0.5506662130355835\n",
            "Loss:0.5506370663642883\n",
            "Loss:0.5506080389022827\n",
            "Loss:0.5505788922309875\n",
            "Loss:0.5505497455596924\n",
            "Loss:0.550520658493042\n",
            "Epoch: 160 | Loss: 0.550520658493042 | Test loss: 0.581969141960144\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7630]])), ('linear_layer.bias', tensor([0.8259]))])\n",
            "Loss:0.5504915714263916\n",
            "Loss:0.5504624843597412\n",
            "Loss:0.550433337688446\n",
            "Loss:0.5504042506217957\n",
            "Loss:0.5503751635551453\n",
            "Loss:0.5503460168838501\n",
            "Loss:0.5503169298171997\n",
            "Loss:0.5502877831459045\n",
            "Loss:0.5502587556838989\n",
            "Loss:0.5502296090126038\n",
            "Epoch: 170 | Loss: 0.5502296090126038 | Test loss: 0.5816288590431213\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7629]])), ('linear_layer.bias', tensor([0.8257]))])\n",
            "Loss:0.5502004623413086\n",
            "Loss:0.550171434879303\n",
            "Loss:0.5501422882080078\n",
            "Loss:0.5501132011413574\n",
            "Loss:0.5500839948654175\n",
            "Loss:0.5500549077987671\n",
            "Loss:0.5500258207321167\n",
            "Loss:0.5499967336654663\n",
            "Loss:0.5499676465988159\n",
            "Loss:0.5499385595321655\n",
            "Epoch: 180 | Loss: 0.5499385595321655 | Test loss: 0.5812886357307434\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7628]])), ('linear_layer.bias', tensor([0.8254]))])\n",
            "Loss:0.5499094128608704\n",
            "Loss:0.54988032579422\n",
            "Loss:0.54985111951828\n",
            "Loss:0.5498220324516296\n",
            "Loss:0.5497929453849792\n",
            "Loss:0.5497637987136841\n",
            "Loss:0.5497347116470337\n",
            "Loss:0.5497056245803833\n",
            "Loss:0.5496765375137329\n",
            "Loss:0.5496474504470825\n",
            "Epoch: 190 | Loss: 0.5496474504470825 | Test loss: 0.5809482932090759\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7627]])), ('linear_layer.bias', tensor([0.8252]))])\n",
            "Loss:0.5496183633804321\n",
            "Loss:0.5495892763137817\n",
            "Loss:0.5495600700378418\n",
            "Loss:0.5495309829711914\n",
            "Loss:0.549501895904541\n",
            "Loss:0.5494727492332458\n",
            "Loss:0.5494436621665955\n",
            "Loss:0.5494145154953003\n",
            "Loss:0.5493854880332947\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5874064564704895\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551430583000183\n",
            "Loss:0.5551081895828247\n",
            "Loss:0.5550732612609863\n",
            "Loss:0.5550383925437927\n",
            "Loss:0.5550035238265991\n",
            "Loss:0.5549686551094055\n",
            "Loss:0.5549337863922119\n",
            "Loss:0.5548989176750183\n",
            "Loss:0.5548640489578247\n",
            "Loss:0.5548291206359863\n",
            "Epoch: 10 | Loss: 0.5548291206359863 | Test loss: 0.5869985818862915\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.554794192314148\n",
            "Loss:0.5547593235969543\n",
            "Loss:0.5547244548797607\n",
            "Loss:0.5546895861625671\n",
            "Loss:0.5546547770500183\n",
            "Loss:0.5546198487281799\n",
            "Loss:0.5545849204063416\n",
            "Loss:0.554550051689148\n",
            "Loss:0.5545151829719543\n",
            "Loss:0.554480254650116\n",
            "Epoch: 20 | Loss: 0.554480254650116 | Test loss: 0.5865907073020935\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8294]))])\n",
            "Loss:0.5544453859329224\n",
            "Loss:0.5544105768203735\n",
            "Loss:0.5543756484985352\n",
            "Loss:0.5543407797813416\n",
            "Loss:0.5543058514595032\n",
            "Loss:0.5542710423469543\n",
            "Loss:0.5542360544204712\n",
            "Loss:0.5542012453079224\n",
            "Loss:0.554166316986084\n",
            "Loss:0.5541314482688904\n",
            "Epoch: 30 | Loss: 0.5541314482688904 | Test loss: 0.5861829519271851\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8291]))])\n",
            "Loss:0.5540965795516968\n",
            "Loss:0.5540617108345032\n",
            "Loss:0.5540268421173096\n",
            "Loss:0.5539919137954712\n",
            "Loss:0.5539571046829224\n",
            "Loss:0.553922176361084\n",
            "Loss:0.5538873076438904\n",
            "Loss:0.5538524389266968\n",
            "Loss:0.5538175702095032\n",
            "Loss:0.55378258228302\n",
            "Epoch: 40 | Loss: 0.55378258228302 | Test loss: 0.5857750773429871\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7641]])), ('linear_layer.bias', tensor([0.8288]))])\n",
            "Loss:0.5537477731704712\n",
            "Loss:0.5537129044532776\n",
            "Loss:0.553678035736084\n",
            "Loss:0.5536431074142456\n",
            "Loss:0.553608238697052\n",
            "Loss:0.5535733699798584\n",
            "Loss:0.55353844165802\n",
            "Loss:0.5535036325454712\n",
            "Loss:0.5534687042236328\n",
            "Loss:0.553433895111084\n",
            "Epoch: 50 | Loss: 0.553433895111084 | Test loss: 0.5853672623634338\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7639]])), ('linear_layer.bias', tensor([0.8285]))])\n",
            "Loss:0.5533989071846008\n",
            "Loss:0.553364098072052\n",
            "Loss:0.5533291101455688\n",
            "Loss:0.55329430103302\n",
            "Loss:0.5532594919204712\n",
            "Loss:0.5532246232032776\n",
            "Loss:0.5531896948814392\n",
            "Loss:0.5531548261642456\n",
            "Loss:0.5531198382377625\n",
            "Loss:0.5530850291252136\n",
            "Epoch: 60 | Loss: 0.5530850291252136 | Test loss: 0.5849593877792358\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7638]])), ('linear_layer.bias', tensor([0.8282]))])\n",
            "Loss:0.5530501008033752\n",
            "Loss:0.5530152320861816\n",
            "Loss:0.552980363368988\n",
            "Loss:0.5529454946517944\n",
            "Loss:0.5529106855392456\n",
            "Loss:0.5528756976127625\n",
            "Loss:0.5528408885002136\n",
            "Loss:0.5528059601783752\n",
            "Loss:0.5527711510658264\n",
            "Loss:0.5527362823486328\n",
            "Epoch: 70 | Loss: 0.5527362823486328 | Test loss: 0.5845516920089722\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7637]])), ('linear_layer.bias', tensor([0.8279]))])\n",
            "Loss:0.5527013540267944\n",
            "Loss:0.5526664853096008\n",
            "Loss:0.5526315569877625\n",
            "Loss:0.5525966882705688\n",
            "Loss:0.5525618195533752\n",
            "Loss:0.5525269508361816\n",
            "Loss:0.5524920225143433\n",
            "Loss:0.5524570941925049\n",
            "Loss:0.552422285079956\n",
            "Loss:0.5523874163627625\n",
            "Epoch: 80 | Loss: 0.5523874163627625 | Test loss: 0.5841437578201294\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7636]])), ('linear_layer.bias', tensor([0.8276]))])\n",
            "Loss:0.5523525476455688\n",
            "Loss:0.5523176193237305\n",
            "Loss:0.5522827506065369\n",
            "Loss:0.5522478818893433\n",
            "Loss:0.5522129535675049\n",
            "Loss:0.5521780848503113\n",
            "Loss:0.5521432161331177\n",
            "Loss:0.5521082878112793\n",
            "Loss:0.5520733594894409\n",
            "Loss:0.5520385503768921\n",
            "Epoch: 90 | Loss: 0.5520385503768921 | Test loss: 0.5837360620498657\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7635]])), ('linear_layer.bias', tensor([0.8273]))])\n",
            "Loss:0.5520037412643433\n",
            "Loss:0.5519688129425049\n",
            "Loss:0.5519338846206665\n",
            "Loss:0.5518990755081177\n",
            "Loss:0.5518641471862793\n",
            "Loss:0.5518292188644409\n",
            "Loss:0.5517944097518921\n",
            "Loss:0.5517594814300537\n",
            "Loss:0.5517246127128601\n",
            "Loss:0.5516897439956665\n",
            "Epoch: 100 | Loss: 0.5516897439956665 | Test loss: 0.583328127861023\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8269]))])\n",
            "Loss:0.5516548156738281\n",
            "Loss:0.5516200065612793\n",
            "Loss:0.5515850782394409\n",
            "Loss:0.5515502095222473\n",
            "Loss:0.5515153408050537\n",
            "Loss:0.5514804124832153\n",
            "Loss:0.5514456033706665\n",
            "Loss:0.5514106750488281\n",
            "Loss:0.5513757467269897\n",
            "Loss:0.5513409376144409\n",
            "Epoch: 110 | Loss: 0.5513409376144409 | Test loss: 0.5829203724861145\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7632]])), ('linear_layer.bias', tensor([0.8266]))])\n",
            "Loss:0.5513060092926025\n",
            "Loss:0.5512712001800537\n",
            "Loss:0.5512362718582153\n",
            "Loss:0.551201343536377\n",
            "Loss:0.5511665344238281\n",
            "Loss:0.5511316061019897\n",
            "Loss:0.5510967373847961\n",
            "Loss:0.5510618686676025\n",
            "Loss:0.5510269999504089\n",
            "Loss:0.5509921312332153\n",
            "Epoch: 120 | Loss: 0.5509921312332153 | Test loss: 0.5825124979019165\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7631]])), ('linear_layer.bias', tensor([0.8263]))])\n",
            "Loss:0.5509572625160217\n",
            "Loss:0.5509222745895386\n",
            "Loss:0.5508874654769897\n",
            "Loss:0.5508525967597961\n",
            "Loss:0.5508176684379578\n",
            "Loss:0.5507827997207642\n",
            "Loss:0.5507478713989258\n",
            "Loss:0.5507130026817322\n",
            "Loss:0.5506781339645386\n",
            "Loss:0.5506433248519897\n",
            "Epoch: 130 | Loss: 0.5506433248519897 | Test loss: 0.5821046233177185\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7630]])), ('linear_layer.bias', tensor([0.8260]))])\n",
            "Loss:0.5506083965301514\n",
            "Loss:0.5505735278129578\n",
            "Loss:0.5505386590957642\n",
            "Loss:0.5505037903785706\n",
            "Loss:0.550468921661377\n",
            "Loss:0.5504339933395386\n",
            "Loss:0.550399124622345\n",
            "Loss:0.5503642559051514\n",
            "Loss:0.550329327583313\n",
            "Loss:0.5502945184707642\n",
            "Epoch: 140 | Loss: 0.5502945184707642 | Test loss: 0.5816968679428101\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7629]])), ('linear_layer.bias', tensor([0.8257]))])\n",
            "Loss:0.5502595901489258\n",
            "Loss:0.5502247214317322\n",
            "Loss:0.5501898527145386\n",
            "Loss:0.550154983997345\n",
            "Loss:0.5501201152801514\n",
            "Loss:0.550085186958313\n",
            "Loss:0.5500502586364746\n",
            "Loss:0.5500154495239258\n",
            "Loss:0.5499805212020874\n",
            "Loss:0.5499456524848938\n",
            "Epoch: 150 | Loss: 0.5499456524848938 | Test loss: 0.5812890529632568\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7628]])), ('linear_layer.bias', tensor([0.8254]))])\n",
            "Loss:0.549910843372345\n",
            "Loss:0.5498759150505066\n",
            "Loss:0.549841046333313\n",
            "Loss:0.5498061180114746\n",
            "Loss:0.5497711896896362\n",
            "Loss:0.5497363805770874\n",
            "Loss:0.5497015118598938\n",
            "Loss:0.5496666431427002\n",
            "Loss:0.5496317148208618\n",
            "Loss:0.549596905708313\n",
            "Epoch: 160 | Loss: 0.549596905708313 | Test loss: 0.5808811783790588\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8251]))])\n",
            "Loss:0.5495619773864746\n",
            "Loss:0.5495270490646362\n",
            "Loss:0.5494922399520874\n",
            "Loss:0.5494572520256042\n",
            "Loss:0.5494224429130554\n",
            "Loss:0.5493875741958618\n",
            "Loss:0.5493527054786682\n",
            "Loss:0.5493178367614746\n",
            "Loss:0.5492829084396362\n",
            "Loss:0.5492480397224426\n",
            "Epoch: 170 | Loss: 0.5492480397224426 | Test loss: 0.5804733633995056\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7625]])), ('linear_layer.bias', tensor([0.8248]))])\n",
            "Loss:0.549213171005249\n",
            "Loss:0.5491782426834106\n",
            "Loss:0.5491433143615723\n",
            "Loss:0.5491085052490234\n",
            "Loss:0.5490735769271851\n",
            "Loss:0.5490387678146362\n",
            "Loss:0.5490038394927979\n",
            "Loss:0.5489689707756042\n",
            "Loss:0.5489340424537659\n",
            "Loss:0.5488991737365723\n",
            "Epoch: 180 | Loss: 0.5488991737365723 | Test loss: 0.5800654888153076\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7624]])), ('linear_layer.bias', tensor([0.8245]))])\n",
            "Loss:0.5488643646240234\n",
            "Loss:0.5488294363021851\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|         | 7/100 [00:02<00:30,  3.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5487945675849915\n",
            "Loss:0.5487596988677979\n",
            "Loss:0.5487247705459595\n",
            "Loss:0.5486899614334106\n",
            "Loss:0.5486549735069275\n",
            "Loss:0.5486201047897339\n",
            "Loss:0.5485852956771851\n",
            "Loss:0.5485504269599915\n",
            "Epoch: 190 | Loss: 0.5485504269599915 | Test loss: 0.5796577334403992\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7623]])), ('linear_layer.bias', tensor([0.8242]))])\n",
            "Loss:0.5485154986381531\n",
            "Loss:0.5484806299209595\n",
            "Loss:0.5484457015991211\n",
            "Loss:0.5484108328819275\n",
            "Loss:0.5483759045600891\n",
            "Loss:0.5483410954475403\n",
            "Loss:0.5483061671257019\n",
            "Loss:0.5482712984085083\n",
            "Loss:0.5482364296913147\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5873996615409851\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551372170448303\n",
            "Loss:0.5550965070724487\n",
            "Loss:0.5550557374954224\n",
            "Loss:0.5550150871276855\n",
            "Loss:0.5549743175506592\n",
            "Loss:0.5549336671829224\n",
            "Loss:0.5548929572105408\n",
            "Loss:0.5548521876335144\n",
            "Loss:0.5548114776611328\n",
            "Loss:0.5547707676887512\n",
            "Epoch: 10 | Loss: 0.5547707676887512 | Test loss: 0.5869235396385193\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5547300577163696\n",
            "Loss:0.5546892881393433\n",
            "Loss:0.5546486377716064\n",
            "Loss:0.5546079277992249\n",
            "Loss:0.5545672178268433\n",
            "Loss:0.5545264482498169\n",
            "Loss:0.5544857978820801\n",
            "Loss:0.5544450283050537\n",
            "Loss:0.5544043779373169\n",
            "Loss:0.5543636083602905\n",
            "Epoch: 20 | Loss: 0.5543636083602905 | Test loss: 0.5864475965499878\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8293]))])\n",
            "Loss:0.5543228983879089\n",
            "Loss:0.5542822480201721\n",
            "Loss:0.5542414784431458\n",
            "Loss:0.5542007684707642\n",
            "Loss:0.5541599988937378\n",
            "Loss:0.554119348526001\n",
            "Loss:0.5540785789489746\n",
            "Loss:0.5540379285812378\n",
            "Loss:0.5539971590042114\n",
            "Loss:0.5539565086364746\n",
            "Epoch: 30 | Loss: 0.5539565086364746 | Test loss: 0.5859715938568115\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7641]])), ('linear_layer.bias', tensor([0.8289]))])\n",
            "Loss:0.5539156794548035\n",
            "Loss:0.5538750886917114\n",
            "Loss:0.5538343191146851\n",
            "Loss:0.5537936091423035\n",
            "Loss:0.5537528991699219\n",
            "Loss:0.5537122488021851\n",
            "Loss:0.5536714792251587\n",
            "Loss:0.5536307096481323\n",
            "Loss:0.5535899996757507\n",
            "Loss:0.5535493493080139\n",
            "Epoch: 40 | Loss: 0.5535493493080139 | Test loss: 0.5854955911636353\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7640]])), ('linear_layer.bias', tensor([0.8286]))])\n",
            "Loss:0.5535086393356323\n",
            "Loss:0.553467869758606\n",
            "Loss:0.5534271001815796\n",
            "Loss:0.5533864498138428\n",
            "Loss:0.5533457398414612\n",
            "Loss:0.5533049702644348\n",
            "Loss:0.5532642602920532\n",
            "Loss:0.5532235503196716\n",
            "Loss:0.5531829595565796\n",
            "Loss:0.5531421899795532\n",
            "Epoch: 50 | Loss: 0.5531421899795532 | Test loss: 0.5850196480751038\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7638]])), ('linear_layer.bias', tensor([0.8282]))])\n",
            "Loss:0.5531014204025269\n",
            "Loss:0.5530607104301453\n",
            "Loss:0.5530200004577637\n",
            "Loss:0.5529792904853821\n",
            "Loss:0.5529385209083557\n",
            "Loss:0.5528978705406189\n",
            "Loss:0.5528571605682373\n",
            "Loss:0.5528165102005005\n",
            "Loss:0.5527757406234741\n",
            "Loss:0.5527349710464478\n",
            "Epoch: 60 | Loss: 0.5527349710464478 | Test loss: 0.5845435857772827\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7637]])), ('linear_layer.bias', tensor([0.8279]))])\n",
            "Loss:0.5526943206787109\n",
            "Loss:0.5526536107063293\n",
            "Loss:0.5526129007339478\n",
            "Loss:0.5525721311569214\n",
            "Loss:0.5525314211845398\n",
            "Loss:0.5524906516075134\n",
            "Loss:0.5524500608444214\n",
            "Loss:0.552409291267395\n",
            "Loss:0.5523685812950134\n",
            "Loss:0.5523278117179871\n",
            "Epoch: 70 | Loss: 0.5523278117179871 | Test loss: 0.5840675830841064\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7636]])), ('linear_layer.bias', tensor([0.8275]))])\n",
            "Loss:0.5522871017456055\n",
            "Loss:0.5522464513778687\n",
            "Loss:0.5522058010101318\n",
            "Loss:0.5521649718284607\n",
            "Loss:0.5521242022514343\n",
            "Loss:0.5520836114883423\n",
            "Loss:0.5520427823066711\n",
            "Loss:0.5520021319389343\n",
            "Loss:0.551961362361908\n",
            "Loss:0.5519207119941711\n",
            "Epoch: 80 | Loss: 0.5519207119941711 | Test loss: 0.5835916996002197\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7634]])), ('linear_layer.bias', tensor([0.8271]))])\n",
            "Loss:0.5518800020217896\n",
            "Loss:0.5518392324447632\n",
            "Loss:0.5517985224723816\n",
            "Loss:0.5517579317092896\n",
            "Loss:0.5517171025276184\n",
            "Loss:0.5516763925552368\n",
            "Loss:0.5516356825828552\n",
            "Loss:0.5515950322151184\n",
            "Loss:0.5515543222427368\n",
            "Loss:0.5515135526657104\n",
            "Epoch: 90 | Loss: 0.5515135526657104 | Test loss: 0.5831155776977539\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8268]))])\n",
            "Loss:0.5514728426933289\n",
            "Loss:0.5514320731163025\n",
            "Loss:0.5513914227485657\n",
            "Loss:0.5513507127761841\n",
            "Loss:0.5513100028038025\n",
            "Loss:0.5512692928314209\n",
            "Loss:0.5512285232543945\n",
            "Loss:0.5511877536773682\n",
            "Loss:0.5511471033096313\n",
            "Loss:0.5511064529418945\n",
            "Epoch: 100 | Loss: 0.5511064529418945 | Test loss: 0.5826395750045776\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7631]])), ('linear_layer.bias', tensor([0.8264]))])\n",
            "Loss:0.5510656833648682\n",
            "Loss:0.5510249733924866\n",
            "Loss:0.550984263420105\n",
            "Loss:0.5509435534477234\n",
            "Loss:0.550902783870697\n",
            "Loss:0.5508621335029602\n",
            "Loss:0.5508214235305786\n",
            "Loss:0.5507806539535522\n",
            "Loss:0.5507399439811707\n",
            "Loss:0.5506992340087891\n",
            "Epoch: 110 | Loss: 0.5506992340087891 | Test loss: 0.5821636915206909\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7630]])), ('linear_layer.bias', tensor([0.8261]))])\n",
            "Loss:0.5506585240364075\n",
            "Loss:0.5506178140640259\n",
            "Loss:0.5505771040916443\n",
            "Loss:0.5505363941192627\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|         | 8/100 [00:02<00:29,  3.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5504956841468811\n",
            "Loss:0.5504549145698547\n",
            "Loss:0.5504142045974731\n",
            "Loss:0.5503734946250916\n",
            "Loss:0.5503328442573547\n",
            "Loss:0.5502920150756836\n",
            "Epoch: 120 | Loss: 0.5502920150756836 | Test loss: 0.5816876888275146\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7629]])), ('linear_layer.bias', tensor([0.8257]))])\n",
            "Loss:0.5502513647079468\n",
            "Loss:0.5502106547355652\n",
            "Loss:0.5501700043678284\n",
            "Loss:0.5501291751861572\n",
            "Loss:0.5500884652137756\n",
            "Loss:0.5500478148460388\n",
            "Loss:0.5500071048736572\n",
            "Loss:0.5499663949012756\n",
            "Loss:0.549925684928894\n",
            "Loss:0.5498849153518677\n",
            "Epoch: 130 | Loss: 0.5498849153518677 | Test loss: 0.5812116861343384\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7627]])), ('linear_layer.bias', tensor([0.8254]))])\n",
            "Loss:0.5498441457748413\n",
            "Loss:0.5498035550117493\n",
            "Loss:0.5497627854347229\n",
            "Loss:0.5497220754623413\n",
            "Loss:0.5496813654899597\n",
            "Loss:0.5496406555175781\n",
            "Loss:0.5495999455451965\n",
            "Loss:0.5495592355728149\n",
            "Loss:0.5495184659957886\n",
            "Loss:0.549477756023407\n",
            "Epoch: 140 | Loss: 0.549477756023407 | Test loss: 0.5807356834411621\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8250]))])\n",
            "Loss:0.5494371056556702\n",
            "Loss:0.5493963360786438\n",
            "Loss:0.5493556261062622\n",
            "Loss:0.5493149161338806\n",
            "Loss:0.549274206161499\n",
            "Loss:0.5492334961891174\n",
            "Loss:0.5491927862167358\n",
            "Loss:0.5491520166397095\n",
            "Loss:0.5491113662719727\n",
            "Loss:0.5490706562995911\n",
            "Epoch: 150 | Loss: 0.5490706562995911 | Test loss: 0.5802596807479858\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7625]])), ('linear_layer.bias', tensor([0.8247]))])\n",
            "Loss:0.5490299463272095\n",
            "Loss:0.5489891767501831\n",
            "Loss:0.5489484667778015\n",
            "Loss:0.5489077568054199\n",
            "Loss:0.5488671064376831\n",
            "Loss:0.5488263368606567\n",
            "Loss:0.5487856268882751\n",
            "Loss:0.5487448573112488\n",
            "Loss:0.5487040877342224\n",
            "Loss:0.5486634969711304\n",
            "Epoch: 160 | Loss: 0.5486634969711304 | Test loss: 0.5797836780548096\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7623]])), ('linear_layer.bias', tensor([0.8243]))])\n",
            "Loss:0.548622727394104\n",
            "Loss:0.5485820770263672\n",
            "Loss:0.5485413074493408\n",
            "Loss:0.548500657081604\n",
            "Loss:0.5484598875045776\n",
            "Loss:0.548419177532196\n",
            "Loss:0.5483784675598145\n",
            "Loss:0.5483378171920776\n",
            "Loss:0.5482970476150513\n",
            "Loss:0.5482562780380249\n",
            "Epoch: 170 | Loss: 0.5482562780380249 | Test loss: 0.5793076753616333\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7622]])), ('linear_layer.bias', tensor([0.8240]))])\n",
            "Loss:0.5482156276702881\n",
            "Loss:0.5481748580932617\n",
            "Loss:0.5481342077255249\n",
            "Loss:0.5480934381484985\n",
            "Loss:0.5480527281761169\n",
            "Loss:0.5480120182037354\n",
            "Loss:0.5479713678359985\n",
            "Loss:0.5479305982589722\n",
            "Loss:0.5478898882865906\n",
            "Loss:0.547849178314209\n",
            "Epoch: 180 | Loss: 0.547849178314209 | Test loss: 0.578831672668457\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7620]])), ('linear_layer.bias', tensor([0.8236]))])\n",
            "Loss:0.5478085279464722\n",
            "Loss:0.5477677583694458\n",
            "Loss:0.5477269887924194\n",
            "Loss:0.5476862788200378\n",
            "Loss:0.5476455688476562\n",
            "Loss:0.5476049184799194\n",
            "Loss:0.5475641489028931\n",
            "Loss:0.5475234985351562\n",
            "Loss:0.5474826693534851\n",
            "Loss:0.5474420189857483\n",
            "Epoch: 190 | Loss: 0.5474420189857483 | Test loss: 0.5783556699752808\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7619]])), ('linear_layer.bias', tensor([0.8233]))])\n",
            "Loss:0.5474013090133667\n",
            "Loss:0.5473605990409851\n",
            "Loss:0.5473198890686035\n",
            "Loss:0.5472791790962219\n",
            "Loss:0.5472384095191956\n",
            "Loss:0.547197699546814\n",
            "Loss:0.5471569895744324\n",
            "Loss:0.5471163392066956\n",
            "Loss:0.547075629234314\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5873928070068359\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551314353942871\n",
            "Loss:0.5550848245620728\n",
            "Loss:0.5550382733345032\n",
            "Loss:0.5549916625022888\n",
            "Loss:0.554945170879364\n",
            "Loss:0.5548986196517944\n",
            "Loss:0.5548520684242249\n",
            "Loss:0.5548055171966553\n",
            "Loss:0.5547589659690857\n",
            "Loss:0.5547124147415161\n",
            "Epoch: 10 | Loss: 0.5547124147415161 | Test loss: 0.5868486166000366\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5546659231185913\n",
            "Loss:0.5546193718910217\n",
            "Loss:0.5545728206634521\n",
            "Loss:0.5545262098312378\n",
            "Loss:0.554479718208313\n",
            "Loss:0.5544331073760986\n",
            "Loss:0.554386556148529\n",
            "Loss:0.5543400049209595\n",
            "Loss:0.5542935132980347\n",
            "Loss:0.5542469620704651\n",
            "Epoch: 20 | Loss: 0.5542469620704651 | Test loss: 0.5863044261932373\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8292]))])\n",
            "Loss:0.5542004108428955\n",
            "Loss:0.5541539192199707\n",
            "Loss:0.5541073083877563\n",
            "Loss:0.5540608167648315\n",
            "Loss:0.5540142059326172\n",
            "Loss:0.5539677143096924\n",
            "Loss:0.553921103477478\n",
            "Loss:0.5538745522499084\n",
            "Loss:0.5538280606269836\n",
            "Loss:0.5537814497947693\n",
            "Epoch: 30 | Loss: 0.5537814497947693 | Test loss: 0.585760235786438\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7641]])), ('linear_layer.bias', tensor([0.8288]))])\n",
            "Loss:0.5537348985671997\n",
            "Loss:0.5536883473396301\n",
            "Loss:0.5536417961120605\n",
            "Loss:0.553595244884491\n",
            "Loss:0.5535486936569214\n",
            "Loss:0.5535022020339966\n",
            "Loss:0.5534555912017822\n",
            "Loss:0.5534090995788574\n",
            "Loss:0.5533624887466431\n",
            "Loss:0.5533159971237183\n",
            "Epoch: 40 | Loss: 0.5533159971237183 | Test loss: 0.5852161645889282\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7639]])), ('linear_layer.bias', tensor([0.8284]))])\n",
            "Loss:0.5532694458961487\n",
            "Loss:0.5532228350639343\n",
            "Loss:0.5531762838363647\n",
            "Loss:0.5531297922134399\n",
            "Loss:0.5530832409858704\n",
            "Loss:0.5530366897583008\n",
            "Loss:0.5529901385307312\n",
            "Loss:0.5529435873031616\n",
            "Loss:0.5528970956802368\n",
            "Loss:0.5528504848480225\n",
            "Epoch: 50 | Loss: 0.5528504848480225 | Test loss: 0.5846719145774841\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7637]])), ('linear_layer.bias', tensor([0.8279]))])\n",
            "Loss:0.5528039336204529\n",
            "Loss:0.5527573823928833\n",
            "Loss:0.5527108311653137\n",
            "Loss:0.5526642799377441\n",
            "Loss:0.5526177287101746\n",
            "Loss:0.552571177482605\n",
            "Loss:0.5525246858596802\n",
            "Loss:0.5524781346321106\n",
            "Loss:0.552431583404541\n",
            "Loss:0.5523849725723267\n",
            "Epoch: 60 | Loss: 0.5523849725723267 | Test loss: 0.5841277837753296\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7636]])), ('linear_layer.bias', tensor([0.8275]))])\n",
            "Loss:0.5523384809494019\n",
            "Loss:0.5522918701171875\n",
            "Loss:0.5522453784942627\n",
            "Loss:0.5521987676620483\n",
            "Loss:0.5521522760391235\n",
            "Loss:0.552105724811554\n",
            "Loss:0.5520591735839844\n",
            "Loss:0.55201256275177\n",
            "Loss:0.5519660711288452\n",
            "Loss:0.5519195795059204\n",
            "Epoch: 70 | Loss: 0.5519195795059204 | Test loss: 0.583583652973175\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7634]])), ('linear_layer.bias', tensor([0.8271]))])\n",
            "Loss:0.5518730282783508\n",
            "Loss:0.5518264174461365\n",
            "Loss:0.5517798662185669\n",
            "Loss:0.5517333149909973\n",
            "Loss:0.5516867637634277\n",
            "Loss:0.5516401529312134\n",
            "Loss:0.5515936613082886\n",
            "Loss:0.551547110080719\n",
            "Loss:0.5515006184577942\n",
            "Loss:0.5514540672302246\n",
            "Epoch: 80 | Loss: 0.5514540672302246 | Test loss: 0.5830394625663757\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8267]))])\n",
            "Loss:0.5514074563980103\n",
            "Loss:0.5513609647750854\n",
            "Loss:0.5513144135475159\n",
            "Loss:0.5512678027153015\n",
            "Loss:0.5512212514877319\n",
            "Loss:0.5511747598648071\n",
            "Loss:0.5511281490325928\n",
            "Loss:0.5510815978050232\n",
            "Loss:0.5510351061820984\n",
            "Loss:0.5509885549545288\n",
            "Epoch: 90 | Loss: 0.5509885549545288 | Test loss: 0.5824953317642212\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7631]])), ('linear_layer.bias', tensor([0.8263]))])\n",
            "Loss:0.550942063331604\n",
            "Loss:0.5508954524993896\n",
            "Loss:0.5508489608764648\n",
            "Loss:0.5508023500442505\n",
            "Loss:0.5507557988166809\n",
            "Loss:0.5507091879844666\n",
            "Loss:0.550662636756897\n",
            "Loss:0.5506161451339722\n",
            "Loss:0.5505695939064026\n",
            "Loss:0.550523042678833\n",
            "Epoch: 100 | Loss: 0.550523042678833 | Test loss: 0.5819510817527771\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7629]])), ('linear_layer.bias', tensor([0.8259]))])\n",
            "Loss:0.5504765510559082\n",
            "Loss:0.5504299998283386\n",
            "Loss:0.550383448600769\n",
            "Loss:0.5503368973731995\n",
            "Loss:0.5502903461456299\n",
            "Loss:0.5502437353134155\n",
            "Loss:0.550197184085846\n",
            "Loss:0.5501506328582764\n",
            "Loss:0.5501040816307068\n",
            "Loss:0.5500575304031372\n",
            "Epoch: 110 | Loss: 0.5500575304031372 | Test loss: 0.5814069509506226\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7628]])), ('linear_layer.bias', tensor([0.8255]))])\n",
            "Loss:0.5500109791755676\n",
            "Loss:0.5499644875526428\n",
            "Loss:0.5499178767204285\n",
            "Loss:0.5498713254928589\n",
            "Loss:0.5498248338699341\n",
            "Loss:0.5497783422470093\n",
            "Loss:0.5497317314147949\n",
            "Loss:0.5496852397918701\n",
            "Loss:0.5496386289596558\n",
            "Loss:0.5495920777320862\n",
            "Epoch: 120 | Loss: 0.5495920777320862 | Test loss: 0.580862820148468\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8251]))])\n",
            "Loss:0.5495454668998718\n",
            "Loss:0.5494989156723022\n",
            "Loss:0.5494524240493774\n",
            "Loss:0.5494059324264526\n",
            "Loss:0.5493593215942383\n",
            "Loss:0.5493127703666687\n",
            "Loss:0.5492662191390991\n",
            "Loss:0.5492197275161743\n",
            "Loss:0.5491731762886047\n",
            "Loss:0.5491266250610352\n",
            "Epoch: 130 | Loss: 0.5491266250610352 | Test loss: 0.5803185701370239\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7625]])), ('linear_layer.bias', tensor([0.8247]))])\n",
            "Loss:0.5490800142288208\n",
            "Loss:0.549033522605896\n",
            "Loss:0.5489869117736816\n",
            "Loss:0.5489403605461121\n",
            "Loss:0.5488938093185425\n",
            "Loss:0.5488473176956177\n",
            "Loss:0.5488007664680481\n",
            "Loss:0.5487542748451233\n",
            "Loss:0.5487076640129089\n",
            "Loss:0.5486611127853394\n",
            "Epoch: 140 | Loss: 0.5486611127853394 | Test loss: 0.5797744989395142\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7623]])), ('linear_layer.bias', tensor([0.8243]))])\n",
            "Loss:0.548614501953125\n",
            "Loss:0.5485680103302002\n",
            "Loss:0.5485213994979858\n",
            "Loss:0.548474907875061\n",
            "Loss:0.5484283566474915\n",
            "Loss:0.5483818054199219\n",
            "Loss:0.5483352541923523\n",
            "Loss:0.5482887029647827\n",
            "Loss:0.5482422113418579\n",
            "Loss:0.5481956601142883\n",
            "Epoch: 150 | Loss: 0.5481956601142883 | Test loss: 0.5792302489280701\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7622]])), ('linear_layer.bias', tensor([0.8239]))])\n",
            "Loss:0.548149049282074\n",
            "Loss:0.5481024980545044\n",
            "Loss:0.5480559468269348\n",
            "Loss:0.5480093955993652\n",
            "Loss:0.5479627847671509\n",
            "Loss:0.5479162931442261\n",
            "Loss:0.5478697419166565\n",
            "Loss:0.5478231906890869\n",
            "Loss:0.5477765798568726\n",
            "Loss:0.5477301478385925\n",
            "Epoch: 160 | Loss: 0.5477301478385925 | Test loss: 0.5786861181259155\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7620]])), ('linear_layer.bias', tensor([0.8235]))])\n",
            "Loss:0.5476835370063782\n",
            "Loss:0.5476370453834534\n",
            "Loss:0.547590434551239\n",
            "Loss:0.5475438833236694\n",
            "Loss:0.5474973917007446\n",
            "Loss:0.5474507808685303\n",
            "Loss:0.5474042296409607\n",
            "Loss:0.5473576784133911\n",
            "Loss:0.5473111867904663\n",
            "Loss:0.5472646951675415\n",
            "Epoch: 170 | Loss: 0.5472646951675415 | Test loss: 0.5781420469284058\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7618]])), ('linear_layer.bias', tensor([0.8231]))])\n",
            "Loss:0.5472180247306824\n",
            "Loss:0.5471714735031128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|         | 9/100 [00:02<00:29,  3.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5471250414848328\n",
            "Loss:0.5470784902572632\n",
            "Loss:0.5470318794250488\n",
            "Loss:0.5469852685928345\n",
            "Loss:0.5469387769699097\n",
            "Loss:0.5468922257423401\n",
            "Loss:0.5468456745147705\n",
            "Loss:0.5467991232872009\n",
            "Epoch: 180 | Loss: 0.5467991232872009 | Test loss: 0.5775977373123169\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7617]])), ('linear_layer.bias', tensor([0.8227]))])\n",
            "Loss:0.5467525720596313\n",
            "Loss:0.5467060208320618\n",
            "Loss:0.5466595888137817\n",
            "Loss:0.5466129779815674\n",
            "Loss:0.5465664267539978\n",
            "Loss:0.5465198159217834\n",
            "Loss:0.5464733242988586\n",
            "Loss:0.5464267134666443\n",
            "Loss:0.5463802218437195\n",
            "Loss:0.5463336110115051\n",
            "Epoch: 190 | Loss: 0.5463336110115051 | Test loss: 0.5770536661148071\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7615]])), ('linear_layer.bias', tensor([0.8223]))])\n",
            "Loss:0.5462871193885803\n",
            "Loss:0.546240508556366\n",
            "Loss:0.5461939573287964\n",
            "Loss:0.5461474657058716\n",
            "Loss:0.5461009740829468\n",
            "Loss:0.5460543632507324\n",
            "Loss:0.5460078716278076\n",
            "Loss:0.5459612607955933\n",
            "Loss:0.5459147095680237\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5873860120773315\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551255345344543\n",
            "Loss:0.5550731420516968\n",
            "Loss:0.5550207495689392\n",
            "Loss:0.5549683570861816\n",
            "Loss:0.5549160838127136\n",
            "Loss:0.5548636317253113\n",
            "Loss:0.5548112392425537\n",
            "Loss:0.5547588467597961\n",
            "Loss:0.5547064542770386\n",
            "Loss:0.554654061794281\n",
            "Epoch: 10 | Loss: 0.554654061794281 | Test loss: 0.5867735743522644\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8295]))])\n",
            "Loss:0.5546017289161682\n",
            "Loss:0.5545493364334106\n",
            "Loss:0.5544968843460083\n",
            "Loss:0.5544446110725403\n",
            "Loss:0.5543921589851379\n",
            "Loss:0.5543397665023804\n",
            "Loss:0.5542874336242676\n",
            "Loss:0.55423504114151\n",
            "Loss:0.5541826486587524\n",
            "Loss:0.5541302561759949\n",
            "Epoch: 20 | Loss: 0.5541302561759949 | Test loss: 0.5861613154411316\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8291]))])\n",
            "Loss:0.5540779232978821\n",
            "Loss:0.5540255308151245\n",
            "Loss:0.5539731383323669\n",
            "Loss:0.5539208054542542\n",
            "Loss:0.5538684129714966\n",
            "Loss:0.5538159608840942\n",
            "Loss:0.5537636876106262\n",
            "Loss:0.5537112355232239\n",
            "Loss:0.5536588430404663\n",
            "Loss:0.5536065101623535\n",
            "Epoch: 30 | Loss: 0.5536065101623535 | Test loss: 0.585548996925354\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7640]])), ('linear_layer.bias', tensor([0.8286]))])\n",
            "Loss:0.553554117679596\n",
            "Loss:0.5535017251968384\n",
            "Loss:0.553449273109436\n",
            "Loss:0.5533968806266785\n",
            "Loss:0.5533446073532104\n",
            "Loss:0.5532921552658081\n",
            "Loss:0.5532398223876953\n",
            "Loss:0.5531874299049377\n",
            "Loss:0.5531350374221802\n",
            "Loss:0.5530825853347778\n",
            "Epoch: 40 | Loss: 0.5530825853347778 | Test loss: 0.5849366188049316\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7638]])), ('linear_layer.bias', tensor([0.8281]))])\n",
            "Loss:0.553030252456665\n",
            "Loss:0.5529779195785522\n",
            "Loss:0.5529254674911499\n",
            "Loss:0.5528731346130371\n",
            "Loss:0.5528207421302795\n",
            "Loss:0.552768349647522\n",
            "Loss:0.5527160167694092\n",
            "Loss:0.5526635646820068\n",
            "Loss:0.552611231803894\n",
            "Loss:0.5525587797164917\n",
            "Epoch: 50 | Loss: 0.5525587797164917 | Test loss: 0.5843242406845093\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7636]])), ('linear_layer.bias', tensor([0.8277]))])\n",
            "Loss:0.5525064468383789\n",
            "Loss:0.5524540543556213\n",
            "Loss:0.5524016618728638\n",
            "Loss:0.5523492693901062\n",
            "Loss:0.5522969365119934\n",
            "Loss:0.5522445440292358\n",
            "Loss:0.5521920919418335\n",
            "Loss:0.5521397590637207\n",
            "Loss:0.5520873665809631\n",
            "Loss:0.5520350337028503\n",
            "Epoch: 60 | Loss: 0.5520350337028503 | Test loss: 0.5837119817733765\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7635]])), ('linear_layer.bias', tensor([0.8272]))])\n",
            "Loss:0.5519826412200928\n",
            "Loss:0.5519302487373352\n",
            "Loss:0.5518778562545776\n",
            "Loss:0.5518254041671753\n",
            "Loss:0.5517730712890625\n",
            "Loss:0.5517207384109497\n",
            "Loss:0.5516682863235474\n",
            "Loss:0.5516158938407898\n",
            "Loss:0.5515636205673218\n",
            "Loss:0.5515111684799194\n",
            "Epoch: 70 | Loss: 0.5515111684799194 | Test loss: 0.5830996036529541\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8268]))])\n",
            "Loss:0.5514587163925171\n",
            "Loss:0.5514063835144043\n",
            "Loss:0.5513539910316467\n",
            "Loss:0.5513016581535339\n",
            "Loss:0.5512492060661316\n",
            "Loss:0.5511968731880188\n",
            "Loss:0.5511444807052612\n",
            "Loss:0.5510921478271484\n",
            "Loss:0.5510398149490356\n",
            "Loss:0.5509873628616333\n",
            "Epoch: 80 | Loss: 0.5509873628616333 | Test loss: 0.5824872255325317\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7631]])), ('linear_layer.bias', tensor([0.8263]))])\n",
            "Loss:0.5509349703788757\n",
            "Loss:0.5508825182914734\n",
            "Loss:0.5508302450180054\n",
            "Loss:0.550777792930603\n",
            "Loss:0.5507254600524902\n",
            "Loss:0.5506730675697327\n",
            "Loss:0.5506206154823303\n",
            "Loss:0.5505683422088623\n",
            "Loss:0.55051589012146\n",
            "Loss:0.5504634976387024\n",
            "Epoch: 90 | Loss: 0.5504634976387024 | Test loss: 0.5818749666213989\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7629]])), ('linear_layer.bias', tensor([0.8259]))])\n",
            "Loss:0.5504111051559448\n",
            "Loss:0.550358772277832\n",
            "Loss:0.5503063201904297\n",
            "Loss:0.5502539873123169\n",
            "Loss:0.5502015948295593\n",
            "Loss:0.5501492619514465\n",
            "Loss:0.550096869468689\n",
            "Loss:0.5500444769859314\n",
            "Loss:0.5499920845031738\n",
            "Loss:0.5499396920204163\n",
            "Epoch: 100 | Loss: 0.5499396920204163 | Test loss: 0.5812625885009766\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7628]])), ('linear_layer.bias', tensor([0.8254]))])\n",
            "Loss:0.5498872995376587\n",
            "Loss:0.5498349666595459\n",
            "Loss:0.5497825145721436\n",
            "Loss:0.5497301816940308\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|         | 10/100 [00:03<00:28,  3.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5496777296066284\n",
            "Loss:0.5496253967285156\n",
            "Loss:0.5495730638504028\n",
            "Loss:0.5495206713676453\n",
            "Loss:0.5494682192802429\n",
            "Loss:0.5494158864021301\n",
            "Epoch: 110 | Loss: 0.5494158864021301 | Test loss: 0.580650269985199\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8250]))])\n",
            "Loss:0.5493635535240173\n",
            "Loss:0.549311101436615\n",
            "Loss:0.5492587685585022\n",
            "Loss:0.5492063164710999\n",
            "Loss:0.5491539835929871\n",
            "Loss:0.5491015911102295\n",
            "Loss:0.5490491986274719\n",
            "Loss:0.5489968061447144\n",
            "Loss:0.5489444136619568\n",
            "Loss:0.5488920211791992\n",
            "Epoch: 120 | Loss: 0.5488920211791992 | Test loss: 0.5800378918647766\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7624]])), ('linear_layer.bias', tensor([0.8245]))])\n",
            "Loss:0.5488396883010864\n",
            "Loss:0.5487872958183289\n",
            "Loss:0.5487349033355713\n",
            "Loss:0.5486825108528137\n",
            "Loss:0.5486301183700562\n",
            "Loss:0.5485777258872986\n",
            "Loss:0.5485254526138306\n",
            "Loss:0.5484730005264282\n",
            "Loss:0.5484206676483154\n",
            "Loss:0.5483682155609131\n",
            "Epoch: 130 | Loss: 0.5483682155609131 | Test loss: 0.579425573348999\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7622]])), ('linear_layer.bias', tensor([0.8241]))])\n",
            "Loss:0.5483158230781555\n",
            "Loss:0.5482634902000427\n",
            "Loss:0.5482110381126404\n",
            "Loss:0.5481587052345276\n",
            "Loss:0.54810631275177\n",
            "Loss:0.5480539202690125\n",
            "Loss:0.5480015277862549\n",
            "Loss:0.5479491353034973\n",
            "Loss:0.5478968024253845\n",
            "Loss:0.547844409942627\n",
            "Epoch: 140 | Loss: 0.547844409942627 | Test loss: 0.5788133144378662\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7620]])), ('linear_layer.bias', tensor([0.8236]))])\n",
            "Loss:0.5477920770645142\n",
            "Loss:0.5477396249771118\n",
            "Loss:0.5476873517036438\n",
            "Loss:0.5476348996162415\n",
            "Loss:0.5475825071334839\n",
            "Loss:0.5475301146507263\n",
            "Loss:0.5474777221679688\n",
            "Loss:0.5474253296852112\n",
            "Loss:0.5473729372024536\n",
            "Loss:0.5473206043243408\n",
            "Epoch: 150 | Loss: 0.5473206043243408 | Test loss: 0.5782009363174438\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7619]])), ('linear_layer.bias', tensor([0.8231]))])\n",
            "Loss:0.5472681522369385\n",
            "Loss:0.5472158193588257\n",
            "Loss:0.5471634268760681\n",
            "Loss:0.5471110343933105\n",
            "Loss:0.5470587015151978\n",
            "Loss:0.5470062494277954\n",
            "Loss:0.5469539165496826\n",
            "Loss:0.5469014644622803\n",
            "Loss:0.5468491315841675\n",
            "Loss:0.5467967391014099\n",
            "Epoch: 160 | Loss: 0.5467967391014099 | Test loss: 0.5775885581970215\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7617]])), ('linear_layer.bias', tensor([0.8227]))])\n",
            "Loss:0.5467443466186523\n",
            "Loss:0.5466920137405396\n",
            "Loss:0.546639621257782\n",
            "Loss:0.5465872287750244\n",
            "Loss:0.5465348362922668\n",
            "Loss:0.5464824438095093\n",
            "Loss:0.5464301109313965\n",
            "Loss:0.5463777780532837\n",
            "Loss:0.5463253259658813\n",
            "Loss:0.5462729334831238\n",
            "Epoch: 170 | Loss: 0.5462729334831238 | Test loss: 0.5769762396812439\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7615]])), ('linear_layer.bias', tensor([0.8222]))])\n",
            "Loss:0.546220600605011\n",
            "Loss:0.5461681485176086\n",
            "Loss:0.5461157560348511\n",
            "Loss:0.5460634231567383\n",
            "Loss:0.5460109710693359\n",
            "Loss:0.5459586381912231\n",
            "Loss:0.5459062457084656\n",
            "Loss:0.545853853225708\n",
            "Loss:0.5458015203475952\n",
            "Loss:0.5457491278648376\n",
            "Epoch: 180 | Loss: 0.5457491278648376 | Test loss: 0.5763639211654663\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7613]])), ('linear_layer.bias', tensor([0.8218]))])\n",
            "Loss:0.5456967353820801\n",
            "Loss:0.5456444025039673\n",
            "Loss:0.5455919504165649\n",
            "Loss:0.5455395579338074\n",
            "Loss:0.5454872250556946\n",
            "Loss:0.5454347729682922\n",
            "Loss:0.5453824996948242\n",
            "Loss:0.5453300476074219\n",
            "Loss:0.5452775955200195\n",
            "Loss:0.5452252626419067\n",
            "Epoch: 190 | Loss: 0.5452252626419067 | Test loss: 0.575751543045044\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7612]])), ('linear_layer.bias', tensor([0.8213]))])\n",
            "Loss:0.5451729893684387\n",
            "Loss:0.5451205372810364\n",
            "Loss:0.5450681447982788\n",
            "Loss:0.5450157523155212\n",
            "Loss:0.5449633002281189\n",
            "Loss:0.5449110269546509\n",
            "Loss:0.5448585748672485\n",
            "Loss:0.5448063015937805\n",
            "Loss:0.5447538495063782\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5873792171478271\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551198124885559\n",
            "Loss:0.5550616383552551\n",
            "Loss:0.5550034642219543\n",
            "Loss:0.5549453496932983\n",
            "Loss:0.5548871755599976\n",
            "Loss:0.5548290014266968\n",
            "Loss:0.554770827293396\n",
            "Loss:0.5547126531600952\n",
            "Loss:0.5546545386314392\n",
            "Loss:0.5545963048934937\n",
            "Epoch: 10 | Loss: 0.5545963048934937 | Test loss: 0.586699366569519\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8295]))])\n",
            "Loss:0.5545382499694824\n",
            "Loss:0.5544800162315369\n",
            "Loss:0.5544219017028809\n",
            "Loss:0.5543637275695801\n",
            "Loss:0.5543055534362793\n",
            "Loss:0.5542473793029785\n",
            "Loss:0.5541893243789673\n",
            "Loss:0.5541310906410217\n",
            "Loss:0.5540729761123657\n",
            "Loss:0.5540148019790649\n",
            "Epoch: 20 | Loss: 0.5540148019790649 | Test loss: 0.5860193967819214\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7641]])), ('linear_layer.bias', tensor([0.8289]))])\n",
            "Loss:0.5539566278457642\n",
            "Loss:0.5538984537124634\n",
            "Loss:0.5538402795791626\n",
            "Loss:0.5537821054458618\n",
            "Loss:0.5537239909172058\n",
            "Loss:0.5536658763885498\n",
            "Loss:0.553607702255249\n",
            "Loss:0.553549587726593\n",
            "Loss:0.5534914135932922\n",
            "Loss:0.5534332990646362\n",
            "Epoch: 30 | Loss: 0.5534332990646362 | Test loss: 0.5853395462036133\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7639]])), ('linear_layer.bias', tensor([0.8284]))])\n",
            "Loss:0.5533751249313354\n",
            "Loss:0.5533169507980347\n",
            "Loss:0.5532587766647339\n",
            "Loss:0.5532006025314331\n",
            "Loss:0.5531424283981323\n",
            "Loss:0.5530843138694763\n",
            "Loss:0.5530261397361755\n",
            "Loss:0.5529680252075195\n",
            "Loss:0.5529098510742188\n",
            "Loss:0.552851676940918\n",
            "Epoch: 40 | Loss: 0.552851676940918 | Test loss: 0.5846596360206604\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7637]])), ('linear_layer.bias', tensor([0.8279]))])\n",
            "Loss:0.5527935028076172\n",
            "Loss:0.552735447883606\n",
            "Loss:0.5526772141456604\n",
            "Loss:0.5526190996170044\n",
            "Loss:0.5525609254837036\n",
            "Loss:0.5525027513504028\n",
            "Loss:0.552444577217102\n",
            "Loss:0.5523864030838013\n",
            "Loss:0.5523282885551453\n",
            "Loss:0.5522701144218445\n",
            "Epoch: 50 | Loss: 0.5522701144218445 | Test loss: 0.5839797258377075\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7635]])), ('linear_layer.bias', tensor([0.8274]))])\n",
            "Loss:0.5522119402885437\n",
            "Loss:0.5521537661552429\n",
            "Loss:0.5520955920219421\n",
            "Loss:0.5520374774932861\n",
            "Loss:0.5519793033599854\n",
            "Loss:0.5519211292266846\n",
            "Loss:0.5518630743026733\n",
            "Loss:0.5518049001693726\n",
            "Loss:0.5517467260360718\n",
            "Loss:0.551688551902771\n",
            "Epoch: 60 | Loss: 0.551688551902771 | Test loss: 0.5832997560501099\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8269]))])\n",
            "Loss:0.5516303777694702\n",
            "Loss:0.5515722632408142\n",
            "Loss:0.5515140295028687\n",
            "Loss:0.5514559745788574\n",
            "Loss:0.5513978004455566\n",
            "Loss:0.5513396263122559\n",
            "Loss:0.5512814521789551\n",
            "Loss:0.5512233376502991\n",
            "Loss:0.5511651635169983\n",
            "Loss:0.5511070489883423\n",
            "Epoch: 70 | Loss: 0.5511070489883423 | Test loss: 0.5826199054718018\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7631]])), ('linear_layer.bias', tensor([0.8264]))])\n",
            "Loss:0.5510488748550415\n",
            "Loss:0.5509907007217407\n",
            "Loss:0.5509325265884399\n",
            "Loss:0.5508743524551392\n",
            "Loss:0.5508161783218384\n",
            "Loss:0.5507580637931824\n",
            "Loss:0.5506998896598816\n",
            "Loss:0.5506417155265808\n",
            "Loss:0.5505836009979248\n",
            "Loss:0.550525426864624\n",
            "Epoch: 80 | Loss: 0.550525426864624 | Test loss: 0.5819399356842041\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7629]])), ('linear_layer.bias', tensor([0.8259]))])\n",
            "Loss:0.550467312335968\n",
            "Loss:0.5504090785980225\n",
            "Loss:0.5503509640693665\n",
            "Loss:0.5502927899360657\n",
            "Loss:0.5502346158027649\n",
            "Loss:0.5501765012741089\n",
            "Loss:0.5501183271408081\n",
            "Loss:0.5500601530075073\n",
            "Loss:0.5500019788742065\n",
            "Loss:0.5499438643455505\n",
            "Epoch: 90 | Loss: 0.5499438643455505 | Test loss: 0.581260085105896\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7627]])), ('linear_layer.bias', tensor([0.8254]))])\n",
            "Loss:0.5498857498168945\n",
            "Loss:0.5498275756835938\n",
            "Loss:0.549769401550293\n",
            "Loss:0.549711287021637\n",
            "Loss:0.549653172492981\n",
            "Loss:0.5495949983596802\n",
            "Loss:0.5495368242263794\n",
            "Loss:0.5494786500930786\n",
            "Loss:0.5494204759597778\n",
            "Loss:0.549362301826477\n",
            "Epoch: 100 | Loss: 0.549362301826477 | Test loss: 0.5805801153182983\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8249]))])\n",
            "Loss:0.5493041276931763\n",
            "Loss:0.5492460131645203\n",
            "Loss:0.5491878390312195\n",
            "Loss:0.5491296648979187\n",
            "Loss:0.5490714907646179\n",
            "Loss:0.5490133166313171\n",
            "Loss:0.5489551424980164\n",
            "Loss:0.5488970279693604\n",
            "Loss:0.5488389134407043\n",
            "Loss:0.5487807393074036\n",
            "Epoch: 110 | Loss: 0.5487807393074036 | Test loss: 0.5799002647399902\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7624]])), ('linear_layer.bias', tensor([0.8244]))])\n",
            "Loss:0.5487226247787476\n",
            "Loss:0.548664391040802\n",
            "Loss:0.548606276512146\n",
            "Loss:0.5485481023788452\n",
            "Loss:0.5484899282455444\n",
            "Loss:0.5484317541122437\n",
            "Loss:0.5483735799789429\n",
            "Loss:0.5483154654502869\n",
            "Loss:0.5482572913169861\n",
            "Loss:0.5481991171836853\n",
            "Epoch: 120 | Loss: 0.5481991171836853 | Test loss: 0.5792203545570374\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7622]])), ('linear_layer.bias', tensor([0.8239]))])\n",
            "Loss:0.5481410026550293\n",
            "Loss:0.5480828881263733\n",
            "Loss:0.5480247139930725\n",
            "Loss:0.5479665994644165\n",
            "Loss:0.5479084253311157\n",
            "Loss:0.5478502511978149\n",
            "Loss:0.5477921366691589\n",
            "Loss:0.5477339625358582\n",
            "Loss:0.5476758480072021\n",
            "Loss:0.5476176142692566\n",
            "Epoch: 130 | Loss: 0.5476176142692566 | Test loss: 0.5785404443740845\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7620]])), ('linear_layer.bias', tensor([0.8234]))])\n",
            "Loss:0.5475594401359558\n",
            "Loss:0.5475013256072998\n",
            "Loss:0.5474430918693542\n",
            "Loss:0.5473849773406982\n",
            "Loss:0.5473268628120422\n",
            "Loss:0.5472686886787415\n",
            "Loss:0.5472105741500854\n",
            "Loss:0.5471523404121399\n",
            "Loss:0.5470942258834839\n",
            "Loss:0.5470360517501831\n",
            "Epoch: 140 | Loss: 0.5470360517501831 | Test loss: 0.5778604745864868\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7618]])), ('linear_layer.bias', tensor([0.8229]))])\n",
            "Loss:0.5469778776168823\n",
            "Loss:0.5469197034835815\n",
            "Loss:0.5468615293502808\n",
            "Loss:0.5468034148216248\n",
            "Loss:0.5467453002929688\n",
            "Loss:0.546687126159668\n",
            "Loss:0.5466289520263672\n",
            "Loss:0.5465707778930664\n",
            "Loss:0.5465126037597656\n",
            "Loss:0.5464544892311096\n",
            "Epoch: 150 | Loss: 0.5464544892311096 | Test loss: 0.5771806240081787\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7616]])), ('linear_layer.bias', tensor([0.8224]))])\n",
            "Loss:0.5463963150978088\n",
            "Loss:0.5463382005691528\n",
            "Loss:0.546280026435852\n",
            "Loss:0.5462218523025513\n",
            "Loss:0.5461636781692505\n",
            "Loss:0.5461055636405945\n",
            "Loss:0.5460473895072937\n",
            "Loss:0.5459892153739929\n",
            "Loss:0.5459311604499817\n",
            "Loss:0.5458729863166809\n",
            "Epoch: 160 | Loss: 0.5458729863166809 | Test loss: 0.576500654220581\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7614]])), ('linear_layer.bias', tensor([0.8219]))])\n",
            "Loss:0.5458148121833801\n",
            "Loss:0.5457566380500793\n",
            "Loss:0.5456984639167786\n",
            "Loss:0.5456403493881226\n",
            "Loss:0.5455821752548218\n",
            "Loss:0.545524001121521\n",
            "Loss:0.5454658269882202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|         | 11/100 [00:03<00:28,  3.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5454076528549194\n",
            "Loss:0.5453495383262634\n",
            "Loss:0.5452913045883179\n",
            "Epoch: 170 | Loss: 0.5452913045883179 | Test loss: 0.575820803642273\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7612]])), ('linear_layer.bias', tensor([0.8214]))])\n",
            "Loss:0.5452332496643066\n",
            "Loss:0.5451750159263611\n",
            "Loss:0.5451169013977051\n",
            "Loss:0.5450587272644043\n",
            "Loss:0.5450005531311035\n",
            "Loss:0.5449423789978027\n",
            "Loss:0.5448843240737915\n",
            "Loss:0.544826090335846\n",
            "Loss:0.5447679758071899\n",
            "Loss:0.5447098016738892\n",
            "Epoch: 180 | Loss: 0.5447098016738892 | Test loss: 0.5751408338546753\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7610]])), ('linear_layer.bias', tensor([0.8209]))])\n",
            "Loss:0.5446516275405884\n",
            "Loss:0.5445934534072876\n",
            "Loss:0.5445352792739868\n",
            "Loss:0.544477105140686\n",
            "Loss:0.54441899061203\n",
            "Loss:0.544360876083374\n",
            "Loss:0.5443027019500732\n",
            "Loss:0.5442445874214172\n",
            "Loss:0.5441864132881165\n",
            "Loss:0.5441282987594604\n",
            "Epoch: 190 | Loss: 0.5441282987594604 | Test loss: 0.5744609832763672\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7608]])), ('linear_layer.bias', tensor([0.8204]))])\n",
            "Loss:0.5440701246261597\n",
            "Loss:0.5440119504928589\n",
            "Loss:0.5439537763595581\n",
            "Loss:0.5438956022262573\n",
            "Loss:0.5438374280929565\n",
            "Loss:0.5437793135643005\n",
            "Loss:0.5437211394309998\n",
            "Loss:0.543662965297699\n",
            "Loss:0.543604850769043\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5873723030090332\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8300]))])\n",
            "Loss:0.5551139116287231\n",
            "Loss:0.5550499558448792\n",
            "Loss:0.5549858808517456\n",
            "Loss:0.5549218654632568\n",
            "Loss:0.5548579096794128\n",
            "Loss:0.5547938346862793\n",
            "Loss:0.5547298192977905\n",
            "Loss:0.5546658635139465\n",
            "Loss:0.5546018481254578\n",
            "Loss:0.5545377731323242\n",
            "Epoch: 10 | Loss: 0.5545377731323242 | Test loss: 0.5866237282752991\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8294]))])\n",
            "Loss:0.5544738173484802\n",
            "Loss:0.5544098019599915\n",
            "Loss:0.5543457269668579\n",
            "Loss:0.5542818307876587\n",
            "Loss:0.5542177557945251\n",
            "Loss:0.5541537404060364\n",
            "Loss:0.5540896654129028\n",
            "Loss:0.5540257096290588\n",
            "Loss:0.5539616346359253\n",
            "Loss:0.5538977384567261\n",
            "Epoch: 20 | Loss: 0.5538977384567261 | Test loss: 0.5858751535415649\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7641]])), ('linear_layer.bias', tensor([0.8288]))])\n",
            "Loss:0.5538336634635925\n",
            "Loss:0.5537696480751038\n",
            "Loss:0.553705632686615\n",
            "Loss:0.5536416172981262\n",
            "Loss:0.5535776019096375\n",
            "Loss:0.5535136461257935\n",
            "Loss:0.5534495711326599\n",
            "Loss:0.5533855557441711\n",
            "Loss:0.5533215403556824\n",
            "Loss:0.5532575249671936\n",
            "Epoch: 30 | Loss: 0.5532575249671936 | Test loss: 0.585126519203186\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7639]])), ('linear_layer.bias', tensor([0.8283]))])\n",
            "Loss:0.5531935095787048\n",
            "Loss:0.5531294941902161\n",
            "Loss:0.5530654788017273\n",
            "Loss:0.5530015230178833\n",
            "Loss:0.5529374480247498\n",
            "Loss:0.552873432636261\n",
            "Loss:0.5528094172477722\n",
            "Loss:0.5527454614639282\n",
            "Loss:0.5526813864707947\n",
            "Loss:0.5526174306869507\n",
            "Epoch: 40 | Loss: 0.5526174306869507 | Test loss: 0.5843778848648071\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7636]])), ('linear_layer.bias', tensor([0.8277]))])\n",
            "Loss:0.5525533556938171\n",
            "Loss:0.5524894595146179\n",
            "Loss:0.5524253845214844\n",
            "Loss:0.5523613691329956\n",
            "Loss:0.5522973537445068\n",
            "Loss:0.5522333383560181\n",
            "Loss:0.5521693229675293\n",
            "Loss:0.5521053075790405\n",
            "Loss:0.5520412921905518\n",
            "Loss:0.551977276802063\n",
            "Epoch: 50 | Loss: 0.551977276802063 | Test loss: 0.5836292505264282\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7634]])), ('linear_layer.bias', tensor([0.8272]))])\n",
            "Loss:0.5519133806228638\n",
            "Loss:0.5518492460250854\n",
            "Loss:0.5517852902412415\n",
            "Loss:0.5517212152481079\n",
            "Loss:0.5516571998596191\n",
            "Loss:0.5515931844711304\n",
            "Loss:0.5515292286872864\n",
            "Loss:0.5514652132987976\n",
            "Loss:0.5514011979103088\n",
            "Loss:0.5513371229171753\n",
            "Epoch: 60 | Loss: 0.5513371229171753 | Test loss: 0.5828806757926941\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7632]])), ('linear_layer.bias', tensor([0.8266]))])\n",
            "Loss:0.5512731075286865\n",
            "Loss:0.5512091517448425\n",
            "Loss:0.5511451363563538\n",
            "Loss:0.5510810613632202\n",
            "Loss:0.5510171055793762\n",
            "Loss:0.5509530901908875\n",
            "Loss:0.5508890748023987\n",
            "Loss:0.5508250594139099\n",
            "Loss:0.5507610440254211\n",
            "Loss:0.5506969690322876\n",
            "Epoch: 70 | Loss: 0.5506969690322876 | Test loss: 0.5821320414543152\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7630]])), ('linear_layer.bias', tensor([0.8261]))])\n",
            "Loss:0.5506330728530884\n",
            "Loss:0.5505689978599548\n",
            "Loss:0.5505049824714661\n",
            "Loss:0.5504409670829773\n",
            "Loss:0.5503770112991333\n",
            "Loss:0.5503129363059998\n",
            "Loss:0.5502489805221558\n",
            "Loss:0.5501848459243774\n",
            "Loss:0.5501208901405334\n",
            "Loss:0.5500569343566895\n",
            "Epoch: 80 | Loss: 0.5500569343566895 | Test loss: 0.5813834071159363\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7628]])), ('linear_layer.bias', tensor([0.8255]))])\n",
            "Loss:0.5499929189682007\n",
            "Loss:0.5499288439750671\n",
            "Loss:0.5498648881912231\n",
            "Loss:0.5498008728027344\n",
            "Loss:0.5497367978096008\n",
            "Loss:0.5496727824211121\n",
            "Loss:0.5496087670326233\n",
            "Loss:0.5495448112487793\n",
            "Loss:0.5494807362556458\n",
            "Loss:0.5494167804718018\n",
            "Epoch: 90 | Loss: 0.5494167804718018 | Test loss: 0.5806348919868469\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8250]))])\n",
            "Loss:0.549352765083313\n",
            "Loss:0.5492886900901794\n",
            "Loss:0.5492246747016907\n",
            "Loss:0.5491607785224915\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|        | 12/100 [00:03<00:27,  3.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5490967035293579\n",
            "Loss:0.5490326285362244\n",
            "Loss:0.5489686727523804\n",
            "Loss:0.5489045977592468\n",
            "Loss:0.5488407015800476\n",
            "Loss:0.5487766265869141\n",
            "Epoch: 100 | Loss: 0.5487766265869141 | Test loss: 0.5798861980438232\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7623]])), ('linear_layer.bias', tensor([0.8244]))])\n",
            "Loss:0.5487126111984253\n",
            "Loss:0.5486486554145813\n",
            "Loss:0.5485845804214478\n",
            "Loss:0.548520565032959\n",
            "Loss:0.5484565496444702\n",
            "Loss:0.5483925342559814\n",
            "Loss:0.5483285188674927\n",
            "Loss:0.5482646226882935\n",
            "Loss:0.5482004880905151\n",
            "Loss:0.5481364727020264\n",
            "Epoch: 110 | Loss: 0.5481364727020264 | Test loss: 0.5791376233100891\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7621]])), ('linear_layer.bias', tensor([0.8238]))])\n",
            "Loss:0.5480724573135376\n",
            "Loss:0.5480084419250488\n",
            "Loss:0.5479444265365601\n",
            "Loss:0.5478805303573608\n",
            "Loss:0.5478163957595825\n",
            "Loss:0.5477523803710938\n",
            "Loss:0.547688364982605\n",
            "Loss:0.547624409198761\n",
            "Loss:0.5475603938102722\n",
            "Loss:0.5474963784217834\n",
            "Epoch: 120 | Loss: 0.5474963784217834 | Test loss: 0.578389048576355\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7619]])), ('linear_layer.bias', tensor([0.8233]))])\n",
            "Loss:0.5474323034286499\n",
            "Loss:0.5473683476448059\n",
            "Loss:0.5473043322563171\n",
            "Loss:0.5472403168678284\n",
            "Loss:0.5471763014793396\n",
            "Loss:0.5471122860908508\n",
            "Loss:0.5470482707023621\n",
            "Loss:0.5469843149185181\n",
            "Loss:0.5469202399253845\n",
            "Loss:0.5468562245368958\n",
            "Epoch: 130 | Loss: 0.5468562245368958 | Test loss: 0.5776404142379761\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7617]])), ('linear_layer.bias', tensor([0.8227]))])\n",
            "Loss:0.546792209148407\n",
            "Loss:0.546728253364563\n",
            "Loss:0.5466641783714294\n",
            "Loss:0.5466002225875854\n",
            "Loss:0.5465361475944519\n",
            "Loss:0.5464721918106079\n",
            "Loss:0.5464081764221191\n",
            "Loss:0.5463441610336304\n",
            "Loss:0.5462800860404968\n",
            "Loss:0.5462161302566528\n",
            "Epoch: 140 | Loss: 0.5462161302566528 | Test loss: 0.5768917798995972\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7615]])), ('linear_layer.bias', tensor([0.8222]))])\n",
            "Loss:0.5461521148681641\n",
            "Loss:0.5460880994796753\n",
            "Loss:0.5460240840911865\n",
            "Loss:0.5459600687026978\n",
            "Loss:0.545896053314209\n",
            "Loss:0.5458320379257202\n",
            "Loss:0.5457680225372314\n",
            "Loss:0.5457040071487427\n",
            "Loss:0.5456399917602539\n",
            "Loss:0.5455759167671204\n",
            "Epoch: 150 | Loss: 0.5455759167671204 | Test loss: 0.576143205165863\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7613]])), ('linear_layer.bias', tensor([0.8216]))])\n",
            "Loss:0.5455120205879211\n",
            "Loss:0.5454479455947876\n",
            "Loss:0.5453839302062988\n",
            "Loss:0.5453199148178101\n",
            "Loss:0.5452559590339661\n",
            "Loss:0.5451918840408325\n",
            "Loss:0.5451279282569885\n",
            "Loss:0.545063853263855\n",
            "Loss:0.5449998378753662\n",
            "Loss:0.5449358820915222\n",
            "Epoch: 160 | Loss: 0.5449358820915222 | Test loss: 0.5753945708274841\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7610]])), ('linear_layer.bias', tensor([0.8211]))])\n",
            "Loss:0.5448718667030334\n",
            "Loss:0.5448078513145447\n",
            "Loss:0.5447438359260559\n",
            "Loss:0.5446797609329224\n",
            "Loss:0.5446158647537231\n",
            "Loss:0.5445517897605896\n",
            "Loss:0.5444877743721008\n",
            "Loss:0.5444237589836121\n",
            "Loss:0.5443597435951233\n",
            "Loss:0.5442956686019897\n",
            "Epoch: 170 | Loss: 0.5442956686019897 | Test loss: 0.5746459364891052\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7608]])), ('linear_layer.bias', tensor([0.8205]))])\n",
            "Loss:0.5442317724227905\n",
            "Loss:0.544167697429657\n",
            "Loss:0.5441036820411682\n",
            "Loss:0.5440397262573242\n",
            "Loss:0.5439757108688354\n",
            "Loss:0.5439116358757019\n",
            "Loss:0.5438476800918579\n",
            "Loss:0.5437836050987244\n",
            "Loss:0.543719470500946\n",
            "Loss:0.5436556339263916\n",
            "Epoch: 180 | Loss: 0.5436556339263916 | Test loss: 0.5738973021507263\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7606]])), ('linear_layer.bias', tensor([0.8200]))])\n",
            "Loss:0.5435916185379028\n",
            "Loss:0.5435275435447693\n",
            "Loss:0.5434635877609253\n",
            "Loss:0.5433995723724365\n",
            "Loss:0.5433355569839478\n",
            "Loss:0.5432714819908142\n",
            "Loss:0.5432074666023254\n",
            "Loss:0.5431435704231262\n",
            "Loss:0.5430794954299927\n",
            "Loss:0.5430154204368591\n",
            "Epoch: 190 | Loss: 0.5430154204368591 | Test loss: 0.573148787021637\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7604]])), ('linear_layer.bias', tensor([0.8194]))])\n",
            "Loss:0.5429514646530151\n",
            "Loss:0.5428873896598816\n",
            "Loss:0.5428234338760376\n",
            "Loss:0.5427594780921936\n",
            "Loss:0.5426954030990601\n",
            "Loss:0.5426313281059265\n",
            "Loss:0.5425673723220825\n",
            "Loss:0.5425033569335938\n",
            "Loss:0.5424394011497498\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5873655676841736\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5551080703735352\n",
            "Loss:0.5550382733345032\n",
            "Loss:0.5549682974815369\n",
            "Loss:0.5548985600471497\n",
            "Loss:0.5548287034034729\n",
            "Loss:0.5547589063644409\n",
            "Loss:0.5546890497207642\n",
            "Loss:0.5546191334724426\n",
            "Loss:0.5545493364334106\n",
            "Loss:0.5544794797897339\n",
            "Epoch: 10 | Loss: 0.5544794797897339 | Test loss: 0.5865487456321716\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8293]))])\n",
            "Loss:0.5544096231460571\n",
            "Loss:0.5543397665023804\n",
            "Loss:0.5542699098587036\n",
            "Loss:0.5542000532150269\n",
            "Loss:0.5541302561759949\n",
            "Loss:0.5540603399276733\n",
            "Loss:0.5539904832839966\n",
            "Loss:0.5539206266403198\n",
            "Loss:0.5538508296012878\n",
            "Loss:0.5537810325622559\n",
            "Epoch: 20 | Loss: 0.5537810325622559 | Test loss: 0.5857319235801697\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7640]])), ('linear_layer.bias', tensor([0.8287]))])\n",
            "Loss:0.5537111163139343\n",
            "Loss:0.5536413192749023\n",
            "Loss:0.5535715222358704\n",
            "Loss:0.5535016059875488\n",
            "Loss:0.5534318089485168\n",
            "Loss:0.5533619523048401\n",
            "Loss:0.5532920956611633\n",
            "Loss:0.5532222390174866\n",
            "Loss:0.5531524419784546\n",
            "Loss:0.5530825853347778\n",
            "Epoch: 30 | Loss: 0.5530825853347778 | Test loss: 0.5849151611328125\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7638]])), ('linear_layer.bias', tensor([0.8281]))])\n",
            "Loss:0.5530127286911011\n",
            "Loss:0.5529428720474243\n",
            "Loss:0.5528730154037476\n",
            "Loss:0.5528031587600708\n",
            "Loss:0.552733302116394\n",
            "Loss:0.5526634454727173\n",
            "Loss:0.5525935888290405\n",
            "Loss:0.5525237321853638\n",
            "Loss:0.552453875541687\n",
            "Loss:0.552384078502655\n",
            "Epoch: 40 | Loss: 0.552384078502655 | Test loss: 0.5840983986854553\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7636]])), ('linear_layer.bias', tensor([0.8275]))])\n",
            "Loss:0.552314281463623\n",
            "Loss:0.5522443056106567\n",
            "Loss:0.55217444896698\n",
            "Loss:0.552104651927948\n",
            "Loss:0.552034854888916\n",
            "Loss:0.551965057849884\n",
            "Loss:0.5518952012062073\n",
            "Loss:0.5518252849578857\n",
            "Loss:0.5517554879188538\n",
            "Loss:0.551685631275177\n",
            "Epoch: 50 | Loss: 0.551685631275177 | Test loss: 0.5832816362380981\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8269]))])\n",
            "Loss:0.5516157746315002\n",
            "Loss:0.5515459179878235\n",
            "Loss:0.5514760613441467\n",
            "Loss:0.5514062643051147\n",
            "Loss:0.551336407661438\n",
            "Loss:0.5512665510177612\n",
            "Loss:0.5511966347694397\n",
            "Loss:0.5511267781257629\n",
            "Loss:0.551056981086731\n",
            "Loss:0.5509871244430542\n",
            "Epoch: 60 | Loss: 0.5509871244430542 | Test loss: 0.582464873790741\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7631]])), ('linear_layer.bias', tensor([0.8263]))])\n",
            "Loss:0.5509173274040222\n",
            "Loss:0.5508474111557007\n",
            "Loss:0.5507776141166687\n",
            "Loss:0.5507076978683472\n",
            "Loss:0.5506379008293152\n",
            "Loss:0.5505681037902832\n",
            "Loss:0.5504981875419617\n",
            "Loss:0.5504283905029297\n",
            "Loss:0.5503585338592529\n",
            "Loss:0.5502886772155762\n",
            "Epoch: 70 | Loss: 0.5502886772155762 | Test loss: 0.5816481113433838\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7629]])), ('linear_layer.bias', tensor([0.8257]))])\n",
            "Loss:0.5502188205718994\n",
            "Loss:0.5501489043235779\n",
            "Loss:0.5500791072845459\n",
            "Loss:0.5500093102455139\n",
            "Loss:0.5499394536018372\n",
            "Loss:0.5498695969581604\n",
            "Loss:0.5497997403144836\n",
            "Loss:0.5497298836708069\n",
            "Loss:0.5496600866317749\n",
            "Loss:0.5495902299880981\n",
            "Epoch: 80 | Loss: 0.5495902299880981 | Test loss: 0.5808313488960266\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8251]))])\n",
            "Loss:0.5495203733444214\n",
            "Loss:0.5494505167007446\n",
            "Loss:0.5493806600570679\n",
            "Loss:0.5493108630180359\n",
            "Loss:0.5492409467697144\n",
            "Loss:0.5491712093353271\n",
            "Loss:0.5491012930870056\n",
            "Loss:0.5490314364433289\n",
            "Loss:0.5489615797996521\n",
            "Loss:0.5488917827606201\n",
            "Epoch: 90 | Loss: 0.5488917827606201 | Test loss: 0.5800145268440247\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7624]])), ('linear_layer.bias', tensor([0.8245]))])\n",
            "Loss:0.5488219261169434\n",
            "Loss:0.5487520098686218\n",
            "Loss:0.5486822724342346\n",
            "Loss:0.5486123561859131\n",
            "Loss:0.5485424995422363\n",
            "Loss:0.5484727025032043\n",
            "Loss:0.5484028458595276\n",
            "Loss:0.5483329892158508\n",
            "Loss:0.5482631325721741\n",
            "Loss:0.5481932759284973\n",
            "Epoch: 100 | Loss: 0.5481932759284973 | Test loss: 0.5791977047920227\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7621]])), ('linear_layer.bias', tensor([0.8239]))])\n",
            "Loss:0.5481234788894653\n",
            "Loss:0.5480535626411438\n",
            "Loss:0.547983705997467\n",
            "Loss:0.5479139089584351\n",
            "Loss:0.5478440523147583\n",
            "Loss:0.5477741956710815\n",
            "Loss:0.5477043390274048\n",
            "Loss:0.547634482383728\n",
            "Loss:0.547564685344696\n",
            "Loss:0.5474948287010193\n",
            "Epoch: 110 | Loss: 0.5474948287010193 | Test loss: 0.5783809423446655\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7619]])), ('linear_layer.bias', tensor([0.8233]))])\n",
            "Loss:0.5474250316619873\n",
            "Loss:0.5473551154136658\n",
            "Loss:0.547285258769989\n",
            "Loss:0.5472154021263123\n",
            "Loss:0.5471456050872803\n",
            "Loss:0.5470757484436035\n",
            "Loss:0.5470058917999268\n",
            "Loss:0.54693603515625\n",
            "Loss:0.546866238117218\n",
            "Loss:0.5467963218688965\n",
            "Epoch: 120 | Loss: 0.5467963218688965 | Test loss: 0.5775641202926636\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7617]])), ('linear_layer.bias', tensor([0.8227]))])\n",
            "Loss:0.5467265248298645\n",
            "Loss:0.5466566681861877\n",
            "Loss:0.546586811542511\n",
            "Loss:0.546517014503479\n",
            "Loss:0.5464470982551575\n",
            "Loss:0.5463772416114807\n",
            "Loss:0.5463074445724487\n",
            "Loss:0.546237587928772\n",
            "Loss:0.5461677312850952\n",
            "Loss:0.5460978746414185\n",
            "Epoch: 130 | Loss: 0.5460978746414185 | Test loss: 0.5767473578453064\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7614]])), ('linear_layer.bias', tensor([0.8221]))])\n",
            "Loss:0.5460280776023865\n",
            "Loss:0.5459581613540649\n",
            "Loss:0.545888364315033\n",
            "Loss:0.5458185076713562\n",
            "Loss:0.5457486510276794\n",
            "Loss:0.5456787943840027\n",
            "Loss:0.5456089377403259\n",
            "Loss:0.5455390810966492\n",
            "Loss:0.5454692244529724\n",
            "Loss:0.5453994274139404\n",
            "Epoch: 140 | Loss: 0.5453994274139404 | Test loss: 0.5759305357933044\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7612]])), ('linear_layer.bias', tensor([0.8215]))])\n",
            "Loss:0.5453295707702637\n",
            "Loss:0.5452597737312317\n",
            "Loss:0.5451898574829102\n",
            "Loss:0.5451200604438782\n",
            "Loss:0.5450502634048462\n",
            "Loss:0.5449803471565247\n",
            "Loss:0.5449104905128479\n",
            "Loss:0.5448406338691711\n",
            "Loss:0.5447708368301392\n",
            "Loss:0.5447009801864624\n",
            "Epoch: 150 | Loss: 0.5447009801864624 | Test loss: 0.5751138925552368\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7610]])), ('linear_layer.bias', tensor([0.8209]))])\n",
            "Loss:0.5446311235427856\n",
            "Loss:0.5445612668991089\n",
            "Loss:0.5444914102554321\n",
            "Loss:0.5444215536117554\n",
            "Loss:0.5443516969680786\n",
            "Loss:0.5442818999290466\n",
            "Loss:0.5442119836807251\n",
            "Loss:0.5441421270370483\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|        | 13/100 [00:04<00:27,  3.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5440723299980164\n",
            "Loss:0.5440024733543396\n",
            "Epoch: 160 | Loss: 0.5440024733543396 | Test loss: 0.5742970705032349\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7607]])), ('linear_layer.bias', tensor([0.8202]))])\n",
            "Loss:0.5439327359199524\n",
            "Loss:0.5438627600669861\n",
            "Loss:0.5437929630279541\n",
            "Loss:0.5437231063842773\n",
            "Loss:0.5436533093452454\n",
            "Loss:0.5435833930969238\n",
            "Loss:0.5435135364532471\n",
            "Loss:0.5434436798095703\n",
            "Loss:0.5433738827705383\n",
            "Loss:0.5433040857315063\n",
            "Epoch: 170 | Loss: 0.5433040857315063 | Test loss: 0.5734802484512329\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7605]])), ('linear_layer.bias', tensor([0.8196]))])\n",
            "Loss:0.5432342290878296\n",
            "Loss:0.5431643724441528\n",
            "Loss:0.5430944561958313\n",
            "Loss:0.5430246591567993\n",
            "Loss:0.5429548025131226\n",
            "Loss:0.5428849458694458\n",
            "Loss:0.542815089225769\n",
            "Loss:0.5427452325820923\n",
            "Loss:0.5426753759384155\n",
            "Loss:0.5426055788993835\n",
            "Epoch: 180 | Loss: 0.5426055788993835 | Test loss: 0.572663426399231\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7603]])), ('linear_layer.bias', tensor([0.8190]))])\n",
            "Loss:0.5425357222557068\n",
            "Loss:0.5424658060073853\n",
            "Loss:0.5423960089683533\n",
            "Loss:0.5423261523246765\n",
            "Loss:0.5422562956809998\n",
            "Loss:0.5421864986419678\n",
            "Loss:0.5421165823936462\n",
            "Loss:0.5420467853546143\n",
            "Loss:0.5419769287109375\n",
            "Loss:0.5419071316719055\n",
            "Epoch: 190 | Loss: 0.5419071316719055 | Test loss: 0.5718467235565186\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7600]])), ('linear_layer.bias', tensor([0.8184]))])\n",
            "Loss:0.5418373346328735\n",
            "Loss:0.541767418384552\n",
            "Loss:0.5416975021362305\n",
            "Loss:0.5416277050971985\n",
            "Loss:0.5415579080581665\n",
            "Loss:0.5414880514144897\n",
            "Loss:0.5414181351661682\n",
            "Loss:0.5413482785224915\n",
            "Loss:0.5412784814834595\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5873587131500244\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5551022887229919\n",
            "Loss:0.5550265908241272\n",
            "Loss:0.5549508333206177\n",
            "Loss:0.5548751950263977\n",
            "Loss:0.554799497127533\n",
            "Loss:0.554723858833313\n",
            "Loss:0.5546481609344482\n",
            "Loss:0.5545724630355835\n",
            "Loss:0.5544968843460083\n",
            "Loss:0.5544211268424988\n",
            "Epoch: 10 | Loss: 0.5544211268424988 | Test loss: 0.5864737033843994\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8293]))])\n",
            "Loss:0.554345428943634\n",
            "Loss:0.5542697310447693\n",
            "Loss:0.5541940927505493\n",
            "Loss:0.5541183948516846\n",
            "Loss:0.5540427565574646\n",
            "Loss:0.5539670586585999\n",
            "Loss:0.5538913607597351\n",
            "Loss:0.5538157224655151\n",
            "Loss:0.5537400245666504\n",
            "Loss:0.5536643266677856\n",
            "Epoch: 20 | Loss: 0.5536643266677856 | Test loss: 0.585588812828064\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7640]])), ('linear_layer.bias', tensor([0.8286]))])\n",
            "Loss:0.5535887479782104\n",
            "Loss:0.5535129308700562\n",
            "Loss:0.553437352180481\n",
            "Loss:0.5533615946769714\n",
            "Loss:0.5532859563827515\n",
            "Loss:0.5532102584838867\n",
            "Loss:0.553134560585022\n",
            "Loss:0.553058922290802\n",
            "Loss:0.5529832243919373\n",
            "Loss:0.5529074668884277\n",
            "Epoch: 30 | Loss: 0.5529074668884277 | Test loss: 0.5847038626670837\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7637]])), ('linear_layer.bias', tensor([0.8280]))])\n",
            "Loss:0.5528318881988525\n",
            "Loss:0.5527561902999878\n",
            "Loss:0.5526804327964783\n",
            "Loss:0.5526047945022583\n",
            "Loss:0.5525291562080383\n",
            "Loss:0.5524534583091736\n",
            "Loss:0.5523777604103088\n",
            "Loss:0.5523020625114441\n",
            "Loss:0.5522264242172241\n",
            "Loss:0.5521507263183594\n",
            "Epoch: 40 | Loss: 0.5521507263183594 | Test loss: 0.5838189125061035\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7635]])), ('linear_layer.bias', tensor([0.8273]))])\n",
            "Loss:0.5520750880241394\n",
            "Loss:0.5519993901252747\n",
            "Loss:0.5519237518310547\n",
            "Loss:0.5518480539321899\n",
            "Loss:0.5517722964286804\n",
            "Loss:0.5516966581344604\n",
            "Loss:0.5516209006309509\n",
            "Loss:0.551545262336731\n",
            "Loss:0.551469624042511\n",
            "Loss:0.5513939261436462\n",
            "Epoch: 50 | Loss: 0.5513939261436462 | Test loss: 0.5829339623451233\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7632]])), ('linear_layer.bias', tensor([0.8267]))])\n",
            "Loss:0.5513182878494263\n",
            "Loss:0.5512425899505615\n",
            "Loss:0.551166832447052\n",
            "Loss:0.551091194152832\n",
            "Loss:0.5510155558586121\n",
            "Loss:0.5509398579597473\n",
            "Loss:0.5508641600608826\n",
            "Loss:0.5507885217666626\n",
            "Loss:0.5507128238677979\n",
            "Loss:0.5506371259689331\n",
            "Epoch: 60 | Loss: 0.5506371259689331 | Test loss: 0.5820490121841431\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7630]])), ('linear_layer.bias', tensor([0.8260]))])\n",
            "Loss:0.5505615472793579\n",
            "Loss:0.5504857301712036\n",
            "Loss:0.5504100918769836\n",
            "Loss:0.5503344535827637\n",
            "Loss:0.5502587556838989\n",
            "Loss:0.5501829981803894\n",
            "Loss:0.5501073598861694\n",
            "Loss:0.5500316619873047\n",
            "Loss:0.5499559640884399\n",
            "Loss:0.54988032579422\n",
            "Epoch: 70 | Loss: 0.54988032579422 | Test loss: 0.5811640620231628\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7627]])), ('linear_layer.bias', tensor([0.8253]))])\n",
            "Loss:0.5498046875\n",
            "Loss:0.5497289896011353\n",
            "Loss:0.5496532320976257\n",
            "Loss:0.5495775938034058\n",
            "Loss:0.5495020151138306\n",
            "Loss:0.549426257610321\n",
            "Loss:0.5493505597114563\n",
            "Loss:0.5492748618125916\n",
            "Loss:0.5491992235183716\n",
            "Loss:0.5491235256195068\n",
            "Epoch: 80 | Loss: 0.5491235256195068 | Test loss: 0.5802791118621826\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7625]])), ('linear_layer.bias', tensor([0.8247]))])\n",
            "Loss:0.5490478873252869\n",
            "Loss:0.5489721894264221\n",
            "Loss:0.5488964915275574\n",
            "Loss:0.5488208532333374\n",
            "Loss:0.5487451553344727\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|        | 14/100 [00:04<00:27,  3.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5486694574356079\n",
            "Loss:0.5485938191413879\n",
            "Loss:0.5485180616378784\n",
            "Loss:0.5484424233436584\n",
            "Loss:0.5483666658401489\n",
            "Epoch: 90 | Loss: 0.5483666658401489 | Test loss: 0.5793941020965576\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7622]])), ('linear_layer.bias', tensor([0.8240]))])\n",
            "Loss:0.5482910871505737\n",
            "Loss:0.548215389251709\n",
            "Loss:0.5481396913528442\n",
            "Loss:0.5480639338493347\n",
            "Loss:0.5479883551597595\n",
            "Loss:0.5479127168655396\n",
            "Loss:0.54783695936203\n",
            "Loss:0.5477612614631653\n",
            "Loss:0.5476856231689453\n",
            "Loss:0.5476099252700806\n",
            "Epoch: 100 | Loss: 0.5476099252700806 | Test loss: 0.5785092115402222\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7619]])), ('linear_layer.bias', tensor([0.8234]))])\n",
            "Loss:0.5475342273712158\n",
            "Loss:0.5474585294723511\n",
            "Loss:0.5473828315734863\n",
            "Loss:0.5473071932792664\n",
            "Loss:0.5472315549850464\n",
            "Loss:0.5471557974815369\n",
            "Loss:0.5470802187919617\n",
            "Loss:0.5470044612884521\n",
            "Loss:0.5469287633895874\n",
            "Loss:0.5468531250953674\n",
            "Epoch: 110 | Loss: 0.5468531250953674 | Test loss: 0.5776242613792419\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7617]])), ('linear_layer.bias', tensor([0.8227]))])\n",
            "Loss:0.5467774271965027\n",
            "Loss:0.5467017889022827\n",
            "Loss:0.546626091003418\n",
            "Loss:0.5465503931045532\n",
            "Loss:0.546474814414978\n",
            "Loss:0.5463990569114685\n",
            "Loss:0.5463234186172485\n",
            "Loss:0.5462476015090942\n",
            "Loss:0.546172022819519\n",
            "Loss:0.5460963249206543\n",
            "Epoch: 120 | Loss: 0.5460963249206543 | Test loss: 0.5767393112182617\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7614]])), ('linear_layer.bias', tensor([0.8221]))])\n",
            "Loss:0.5460206270217896\n",
            "Loss:0.5459449887275696\n",
            "Loss:0.5458692312240601\n",
            "Loss:0.5457936525344849\n",
            "Loss:0.5457178950309753\n",
            "Loss:0.5456422567367554\n",
            "Loss:0.5455665588378906\n",
            "Loss:0.5454909205436707\n",
            "Loss:0.5454152226448059\n",
            "Loss:0.5453394651412964\n",
            "Epoch: 130 | Loss: 0.5453394651412964 | Test loss: 0.5758543610572815\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7612]])), ('linear_layer.bias', tensor([0.8214]))])\n",
            "Loss:0.5452638864517212\n",
            "Loss:0.5451881289482117\n",
            "Loss:0.5451124906539917\n",
            "Loss:0.545036792755127\n",
            "Loss:0.544961154460907\n",
            "Loss:0.544885516166687\n",
            "Loss:0.5448097586631775\n",
            "Loss:0.5447341203689575\n",
            "Loss:0.5446584820747375\n",
            "Loss:0.544582724571228\n",
            "Epoch: 140 | Loss: 0.544582724571228 | Test loss: 0.5749694108963013\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7609]])), ('linear_layer.bias', tensor([0.8207]))])\n",
            "Loss:0.5445071458816528\n",
            "Loss:0.5444313287734985\n",
            "Loss:0.5443556904792786\n",
            "Loss:0.5442799925804138\n",
            "Loss:0.5442042946815491\n",
            "Loss:0.5441285967826843\n",
            "Loss:0.5440529584884644\n",
            "Loss:0.5439772605895996\n",
            "Loss:0.5439016222953796\n",
            "Loss:0.5438259243965149\n",
            "Epoch: 150 | Loss: 0.5438259243965149 | Test loss: 0.574084460735321\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7607]])), ('linear_layer.bias', tensor([0.8201]))])\n",
            "Loss:0.5437502264976501\n",
            "Loss:0.5436745882034302\n",
            "Loss:0.5435988903045654\n",
            "Loss:0.5435231924057007\n",
            "Loss:0.5434475541114807\n",
            "Loss:0.543371856212616\n",
            "Loss:0.543296217918396\n",
            "Loss:0.5432205200195312\n",
            "Loss:0.5431448221206665\n",
            "Loss:0.5430691838264465\n",
            "Epoch: 160 | Loss: 0.5430691838264465 | Test loss: 0.5731995105743408\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7604]])), ('linear_layer.bias', tensor([0.8194]))])\n",
            "Loss:0.5429934859275818\n",
            "Loss:0.5429177284240723\n",
            "Loss:0.5428420901298523\n",
            "Loss:0.5427664518356323\n",
            "Loss:0.5426906943321228\n",
            "Loss:0.5426150560379028\n",
            "Loss:0.5425394177436829\n",
            "Loss:0.5424636602401733\n",
            "Loss:0.5423880219459534\n",
            "Loss:0.5423123240470886\n",
            "Epoch: 170 | Loss: 0.5423123240470886 | Test loss: 0.5723145008087158\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7602]])), ('linear_layer.bias', tensor([0.8188]))])\n",
            "Loss:0.5422366857528687\n",
            "Loss:0.5421609282493591\n",
            "Loss:0.5420852899551392\n",
            "Loss:0.5420095920562744\n",
            "Loss:0.5419338941574097\n",
            "Loss:0.5418582558631897\n",
            "Loss:0.541782557964325\n",
            "Loss:0.541706919670105\n",
            "Loss:0.541631281375885\n",
            "Loss:0.5415555238723755\n",
            "Epoch: 180 | Loss: 0.5415555238723755 | Test loss: 0.5714296102523804\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7599]])), ('linear_layer.bias', tensor([0.8181]))])\n",
            "Loss:0.5414799451828003\n",
            "Loss:0.541404128074646\n",
            "Loss:0.5413284301757812\n",
            "Loss:0.5412527918815613\n",
            "Loss:0.5411771535873413\n",
            "Loss:0.5411014556884766\n",
            "Loss:0.5410258173942566\n",
            "Loss:0.5409501194953918\n",
            "Loss:0.5408744812011719\n",
            "Loss:0.5407987236976624\n",
            "Epoch: 190 | Loss: 0.5407987236976624 | Test loss: 0.5705446600914001\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7596]])), ('linear_layer.bias', tensor([0.8175]))])\n",
            "Loss:0.5407230854034424\n",
            "Loss:0.5406473875045776\n",
            "Loss:0.5405716300010681\n",
            "Loss:0.5404959917068481\n",
            "Loss:0.5404203534126282\n",
            "Loss:0.5403445959091187\n",
            "Loss:0.5402689576148987\n",
            "Loss:0.5401932597160339\n",
            "Loss:0.540117621421814\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.58735191822052\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5550965070724487\n",
            "Loss:0.5550150275230408\n",
            "Loss:0.5549335479736328\n",
            "Loss:0.5548521280288696\n",
            "Loss:0.5547707080841064\n",
            "Loss:0.5546892285346985\n",
            "Loss:0.5546077489852905\n",
            "Loss:0.5545263290405273\n",
            "Loss:0.5544448494911194\n",
            "Loss:0.5543633699417114\n",
            "Epoch: 10 | Loss: 0.5543633699417114 | Test loss: 0.5863994359970093\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8292]))])\n",
            "Loss:0.5542818903923035\n",
            "Loss:0.5542004704475403\n",
            "Loss:0.5541190505027771\n",
            "Loss:0.5540375709533691\n",
            "Loss:0.553956151008606\n",
            "Loss:0.5538746118545532\n",
            "Loss:0.5537932515144348\n",
            "Loss:0.5537117719650269\n",
            "Loss:0.5536302328109741\n",
            "Loss:0.5535489320755005\n",
            "Epoch: 20 | Loss: 0.5535489320755005 | Test loss: 0.5854469537734985\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7640]])), ('linear_layer.bias', tensor([0.8285]))])\n",
            "Loss:0.5534673929214478\n",
            "Loss:0.5533859133720398\n",
            "Loss:0.5533045530319214\n",
            "Loss:0.5532230138778687\n",
            "Loss:0.5531415939331055\n",
            "Loss:0.5530601739883423\n",
            "Loss:0.5529786944389343\n",
            "Loss:0.5528972744941711\n",
            "Loss:0.5528157949447632\n",
            "Loss:0.5527343153953552\n",
            "Epoch: 30 | Loss: 0.5527343153953552 | Test loss: 0.5844943523406982\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7637]])), ('linear_layer.bias', tensor([0.8278]))])\n",
            "Loss:0.552652895450592\n",
            "Loss:0.5525714159011841\n",
            "Loss:0.5524899363517761\n",
            "Loss:0.5524085164070129\n",
            "Loss:0.552327036857605\n",
            "Loss:0.552245557308197\n",
            "Loss:0.5521641969680786\n",
            "Loss:0.5520826578140259\n",
            "Loss:0.5520011782646179\n",
            "Loss:0.5519197583198547\n",
            "Epoch: 40 | Loss: 0.5519197583198547 | Test loss: 0.5835418701171875\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7634]])), ('linear_layer.bias', tensor([0.8271]))])\n",
            "Loss:0.5518382787704468\n",
            "Loss:0.5517569184303284\n",
            "Loss:0.5516754388809204\n",
            "Loss:0.5515939593315125\n",
            "Loss:0.5515124797821045\n",
            "Loss:0.5514310598373413\n",
            "Loss:0.5513496398925781\n",
            "Loss:0.5512681007385254\n",
            "Loss:0.5511866807937622\n",
            "Loss:0.551105260848999\n",
            "Epoch: 50 | Loss: 0.551105260848999 | Test loss: 0.5825892686843872\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7631]])), ('linear_layer.bias', tensor([0.8264]))])\n",
            "Loss:0.5510237812995911\n",
            "Loss:0.5509423017501831\n",
            "Loss:0.5508608222007751\n",
            "Loss:0.5507794618606567\n",
            "Loss:0.5506979823112488\n",
            "Loss:0.5506165623664856\n",
            "Loss:0.5505350828170776\n",
            "Loss:0.5504535436630249\n",
            "Loss:0.5503721237182617\n",
            "Loss:0.5502907037734985\n",
            "Epoch: 60 | Loss: 0.5502907037734985 | Test loss: 0.5816367864608765\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7629]])), ('linear_layer.bias', tensor([0.8257]))])\n",
            "Loss:0.5502092838287354\n",
            "Loss:0.5501278042793274\n",
            "Loss:0.5500463247299194\n",
            "Loss:0.549964964389801\n",
            "Loss:0.5498834848403931\n",
            "Loss:0.5498019456863403\n",
            "Loss:0.5497205257415771\n",
            "Loss:0.549639105796814\n",
            "Loss:0.549557626247406\n",
            "Loss:0.549476146697998\n",
            "Epoch: 70 | Loss: 0.549476146697998 | Test loss: 0.5806843042373657\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8250]))])\n",
            "Loss:0.5493947267532349\n",
            "Loss:0.5493132472038269\n",
            "Loss:0.5492317080497742\n",
            "Loss:0.5491503477096558\n",
            "Loss:0.5490688681602478\n",
            "Loss:0.5489875078201294\n",
            "Loss:0.5489059686660767\n",
            "Loss:0.5488246083259583\n",
            "Loss:0.5487431287765503\n",
            "Loss:0.5486615896224976\n",
            "Epoch: 80 | Loss: 0.5486615896224976 | Test loss: 0.5797317624092102\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7623]])), ('linear_layer.bias', tensor([0.8243]))])\n",
            "Loss:0.5485801696777344\n",
            "Loss:0.5484986901283264\n",
            "Loss:0.5484172701835632\n",
            "Loss:0.5483358502388\n",
            "Loss:0.5482543706893921\n",
            "Loss:0.5481728911399841\n",
            "Loss:0.5480914115905762\n",
            "Loss:0.548009991645813\n",
            "Loss:0.547928512096405\n",
            "Loss:0.5478470921516418\n",
            "Epoch: 90 | Loss: 0.5478470921516418 | Test loss: 0.5787792205810547\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7620]])), ('linear_layer.bias', tensor([0.8236]))])\n",
            "Loss:0.5477656722068787\n",
            "Loss:0.5476841926574707\n",
            "Loss:0.5476027131080627\n",
            "Loss:0.5475212335586548\n",
            "Loss:0.5474397540092468\n",
            "Loss:0.5473583936691284\n",
            "Loss:0.5472769141197205\n",
            "Loss:0.5471954941749573\n",
            "Loss:0.5471140146255493\n",
            "Loss:0.5470325350761414\n",
            "Epoch: 100 | Loss: 0.5470325350761414 | Test loss: 0.577826738357544\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7618]])), ('linear_layer.bias', tensor([0.8229]))])\n",
            "Loss:0.5469511151313782\n",
            "Loss:0.5468696355819702\n",
            "Loss:0.5467881560325623\n",
            "Loss:0.5467067360877991\n",
            "Loss:0.5466252565383911\n",
            "Loss:0.5465437769889832\n",
            "Loss:0.5464622974395752\n",
            "Loss:0.546380877494812\n",
            "Loss:0.546299397945404\n",
            "Loss:0.5462180376052856\n",
            "Epoch: 110 | Loss: 0.5462180376052856 | Test loss: 0.5768741965293884\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7615]])), ('linear_layer.bias', tensor([0.8222]))])\n",
            "Loss:0.5461365580558777\n",
            "Loss:0.5460550785064697\n",
            "Loss:0.5459736585617065\n",
            "Loss:0.5458921194076538\n",
            "Loss:0.5458106994628906\n",
            "Loss:0.5457292795181274\n",
            "Loss:0.5456477999687195\n",
            "Loss:0.5455664396286011\n",
            "Loss:0.5454849004745483\n",
            "Loss:0.5454034805297852\n",
            "Epoch: 120 | Loss: 0.5454034805297852 | Test loss: 0.5759216547012329\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7612]])), ('linear_layer.bias', tensor([0.8215]))])\n",
            "Loss:0.5453220009803772\n",
            "Loss:0.5452405214309692\n",
            "Loss:0.5451591610908508\n",
            "Loss:0.5450776219367981\n",
            "Loss:0.5449962019920349\n",
            "Loss:0.544914722442627\n",
            "Loss:0.5448333621025085\n",
            "Loss:0.544751763343811\n",
            "Loss:0.5446702837944031\n",
            "Loss:0.5445889234542847\n",
            "Epoch: 130 | Loss: 0.5445889234542847 | Test loss: 0.5749691724777222\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7609]])), ('linear_layer.bias', tensor([0.8207]))])\n",
            "Loss:0.5445074439048767\n",
            "Loss:0.5444260835647583\n",
            "Loss:0.5443445444107056\n",
            "Loss:0.5442631840705872\n",
            "Loss:0.5441817045211792\n",
            "Loss:0.5441001653671265\n",
            "Loss:0.5440187454223633\n",
            "Loss:0.5439373254776001\n",
            "Loss:0.5438558459281921\n",
            "Loss:0.5437743663787842\n",
            "Epoch: 140 | Loss: 0.5437743663787842 | Test loss: 0.5740166306495667\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7606]])), ('linear_layer.bias', tensor([0.8200]))])\n",
            "Loss:0.543692946434021\n",
            "Loss:0.543611466884613\n",
            "Loss:0.5435300469398499\n",
            "Loss:0.5434485673904419\n",
            "Loss:0.5433671474456787\n",
            "Loss:0.5432856678962708\n",
            "Loss:0.5432042479515076\n",
            "Loss:0.5431227087974548\n",
            "Loss:0.5430412292480469\n",
            "Loss:0.5429598093032837\n",
            "Epoch: 150 | Loss: 0.5429598093032837 | Test loss: 0.5730640888214111\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7604]])), ('linear_layer.bias', tensor([0.8193]))])\n",
            "Loss:0.5428783297538757\n",
            "Loss:0.5427969694137573\n",
            "Loss:0.5427154302597046\n",
            "Loss:0.5426340699195862\n",
            "Loss:0.5425525903701782\n",
            "Loss:0.5424711108207703\n",
            "Loss:0.5423896312713623\n",
            "Loss:0.5423082113265991"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|        | 15/100 [00:04<00:26,  3.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loss:0.5422267913818359\n",
            "Loss:0.542145311832428\n",
            "Epoch: 160 | Loss: 0.542145311832428 | Test loss: 0.5721115469932556\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7601]])), ('linear_layer.bias', tensor([0.8186]))])\n",
            "Loss:0.5420638918876648\n",
            "Loss:0.5419824123382568\n",
            "Loss:0.5419009327888489\n",
            "Loss:0.5418194532394409\n",
            "Loss:0.541737973690033\n",
            "Loss:0.5416566133499146\n",
            "Loss:0.5415751338005066\n",
            "Loss:0.5414937138557434\n",
            "Loss:0.5414122343063354\n",
            "Loss:0.5413307547569275\n",
            "Epoch: 170 | Loss: 0.5413307547569275 | Test loss: 0.5711590647697449\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7598]])), ('linear_layer.bias', tensor([0.8179]))])\n",
            "Loss:0.5412492752075195\n",
            "Loss:0.5411678552627563\n",
            "Loss:0.5410863757133484\n",
            "Loss:0.5410049557685852\n",
            "Loss:0.5409234762191772\n",
            "Loss:0.5408421158790588\n",
            "Loss:0.5407606363296509\n",
            "Loss:0.5406791567802429\n",
            "Loss:0.540597677230835\n",
            "Loss:0.540516197681427\n",
            "Epoch: 180 | Loss: 0.540516197681427 | Test loss: 0.5702065229415894\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7595]])), ('linear_layer.bias', tensor([0.8172]))])\n",
            "Loss:0.5404347777366638\n",
            "Loss:0.5403534173965454\n",
            "Loss:0.5402718782424927\n",
            "Loss:0.5401903986930847\n",
            "Loss:0.5401089191436768\n",
            "Loss:0.5400274991989136\n",
            "Loss:0.5399460792541504\n",
            "Loss:0.5398645997047424\n",
            "Loss:0.5397831797599792\n",
            "Loss:0.5397016406059265\n",
            "Epoch: 190 | Loss: 0.5397016406059265 | Test loss: 0.5692540407180786\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7593]])), ('linear_layer.bias', tensor([0.8165]))])\n",
            "Loss:0.5396202206611633\n",
            "Loss:0.5395387411117554\n",
            "Loss:0.5394573211669922\n",
            "Loss:0.539375901222229\n",
            "Loss:0.5392943620681763\n",
            "Loss:0.5392130017280579\n",
            "Loss:0.5391315221786499\n",
            "Loss:0.5390499830245972\n",
            "Loss:0.5389686226844788\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5873451232910156\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.555090606212616\n",
            "Loss:0.55500328540802\n",
            "Loss:0.5549160838127136\n",
            "Loss:0.5548287630081177\n",
            "Loss:0.5547415018081665\n",
            "Loss:0.5546541810035706\n",
            "Loss:0.5545669198036194\n",
            "Loss:0.5544796586036682\n",
            "Loss:0.5543923377990723\n",
            "Loss:0.5543050765991211\n",
            "Epoch: 10 | Loss: 0.5543050765991211 | Test loss: 0.5863244533538818\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8292]))])\n",
            "Loss:0.5542177557945251\n",
            "Loss:0.5541304349899292\n",
            "Loss:0.554043173789978\n",
            "Loss:0.5539559125900269\n",
            "Loss:0.5538686513900757\n",
            "Loss:0.5537813901901245\n",
            "Loss:0.5536940097808838\n",
            "Loss:0.5536067485809326\n",
            "Loss:0.5535195469856262\n",
            "Loss:0.5534322261810303\n",
            "Epoch: 20 | Loss: 0.5534322261810303 | Test loss: 0.5853036642074585\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7639]])), ('linear_layer.bias', tensor([0.8284]))])\n",
            "Loss:0.5533449053764343\n",
            "Loss:0.5532575845718384\n",
            "Loss:0.5531703233718872\n",
            "Loss:0.553083062171936\n",
            "Loss:0.5529956817626953\n",
            "Loss:0.5529084801673889\n",
            "Loss:0.552821159362793\n",
            "Loss:0.5527338981628418\n",
            "Loss:0.5526466369628906\n",
            "Loss:0.5525592565536499\n",
            "Epoch: 30 | Loss: 0.5525592565536499 | Test loss: 0.5842831134796143\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7636]])), ('linear_layer.bias', tensor([0.8277]))])\n",
            "Loss:0.5524719953536987\n",
            "Loss:0.5523847341537476\n",
            "Loss:0.5522974729537964\n",
            "Loss:0.5522101521492004\n",
            "Loss:0.5521228909492493\n",
            "Loss:0.5520356297492981\n",
            "Loss:0.5519482493400574\n",
            "Loss:0.551861047744751\n",
            "Loss:0.5517736673355103\n",
            "Loss:0.5516864061355591\n",
            "Epoch: 40 | Loss: 0.5516864061355591 | Test loss: 0.5832623243331909\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8269]))])\n",
            "Loss:0.5515991449356079\n",
            "Loss:0.5515118837356567\n",
            "Loss:0.5514246225357056\n",
            "Loss:0.5513373017311096\n",
            "Loss:0.5512501001358032\n",
            "Loss:0.5511627197265625\n",
            "Loss:0.5510753989219666\n",
            "Loss:0.5509881377220154\n",
            "Loss:0.5509008169174194\n",
            "Loss:0.5508135557174683\n",
            "Epoch: 50 | Loss: 0.5508135557174683 | Test loss: 0.5822416543960571\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7630]])), ('linear_layer.bias', tensor([0.8261]))])\n",
            "Loss:0.5507262945175171\n",
            "Loss:0.5506390333175659\n",
            "Loss:0.55055171251297\n",
            "Loss:0.550464391708374\n",
            "Loss:0.5503771901130676\n",
            "Loss:0.5502898693084717\n",
            "Loss:0.5502025485038757\n",
            "Loss:0.5501152276992798\n",
            "Loss:0.5500279664993286\n",
            "Loss:0.5499407052993774\n",
            "Epoch: 60 | Loss: 0.5499407052993774 | Test loss: 0.5812209844589233\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7627]])), ('linear_layer.bias', tensor([0.8254]))])\n",
            "Loss:0.5498534440994263\n",
            "Loss:0.5497661828994751\n",
            "Loss:0.5496788024902344\n",
            "Loss:0.5495914816856384\n",
            "Loss:0.549504280090332\n",
            "Loss:0.5494169592857361\n",
            "Loss:0.5493296980857849\n",
            "Loss:0.549242377281189\n",
            "Loss:0.5491551160812378\n",
            "Loss:0.5490678548812866\n",
            "Epoch: 70 | Loss: 0.5490678548812866 | Test loss: 0.5802003145217896\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7624]])), ('linear_layer.bias', tensor([0.8246]))])\n",
            "Loss:0.5489804744720459\n",
            "Loss:0.5488932728767395\n",
            "Loss:0.5488059520721436\n",
            "Loss:0.5487186312675476\n",
            "Loss:0.5486313700675964\n",
            "Loss:0.5485440492630005\n",
            "Loss:0.5484567880630493\n",
            "Loss:0.5483695268630981\n",
            "Loss:0.5482822060585022\n",
            "Loss:0.548194944858551\n",
            "Epoch: 80 | Loss: 0.548194944858551 | Test loss: 0.579179584980011\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7621]])), ('linear_layer.bias', tensor([0.8239]))])\n",
            "Loss:0.5481076240539551\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|        | 16/100 [00:05<00:26,  3.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5480203628540039\n",
            "Loss:0.547933042049408\n",
            "Loss:0.547845721244812\n",
            "Loss:0.5477585196495056\n",
            "Loss:0.5476711988449097\n",
            "Loss:0.5475839376449585\n",
            "Loss:0.5474966764450073\n",
            "Loss:0.5474093556404114\n",
            "Loss:0.5473220944404602\n",
            "Epoch: 90 | Loss: 0.5473220944404602 | Test loss: 0.5781588554382324\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7618]])), ('linear_layer.bias', tensor([0.8231]))])\n",
            "Loss:0.5472347140312195\n",
            "Loss:0.5471475124359131\n",
            "Loss:0.5470601916313171\n",
            "Loss:0.546972930431366\n",
            "Loss:0.54688560962677\n",
            "Loss:0.5467983484268188\n",
            "Loss:0.5467110276222229\n",
            "Loss:0.5466238260269165\n",
            "Loss:0.5465364456176758\n",
            "Loss:0.5464491844177246\n",
            "Epoch: 100 | Loss: 0.5464491844177246 | Test loss: 0.5771381855010986\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7616]])), ('linear_layer.bias', tensor([0.8224]))])\n",
            "Loss:0.5463619232177734\n",
            "Loss:0.5462745428085327\n",
            "Loss:0.5461872816085815\n",
            "Loss:0.5461000204086304\n",
            "Loss:0.5460127592086792\n",
            "Loss:0.545925498008728\n",
            "Loss:0.5458381772041321\n",
            "Loss:0.5457509160041809\n",
            "Loss:0.545663595199585\n",
            "Loss:0.545576274394989\n",
            "Epoch: 110 | Loss: 0.545576274394989 | Test loss: 0.5761175155639648\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7613]])), ('linear_layer.bias', tensor([0.8216]))])\n",
            "Loss:0.5454890131950378\n",
            "Loss:0.5454016923904419\n",
            "Loss:0.5453144311904907\n",
            "Loss:0.5452271699905396\n",
            "Loss:0.5451399087905884\n",
            "Loss:0.5450525879859924\n",
            "Loss:0.5449653267860413\n",
            "Loss:0.5448780059814453\n",
            "Loss:0.5447907447814941\n",
            "Loss:0.5447034239768982\n",
            "Epoch: 120 | Loss: 0.5447034239768982 | Test loss: 0.575096845626831\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7610]])), ('linear_layer.bias', tensor([0.8208]))])\n",
            "Loss:0.5446161031723022\n",
            "Loss:0.5445288419723511\n",
            "Loss:0.5444415807723999\n",
            "Loss:0.544354259967804\n",
            "Loss:0.5442669987678528\n",
            "Loss:0.5441796779632568\n",
            "Loss:0.5440924763679504\n",
            "Loss:0.5440050959587097\n",
            "Loss:0.5439178347587585\n",
            "Loss:0.5438305735588074\n",
            "Epoch: 130 | Loss: 0.5438305735588074 | Test loss: 0.5740760564804077\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7607]])), ('linear_layer.bias', tensor([0.8201]))])\n",
            "Loss:0.5437432527542114\n",
            "Loss:0.5436559915542603\n",
            "Loss:0.5435687303543091\n",
            "Loss:0.5434814691543579\n",
            "Loss:0.543394148349762\n",
            "Loss:0.5433067679405212\n",
            "Loss:0.5432195067405701\n",
            "Loss:0.5431322455406189\n",
            "Loss:0.5430449843406677\n",
            "Loss:0.5429576635360718\n",
            "Epoch: 140 | Loss: 0.5429576635360718 | Test loss: 0.5730553865432739\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7604]])), ('linear_layer.bias', tensor([0.8193]))])\n",
            "Loss:0.5428704023361206\n",
            "Loss:0.5427830815315247\n",
            "Loss:0.5426958203315735\n",
            "Loss:0.5426085591316223\n",
            "Loss:0.5425212383270264\n",
            "Loss:0.5424339771270752\n",
            "Loss:0.542346715927124\n",
            "Loss:0.5422593951225281\n",
            "Loss:0.5421720743179321\n",
            "Loss:0.542084813117981\n",
            "Epoch: 150 | Loss: 0.542084813117981 | Test loss: 0.5720347762107849\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7601]])), ('linear_layer.bias', tensor([0.8186]))])\n",
            "Loss:0.5419975519180298\n",
            "Loss:0.5419101715087891\n",
            "Loss:0.5418229699134827\n",
            "Loss:0.5417356491088867\n",
            "Loss:0.5416483879089355\n",
            "Loss:0.5415610074996948\n",
            "Loss:0.5414738059043884\n",
            "Loss:0.5413864850997925\n",
            "Loss:0.5412992238998413\n",
            "Loss:0.5412119626998901\n",
            "Epoch: 160 | Loss: 0.5412119626998901 | Test loss: 0.5710140466690063\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7598]])), ('linear_layer.bias', tensor([0.8178]))])\n",
            "Loss:0.5411246418952942\n",
            "Loss:0.5410373210906982\n",
            "Loss:0.5409501194953918\n",
            "Loss:0.5408627986907959\n",
            "Loss:0.5407754778862\n",
            "Loss:0.5406882166862488\n",
            "Loss:0.5406008958816528\n",
            "Loss:0.5405136346817017\n",
            "Loss:0.5404263138771057\n",
            "Loss:0.5403390526771545\n",
            "Epoch: 170 | Loss: 0.5403390526771545 | Test loss: 0.5699933767318726\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7595]])), ('linear_layer.bias', tensor([0.8171]))])\n",
            "Loss:0.5402517914772034\n",
            "Loss:0.540164589881897\n",
            "Loss:0.5400772094726562\n",
            "Loss:0.5399898886680603\n",
            "Loss:0.5399026274681091\n",
            "Loss:0.539815366268158\n",
            "Loss:0.539728045463562\n",
            "Loss:0.5396407246589661\n",
            "Loss:0.5395535230636597\n",
            "Loss:0.5394662022590637\n",
            "Epoch: 180 | Loss: 0.5394662022590637 | Test loss: 0.5689725875854492\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7592]])), ('linear_layer.bias', tensor([0.8163]))])\n",
            "Loss:0.5393788814544678\n",
            "Loss:0.5392915606498718\n",
            "Loss:0.5392043590545654\n",
            "Loss:0.5391170382499695\n",
            "Loss:0.5390297770500183\n",
            "Loss:0.5389424562454224\n",
            "Loss:0.5388551950454712\n",
            "Loss:0.53876793384552\n",
            "Loss:0.5386806726455688\n",
            "Loss:0.5385932922363281\n",
            "Epoch: 190 | Loss: 0.5385932922363281 | Test loss: 0.567952036857605\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7589]])), ('linear_layer.bias', tensor([0.8155]))])\n",
            "Loss:0.538506031036377\n",
            "Loss:0.5384187698364258\n",
            "Loss:0.5383313894271851\n",
            "Loss:0.5382441282272339\n",
            "Loss:0.5381569266319275\n",
            "Loss:0.5380696058273315\n",
            "Loss:0.5379823446273804\n",
            "Loss:0.5378950238227844\n",
            "Loss:0.5378077030181885\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5873383283615112\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5550848245620728\n",
            "Loss:0.5549916625022888\n",
            "Loss:0.5548986196517944\n",
            "Loss:0.5548054575920105\n",
            "Loss:0.5547123551368713\n",
            "Loss:0.5546191334724426\n",
            "Loss:0.5545260906219482\n",
            "Loss:0.5544329881668091\n",
            "Loss:0.5543398857116699\n",
            "Loss:0.554246723651886\n",
            "Epoch: 10 | Loss: 0.554246723651886 | Test loss: 0.5862494707107544\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8291]))])\n",
            "Loss:0.5541536211967468\n",
            "Loss:0.5540605187416077\n",
            "Loss:0.5539673566818237\n",
            "Loss:0.5538741946220398\n",
            "Loss:0.5537810921669006\n",
            "Loss:0.5536879897117615\n",
            "Loss:0.5535948872566223\n",
            "Loss:0.5535017251968384\n",
            "Loss:0.5534086227416992\n",
            "Loss:0.5533155202865601\n",
            "Epoch: 20 | Loss: 0.5533155202865601 | Test loss: 0.5851606130599976\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7639]])), ('linear_layer.bias', tensor([0.8283]))])\n",
            "Loss:0.5532224774360657\n",
            "Loss:0.553129255771637\n",
            "Loss:0.5530361533164978\n",
            "Loss:0.5529430508613586\n",
            "Loss:0.5528498888015747\n",
            "Loss:0.5527568459510803\n",
            "Loss:0.5526636242866516\n",
            "Loss:0.5525705218315125\n",
            "Loss:0.5524774789810181\n",
            "Loss:0.5523843765258789\n",
            "Epoch: 30 | Loss: 0.5523843765258789 | Test loss: 0.5840717554092407\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7636]])), ('linear_layer.bias', tensor([0.8275]))])\n",
            "Loss:0.5522911548614502\n",
            "Loss:0.552198052406311\n",
            "Loss:0.5521049499511719\n",
            "Loss:0.5520117878913879\n",
            "Loss:0.5519186854362488\n",
            "Loss:0.5518255829811096\n",
            "Loss:0.5517324209213257\n",
            "Loss:0.5516393780708313\n",
            "Loss:0.5515462160110474\n",
            "Loss:0.5514531135559082\n",
            "Epoch: 40 | Loss: 0.5514531135559082 | Test loss: 0.5829828381538391\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7632]])), ('linear_layer.bias', tensor([0.8267]))])\n",
            "Loss:0.551360011100769\n",
            "Loss:0.5512667894363403\n",
            "Loss:0.551173746585846\n",
            "Loss:0.551080584526062\n",
            "Loss:0.5509874820709229\n",
            "Loss:0.5508943796157837\n",
            "Loss:0.5508012771606445\n",
            "Loss:0.5507081151008606\n",
            "Loss:0.5506150126457214\n",
            "Loss:0.5505218505859375\n",
            "Epoch: 50 | Loss: 0.5505218505859375 | Test loss: 0.5818939805030823\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7629]])), ('linear_layer.bias', tensor([0.8259]))])\n",
            "Loss:0.5504287481307983\n",
            "Loss:0.550335705280304\n",
            "Loss:0.55024254322052\n",
            "Loss:0.5501494407653809\n",
            "Loss:0.5500562787055969\n",
            "Loss:0.549963116645813\n",
            "Loss:0.5498700141906738\n",
            "Loss:0.5497769117355347\n",
            "Loss:0.5496838092803955\n",
            "Loss:0.5495907068252563\n",
            "Epoch: 60 | Loss: 0.5495907068252563 | Test loss: 0.5808051228523254\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8251]))])\n",
            "Loss:0.5494975447654724\n",
            "Loss:0.5494044423103333\n",
            "Loss:0.5493113398551941\n",
            "Loss:0.5492181777954102\n",
            "Loss:0.549125075340271\n",
            "Loss:0.5490319728851318\n",
            "Loss:0.5489388704299927\n",
            "Loss:0.548845648765564\n",
            "Loss:0.5487526059150696\n",
            "Loss:0.5486595034599304\n",
            "Epoch: 70 | Loss: 0.5486595034599304 | Test loss: 0.5797163248062134\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7623]])), ('linear_layer.bias', tensor([0.8243]))])\n",
            "Loss:0.5485663414001465\n",
            "Loss:0.5484732389450073\n",
            "Loss:0.5483800768852234\n",
            "Loss:0.5482869744300842\n",
            "Loss:0.5481938719749451\n",
            "Loss:0.5481006503105164\n",
            "Loss:0.5480076670646667\n",
            "Loss:0.5479145050048828\n",
            "Loss:0.5478213429450989\n",
            "Loss:0.5477282404899597\n",
            "Epoch: 80 | Loss: 0.5477282404899597 | Test loss: 0.5786274671554565\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7620]])), ('linear_layer.bias', tensor([0.8235]))])\n",
            "Loss:0.5476351976394653\n",
            "Loss:0.5475420355796814\n",
            "Loss:0.5474489331245422\n",
            "Loss:0.5473557710647583\n",
            "Loss:0.5472626686096191\n",
            "Loss:0.5471695065498352\n",
            "Loss:0.547076404094696\n",
            "Loss:0.5469832420349121\n",
            "Loss:0.546890139579773\n",
            "Loss:0.5467970371246338\n",
            "Epoch: 90 | Loss: 0.5467970371246338 | Test loss: 0.5775386095046997\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7617]])), ('linear_layer.bias', tensor([0.8227]))])\n",
            "Loss:0.5467039346694946\n",
            "Loss:0.5466107726097107\n",
            "Loss:0.5465176105499268\n",
            "Loss:0.5464245676994324\n",
            "Loss:0.5463314652442932\n",
            "Loss:0.5462383031845093\n",
            "Loss:0.5461452603340149\n",
            "Loss:0.546052098274231\n",
            "Loss:0.5459590554237366\n",
            "Loss:0.5458658933639526\n",
            "Epoch: 100 | Loss: 0.5458658933639526 | Test loss: 0.5764495730400085\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7614]])), ('linear_layer.bias', tensor([0.8218]))])\n",
            "Loss:0.5457726716995239\n",
            "Loss:0.5456796288490295\n",
            "Loss:0.5455864667892456\n",
            "Loss:0.5454934239387512\n",
            "Loss:0.5454002618789673\n",
            "Loss:0.5453070402145386\n",
            "Loss:0.5452139973640442\n",
            "Loss:0.545120894908905\n",
            "Loss:0.5450277924537659\n",
            "Loss:0.5449346303939819\n",
            "Epoch: 110 | Loss: 0.5449346303939819 | Test loss: 0.5753607749938965\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7610]])), ('linear_layer.bias', tensor([0.8210]))])\n",
            "Loss:0.5448415279388428\n",
            "Loss:0.5447484254837036\n",
            "Loss:0.5446552038192749\n",
            "Loss:0.5445621609687805\n",
            "Loss:0.5444689989089966\n",
            "Loss:0.5443758964538574\n",
            "Loss:0.5442827343940735\n",
            "Loss:0.5441896915435791\n",
            "Loss:0.5440965890884399\n",
            "Loss:0.544003427028656\n",
            "Epoch: 120 | Loss: 0.544003427028656 | Test loss: 0.5742719769477844\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7607]])), ('linear_layer.bias', tensor([0.8202]))])\n",
            "Loss:0.5439103245735168\n",
            "Loss:0.5438171625137329\n",
            "Loss:0.5437240600585938\n",
            "Loss:0.5436309576034546\n",
            "Loss:0.5435377359390259\n",
            "Loss:0.5434447526931763\n",
            "Loss:0.5433515310287476\n",
            "Loss:0.5432584881782532\n",
            "Loss:0.5431653261184692\n",
            "Loss:0.5430722236633301\n",
            "Epoch: 130 | Loss: 0.5430722236633301 | Test loss: 0.5731830596923828\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7604]])), ('linear_layer.bias', tensor([0.8194]))])\n",
            "Loss:0.5429791212081909\n",
            "Loss:0.542885959148407\n",
            "Loss:0.5427928566932678\n",
            "Loss:0.5426996946334839\n",
            "Loss:0.5426066517829895\n",
            "Loss:0.5425134897232056\n",
            "Loss:0.5424203276634216\n",
            "Loss:0.5423272252082825\n",
            "Loss:0.5422341227531433\n",
            "Loss:0.5421410799026489\n",
            "Epoch: 140 | Loss: 0.5421410799026489 | Test loss: 0.5720942616462708\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7601]])), ('linear_layer.bias', tensor([0.8186]))])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|        | 17/100 [00:05<00:26,  3.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5420478582382202\n",
            "Loss:0.5419546961784363\n",
            "Loss:0.5418616533279419\n",
            "Loss:0.5417685508728027\n",
            "Loss:0.5416754484176636\n",
            "Loss:0.5415822267532349\n",
            "Loss:0.5414891839027405\n",
            "Loss:0.5413960814476013\n",
            "Loss:0.5413029789924622\n",
            "Loss:0.5412098169326782\n",
            "Epoch: 150 | Loss: 0.5412098169326782 | Test loss: 0.5710053443908691\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7598]])), ('linear_layer.bias', tensor([0.8178]))])\n",
            "Loss:0.5411166548728943\n",
            "Loss:0.5410235524177551\n",
            "Loss:0.540930449962616\n",
            "Loss:0.540837287902832\n",
            "Loss:0.5407441854476929\n",
            "Loss:0.5406510829925537\n",
            "Loss:0.5405579805374146\n",
            "Loss:0.5404648184776306\n",
            "Loss:0.5403717160224915\n",
            "Loss:0.5402785539627075\n",
            "Epoch: 160 | Loss: 0.5402785539627075 | Test loss: 0.5699164271354675\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7595]])), ('linear_layer.bias', tensor([0.8170]))])\n",
            "Loss:0.5401855111122131\n",
            "Loss:0.5400923490524292\n",
            "Loss:0.5399991869926453\n",
            "Loss:0.5399061441421509\n",
            "Loss:0.5398130416870117\n",
            "Loss:0.5397198796272278\n",
            "Loss:0.5396267771720886\n",
            "Loss:0.5395336151123047\n",
            "Loss:0.5394405126571655\n",
            "Loss:0.5393473505973816\n",
            "Epoch: 170 | Loss: 0.5393473505973816 | Test loss: 0.5688276886940002\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7591]])), ('linear_layer.bias', tensor([0.8162]))])\n",
            "Loss:0.5392542481422424\n",
            "Loss:0.5391611456871033\n",
            "Loss:0.5390680432319641\n",
            "Loss:0.5389748811721802\n",
            "Loss:0.538881778717041\n",
            "Loss:0.5387886762619019\n",
            "Loss:0.5386955738067627\n",
            "Loss:0.5386024117469788\n",
            "Loss:0.5385092496871948\n",
            "Loss:0.5384161472320557\n",
            "Epoch: 180 | Loss: 0.5384161472320557 | Test loss: 0.5677387118339539\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7588]])), ('linear_layer.bias', tensor([0.8154]))])\n",
            "Loss:0.5383230447769165\n",
            "Loss:0.5382298827171326\n",
            "Loss:0.5381367802619934\n",
            "Loss:0.5380436778068542\n",
            "Loss:0.5379505753517151\n",
            "Loss:0.5378574132919312\n",
            "Loss:0.537764310836792\n",
            "Loss:0.5376712083816528\n",
            "Loss:0.5375780463218689\n",
            "Loss:0.5374849438667297\n",
            "Epoch: 190 | Loss: 0.5374849438667297 | Test loss: 0.566649854183197\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7585]])), ('linear_layer.bias', tensor([0.8146]))])\n",
            "Loss:0.5373918414115906\n",
            "Loss:0.5372986793518066\n",
            "Loss:0.5372055768966675\n",
            "Loss:0.5371124148368835\n",
            "Loss:0.5370193719863892\n",
            "Loss:0.5369262099266052\n",
            "Loss:0.5368331670761108\n",
            "Loss:0.5367399454116821\n",
            "Loss:0.536646842956543\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5873315334320068\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5550791025161743\n",
            "Loss:0.5549801588058472\n",
            "Loss:0.55488121509552\n",
            "Loss:0.5547823309898376\n",
            "Loss:0.5546835064888\n",
            "Loss:0.5545845627784729\n",
            "Loss:0.5544856190681458\n",
            "Loss:0.5543867945671082\n",
            "Loss:0.554287850856781\n",
            "Loss:0.5541889667510986\n",
            "Epoch: 10 | Loss: 0.5541889667510986 | Test loss: 0.5861750841140747\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7642]])), ('linear_layer.bias', tensor([0.8291]))])\n",
            "Loss:0.554090142250061\n",
            "Loss:0.5539911985397339\n",
            "Loss:0.5538923144340515\n",
            "Loss:0.5537934303283691\n",
            "Loss:0.553694486618042\n",
            "Loss:0.5535956621170044\n",
            "Loss:0.5534967184066772\n",
            "Loss:0.5533977746963501\n",
            "Loss:0.5532988905906677\n",
            "Loss:0.5532000660896301\n",
            "Epoch: 20 | Loss: 0.5532000660896301 | Test loss: 0.5850187540054321\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7638]])), ('linear_layer.bias', tensor([0.8282]))])\n",
            "Loss:0.553101122379303\n",
            "Loss:0.5530022978782654\n",
            "Loss:0.5529033541679382\n",
            "Loss:0.5528044700622559\n",
            "Loss:0.5527055859565735\n",
            "Loss:0.5526066422462463\n",
            "Loss:0.552507758140564\n",
            "Loss:0.5524088740348816\n",
            "Loss:0.5523099303245544\n",
            "Loss:0.5522111654281616\n",
            "Epoch: 30 | Loss: 0.5522111654281616 | Test loss: 0.5838623046875\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7635]])), ('linear_layer.bias', tensor([0.8273]))])\n",
            "Loss:0.5521121621131897\n",
            "Loss:0.5520132780075073\n",
            "Loss:0.551914393901825\n",
            "Loss:0.5518154501914978\n",
            "Loss:0.5517166256904602\n",
            "Loss:0.5516177415847778\n",
            "Loss:0.5515187978744507\n",
            "Loss:0.5514199137687683\n",
            "Loss:0.5513210296630859\n",
            "Loss:0.5512221455574036\n",
            "Epoch: 40 | Loss: 0.5512221455574036 | Test loss: 0.5827057957649231\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7632]])), ('linear_layer.bias', tensor([0.8265]))])\n",
            "Loss:0.551123321056366\n",
            "Loss:0.551024317741394\n",
            "Loss:0.5509254336357117\n",
            "Loss:0.5508265495300293\n",
            "Loss:0.5507276654243469\n",
            "Loss:0.5506287813186646\n",
            "Loss:0.5505298376083374\n",
            "Loss:0.550430953502655\n",
            "Loss:0.5503320693969727\n",
            "Loss:0.5502332448959351\n",
            "Epoch: 50 | Loss: 0.5502332448959351 | Test loss: 0.581549346446991\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7628]])), ('linear_layer.bias', tensor([0.8256]))])\n",
            "Loss:0.5501343011856079\n",
            "Loss:0.5500354170799255\n",
            "Loss:0.5499364733695984\n",
            "Loss:0.5498375296592712\n",
            "Loss:0.5497387647628784\n",
            "Loss:0.5496398210525513\n",
            "Loss:0.5495409369468689\n",
            "Loss:0.5494420528411865\n",
            "Loss:0.5493431091308594\n",
            "Loss:0.5492442846298218\n",
            "Epoch: 60 | Loss: 0.5492442846298218 | Test loss: 0.5803929567337036\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7625]])), ('linear_layer.bias', tensor([0.8248]))])\n",
            "Loss:0.5491454005241394\n",
            "Loss:0.5490463972091675\n",
            "Loss:0.5489475727081299\n",
            "Loss:0.5488486886024475\n",
            "Loss:0.5487498044967651\n",
            "Loss:0.5486509203910828\n",
            "Loss:0.5485519170761108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|        | 18/100 [00:05<00:25,  3.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5484530329704285\n",
            "Loss:0.5483541488647461\n",
            "Loss:0.5482553243637085\n",
            "Epoch: 70 | Loss: 0.5482553243637085 | Test loss: 0.5792365670204163\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7622]])), ('linear_layer.bias', tensor([0.8239]))])\n",
            "Loss:0.5481563806533813\n",
            "Loss:0.548057496547699\n",
            "Loss:0.5479586124420166\n",
            "Loss:0.5478597283363342\n",
            "Loss:0.5477608442306519\n",
            "Loss:0.5476619005203247\n",
            "Loss:0.5475630164146423\n",
            "Loss:0.54746413230896\n",
            "Loss:0.5473653078079224\n",
            "Loss:0.5472663640975952\n",
            "Epoch: 80 | Loss: 0.5472663640975952 | Test loss: 0.5780800580978394\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7618]])), ('linear_layer.bias', tensor([0.8231]))])\n",
            "Loss:0.5471674203872681\n",
            "Loss:0.5470684766769409\n",
            "Loss:0.5469696521759033\n",
            "Loss:0.5468708276748657\n",
            "Loss:0.5467718839645386\n",
            "Loss:0.5466729402542114\n",
            "Loss:0.546574056148529\n",
            "Loss:0.5464752316474915\n",
            "Loss:0.5463763475418091\n",
            "Loss:0.5462774038314819\n",
            "Epoch: 90 | Loss: 0.5462774038314819 | Test loss: 0.5769236087799072\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7615]])), ('linear_layer.bias', tensor([0.8222]))])\n",
            "Loss:0.5461785197257996\n",
            "Loss:0.5460795760154724\n",
            "Loss:0.54598069190979\n",
            "Loss:0.5458818674087524\n",
            "Loss:0.5457829236984253\n",
            "Loss:0.5456840395927429\n",
            "Loss:0.5455850958824158\n",
            "Loss:0.5454862117767334\n",
            "Loss:0.5453873872756958\n",
            "Loss:0.5452884435653687\n",
            "Epoch: 100 | Loss: 0.5452884435653687 | Test loss: 0.5757672190666199\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7612]])), ('linear_layer.bias', tensor([0.8213]))])\n",
            "Loss:0.5451894998550415\n",
            "Loss:0.5450906753540039\n",
            "Loss:0.5449917912483215\n",
            "Loss:0.5448929071426392\n",
            "Loss:0.544793963432312\n",
            "Loss:0.5446950197219849\n",
            "Loss:0.5445961952209473\n",
            "Loss:0.5444973111152649\n",
            "Loss:0.5443984270095825\n",
            "Loss:0.5442994832992554\n",
            "Epoch: 110 | Loss: 0.5442994832992554 | Test loss: 0.5746107697486877\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7608]])), ('linear_layer.bias', tensor([0.8205]))])\n",
            "Loss:0.544200599193573\n",
            "Loss:0.5441015958786011\n",
            "Loss:0.5440027713775635\n",
            "Loss:0.5439039468765259\n",
            "Loss:0.5438050031661987\n",
            "Loss:0.5437061190605164\n",
            "Loss:0.543607234954834\n",
            "Loss:0.5435083508491516\n",
            "Loss:0.5434094667434692\n",
            "Loss:0.5433105230331421\n",
            "Epoch: 120 | Loss: 0.5433105230331421 | Test loss: 0.5734542608261108\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7605]])), ('linear_layer.bias', tensor([0.8196]))])\n",
            "Loss:0.5432116985321045\n",
            "Loss:0.5431127548217773\n",
            "Loss:0.5430139303207397\n",
            "Loss:0.5429149866104126\n",
            "Loss:0.5428160429000854\n",
            "Loss:0.5427172183990479\n",
            "Loss:0.5426182746887207\n",
            "Loss:0.5425193905830383\n",
            "Loss:0.542420506477356\n",
            "Loss:0.5423216223716736\n",
            "Epoch: 130 | Loss: 0.5423216223716736 | Test loss: 0.5722979307174683\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7602]])), ('linear_layer.bias', tensor([0.8188]))])\n",
            "Loss:0.5422226786613464\n",
            "Loss:0.5421237945556641\n",
            "Loss:0.5420249104499817\n",
            "Loss:0.5419260263442993\n",
            "Loss:0.5418271422386169\n",
            "Loss:0.5417282581329346\n",
            "Loss:0.5416293144226074\n",
            "Loss:0.5415304899215698\n",
            "Loss:0.5414315462112427\n",
            "Loss:0.5413327217102051\n",
            "Epoch: 140 | Loss: 0.5413327217102051 | Test loss: 0.5711414217948914\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7598]])), ('linear_layer.bias', tensor([0.8179]))])\n",
            "Loss:0.5412337779998779\n",
            "Loss:0.5411348342895508\n",
            "Loss:0.5410360097885132\n",
            "Loss:0.540937066078186\n",
            "Loss:0.5408381223678589\n",
            "Loss:0.5407392978668213\n",
            "Loss:0.5406404137611389\n",
            "Loss:0.5405414700508118\n",
            "Loss:0.5404425859451294\n",
            "Loss:0.5403436422348022\n",
            "Epoch: 150 | Loss: 0.5403436422348022 | Test loss: 0.569985032081604\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7595]])), ('linear_layer.bias', tensor([0.8170]))])\n",
            "Loss:0.5402447581291199\n",
            "Loss:0.540145993232727\n",
            "Loss:0.5400470495223999\n",
            "Loss:0.5399481058120728\n",
            "Loss:0.5398492217063904\n",
            "Loss:0.5397502779960632\n",
            "Loss:0.5396515130996704\n",
            "Loss:0.5395525097846985\n",
            "Loss:0.5394536256790161\n",
            "Loss:0.5393548011779785\n",
            "Epoch: 160 | Loss: 0.5393548011779785 | Test loss: 0.5688285231590271\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7591]])), ('linear_layer.bias', tensor([0.8162]))])\n",
            "Loss:0.5392558574676514\n",
            "Loss:0.5391570329666138\n",
            "Loss:0.5390580892562866\n",
            "Loss:0.5389591455459595\n",
            "Loss:0.5388603210449219\n",
            "Loss:0.5387613773345947\n",
            "Loss:0.5386624932289124\n",
            "Loss:0.53856360912323\n",
            "Loss:0.5384646654129028\n",
            "Loss:0.5383658409118652\n",
            "Epoch: 170 | Loss: 0.5383658409118652 | Test loss: 0.5676721334457397\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7588]])), ('linear_layer.bias', tensor([0.8153]))])\n",
            "Loss:0.5382668972015381\n",
            "Loss:0.5381680727005005\n",
            "Loss:0.5380691289901733\n",
            "Loss:0.5379701852798462\n",
            "Loss:0.5378713607788086\n",
            "Loss:0.5377724766731262\n",
            "Loss:0.5376735925674438\n",
            "Loss:0.5375745892524719\n",
            "Loss:0.5374757051467896\n",
            "Loss:0.537376880645752\n",
            "Epoch: 180 | Loss: 0.537376880645752 | Test loss: 0.5665156841278076\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7585]])), ('linear_layer.bias', tensor([0.8145]))])\n",
            "Loss:0.5372779369354248\n",
            "Loss:0.5371791124343872\n",
            "Loss:0.5370801687240601\n",
            "Loss:0.5369812846183777\n",
            "Loss:0.5368824601173401\n",
            "Loss:0.5367834568023682\n",
            "Loss:0.5366846323013306\n",
            "Loss:0.5365856885910034\n",
            "Loss:0.536486804485321\n",
            "Loss:0.5363879799842834\n",
            "Epoch: 190 | Loss: 0.5363879799842834 | Test loss: 0.5653592944145203\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7581]])), ('linear_layer.bias', tensor([0.8136]))])\n",
            "Loss:0.5362889766693115\n",
            "Loss:0.5361900925636292\n",
            "Loss:0.5360912084579468\n",
            "Loss:0.5359922647476196\n",
            "Loss:0.5358933806419373\n",
            "Loss:0.5357945561408997\n",
            "Loss:0.5356956720352173\n",
            "Loss:0.5355967283248901\n",
            "Loss:0.5354978442192078\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5873247385025024\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5550732612609863\n",
            "Loss:0.5549684166908264\n",
            "Loss:0.5548637509346008\n",
            "Loss:0.5547589659690857\n",
            "Loss:0.5546543002128601\n",
            "Loss:0.5545495748519897\n",
            "Loss:0.5544447898864746\n",
            "Loss:0.554340124130249\n",
            "Loss:0.5542353391647339\n",
            "Loss:0.5541306734085083\n",
            "Epoch: 10 | Loss: 0.5541306734085083 | Test loss: 0.5861001014709473\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7641]])), ('linear_layer.bias', tensor([0.8290]))])\n",
            "Loss:0.5540259480476379\n",
            "Loss:0.5539212226867676\n",
            "Loss:0.5538164377212524\n",
            "Loss:0.5537117123603821\n",
            "Loss:0.5536069869995117\n",
            "Loss:0.5535022616386414\n",
            "Loss:0.5533975958824158\n",
            "Loss:0.5532928109169006\n",
            "Loss:0.5531880259513855\n",
            "Loss:0.5530833005905151\n",
            "Epoch: 20 | Loss: 0.5530833005905151 | Test loss: 0.5848755836486816\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7638]])), ('linear_layer.bias', tensor([0.8281]))])\n",
            "Loss:0.5529786348342896\n",
            "Loss:0.5528739094734192\n",
            "Loss:0.5527691841125488\n",
            "Loss:0.5526643991470337\n",
            "Loss:0.5525596737861633\n",
            "Loss:0.5524550080299377\n",
            "Loss:0.5523502826690674\n",
            "Loss:0.552245557308197\n",
            "Loss:0.5521408319473267\n",
            "Loss:0.5520360469818115\n",
            "Epoch: 30 | Loss: 0.5520360469818115 | Test loss: 0.5836509466171265\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7634]])), ('linear_layer.bias', tensor([0.8272]))])\n",
            "Loss:0.5519313216209412\n",
            "Loss:0.5518266558647156\n",
            "Loss:0.5517218708992004\n",
            "Loss:0.5516172051429749\n",
            "Loss:0.5515124201774597\n",
            "Loss:0.5514076948165894\n",
            "Loss:0.5513030290603638\n",
            "Loss:0.5511983036994934\n",
            "Loss:0.5510934591293335\n",
            "Loss:0.5509887933731079\n",
            "Epoch: 40 | Loss: 0.5509887933731079 | Test loss: 0.5824263095855713\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7631]])), ('linear_layer.bias', tensor([0.8263]))])\n",
            "Loss:0.5508840680122375\n",
            "Loss:0.5507793426513672\n",
            "Loss:0.5506746172904968\n",
            "Loss:0.5505698919296265\n",
            "Loss:0.5504651069641113\n",
            "Loss:0.550360381603241\n",
            "Loss:0.5502556562423706\n",
            "Loss:0.550150990486145\n",
            "Loss:0.5500462651252747\n",
            "Loss:0.5499415397644043\n",
            "Epoch: 50 | Loss: 0.5499415397644043 | Test loss: 0.5812016725540161\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7627]])), ('linear_layer.bias', tensor([0.8254]))])\n",
            "Loss:0.5498367547988892\n",
            "Loss:0.5497320294380188\n",
            "Loss:0.5496273040771484\n",
            "Loss:0.5495225787162781\n",
            "Loss:0.5494178533554077\n",
            "Loss:0.5493131279945374\n",
            "Loss:0.5492084622383118\n",
            "Loss:0.5491037368774414\n",
            "Loss:0.548999011516571\n",
            "Loss:0.5488942861557007\n",
            "Epoch: 60 | Loss: 0.5488942861557007 | Test loss: 0.5799770951271057\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7624]])), ('linear_layer.bias', tensor([0.8245]))])\n",
            "Loss:0.5487894415855408\n",
            "Loss:0.5486847758293152\n",
            "Loss:0.5485800504684448\n",
            "Loss:0.5484753847122192\n",
            "Loss:0.5483705401420593\n",
            "Loss:0.548265814781189\n",
            "Loss:0.5481611490249634\n",
            "Loss:0.5480563640594482\n",
            "Loss:0.5479516386985779\n",
            "Loss:0.5478469133377075\n",
            "Epoch: 70 | Loss: 0.5478469133377075 | Test loss: 0.5787524580955505\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7620]])), ('linear_layer.bias', tensor([0.8236]))])\n",
            "Loss:0.5477421879768372\n",
            "Loss:0.5476374626159668\n",
            "Loss:0.5475326776504517\n",
            "Loss:0.5474280714988708\n",
            "Loss:0.5473233461380005\n",
            "Loss:0.5472186207771301\n",
            "Loss:0.547113835811615\n",
            "Loss:0.5470091104507446\n",
            "Loss:0.546904444694519\n",
            "Loss:0.5467997193336487\n",
            "Epoch: 80 | Loss: 0.5467997193336487 | Test loss: 0.5775278806686401\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7617]])), ('linear_layer.bias', tensor([0.8226]))])\n",
            "Loss:0.5466949939727783\n",
            "Loss:0.5465902090072632\n",
            "Loss:0.5464855432510376\n",
            "Loss:0.5463807582855225\n",
            "Loss:0.5462759733200073\n",
            "Loss:0.5461713075637817\n",
            "Loss:0.5460665822029114\n",
            "Loss:0.5459617376327515\n",
            "Loss:0.5458570718765259\n",
            "Loss:0.5457523465156555\n",
            "Epoch: 90 | Loss: 0.5457523465156555 | Test loss: 0.576303243637085\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7613]])), ('linear_layer.bias', tensor([0.8217]))])\n",
            "Loss:0.5456476211547852\n",
            "Loss:0.5455428957939148\n",
            "Loss:0.5454381704330444\n",
            "Loss:0.5453334450721741\n",
            "Loss:0.5452287197113037\n",
            "Loss:0.5451239943504333\n",
            "Loss:0.545019268989563\n",
            "Loss:0.5449145436286926\n",
            "Loss:0.5448098182678223\n",
            "Loss:0.5447050929069519\n",
            "Epoch: 100 | Loss: 0.5447050929069519 | Test loss: 0.5750786066055298\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7610]])), ('linear_layer.bias', tensor([0.8208]))])\n",
            "Loss:0.5446003675460815\n",
            "Loss:0.544495701789856\n",
            "Loss:0.544390857219696\n",
            "Loss:0.5442861318588257\n",
            "Loss:0.5441814661026001\n",
            "Loss:0.5440767407417297\n",
            "Loss:0.5439720153808594\n",
            "Loss:0.543867290019989\n",
            "Loss:0.5437625050544739\n",
            "Loss:0.5436577796936035\n",
            "Epoch: 110 | Loss: 0.5436577796936035 | Test loss: 0.5738540887832642\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7606]])), ('linear_layer.bias', tensor([0.8199]))])\n",
            "Loss:0.5435530543327332\n",
            "Loss:0.5434483289718628\n",
            "Loss:0.5433436632156372\n",
            "Loss:0.5432388782501221\n",
            "Loss:0.5431341528892517\n",
            "Loss:0.5430294275283813\n",
            "Loss:0.542924702167511\n",
            "Loss:0.5428199768066406\n",
            "Loss:0.5427152514457703\n",
            "Loss:0.5426105260848999\n",
            "Epoch: 120 | Loss: 0.5426105260848999 | Test loss: 0.572629451751709\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7602]])), ('linear_layer.bias', tensor([0.8190]))])\n",
            "Loss:0.5425058007240295\n",
            "Loss:0.5424010753631592\n",
            "Loss:0.5422964096069336\n",
            "Loss:0.5421916246414185\n",
            "Loss:0.5420868992805481\n",
            "Loss:0.5419821739196777\n",
            "Loss:0.5418774485588074\n",
            "Loss:0.541772723197937\n",
            "Loss:0.5416680574417114\n",
            "Loss:0.5415632128715515\n",
            "Epoch: 130 | Loss: 0.5415632128715515 | Test loss: 0.5714048147201538\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7599]])), ('linear_layer.bias', tensor([0.8181]))])\n",
            "Loss:0.5414584875106812\n",
            "Loss:0.5413538217544556\n",
            "Loss:0.5412490963935852\n",
            "Loss:0.5411443114280701\n",
            "Loss:0.5410395860671997\n",
            "Loss:0.5409349203109741\n",
            "Loss:0.540830135345459\n",
            "Loss:0.5407254099845886\n",
            "Loss:0.5406206846237183\n",
            "Loss:0.5405160188674927\n",
            "Epoch: 140 | Loss: 0.5405160188674927 | Test loss: 0.5701802372932434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|        | 19/100 [00:06<00:25,  3.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('linear_layer.weight', tensor([[0.7595]])), ('linear_layer.bias', tensor([0.8172]))])\n",
            "Loss:0.5404112339019775\n",
            "Loss:0.5403064489364624\n",
            "Loss:0.5402017831802368\n",
            "Loss:0.5400970578193665\n",
            "Loss:0.5399922728538513\n",
            "Loss:0.5398876070976257\n",
            "Loss:0.5397828817367554\n",
            "Loss:0.5396782159805298\n",
            "Loss:0.5395733714103699\n",
            "Loss:0.5394686460494995\n",
            "Epoch: 150 | Loss: 0.5394686460494995 | Test loss: 0.5689556002616882\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7592]])), ('linear_layer.bias', tensor([0.8163]))])\n",
            "Loss:0.5393639802932739\n",
            "Loss:0.539259135723114\n",
            "Loss:0.5391544699668884\n",
            "Loss:0.5390498042106628\n",
            "Loss:0.5389450192451477\n",
            "Loss:0.5388402938842773\n",
            "Loss:0.538735568523407\n",
            "Loss:0.5386308431625366\n",
            "Loss:0.5385261178016663\n",
            "Loss:0.5384213924407959\n",
            "Epoch: 160 | Loss: 0.5384213924407959 | Test loss: 0.5677310228347778\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7588]])), ('linear_layer.bias', tensor([0.8154]))])\n",
            "Loss:0.5383166670799255\n",
            "Loss:0.5382118821144104\n",
            "Loss:0.5381072163581848\n",
            "Loss:0.5380024909973145\n",
            "Loss:0.5378977060317993\n",
            "Loss:0.5377930998802185\n",
            "Loss:0.5376882553100586\n",
            "Loss:0.537583589553833\n",
            "Loss:0.5374788045883179\n",
            "Loss:0.5373741388320923\n",
            "Epoch: 170 | Loss: 0.5373741388320923 | Test loss: 0.5665063858032227\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7585]])), ('linear_layer.bias', tensor([0.8145]))])\n",
            "Loss:0.5372694134712219\n",
            "Loss:0.537164568901062\n",
            "Loss:0.5370599031448364\n",
            "Loss:0.5369551777839661\n",
            "Loss:0.5368504524230957\n",
            "Loss:0.5367457270622253\n",
            "Loss:0.536641001701355\n",
            "Loss:0.5365362763404846\n",
            "Loss:0.5364314913749695\n",
            "Loss:0.5363267660140991\n",
            "Epoch: 180 | Loss: 0.5363267660140991 | Test loss: 0.5652817487716675\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7581]])), ('linear_layer.bias', tensor([0.8136]))])\n",
            "Loss:0.5362221002578735\n",
            "Loss:0.536117434501648\n",
            "Loss:0.5360126495361328\n",
            "Loss:0.5359078645706177\n",
            "Loss:0.5358031988143921\n",
            "Loss:0.5356984734535217\n",
            "Loss:0.5355938076972961\n",
            "Loss:0.5354890823364258\n",
            "Loss:0.5353842973709106\n",
            "Loss:0.5352795720100403\n",
            "Epoch: 190 | Loss: 0.5352795720100403 | Test loss: 0.5640572309494019\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7578]])), ('linear_layer.bias', tensor([0.8126]))])\n",
            "Loss:0.5351747870445251\n",
            "Loss:0.5350701212882996\n",
            "Loss:0.5349653363227844\n",
            "Loss:0.5348607301712036\n",
            "Loss:0.5347558259963989\n",
            "Loss:0.5346511602401733\n",
            "Loss:0.534546434879303\n",
            "Loss:0.5344417095184326\n",
            "Loss:0.5343369245529175\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.587317943572998\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5550673604011536\n",
            "Loss:0.5549567937850952\n",
            "Loss:0.5548462867736816\n",
            "Loss:0.5547357201576233\n",
            "Loss:0.5546250939369202\n",
            "Loss:0.5545145273208618\n",
            "Loss:0.554404079914093\n",
            "Loss:0.5542934536933899\n",
            "Loss:0.5541828870773315\n",
            "Loss:0.554072380065918\n",
            "Epoch: 10 | Loss: 0.554072380065918 | Test loss: 0.5860251188278198\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7641]])), ('linear_layer.bias', tensor([0.8290]))])\n",
            "Loss:0.5539618134498596\n",
            "Loss:0.5538511872291565\n",
            "Loss:0.5537406206130981\n",
            "Loss:0.5536300539970398\n",
            "Loss:0.5535195469856262\n",
            "Loss:0.5534089207649231\n",
            "Loss:0.5532983541488647\n",
            "Loss:0.5531878471374512\n",
            "Loss:0.553077220916748\n",
            "Loss:0.5529667139053345\n",
            "Epoch: 20 | Loss: 0.5529667139053345 | Test loss: 0.5847324132919312\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7638]])), ('linear_layer.bias', tensor([0.8280]))])\n",
            "Loss:0.5528560876846313\n",
            "Loss:0.5527455806732178\n",
            "Loss:0.5526350140571594\n",
            "Loss:0.5525244474411011\n",
            "Loss:0.552413821220398\n",
            "Loss:0.5523033142089844\n",
            "Loss:0.5521928071975708\n",
            "Loss:0.5520821809768677\n",
            "Loss:0.5519716143608093\n",
            "Loss:0.5518611073493958\n",
            "Epoch: 30 | Loss: 0.5518611073493958 | Test loss: 0.5834395885467529\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7634]])), ('linear_layer.bias', tensor([0.8270]))])\n",
            "Loss:0.5517505407333374\n",
            "Loss:0.5516399145126343\n",
            "Loss:0.5515294075012207\n",
            "Loss:0.5514189004898071\n",
            "Loss:0.551308274269104\n",
            "Loss:0.5511976480484009\n",
            "Loss:0.5510872602462769\n",
            "Loss:0.5509766340255737\n",
            "Loss:0.5508660078048706\n",
            "Loss:0.5507554411888123\n",
            "Epoch: 40 | Loss: 0.5507554411888123 | Test loss: 0.5821468234062195\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7630]])), ('linear_layer.bias', tensor([0.8261]))])\n",
            "Loss:0.5506449341773987\n",
            "Loss:0.5505343675613403\n",
            "Loss:0.5504237413406372\n",
            "Loss:0.5503132343292236\n",
            "Loss:0.5502026677131653\n",
            "Loss:0.5500921010971069\n",
            "Loss:0.5499815344810486\n",
            "Loss:0.5498709082603455\n",
            "Loss:0.5497604012489319\n",
            "Loss:0.5496498942375183\n",
            "Epoch: 50 | Loss: 0.5496498942375183 | Test loss: 0.580854058265686\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8251]))])\n",
            "Loss:0.5495392680168152\n",
            "Loss:0.5494286417961121\n",
            "Loss:0.5493181943893433\n",
            "Loss:0.5492076277732849\n",
            "Loss:0.549096941947937\n",
            "Loss:0.5489864945411682\n",
            "Loss:0.5488759279251099\n",
            "Loss:0.5487653017044067\n",
            "Loss:0.5486547946929932\n",
            "Loss:0.5485442876815796\n",
            "Epoch: 60 | Loss: 0.5485442876815796 | Test loss: 0.5795612931251526\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7623]])), ('linear_layer.bias', tensor([0.8242]))])\n",
            "Loss:0.5484336614608765\n",
            "Loss:0.5483230352401733\n",
            "Loss:0.5482125282287598\n",
            "Loss:0.5481020212173462\n",
            "Loss:0.5479913949966431\n",
            "Loss:0.5478808283805847\n",
            "Loss:0.5477703213691711\n",
            "Loss:0.5476597547531128\n",
            "Loss:0.5475491285324097\n",
            "Loss:0.5474385023117065\n",
            "Epoch: 70 | Loss: 0.5474385023117065 | Test loss: 0.5782685279846191\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7619]])), ('linear_layer.bias', tensor([0.8232]))])\n",
            "Loss:0.5473280549049377\n",
            "Loss:0.5472174882888794\n",
            "Loss:0.547106921672821\n",
            "Loss:0.5469963550567627\n",
            "Loss:0.5468857884407043\n",
            "Loss:0.546775221824646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|        | 20/100 [00:06<00:24,  3.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5466646552085876\n",
            "Loss:0.5465540885925293\n",
            "Loss:0.546443521976471\n",
            "Loss:0.5463330149650574\n",
            "Epoch: 80 | Loss: 0.5463330149650574 | Test loss: 0.5769757032394409\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7615]])), ('linear_layer.bias', tensor([0.8222]))])\n",
            "Loss:0.546222448348999\n",
            "Loss:0.5461118817329407\n",
            "Loss:0.5460013151168823\n",
            "Loss:0.545890748500824\n",
            "Loss:0.5457801818847656\n",
            "Loss:0.5456696152687073\n",
            "Loss:0.5455591082572937\n",
            "Loss:0.5454484820365906\n",
            "Loss:0.5453378558158875\n",
            "Loss:0.5452274084091187\n",
            "Epoch: 90 | Loss: 0.5452274084091187 | Test loss: 0.5756829977035522\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7611]])), ('linear_layer.bias', tensor([0.8213]))])\n",
            "Loss:0.5451168417930603\n",
            "Loss:0.545006275177002\n",
            "Loss:0.5448956489562988\n",
            "Loss:0.5447851419448853\n",
            "Loss:0.5446745157241821\n",
            "Loss:0.5445639491081238\n",
            "Loss:0.5444534420967102\n",
            "Loss:0.5443428754806519\n",
            "Loss:0.5442323088645935\n",
            "Loss:0.5441218018531799\n",
            "Epoch: 100 | Loss: 0.5441218018531799 | Test loss: 0.574390172958374\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7608]])), ('linear_layer.bias', tensor([0.8203]))])\n",
            "Loss:0.5440111756324768\n",
            "Loss:0.5439006090164185\n",
            "Loss:0.5437900424003601\n",
            "Loss:0.5436795353889465\n",
            "Loss:0.5435689091682434\n",
            "Loss:0.5434583425521851\n",
            "Loss:0.5433478355407715\n",
            "Loss:0.5432372093200684\n",
            "Loss:0.5431267023086548\n",
            "Loss:0.5430161356925964\n",
            "Epoch: 110 | Loss: 0.5430161356925964 | Test loss: 0.5730974078178406\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7604]])), ('linear_layer.bias', tensor([0.8194]))])\n",
            "Loss:0.5429055690765381\n",
            "Loss:0.5427950024604797\n",
            "Loss:0.5426845550537109\n",
            "Loss:0.5425739288330078\n",
            "Loss:0.5424633026123047\n",
            "Loss:0.5423527359962463\n",
            "Loss:0.5422422289848328\n",
            "Loss:0.5421316623687744\n",
            "Loss:0.5420210957527161\n",
            "Loss:0.5419104695320129\n",
            "Epoch: 120 | Loss: 0.5419104695320129 | Test loss: 0.5718046426773071\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7600]])), ('linear_layer.bias', tensor([0.8184]))])\n",
            "Loss:0.5417999029159546\n",
            "Loss:0.541689395904541\n",
            "Loss:0.5415787696838379\n",
            "Loss:0.5414682626724243\n",
            "Loss:0.5413576364517212\n",
            "Loss:0.5412471890449524\n",
            "Loss:0.541136622428894\n",
            "Loss:0.5410259962081909\n",
            "Loss:0.5409154891967773\n",
            "Loss:0.5408048629760742\n",
            "Epoch: 130 | Loss: 0.5408048629760742 | Test loss: 0.5705118179321289\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7596]])), ('linear_layer.bias', tensor([0.8174]))])\n",
            "Loss:0.5406943559646606\n",
            "Loss:0.5405837297439575\n",
            "Loss:0.5404731631278992\n",
            "Loss:0.5403626561164856\n",
            "Loss:0.5402520895004272\n",
            "Loss:0.5401415228843689\n",
            "Loss:0.5400310158729553\n",
            "Loss:0.539920449256897\n",
            "Loss:0.5398098230361938\n",
            "Loss:0.539699375629425\n",
            "Epoch: 140 | Loss: 0.539699375629425 | Test loss: 0.5692190527915955\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7593]])), ('linear_layer.bias', tensor([0.8165]))])\n",
            "Loss:0.5395887494087219\n",
            "Loss:0.5394781231880188\n",
            "Loss:0.5393675565719604\n",
            "Loss:0.5392571091651917\n",
            "Loss:0.5391464829444885\n",
            "Loss:0.5390359163284302\n",
            "Loss:0.538925290107727\n",
            "Loss:0.5388147830963135\n",
            "Loss:0.5387042164802551\n",
            "Loss:0.5385936498641968\n",
            "Epoch: 150 | Loss: 0.5385936498641968 | Test loss: 0.567926287651062\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7589]])), ('linear_layer.bias', tensor([0.8155]))])\n",
            "Loss:0.5384830236434937\n",
            "Loss:0.5383725762367249\n",
            "Loss:0.5382620096206665\n",
            "Loss:0.5381513833999634\n",
            "Loss:0.538040816783905\n",
            "Loss:0.5379303693771362\n",
            "Loss:0.5378197431564331\n",
            "Loss:0.53770911693573\n",
            "Loss:0.5375986099243164\n",
            "Loss:0.5374881029129028\n",
            "Epoch: 160 | Loss: 0.5374881029129028 | Test loss: 0.5666335225105286\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7585]])), ('linear_layer.bias', tensor([0.8146]))])\n",
            "Loss:0.5373774766921997\n",
            "Loss:0.5372669100761414\n",
            "Loss:0.5371564030647278\n",
            "Loss:0.5370458364486694\n",
            "Loss:0.5369352102279663\n",
            "Loss:0.5368247032165527\n",
            "Loss:0.5367141366004944\n",
            "Loss:0.536603569984436\n",
            "Loss:0.5364929437637329\n",
            "Loss:0.5363823771476746\n",
            "Epoch: 170 | Loss: 0.5363823771476746 | Test loss: 0.5653407573699951\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7581]])), ('linear_layer.bias', tensor([0.8136]))])\n",
            "Loss:0.536271870136261\n",
            "Loss:0.5361613035202026\n",
            "Loss:0.5360506772994995\n",
            "Loss:0.5359401702880859\n",
            "Loss:0.5358296632766724\n",
            "Loss:0.5357190370559692\n",
            "Loss:0.5356084704399109\n",
            "Loss:0.5354979634284973\n",
            "Loss:0.535387396812439\n",
            "Loss:0.5352767705917358\n",
            "Epoch: 180 | Loss: 0.5352767705917358 | Test loss: 0.5640479326248169\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7578]])), ('linear_layer.bias', tensor([0.8126]))])\n",
            "Loss:0.5351662039756775\n",
            "Loss:0.5350556969642639\n",
            "Loss:0.5349451303482056\n",
            "Loss:0.5348345637321472\n",
            "Loss:0.5347239971160889\n",
            "Loss:0.5346134305000305\n",
            "Loss:0.5345028638839722\n",
            "Loss:0.5343923568725586\n",
            "Loss:0.5342816710472107\n",
            "Loss:0.5341712236404419\n",
            "Epoch: 190 | Loss: 0.5341712236404419 | Test loss: 0.5627552270889282\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7574]])), ('linear_layer.bias', tensor([0.8117]))])\n",
            "Loss:0.5340605974197388\n",
            "Loss:0.5339500308036804\n",
            "Loss:0.5338395237922668\n",
            "Loss:0.5337289571762085\n",
            "Loss:0.5336183309555054\n",
            "Loss:0.533507764339447\n",
            "Loss:0.5333972573280334\n",
            "Loss:0.5332866907119751\n",
            "Loss:0.5331761240959167\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5873111486434937\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5550615191459656\n",
            "Loss:0.5549451112747192\n",
            "Loss:0.5548287630081177\n",
            "Loss:0.5547123551368713\n",
            "Loss:0.554595947265625\n",
            "Loss:0.5544795989990234\n",
            "Loss:0.5543631315231323\n",
            "Loss:0.5542467832565308\n",
            "Loss:0.5541303753852844\n",
            "Loss:0.5540139675140381\n",
            "Epoch: 10 | Loss: 0.5540139675140381 | Test loss: 0.5859501957893372\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7641]])), ('linear_layer.bias', tensor([0.8289]))])\n",
            "Loss:0.5538976788520813\n",
            "Loss:0.5537811517715454\n",
            "Loss:0.5536648035049438\n",
            "Loss:0.5535484552383423\n",
            "Loss:0.5534319281578064\n",
            "Loss:0.5533155798912048\n",
            "Loss:0.5531991720199585\n",
            "Loss:0.5530828237533569\n",
            "Loss:0.5529664158821106\n",
            "Loss:0.552850067615509\n",
            "Epoch: 20 | Loss: 0.552850067615509 | Test loss: 0.5845892429351807\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7637]])), ('linear_layer.bias', tensor([0.8279]))])\n",
            "Loss:0.5527336001396179\n",
            "Loss:0.5526171922683716\n",
            "Loss:0.55250084400177\n",
            "Loss:0.5523844957351685\n",
            "Loss:0.5522680282592773\n",
            "Loss:0.5521516799926758\n",
            "Loss:0.5520352125167847\n",
            "Loss:0.5519188642501831\n",
            "Loss:0.5518024563789368\n",
            "Loss:0.5516861081123352\n",
            "Epoch: 30 | Loss: 0.5516861081123352 | Test loss: 0.5832282900810242\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8269]))])\n",
            "Loss:0.5515696406364441\n",
            "Loss:0.5514532923698425\n",
            "Loss:0.5513368844985962\n",
            "Loss:0.5512205362319946\n",
            "Loss:0.5511040687561035\n",
            "Loss:0.5509876608848572\n",
            "Loss:0.5508712530136108\n",
            "Loss:0.5507549047470093\n",
            "Loss:0.5506385564804077\n",
            "Loss:0.5505220293998718\n",
            "Epoch: 40 | Loss: 0.5505220293998718 | Test loss: 0.5818673372268677\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7629]])), ('linear_layer.bias', tensor([0.8259]))])\n",
            "Loss:0.5504056811332703\n",
            "Loss:0.5502893328666687\n",
            "Loss:0.5501728653907776\n",
            "Loss:0.5500565767288208\n",
            "Loss:0.5499401688575745\n",
            "Loss:0.5498237609863281\n",
            "Loss:0.5497073531150818\n",
            "Loss:0.5495909452438354\n",
            "Loss:0.5494745969772339\n",
            "Loss:0.5493581295013428\n",
            "Epoch: 50 | Loss: 0.5493581295013428 | Test loss: 0.580506443977356\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7625]])), ('linear_layer.bias', tensor([0.8249]))])\n",
            "Loss:0.5492417216300964\n",
            "Loss:0.5491253733634949\n",
            "Loss:0.5490089654922485\n",
            "Loss:0.548892617225647\n",
            "Loss:0.5487762093544006\n",
            "Loss:0.5486598610877991\n",
            "Loss:0.5485433340072632\n",
            "Loss:0.5484269857406616\n",
            "Loss:0.5483106374740601\n",
            "Loss:0.548194169998169\n",
            "Epoch: 60 | Loss: 0.548194169998169 | Test loss: 0.5791453719139099\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7621]])), ('linear_layer.bias', tensor([0.8238]))])\n",
            "Loss:0.5480778217315674\n",
            "Loss:0.547961413860321\n",
            "Loss:0.5478450059890747\n",
            "Loss:0.5477286577224731\n",
            "Loss:0.5476123094558716\n",
            "Loss:0.5474957823753357\n",
            "Loss:0.5473794341087341\n",
            "Loss:0.5472630262374878\n",
            "Loss:0.5471466183662415\n",
            "Loss:0.5470303297042847\n",
            "Epoch: 70 | Loss: 0.5470303297042847 | Test loss: 0.5777844786643982\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7617]])), ('linear_layer.bias', tensor([0.8228]))])\n",
            "Loss:0.5469139218330383\n",
            "Loss:0.5467973947525024\n",
            "Loss:0.5466810464859009\n",
            "Loss:0.5465646982192993\n",
            "Loss:0.546448290348053\n",
            "Loss:0.5463319420814514\n",
            "Loss:0.5462154746055603\n",
            "Loss:0.546099066734314\n",
            "Loss:0.5459827184677124\n",
            "Loss:0.5458663105964661\n",
            "Epoch: 80 | Loss: 0.5458663105964661 | Test loss: 0.5764234662055969\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7613]])), ('linear_layer.bias', tensor([0.8218]))])\n",
            "Loss:0.545749843120575\n",
            "Loss:0.5456334948539734\n",
            "Loss:0.545517086982727\n",
            "Loss:0.5454007387161255\n",
            "Loss:0.5452842712402344\n",
            "Loss:0.5451679229736328\n",
            "Loss:0.5450515747070312\n",
            "Loss:0.5449352264404297\n",
            "Loss:0.5448187589645386\n",
            "Loss:0.544702410697937\n",
            "Epoch: 90 | Loss: 0.544702410697937 | Test loss: 0.57506263256073\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7610]])), ('linear_layer.bias', tensor([0.8208]))])\n",
            "Loss:0.5445859432220459\n",
            "Loss:0.5444695353507996\n",
            "Loss:0.544353187084198\n",
            "Loss:0.5442367792129517\n",
            "Loss:0.5441203713417053\n",
            "Loss:0.544003963470459\n",
            "Loss:0.5438875555992126\n",
            "Loss:0.5437711477279663\n",
            "Loss:0.54365473985672\n",
            "Loss:0.5435383915901184\n",
            "Epoch: 100 | Loss: 0.5435383915901184 | Test loss: 0.5737016797065735\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7606]])), ('linear_layer.bias', tensor([0.8198]))])\n",
            "Loss:0.5434220433235168\n",
            "Loss:0.5433055758476257\n",
            "Loss:0.5431891679763794\n",
            "Loss:0.5430728197097778\n",
            "Loss:0.5429564714431763\n",
            "Loss:0.5428400039672852\n",
            "Loss:0.5427237153053284\n",
            "Loss:0.5426071882247925\n",
            "Loss:0.5424908399581909\n",
            "Loss:0.5423744916915894\n",
            "Epoch: 110 | Loss: 0.5423744916915894 | Test loss: 0.5723406672477722\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7602]])), ('linear_layer.bias', tensor([0.8188]))])\n",
            "Loss:0.542258083820343\n",
            "Loss:0.5421416759490967\n",
            "Loss:0.5420252084732056\n",
            "Loss:0.541908860206604\n",
            "Loss:0.5417925119400024\n",
            "Loss:0.5416761040687561\n",
            "Loss:0.541559636592865\n",
            "Loss:0.5414432287216187\n",
            "Loss:0.5413268804550171\n",
            "Loss:0.5412104725837708\n",
            "Epoch: 120 | Loss: 0.5412104725837708 | Test loss: 0.5709797739982605\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7598]])), ('linear_layer.bias', tensor([0.8178]))])\n",
            "Loss:0.5410941243171692\n",
            "Loss:0.5409777760505676\n",
            "Loss:0.5408612489700317\n",
            "Loss:0.5407449007034302\n",
            "Loss:0.5406284928321838\n",
            "Loss:0.5405121445655823\n",
            "Loss:0.5403957366943359\n",
            "Loss:0.5402792692184448\n",
            "Loss:0.5401629209518433\n",
            "Loss:0.5400465726852417\n",
            "Epoch: 130 | Loss: 0.5400465726852417 | Test loss: 0.569618821144104\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7594]])), ('linear_layer.bias', tensor([0.8168]))])\n",
            "Loss:0.5399301052093506\n",
            "Loss:0.539813756942749\n",
            "Loss:0.5396974086761475\n",
            "Loss:0.5395809412002563\n",
            "Loss:0.5394645929336548\n",
            "Loss:0.5393482446670532\n",
            "Loss:0.5392317771911621\n",
            "Loss:0.5391153693199158\n",
            "Loss:0.5389989614486694\n",
            "Loss:0.5388826131820679\n",
            "Epoch: 140 | Loss: 0.5388826131820679 | Test loss: 0.5682578086853027\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7590]])), ('linear_layer.bias', tensor([0.8158]))])\n",
            "Loss:0.5387662053108215\n",
            "Loss:0.53864985704422\n",
            "Loss:0.5385333895683289\n",
            "Loss:0.5384169816970825\n",
            "Loss:0.538300633430481\n",
            "Loss:0.5381842255592346\n",
            "Loss:0.5380678772926331\n",
            "Loss:0.5379514098167419\n",
            "Loss:0.5378350019454956\n",
            "Loss:0.537718653678894\n",
            "Epoch: 150 | Loss: 0.537718653678894 | Test loss: 0.566896915435791\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7586]])), ('linear_layer.bias', tensor([0.8148]))])\n",
            "Loss:0.5376022458076477\n",
            "Loss:0.5374857783317566\n",
            "Loss:0.537369430065155\n",
            "Loss:0.5372530221939087\n",
            "Loss:0.5371366739273071\n",
            "Loss:0.5370202660560608\n",
            "Loss:0.5369038581848145\n",
            "Loss:0.5367874503135681\n",
            "Loss:0.5366710424423218\n",
            "Loss:0.5365546941757202\n",
            "Epoch: 160 | Loss: 0.5365546941757202 | Test loss: 0.5655359029769897\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7582]])), ('linear_layer.bias', tensor([0.8137]))])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|        | 21/100 [00:06<00:24,  3.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5364382863044739\n",
            "Loss:0.5363218188285828\n",
            "Loss:0.5362054705619812\n",
            "Loss:0.5360891222953796\n",
            "Loss:0.5359726548194885\n",
            "Loss:0.5358562469482422\n",
            "Loss:0.5357398986816406\n",
            "Loss:0.5356234908103943\n",
            "Loss:0.535507082939148\n",
            "Loss:0.5353907346725464\n",
            "Epoch: 170 | Loss: 0.5353907346725464 | Test loss: 0.564175009727478\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7578]])), ('linear_layer.bias', tensor([0.8127]))])\n",
            "Loss:0.5352743864059448\n",
            "Loss:0.5351579189300537\n",
            "Loss:0.5350415110588074\n",
            "Loss:0.5349251627922058\n",
            "Loss:0.5348087549209595\n",
            "Loss:0.5346923470497131\n",
            "Loss:0.5345759391784668\n",
            "Loss:0.5344595909118652\n",
            "Loss:0.5343431234359741\n",
            "Loss:0.5342267751693726\n",
            "Epoch: 180 | Loss: 0.5342267751693726 | Test loss: 0.5628140568733215\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7574]])), ('linear_layer.bias', tensor([0.8117]))])\n",
            "Loss:0.5341103672981262\n",
            "Loss:0.5339940190315247\n",
            "Loss:0.5338776111602783\n",
            "Loss:0.533761203289032\n",
            "Loss:0.5336447954177856\n",
            "Loss:0.5335284471511841\n",
            "Loss:0.533411979675293\n",
            "Loss:0.5332955718040466\n",
            "Loss:0.5331791639328003\n",
            "Loss:0.5330628156661987\n",
            "Epoch: 190 | Loss: 0.5330628156661987 | Test loss: 0.561453104019165\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7570]])), ('linear_layer.bias', tensor([0.8107]))])\n",
            "Loss:0.5329464673995972\n",
            "Loss:0.5328300595283508\n",
            "Loss:0.5327135920524597\n",
            "Loss:0.5325971841812134\n",
            "Loss:0.5324808359146118\n",
            "Loss:0.5323644280433655\n",
            "Loss:0.5322480797767639\n",
            "Loss:0.5321316719055176\n",
            "Loss:0.5320152640342712\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5873042941093445\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5550557374954224\n",
            "Loss:0.5549335479736328\n",
            "Loss:0.554811418056488\n",
            "Loss:0.5546892285346985\n",
            "Loss:0.5545669794082642\n",
            "Loss:0.5544449090957642\n",
            "Loss:0.5543227195739746\n",
            "Loss:0.5542005300521851\n",
            "Loss:0.5540784597396851\n",
            "Loss:0.5539562106132507\n",
            "Epoch: 10 | Loss: 0.5539562106132507 | Test loss: 0.5858758687973022\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7641]])), ('linear_layer.bias', tensor([0.8288]))])\n",
            "Loss:0.5538340210914612\n",
            "Loss:0.5537119507789612\n",
            "Loss:0.5535897612571716\n",
            "Loss:0.5534675717353821\n",
            "Loss:0.5533454418182373\n",
            "Loss:0.5532232522964478\n",
            "Loss:0.5531010031700134\n",
            "Loss:0.5529788732528687\n",
            "Loss:0.5528566837310791\n",
            "Loss:0.5527344942092896\n",
            "Epoch: 20 | Loss: 0.5527344942092896 | Test loss: 0.5844472646713257\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7637]])), ('linear_layer.bias', tensor([0.8278]))])\n",
            "Loss:0.5526124238967896\n",
            "Loss:0.552490234375\n",
            "Loss:0.5523680448532104\n",
            "Loss:0.5522457957267761\n",
            "Loss:0.5521236658096313\n",
            "Loss:0.5520014762878418\n",
            "Loss:0.551879346370697\n",
            "Loss:0.5517572164535522\n",
            "Loss:0.5516350269317627\n",
            "Loss:0.5515128374099731\n",
            "Epoch: 30 | Loss: 0.5515128374099731 | Test loss: 0.5830187797546387\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8267]))])\n",
            "Loss:0.5513907074928284\n",
            "Loss:0.551268458366394\n",
            "Loss:0.5511462688446045\n",
            "Loss:0.5510242581367493\n",
            "Loss:0.5509020090103149\n",
            "Loss:0.5507798194885254\n",
            "Loss:0.5506576299667358\n",
            "Loss:0.5505355000495911\n",
            "Loss:0.5504133105278015\n",
            "Loss:0.5502911806106567\n",
            "Epoch: 40 | Loss: 0.5502911806106567 | Test loss: 0.5815902948379517\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7628]])), ('linear_layer.bias', tensor([0.8257]))])\n",
            "Loss:0.5501689910888672\n",
            "Loss:0.5500468015670776\n",
            "Loss:0.5499246120452881\n",
            "Loss:0.5498024821281433\n",
            "Loss:0.5496802926063538\n",
            "Loss:0.549558162689209\n",
            "Loss:0.5494359731674194\n",
            "Loss:0.5493138432502747\n",
            "Loss:0.5491916537284851\n",
            "Loss:0.5490695238113403\n",
            "Epoch: 50 | Loss: 0.5490695238113403 | Test loss: 0.5801617503166199\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7624]])), ('linear_layer.bias', tensor([0.8246]))])\n",
            "Loss:0.548947274684906\n",
            "Loss:0.5488251447677612\n",
            "Loss:0.5487030148506165\n",
            "Loss:0.5485807657241821\n",
            "Loss:0.5484585762023926\n",
            "Loss:0.5483365058898926\n",
            "Loss:0.548214316368103\n",
            "Loss:0.5480921268463135\n",
            "Loss:0.5479699373245239\n",
            "Loss:0.5478477478027344\n",
            "Epoch: 60 | Loss: 0.5478477478027344 | Test loss: 0.5787332057952881\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7620]])), ('linear_layer.bias', tensor([0.8235]))])\n",
            "Loss:0.5477255582809448\n",
            "Loss:0.5476034283638\n",
            "Loss:0.5474812984466553\n",
            "Loss:0.5473591089248657\n",
            "Loss:0.5472369194030762\n",
            "Loss:0.5471147298812866\n",
            "Loss:0.5469925999641418\n",
            "Loss:0.5468704104423523\n",
            "Loss:0.5467482805252075\n",
            "Loss:0.546626091003418\n",
            "Epoch: 70 | Loss: 0.546626091003418 | Test loss: 0.5773047208786011\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7616]])), ('linear_layer.bias', tensor([0.8225]))])\n",
            "Loss:0.5465039014816284\n",
            "Loss:0.5463818311691284\n",
            "Loss:0.5462595820426941\n",
            "Loss:0.5461374521255493\n",
            "Loss:0.5460152626037598\n",
            "Loss:0.5458930730819702\n",
            "Loss:0.5457708835601807\n",
            "Loss:0.5456486940383911\n",
            "Loss:0.5455266237258911\n",
            "Loss:0.5454043745994568\n",
            "Epoch: 80 | Loss: 0.5454043745994568 | Test loss: 0.5758762359619141\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7612]])), ('linear_layer.bias', tensor([0.8214]))])\n",
            "Loss:0.545282244682312\n",
            "Loss:0.5451600551605225\n",
            "Loss:0.5450378656387329\n",
            "Loss:0.5449157357215881\n",
            "Loss:0.5447935461997986\n",
            "Loss:0.544671356678009\n",
            "Loss:0.5445492267608643\n",
            "Loss:0.5444270372390747\n",
            "Loss:0.5443049073219299\n",
            "Loss:0.5441826581954956\n",
            "Epoch: 90 | Loss: 0.5441826581954956 | Test loss: 0.5744476914405823\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7608]])), ('linear_layer.bias', tensor([0.8204]))])\n",
            "Loss:0.5440605282783508\n",
            "Loss:0.5439383387565613\n",
            "Loss:0.5438162088394165\n",
            "Loss:0.5436940789222717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|       | 22/100 [00:06<00:23,  3.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5435718297958374\n",
            "Loss:0.5434496998786926\n",
            "Loss:0.5433274507522583\n",
            "Loss:0.5432053804397583\n",
            "Loss:0.543083131313324\n",
            "Loss:0.5429610013961792\n",
            "Epoch: 100 | Loss: 0.5429610013961792 | Test loss: 0.5730191469192505\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7604]])), ('linear_layer.bias', tensor([0.8193]))])\n",
            "Loss:0.5428389310836792\n",
            "Loss:0.5427166223526001\n",
            "Loss:0.5425945520401001\n",
            "Loss:0.5424723625183105\n",
            "Loss:0.5423501133918762\n",
            "Loss:0.5422280430793762\n",
            "Loss:0.5421057939529419\n",
            "Loss:0.5419836640357971\n",
            "Loss:0.5418614745140076\n",
            "Loss:0.5417393445968628\n",
            "Epoch: 110 | Loss: 0.5417393445968628 | Test loss: 0.5715906620025635\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7599]])), ('linear_layer.bias', tensor([0.8182]))])\n",
            "Loss:0.5416170954704285\n",
            "Loss:0.5414949655532837\n",
            "Loss:0.5413728356361389\n",
            "Loss:0.5412506461143494\n",
            "Loss:0.5411284565925598\n",
            "Loss:0.541006326675415\n",
            "Loss:0.5408840775489807\n",
            "Loss:0.5407618880271912\n",
            "Loss:0.5406397581100464\n",
            "Loss:0.5405176281929016\n",
            "Epoch: 120 | Loss: 0.5405176281929016 | Test loss: 0.5701621174812317\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7595]])), ('linear_layer.bias', tensor([0.8172]))])\n",
            "Loss:0.5403954982757568\n",
            "Loss:0.5402733087539673\n",
            "Loss:0.5401511192321777\n",
            "Loss:0.5400289297103882\n",
            "Loss:0.5399067997932434\n",
            "Loss:0.5397846102714539\n",
            "Loss:0.5396624207496643\n",
            "Loss:0.5395402908325195\n",
            "Loss:0.53941810131073\n",
            "Loss:0.5392958521842957\n",
            "Epoch: 130 | Loss: 0.5392958521842957 | Test loss: 0.5687335729598999\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7591]])), ('linear_layer.bias', tensor([0.8161]))])\n",
            "Loss:0.5391737818717957\n",
            "Loss:0.5390516519546509\n",
            "Loss:0.5389294028282166\n",
            "Loss:0.5388072729110718\n",
            "Loss:0.5386850833892822\n",
            "Loss:0.5385628938674927\n",
            "Loss:0.5384407639503479\n",
            "Loss:0.5383185148239136\n",
            "Loss:0.5381963849067688\n",
            "Loss:0.5380741953849792\n",
            "Epoch: 140 | Loss: 0.5380741953849792 | Test loss: 0.5673050284385681\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7587]])), ('linear_layer.bias', tensor([0.8151]))])\n",
            "Loss:0.5379520654678345\n",
            "Loss:0.5378298759460449\n",
            "Loss:0.5377076864242554\n",
            "Loss:0.5375856161117554\n",
            "Loss:0.537463366985321\n",
            "Loss:0.5373412370681763\n",
            "Loss:0.5372191071510315\n",
            "Loss:0.5370969176292419\n",
            "Loss:0.5369747281074524\n",
            "Loss:0.5368524789810181\n",
            "Epoch: 150 | Loss: 0.5368524789810181 | Test loss: 0.5658765435218811\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7583]])), ('linear_layer.bias', tensor([0.8140]))])\n",
            "Loss:0.5367304086685181\n",
            "Loss:0.536608099937439\n",
            "Loss:0.536486029624939\n",
            "Loss:0.5363638997077942\n",
            "Loss:0.5362416505813599\n",
            "Loss:0.5361195802688599\n",
            "Loss:0.5359973907470703\n",
            "Loss:0.5358752012252808\n",
            "Loss:0.535753071308136\n",
            "Loss:0.5356308817863464\n",
            "Epoch: 160 | Loss: 0.5356308817863464 | Test loss: 0.5644479990005493\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7579]])), ('linear_layer.bias', tensor([0.8129]))])\n",
            "Loss:0.5355086922645569\n",
            "Loss:0.5353865027427673\n",
            "Loss:0.5352643728256226\n",
            "Loss:0.5351421236991882\n",
            "Loss:0.5350199937820435\n",
            "Loss:0.5348979234695435\n",
            "Loss:0.5347756147384644\n",
            "Loss:0.5346535444259644\n",
            "Loss:0.5345313549041748\n",
            "Loss:0.5344091653823853\n",
            "Epoch: 170 | Loss: 0.5344091653823853 | Test loss: 0.5630195140838623\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7575]])), ('linear_layer.bias', tensor([0.8119]))])\n",
            "Loss:0.5342869758605957\n",
            "Loss:0.5341647863388062\n",
            "Loss:0.5340426564216614\n",
            "Loss:0.5339204668998718\n",
            "Loss:0.533798336982727\n",
            "Loss:0.5336761474609375\n",
            "Loss:0.533553957939148\n",
            "Loss:0.5334317684173584\n",
            "Loss:0.5333096385002136\n",
            "Loss:0.5331875085830688\n",
            "Epoch: 180 | Loss: 0.5331875085830688 | Test loss: 0.5615910291671753\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7571]])), ('linear_layer.bias', tensor([0.8108]))])\n",
            "Loss:0.5330653190612793\n",
            "Loss:0.5329431295394897\n",
            "Loss:0.532820999622345\n",
            "Loss:0.5326987504959106\n",
            "Loss:0.5325766205787659\n",
            "Loss:0.5324543714523315\n",
            "Loss:0.5323323011398315\n",
            "Loss:0.5322101712226868\n",
            "Loss:0.5320879220962524\n",
            "Loss:0.5319657921791077\n",
            "Epoch: 190 | Loss: 0.5319657921791077 | Test loss: 0.5601624250411987\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7566]])), ('linear_layer.bias', tensor([0.8098]))])\n",
            "Loss:0.5318436026573181\n",
            "Loss:0.5317214131355286\n",
            "Loss:0.531599223613739\n",
            "Loss:0.531477153301239\n",
            "Loss:0.5313549637794495\n",
            "Loss:0.5312327146530151\n",
            "Loss:0.5311106443405151\n",
            "Loss:0.5309883952140808\n",
            "Loss:0.530866265296936\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5872975587844849\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5550499558448792\n",
            "Loss:0.5549219250679016\n",
            "Loss:0.5547939538955688\n",
            "Loss:0.5546659231185913\n",
            "Loss:0.5545378923416138\n",
            "Loss:0.554409921169281\n",
            "Loss:0.5542818903923035\n",
            "Loss:0.5541539192199707\n",
            "Loss:0.5540259480476379\n",
            "Loss:0.5538979768753052\n",
            "Epoch: 10 | Loss: 0.5538979768753052 | Test loss: 0.5858008861541748\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7641]])), ('linear_layer.bias', tensor([0.8288]))])\n",
            "Loss:0.5537699460983276\n",
            "Loss:0.5536419153213501\n",
            "Loss:0.5535138845443726\n",
            "Loss:0.553385853767395\n",
            "Loss:0.5532578825950623\n",
            "Loss:0.5531298518180847\n",
            "Loss:0.5530019402503967\n",
            "Loss:0.5528739094734192\n",
            "Loss:0.5527458786964417\n",
            "Loss:0.5526178479194641\n",
            "Epoch: 20 | Loss: 0.5526178479194641 | Test loss: 0.58430415391922\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7636]])), ('linear_layer.bias', tensor([0.8277]))])\n",
            "Loss:0.5524898767471313\n",
            "Loss:0.5523618459701538\n",
            "Loss:0.552233874797821\n",
            "Loss:0.5521057844161987\n",
            "Loss:0.5519778728485107\n",
            "Loss:0.5518498420715332\n",
            "Loss:0.5517218708992004\n",
            "Loss:0.5515937805175781\n",
            "Loss:0.5514658689498901\n",
            "Loss:0.5513378977775574\n",
            "Epoch: 30 | Loss: 0.5513378977775574 | Test loss: 0.5828074812889099\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7632]])), ('linear_layer.bias', tensor([0.8266]))])\n",
            "Loss:0.5512098073959351\n",
            "Loss:0.5510818362236023\n",
            "Loss:0.5509538054466248\n",
            "Loss:0.5508258938789368\n",
            "Loss:0.5506978034973145\n",
            "Loss:0.5505697727203369\n",
            "Loss:0.5504418611526489\n",
            "Loss:0.5503138303756714\n",
            "Loss:0.5501857995986938\n",
            "Loss:0.5500578880310059\n",
            "Epoch: 40 | Loss: 0.5500578880310059 | Test loss: 0.5813108086585999\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7628]])), ('linear_layer.bias', tensor([0.8255]))])\n",
            "Loss:0.5499297976493835\n",
            "Loss:0.5498018264770508\n",
            "Loss:0.549673855304718\n",
            "Loss:0.5495458245277405\n",
            "Loss:0.5494178533554077\n",
            "Loss:0.5492898225784302\n",
            "Loss:0.5491617918014526\n",
            "Loss:0.5490338206291199\n",
            "Loss:0.5489057898521423\n",
            "Loss:0.5487777590751648\n",
            "Epoch: 50 | Loss: 0.5487777590751648 | Test loss: 0.579814076423645\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7623]])), ('linear_layer.bias', tensor([0.8243]))])\n",
            "Loss:0.548649787902832\n",
            "Loss:0.5485217571258545\n",
            "Loss:0.5483938455581665\n",
            "Loss:0.5482657551765442\n",
            "Loss:0.5481377840042114\n",
            "Loss:0.5480097532272339\n",
            "Loss:0.5478817820549011\n",
            "Loss:0.5477537512779236\n",
            "Loss:0.547625720500946\n",
            "Loss:0.5474977493286133\n",
            "Epoch: 60 | Loss: 0.5474977493286133 | Test loss: 0.5783174633979797\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7619]])), ('linear_layer.bias', tensor([0.8232]))])\n",
            "Loss:0.5473697781562805\n",
            "Loss:0.547241747379303\n",
            "Loss:0.5471137762069702\n",
            "Loss:0.5469857454299927\n",
            "Loss:0.5468577742576599\n",
            "Loss:0.5467297434806824\n",
            "Loss:0.5466017723083496\n",
            "Loss:0.5464737415313721\n",
            "Loss:0.5463457703590393\n",
            "Loss:0.5462177395820618\n",
            "Epoch: 70 | Loss: 0.5462177395820618 | Test loss: 0.5768207311630249\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7615]])), ('linear_layer.bias', tensor([0.8221]))])\n",
            "Loss:0.546089768409729\n",
            "Loss:0.5459617376327515\n",
            "Loss:0.5458337068557739\n",
            "Loss:0.5457056760787964\n",
            "Loss:0.5455777049064636\n",
            "Loss:0.5454496741294861\n",
            "Loss:0.5453217625617981\n",
            "Loss:0.5451937317848206\n",
            "Loss:0.545065701007843\n",
            "Loss:0.5449377298355103\n",
            "Epoch: 80 | Loss: 0.5449377298355103 | Test loss: 0.5753239989280701\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7610]])), ('linear_layer.bias', tensor([0.8210]))])\n",
            "Loss:0.5448096990585327\n",
            "Loss:0.5446816682815552\n",
            "Loss:0.5445536971092224\n",
            "Loss:0.5444256067276001\n",
            "Loss:0.5442976951599121\n",
            "Loss:0.5441696643829346\n",
            "Loss:0.5440417528152466\n",
            "Loss:0.5439136624336243\n",
            "Loss:0.5437856912612915\n",
            "Loss:0.543657660484314\n",
            "Epoch: 90 | Loss: 0.543657660484314 | Test loss: 0.57382732629776\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7606]])), ('linear_layer.bias', tensor([0.8199]))])\n",
            "Loss:0.543529748916626\n",
            "Loss:0.5434015989303589\n",
            "Loss:0.5432736873626709\n",
            "Loss:0.5431456565856934\n",
            "Loss:0.5430176854133606\n",
            "Loss:0.5428897142410278\n",
            "Loss:0.5427616834640503\n",
            "Loss:0.5426336526870728\n",
            "Loss:0.5425056219100952\n",
            "Loss:0.5423776507377625\n",
            "Epoch: 100 | Loss: 0.5423776507377625 | Test loss: 0.5723307132720947\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7602]])), ('linear_layer.bias', tensor([0.8188]))])\n",
            "Loss:0.5422496795654297\n",
            "Loss:0.5421216487884521\n",
            "Loss:0.5419937372207642\n",
            "Loss:0.5418656468391418\n",
            "Loss:0.5417376756668091\n",
            "Loss:0.5416096448898315\n",
            "Loss:0.541481614112854\n",
            "Loss:0.5413535833358765\n",
            "Loss:0.5412256717681885\n",
            "Loss:0.5410976409912109\n",
            "Epoch: 110 | Loss: 0.5410976409912109 | Test loss: 0.5708339810371399\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7597]])), ('linear_layer.bias', tensor([0.8177]))])\n",
            "Loss:0.5409696698188782\n",
            "Loss:0.5408415794372559\n",
            "Loss:0.5407136678695679\n",
            "Loss:0.5405855774879456\n",
            "Loss:0.5404576063156128\n",
            "Loss:0.5403295755386353\n",
            "Loss:0.5402016043663025\n",
            "Loss:0.5400735139846802\n",
            "Loss:0.5399456024169922\n",
            "Loss:0.5398175716400146\n",
            "Epoch: 120 | Loss: 0.5398175716400146 | Test loss: 0.5693372488021851\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7593]])), ('linear_layer.bias', tensor([0.8166]))])\n",
            "Loss:0.5396896600723267\n",
            "Loss:0.5395615696907043\n",
            "Loss:0.5394335985183716\n",
            "Loss:0.539305567741394\n",
            "Loss:0.5391775965690613\n",
            "Loss:0.5390495657920837\n",
            "Loss:0.5389215350151062\n",
            "Loss:0.5387935638427734\n",
            "Loss:0.5386655926704407\n",
            "Loss:0.5385375618934631\n",
            "Epoch: 130 | Loss: 0.5385375618934631 | Test loss: 0.5678405165672302\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7589]])), ('linear_layer.bias', tensor([0.8155]))])\n",
            "Loss:0.5384095907211304\n",
            "Loss:0.5382815599441528\n",
            "Loss:0.5381535291671753\n",
            "Loss:0.5380255579948425\n",
            "Loss:0.5378975868225098\n",
            "Loss:0.5377694964408875\n",
            "Loss:0.5376415848731995\n",
            "Loss:0.5375136137008667\n",
            "Loss:0.5373855829238892\n",
            "Loss:0.5372575521469116\n",
            "Epoch: 140 | Loss: 0.5372575521469116 | Test loss: 0.5663439035415649\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7584]])), ('linear_layer.bias', tensor([0.8143]))])\n",
            "Loss:0.5371295809745789\n",
            "Loss:0.5370015501976013\n",
            "Loss:0.5368735790252686\n",
            "Loss:0.536745548248291\n",
            "Loss:0.5366175770759583\n",
            "Loss:0.5364894866943359\n",
            "Loss:0.536361575126648\n",
            "Loss:0.5362335443496704\n",
            "Loss:0.5361055135726929\n",
            "Loss:0.5359774827957153\n",
            "Epoch: 150 | Loss: 0.5359774827957153 | Test loss: 0.5648472309112549\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7580]])), ('linear_layer.bias', tensor([0.8132]))])\n",
            "Loss:0.5358494520187378\n",
            "Loss:0.535721480846405\n",
            "Loss:0.5355933904647827\n",
            "Loss:0.5354654788970947\n",
            "Loss:0.5353375673294067\n",
            "Loss:0.5352095365524292\n",
            "Loss:0.5350815057754517\n",
            "Loss:0.5349534749984741\n",
            "Loss:0.5348255038261414\n",
            "Loss:0.5346974730491638\n",
            "Epoch: 160 | Loss: 0.5346974730491638 | Test loss: 0.5633504390716553\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7576]])), ('linear_layer.bias', tensor([0.8121]))])\n",
            "Loss:0.5345694422721863\n",
            "Loss:0.5344414710998535\n",
            "Loss:0.5343134999275208\n",
            "Loss:0.534185528755188\n",
            "Loss:0.5340574979782104\n",
            "Loss:0.5339294672012329\n",
            "Loss:0.5338014364242554\n",
            "Loss:0.5336734652519226\n",
            "Loss:0.5335454940795898\n",
            "Loss:0.5334174633026123\n",
            "Epoch: 170 | Loss: 0.5334174633026123 | Test loss: 0.5618537664413452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|       | 23/100 [00:07<00:23,  3.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('linear_layer.weight', tensor([[0.7571]])), ('linear_layer.bias', tensor([0.8110]))])\n",
            "Loss:0.5332894325256348\n",
            "Loss:0.533161461353302\n",
            "Loss:0.5330334901809692\n",
            "Loss:0.5329054594039917\n",
            "Loss:0.5327774286270142\n",
            "Loss:0.5326494574546814\n",
            "Loss:0.5325214266777039\n",
            "Loss:0.5323934555053711\n",
            "Loss:0.5322654843330383\n",
            "Loss:0.5321374535560608\n",
            "Epoch: 180 | Loss: 0.5321374535560608 | Test loss: 0.5603570938110352\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7567]])), ('linear_layer.bias', tensor([0.8099]))])\n",
            "Loss:0.5320094227790833\n",
            "Loss:0.5318814516067505\n",
            "Loss:0.531753420829773\n",
            "Loss:0.5316253900527954\n",
            "Loss:0.5314974784851074\n",
            "Loss:0.5313693881034851\n",
            "Loss:0.5312414169311523\n",
            "Loss:0.5311133861541748\n",
            "Loss:0.5309854745864868\n",
            "Loss:0.5308574438095093\n",
            "Epoch: 190 | Loss: 0.5308574438095093 | Test loss: 0.5588604211807251\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7563]])), ('linear_layer.bias', tensor([0.8088]))])\n",
            "Loss:0.5307294130325317\n",
            "Loss:0.5306013822555542\n",
            "Loss:0.5304733514785767\n",
            "Loss:0.5303453803062439\n",
            "Loss:0.5302174091339111\n",
            "Loss:0.5300893783569336\n",
            "Loss:0.5299614071846008\n",
            "Loss:0.5298333764076233\n",
            "Loss:0.5297054052352905\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5872907638549805\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5550440549850464\n",
            "Loss:0.5549102425575256\n",
            "Loss:0.5547764301300049\n",
            "Loss:0.5546425580978394\n",
            "Loss:0.5545088052749634\n",
            "Loss:0.5543748736381531\n",
            "Loss:0.5542410612106323\n",
            "Loss:0.5541072487831116\n",
            "Loss:0.553973376750946\n",
            "Loss:0.5538395643234253\n",
            "Epoch: 10 | Loss: 0.5538395643234253 | Test loss: 0.5857258439064026\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7640]])), ('linear_layer.bias', tensor([0.8287]))])\n",
            "Loss:0.5537057518959045\n",
            "Loss:0.5535719394683838\n",
            "Loss:0.5534380674362183\n",
            "Loss:0.5533041954040527\n",
            "Loss:0.553170382976532\n",
            "Loss:0.5530365705490112\n",
            "Loss:0.5529027581214905\n",
            "Loss:0.552768886089325\n",
            "Loss:0.5526350140571594\n",
            "Loss:0.5525012016296387\n",
            "Epoch: 20 | Loss: 0.5525012016296387 | Test loss: 0.5841609835624695\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7636]])), ('linear_layer.bias', tensor([0.8276]))])\n",
            "Loss:0.5523673892021179\n",
            "Loss:0.5522335767745972\n",
            "Loss:0.5520997047424316\n",
            "Loss:0.5519658327102661\n",
            "Loss:0.5518320798873901\n",
            "Loss:0.5516982078552246\n",
            "Loss:0.5515643358230591\n",
            "Loss:0.5514305233955383\n",
            "Loss:0.5512966513633728\n",
            "Loss:0.551162838935852\n",
            "Epoch: 30 | Loss: 0.551162838935852 | Test loss: 0.5825961828231812\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7631]])), ('linear_layer.bias', tensor([0.8264]))])\n",
            "Loss:0.5510290265083313\n",
            "Loss:0.5508952140808105\n",
            "Loss:0.550761342048645\n",
            "Loss:0.5506274700164795\n",
            "Loss:0.5504937171936035\n",
            "Loss:0.550359845161438\n",
            "Loss:0.5502260327339172\n",
            "Loss:0.5500921607017517\n",
            "Loss:0.5499582886695862\n",
            "Loss:0.5498244762420654\n",
            "Epoch: 40 | Loss: 0.5498244762420654 | Test loss: 0.5810312628746033\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7627]])), ('linear_layer.bias', tensor([0.8252]))])\n",
            "Loss:0.5496906042098999\n",
            "Loss:0.5495567917823792\n",
            "Loss:0.5494229197502136\n",
            "Loss:0.5492891073226929\n",
            "Loss:0.5491553544998169\n",
            "Loss:0.5490214228630066\n",
            "Loss:0.5488876104354858\n",
            "Loss:0.5487537980079651\n",
            "Loss:0.5486199855804443\n",
            "Loss:0.5484861135482788\n",
            "Epoch: 50 | Loss: 0.5484861135482788 | Test loss: 0.5794664025306702\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7622]])), ('linear_layer.bias', tensor([0.8241]))])\n",
            "Loss:0.5483523011207581\n",
            "Loss:0.5482184290885925\n",
            "Loss:0.5480846166610718\n",
            "Loss:0.547950804233551\n",
            "Loss:0.5478169918060303\n",
            "Loss:0.5476831197738647\n",
            "Loss:0.547549307346344\n",
            "Loss:0.547415554523468\n",
            "Loss:0.5472816228866577\n",
            "Loss:0.5471477508544922\n",
            "Epoch: 60 | Loss: 0.5471477508544922 | Test loss: 0.5779015421867371\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7618]])), ('linear_layer.bias', tensor([0.8229]))])\n",
            "Loss:0.5470138788223267\n",
            "Loss:0.5468800663948059\n",
            "Loss:0.5467462539672852\n",
            "Loss:0.5466124415397644\n",
            "Loss:0.5464785695075989\n",
            "Loss:0.5463446974754333\n",
            "Loss:0.5462108850479126\n",
            "Loss:0.5460770726203918\n",
            "Loss:0.5459432005882263\n",
            "Loss:0.5458093881607056\n",
            "Epoch: 70 | Loss: 0.5458093881607056 | Test loss: 0.5763367414474487\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7613]])), ('linear_layer.bias', tensor([0.8218]))])\n",
            "Loss:0.5456754565238953\n",
            "Loss:0.5455417037010193\n",
            "Loss:0.5454078912734985\n",
            "Loss:0.545274019241333\n",
            "Loss:0.5451401472091675\n",
            "Loss:0.5450063943862915\n",
            "Loss:0.5448725819587708\n",
            "Loss:0.5447386503219604\n",
            "Loss:0.5446048974990845\n",
            "Loss:0.544471025466919\n",
            "Epoch: 80 | Loss: 0.544471025466919 | Test loss: 0.5747718811035156\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7609]])), ('linear_layer.bias', tensor([0.8206]))])\n",
            "Loss:0.5443372130393982\n",
            "Loss:0.5442034006118774\n",
            "Loss:0.5440695285797119\n",
            "Loss:0.5439356565475464\n",
            "Loss:0.5438017845153809\n",
            "Loss:0.5436680316925049\n",
            "Loss:0.5435342192649841\n",
            "Loss:0.5434003472328186\n",
            "Loss:0.5432664752006531\n",
            "Loss:0.5431326627731323\n",
            "Epoch: 90 | Loss: 0.5431326627731323 | Test loss: 0.5732069611549377\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7604]])), ('linear_layer.bias', tensor([0.8194]))])\n",
            "Loss:0.5429988503456116\n",
            "Loss:0.542864978313446\n",
            "Loss:0.5427311658859253\n",
            "Loss:0.5425973534584045\n",
            "Loss:0.542463481426239\n",
            "Loss:0.5423296689987183\n",
            "Loss:0.5421957969665527\n",
            "Loss:0.5420619249343872\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|       | 24/100 [00:07<00:23,  3.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5419281125068665\n",
            "Loss:0.5417943000793457\n",
            "Epoch: 100 | Loss: 0.5417943000793457 | Test loss: 0.5716421008110046\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7600]])), ('linear_layer.bias', tensor([0.8183]))])\n",
            "Loss:0.5416604280471802\n",
            "Loss:0.5415266752243042\n",
            "Loss:0.5413928031921387\n",
            "Loss:0.5412589311599731\n",
            "Loss:0.5411251187324524\n",
            "Loss:0.5409913063049316\n",
            "Loss:0.5408574342727661\n",
            "Loss:0.5407236218452454\n",
            "Loss:0.5405898094177246\n",
            "Loss:0.5404559373855591\n",
            "Epoch: 110 | Loss: 0.5404559373855591 | Test loss: 0.5700773000717163\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7595]])), ('linear_layer.bias', tensor([0.8171]))])\n",
            "Loss:0.5403221249580383\n",
            "Loss:0.5401882529258728\n",
            "Loss:0.540054440498352\n",
            "Loss:0.5399206280708313\n",
            "Loss:0.5397867560386658\n",
            "Loss:0.539652943611145\n",
            "Loss:0.5395190715789795\n",
            "Loss:0.5393852591514587\n",
            "Loss:0.539251446723938\n",
            "Loss:0.5391175746917725\n",
            "Epoch: 120 | Loss: 0.5391175746917725 | Test loss: 0.5685123801231384\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7591]])), ('linear_layer.bias', tensor([0.8160]))])\n",
            "Loss:0.5389837026596069\n",
            "Loss:0.538849949836731\n",
            "Loss:0.5387161374092102\n",
            "Loss:0.5385822057723999\n",
            "Loss:0.5384483933448792\n",
            "Loss:0.5383145809173584\n",
            "Loss:0.5381807088851929\n",
            "Loss:0.5380469560623169\n",
            "Loss:0.5379130244255066\n",
            "Loss:0.5377792119979858\n",
            "Epoch: 130 | Loss: 0.5377792119979858 | Test loss: 0.5669475197792053\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7586]])), ('linear_layer.bias', tensor([0.8148]))])\n",
            "Loss:0.5376453995704651\n",
            "Loss:0.5375115275382996\n",
            "Loss:0.5373777151107788\n",
            "Loss:0.5372438430786133\n",
            "Loss:0.5371099710464478\n",
            "Loss:0.5369762182235718\n",
            "Loss:0.5368423461914062\n",
            "Loss:0.5367084741592407\n",
            "Loss:0.5365747213363647\n",
            "Loss:0.536440908908844\n",
            "Epoch: 140 | Loss: 0.536440908908844 | Test loss: 0.5653826594352722\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7582]])), ('linear_layer.bias', tensor([0.8136]))])\n",
            "Loss:0.5363070368766785\n",
            "Loss:0.5361731648445129\n",
            "Loss:0.5360393524169922\n",
            "Loss:0.5359054803848267\n",
            "Loss:0.5357717275619507\n",
            "Loss:0.5356379151344299\n",
            "Loss:0.5355039834976196\n",
            "Loss:0.5353701710700989\n",
            "Loss:0.5352363586425781\n",
            "Loss:0.5351024866104126\n",
            "Epoch: 150 | Loss: 0.5351024866104126 | Test loss: 0.5638178586959839\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7577]])), ('linear_layer.bias', tensor([0.8125]))])\n",
            "Loss:0.5349686741828918\n",
            "Loss:0.5348348021507263\n",
            "Loss:0.5347009897232056\n",
            "Loss:0.5345670580863953\n",
            "Loss:0.5344333052635193\n",
            "Loss:0.5342994928359985\n",
            "Loss:0.5341656804084778\n",
            "Loss:0.5340318083763123\n",
            "Loss:0.5338979959487915\n",
            "Loss:0.5337641835212708\n",
            "Epoch: 160 | Loss: 0.5337641835212708 | Test loss: 0.5622529983520508\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7572]])), ('linear_layer.bias', tensor([0.8113]))])\n",
            "Loss:0.5336302518844604\n",
            "Loss:0.5334964394569397\n",
            "Loss:0.5333625674247742\n",
            "Loss:0.5332287549972534\n",
            "Loss:0.5330950021743774\n",
            "Loss:0.5329610705375671\n",
            "Loss:0.5328272581100464\n",
            "Loss:0.5326934456825256\n",
            "Loss:0.5325595736503601\n",
            "Loss:0.5324257612228394\n",
            "Epoch: 170 | Loss: 0.5324257612228394 | Test loss: 0.5606880784034729\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7568]])), ('linear_layer.bias', tensor([0.8101]))])\n",
            "Loss:0.5322919487953186\n",
            "Loss:0.5321580767631531\n",
            "Loss:0.5320242643356323\n",
            "Loss:0.5318903923034668\n",
            "Loss:0.531756579875946\n",
            "Loss:0.5316227674484253\n",
            "Loss:0.5314889550209045\n",
            "Loss:0.531355082988739\n",
            "Loss:0.5312212109565735\n",
            "Loss:0.5310873985290527\n",
            "Epoch: 180 | Loss: 0.5310873985290527 | Test loss: 0.5591232180595398\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7563]])), ('linear_layer.bias', tensor([0.8090]))])\n",
            "Loss:0.5309535264968872\n",
            "Loss:0.5308197736740112\n",
            "Loss:0.5306859016418457\n",
            "Loss:0.5305520296096802\n",
            "Loss:0.5304182767868042\n",
            "Loss:0.5302844047546387\n",
            "Loss:0.5301505327224731\n",
            "Loss:0.5300167202949524\n",
            "Loss:0.5298828482627869\n",
            "Loss:0.5297490358352661\n",
            "Epoch: 190 | Loss: 0.5297490358352661 | Test loss: 0.5575584173202515\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7559]])), ('linear_layer.bias', tensor([0.8078]))])\n",
            "Loss:0.5296152234077454\n",
            "Loss:0.5294814109802246\n",
            "Loss:0.5293475389480591\n",
            "Loss:0.5292136669158936\n",
            "Loss:0.5290798544883728\n",
            "Loss:0.528946042060852\n",
            "Loss:0.5288122296333313\n",
            "Loss:0.5286783576011658\n",
            "Loss:0.5285444855690002\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5872839093208313\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5550382733345032\n",
            "Loss:0.5548986196517944\n",
            "Loss:0.5547589063644409\n",
            "Loss:0.5546191930770874\n",
            "Loss:0.5544795989990234\n",
            "Loss:0.5543399453163147\n",
            "Loss:0.554200291633606\n",
            "Loss:0.5540605783462524\n",
            "Loss:0.5539208650588989\n",
            "Loss:0.553781270980835\n",
            "Epoch: 10 | Loss: 0.553781270980835 | Test loss: 0.5856509208679199\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7640]])), ('linear_layer.bias', tensor([0.8287]))])\n",
            "Loss:0.5536416172981262\n",
            "Loss:0.5535019040107727\n",
            "Loss:0.5533621907234192\n",
            "Loss:0.5532225370407104\n",
            "Loss:0.5530828237533569\n",
            "Loss:0.552943229675293\n",
            "Loss:0.5528035759925842\n",
            "Loss:0.5526639223098755\n",
            "Loss:0.5525241494178772\n",
            "Loss:0.5523844957351685\n",
            "Epoch: 20 | Loss: 0.5523844957351685 | Test loss: 0.5840178728103638\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7635]])), ('linear_layer.bias', tensor([0.8275]))])\n",
            "Loss:0.5522448420524597\n",
            "Loss:0.5521051287651062\n",
            "Loss:0.5519655346870422\n",
            "Loss:0.5518258810043335\n",
            "Loss:0.55168616771698\n",
            "Loss:0.5515464544296265\n",
            "Loss:0.5514068603515625\n",
            "Loss:0.551267147064209\n",
            "Loss:0.551127552986145\n",
            "Loss:0.5509877800941467\n",
            "Epoch: 30 | Loss: 0.5509877800941467 | Test loss: 0.5823848247528076\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7631]])), ('linear_layer.bias', tensor([0.8262]))])\n",
            "Loss:0.5508481860160828\n",
            "Loss:0.550708532333374\n",
            "Loss:0.5505688190460205\n",
            "Loss:0.5504292249679565\n",
            "Loss:0.550289511680603\n",
            "Loss:0.5501497983932495\n",
            "Loss:0.550010085105896\n",
            "Loss:0.549870491027832\n",
            "Loss:0.5497308373451233\n",
            "Loss:0.5495911836624146\n",
            "Epoch: 40 | Loss: 0.5495911836624146 | Test loss: 0.5807517766952515\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8250]))])\n",
            "Loss:0.549451470375061\n",
            "Loss:0.5493118166923523\n",
            "Loss:0.5491721034049988\n",
            "Loss:0.54903244972229\n",
            "Loss:0.5488927960395813\n",
            "Loss:0.5487531423568726\n",
            "Loss:0.548613429069519\n",
            "Loss:0.5484738349914551\n",
            "Loss:0.5483341217041016\n",
            "Loss:0.548194408416748\n",
            "Epoch: 50 | Loss: 0.548194408416748 | Test loss: 0.5791187882423401\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7621]])), ('linear_layer.bias', tensor([0.8238]))])\n",
            "Loss:0.5480548143386841\n",
            "Loss:0.5479151010513306\n",
            "Loss:0.5477754473686218\n",
            "Loss:0.5476357936859131\n",
            "Loss:0.5474961400032043\n",
            "Loss:0.547356367111206\n",
            "Loss:0.5472167134284973\n",
            "Loss:0.5470771193504333\n",
            "Loss:0.5469374060630798\n",
            "Loss:0.5467977523803711\n",
            "Epoch: 60 | Loss: 0.5467977523803711 | Test loss: 0.5774856805801392\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7617]])), ('linear_layer.bias', tensor([0.8226]))])\n",
            "Loss:0.5466580986976624\n",
            "Loss:0.5465183258056641\n",
            "Loss:0.5463787317276001\n",
            "Loss:0.5462390780448914\n",
            "Loss:0.5460993647575378\n",
            "Loss:0.5459597110748291\n",
            "Loss:0.5458201169967651\n",
            "Loss:0.5456804037094116\n",
            "Loss:0.5455406904220581\n",
            "Loss:0.5454010367393494\n",
            "Epoch: 70 | Loss: 0.5454010367393494 | Test loss: 0.5758526921272278\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7612]])), ('linear_layer.bias', tensor([0.8214]))])\n",
            "Loss:0.5452613830566406\n",
            "Loss:0.5451216697692871\n",
            "Loss:0.5449820756912231\n",
            "Loss:0.5448423624038696\n",
            "Loss:0.5447027087211609\n",
            "Loss:0.5445630550384521\n",
            "Loss:0.5444233417510986\n",
            "Loss:0.5442836880683899\n",
            "Loss:0.5441440343856812\n",
            "Loss:0.5440043210983276\n",
            "Epoch: 80 | Loss: 0.5440043210983276 | Test loss: 0.5742197036743164\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7607]])), ('linear_layer.bias', tensor([0.8202]))])\n",
            "Loss:0.5438646674156189\n",
            "Loss:0.5437250137329102\n",
            "Loss:0.5435853004455566\n",
            "Loss:0.5434457063674927\n",
            "Loss:0.5433059930801392\n",
            "Loss:0.5431662797927856\n",
            "Loss:0.5430266261100769\n",
            "Loss:0.5428869724273682\n",
            "Loss:0.5427473783493042\n",
            "Loss:0.5426076650619507\n",
            "Epoch: 90 | Loss: 0.5426076650619507 | Test loss: 0.5725866556167603\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7602]])), ('linear_layer.bias', tensor([0.8190]))])\n",
            "Loss:0.5424679517745972\n",
            "Loss:0.5423282980918884\n",
            "Loss:0.5421886444091797\n",
            "Loss:0.5420490503311157\n",
            "Loss:0.5419093370437622\n",
            "Loss:0.5417696237564087\n",
            "Loss:0.5416299104690552\n",
            "Loss:0.5414903163909912\n",
            "Loss:0.5413506627082825\n",
            "Loss:0.541210949420929\n",
            "Epoch: 100 | Loss: 0.541210949420929 | Test loss: 0.5709536075592041\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7598]])), ('linear_layer.bias', tensor([0.8178]))])\n",
            "Loss:0.5410712361335754\n",
            "Loss:0.5409315824508667\n",
            "Loss:0.540791928768158\n",
            "Loss:0.5406522750854492\n",
            "Loss:0.5405126810073853\n",
            "Loss:0.5403729677200317\n",
            "Loss:0.5402332544326782\n",
            "Loss:0.5400936007499695\n",
            "Loss:0.5399539470672607\n",
            "Loss:0.5398141741752625\n",
            "Epoch: 110 | Loss: 0.5398141741752625 | Test loss: 0.569320559501648\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7593]])), ('linear_layer.bias', tensor([0.8166]))])\n",
            "Loss:0.5396746397018433\n",
            "Loss:0.5395349264144897\n",
            "Loss:0.5393952131271362\n",
            "Loss:0.5392555594444275\n",
            "Loss:0.5391159057617188\n",
            "Loss:0.53897625207901\n",
            "Loss:0.5388365983963013\n",
            "Loss:0.5386968851089478\n",
            "Loss:0.5385571718215942\n",
            "Loss:0.5384175181388855\n",
            "Epoch: 120 | Loss: 0.5384175181388855 | Test loss: 0.5676875710487366\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7588]])), ('linear_layer.bias', tensor([0.8153]))])\n",
            "Loss:0.5382779240608215\n",
            "Loss:0.538138210773468\n",
            "Loss:0.5379985570907593\n",
            "Loss:0.5378588438034058\n",
            "Loss:0.537719190120697\n",
            "Loss:0.5375795364379883\n",
            "Loss:0.5374399423599243\n",
            "Loss:0.537300169467926\n",
            "Loss:0.5371605157852173\n",
            "Loss:0.5370208024978638\n",
            "Epoch: 130 | Loss: 0.5370208024978638 | Test loss: 0.5660544633865356\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7583]])), ('linear_layer.bias', tensor([0.8141]))])\n",
            "Loss:0.536881148815155\n",
            "Loss:0.5367415547370911\n",
            "Loss:0.5366019010543823\n",
            "Loss:0.5364621877670288\n",
            "Loss:0.5363224744796753\n",
            "Loss:0.5361828804016113\n",
            "Loss:0.5360431671142578\n",
            "Loss:0.5359035134315491\n",
            "Loss:0.5357638001441956\n",
            "Loss:0.5356241464614868\n",
            "Epoch: 140 | Loss: 0.5356241464614868 | Test loss: 0.5644214749336243\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7579]])), ('linear_layer.bias', tensor([0.8129]))])\n",
            "Loss:0.5354844927787781\n",
            "Loss:0.5353448390960693\n",
            "Loss:0.5352051258087158\n",
            "Loss:0.5350654721260071\n",
            "Loss:0.5349258184432983\n",
            "Loss:0.5347861051559448\n",
            "Loss:0.5346464514732361\n",
            "Loss:0.5345068573951721\n",
            "Loss:0.5343672037124634\n",
            "Loss:0.5342274308204651\n",
            "Epoch: 150 | Loss: 0.5342274308204651 | Test loss: 0.5627884268760681\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7574]])), ('linear_layer.bias', tensor([0.8117]))])\n",
            "Loss:0.5340877771377563\n",
            "Loss:0.5339481234550476\n",
            "Loss:0.5338084697723389\n",
            "Loss:0.5336688160896301\n",
            "Loss:0.5335291624069214\n",
            "Loss:0.5333894491195679\n",
            "Loss:0.5332497954368591\n",
            "Loss:0.5331100821495056\n",
            "Loss:0.5329704880714417\n",
            "Loss:0.5328307747840881\n",
            "Epoch: 160 | Loss: 0.5328307747840881 | Test loss: 0.5611554384231567\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7569]])), ('linear_layer.bias', tensor([0.8105]))])\n",
            "Loss:0.5326911211013794\n",
            "Loss:0.5325514078140259\n",
            "Loss:0.5324117541313171\n",
            "Loss:0.5322720408439636\n",
            "Loss:0.5321323871612549\n",
            "Loss:0.5319927334785461\n",
            "Loss:0.5318530797958374\n",
            "Loss:0.5317134261131287\n",
            "Loss:0.5315737128257751\n",
            "Loss:0.5314341187477112\n",
            "Epoch: 170 | Loss: 0.5314341187477112 | Test loss: 0.5595223903656006\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7565]])), ('linear_layer.bias', tensor([0.8093]))])\n",
            "Loss:0.5312944054603577\n",
            "Loss:0.5311547517776489\n",
            "Loss:0.5310150384902954\n",
            "Loss:0.5308753848075867\n",
            "Loss:0.5307357311248779\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|       | 25/100 [00:07<00:22,  3.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5305960774421692\n",
            "Loss:0.5304563641548157\n",
            "Loss:0.5303167104721069\n",
            "Loss:0.5301769971847534\n",
            "Loss:0.5300373435020447\n",
            "Epoch: 180 | Loss: 0.5300373435020447 | Test loss: 0.5578893423080444\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7560]])), ('linear_layer.bias', tensor([0.8081]))])\n",
            "Loss:0.5298976898193359\n",
            "Loss:0.5297580361366272\n",
            "Loss:0.5296183824539185\n",
            "Loss:0.5294787287712097\n",
            "Loss:0.5293390154838562\n",
            "Loss:0.5291993618011475\n",
            "Loss:0.5290597081184387\n",
            "Loss:0.5289199948310852\n",
            "Loss:0.5287803411483765\n",
            "Loss:0.5286406874656677\n",
            "Epoch: 190 | Loss: 0.5286406874656677 | Test loss: 0.5562563538551331\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7555]])), ('linear_layer.bias', tensor([0.8069]))])\n",
            "Loss:0.528501033782959\n",
            "Loss:0.5283613204956055\n",
            "Loss:0.5282216668128967\n",
            "Loss:0.528082013130188\n",
            "Loss:0.5279422998428345\n",
            "Loss:0.5278026461601257\n",
            "Loss:0.527662992477417\n",
            "Loss:0.5275232791900635\n",
            "Loss:0.5273836255073547\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5872771739959717\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5550324320793152\n",
            "Loss:0.5548869967460632\n",
            "Loss:0.5547416806221008\n",
            "Loss:0.5545961260795593\n",
            "Loss:0.5544506907463074\n",
            "Loss:0.5543053150177002\n",
            "Loss:0.5541598200798035\n",
            "Loss:0.5540143847465515\n",
            "Loss:0.5538688898086548\n",
            "Loss:0.5537235140800476\n",
            "Epoch: 10 | Loss: 0.5537235140800476 | Test loss: 0.5855764746665955\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7640]])), ('linear_layer.bias', tensor([0.8286]))])\n",
            "Loss:0.5535780191421509\n",
            "Loss:0.5534325838088989\n",
            "Loss:0.553287148475647\n",
            "Loss:0.553141713142395\n",
            "Loss:0.5529962778091431\n",
            "Loss:0.5528508424758911\n",
            "Loss:0.5527053475379944\n",
            "Loss:0.5525599122047424\n",
            "Loss:0.5524145364761353\n",
            "Loss:0.5522689819335938\n",
            "Epoch: 20 | Loss: 0.5522689819335938 | Test loss: 0.5838758945465088\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7635]])), ('linear_layer.bias', tensor([0.8274]))])\n",
            "Loss:0.5521236658096313\n",
            "Loss:0.5519781708717346\n",
            "Loss:0.5518326759338379\n",
            "Loss:0.5516872406005859\n",
            "Loss:0.5515418648719788\n",
            "Loss:0.5513964295387268\n",
            "Loss:0.5512509346008301\n",
            "Loss:0.5511054992675781\n",
            "Loss:0.5509600639343262\n",
            "Loss:0.5508145689964294\n",
            "Epoch: 30 | Loss: 0.5508145689964294 | Test loss: 0.5821753144264221\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7630]])), ('linear_layer.bias', tensor([0.8261]))])\n",
            "Loss:0.5506691336631775\n",
            "Loss:0.5505238175392151\n",
            "Loss:0.5503783226013184\n",
            "Loss:0.5502328276634216\n",
            "Loss:0.5500873923301697\n",
            "Loss:0.5499420166015625\n",
            "Loss:0.5497965216636658\n",
            "Loss:0.549651026725769\n",
            "Loss:0.5495056509971619\n",
            "Loss:0.5493601560592651\n",
            "Epoch: 40 | Loss: 0.5493601560592651 | Test loss: 0.5804747343063354\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7625]])), ('linear_layer.bias', tensor([0.8248]))])\n",
            "Loss:0.5492147207260132\n",
            "Loss:0.5490692853927612\n",
            "Loss:0.5489238500595093\n",
            "Loss:0.5487784147262573\n",
            "Loss:0.5486329793930054\n",
            "Loss:0.5484874844551086\n",
            "Loss:0.5483421087265015\n",
            "Loss:0.5481966733932495\n",
            "Loss:0.5480511784553528\n",
            "Loss:0.5479057431221008\n",
            "Epoch: 50 | Loss: 0.5479057431221008 | Test loss: 0.578774094581604\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7620]])), ('linear_layer.bias', tensor([0.8236]))])\n",
            "Loss:0.5477603077888489\n",
            "Loss:0.5476148724555969\n",
            "Loss:0.5474693775177002\n",
            "Loss:0.547324001789093\n",
            "Loss:0.5471785664558411\n",
            "Loss:0.5470330715179443\n",
            "Loss:0.5468876361846924\n",
            "Loss:0.5467422604560852\n",
            "Loss:0.5465968251228333\n",
            "Loss:0.5464513301849365\n",
            "Epoch: 60 | Loss: 0.5464513301849365 | Test loss: 0.5770735144615173\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7615]])), ('linear_layer.bias', tensor([0.8223]))])\n",
            "Loss:0.5463059544563293\n",
            "Loss:0.5461603999137878\n",
            "Loss:0.5460149049758911\n",
            "Loss:0.5458694696426392\n",
            "Loss:0.545724093914032\n",
            "Loss:0.5455785989761353\n",
            "Loss:0.5454331636428833\n",
            "Loss:0.5452877879142761\n",
            "Loss:0.5451422929763794\n",
            "Loss:0.5449968576431274\n",
            "Epoch: 70 | Loss: 0.5449968576431274 | Test loss: 0.5753728747367859\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7610]])), ('linear_layer.bias', tensor([0.8210]))])\n",
            "Loss:0.5448514223098755\n",
            "Loss:0.5447059869766235\n",
            "Loss:0.5445605516433716\n",
            "Loss:0.5444151163101196\n",
            "Loss:0.5442696809768677\n",
            "Loss:0.544124186038971\n",
            "Loss:0.543978750705719\n",
            "Loss:0.543833315372467\n",
            "Loss:0.5436878204345703\n",
            "Loss:0.5435424447059631\n",
            "Epoch: 80 | Loss: 0.5435424447059631 | Test loss: 0.573672354221344\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7606]])), ('linear_layer.bias', tensor([0.8198]))])\n",
            "Loss:0.5433970093727112\n",
            "Loss:0.5432515144348145\n",
            "Loss:0.5431061387062073\n",
            "Loss:0.5429606437683105\n",
            "Loss:0.5428152680397034\n",
            "Loss:0.5426697731018066\n",
            "Loss:0.5425243377685547\n",
            "Loss:0.5423789024353027\n",
            "Loss:0.542233407497406\n",
            "Loss:0.542087972164154\n",
            "Epoch: 90 | Loss: 0.542087972164154 | Test loss: 0.5719717144966125\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7601]])), ('linear_layer.bias', tensor([0.8185]))])\n",
            "Loss:0.5419425368309021\n",
            "Loss:0.5417971014976501\n",
            "Loss:0.5416516065597534\n",
            "Loss:0.5415062308311462\n",
            "Loss:0.5413607358932495\n",
            "Loss:0.5412153005599976\n",
            "Loss:0.5410698652267456\n",
            "Loss:0.5409244298934937\n",
            "Loss:0.5407789945602417\n",
            "Loss:0.5406335592269897\n",
            "Epoch: 100 | Loss: 0.5406335592269897 | Test loss: 0.5702711343765259\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7596]])), ('linear_layer.bias', tensor([0.8173]))])\n",
            "Loss:0.540488064289093\n",
            "Loss:0.5403426885604858\n",
            "Loss:0.5401972532272339\n",
            "Loss:0.5400518178939819\n",
            "Loss:0.5399063229560852\n",
            "Loss:0.539760947227478\n",
            "Loss:0.5396155118942261\n",
            "Loss:0.5394700765609741\n",
            "Loss:0.5393245816230774\n",
            "Loss:0.5391791462898254\n",
            "Epoch: 110 | Loss: 0.5391791462898254 | Test loss: 0.5685704946517944\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7591]])), ('linear_layer.bias', tensor([0.8160]))])\n",
            "Loss:0.5390337109565735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|       | 26/100 [00:08<00:22,  3.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5388882756233215\n",
            "Loss:0.5387428402900696\n",
            "Loss:0.5385974049568176\n",
            "Loss:0.5384518504142761\n",
            "Loss:0.5383065342903137\n",
            "Loss:0.538161039352417\n",
            "Loss:0.5380155444145203\n",
            "Loss:0.5378701090812683\n",
            "Loss:0.5377246737480164\n",
            "Epoch: 120 | Loss: 0.5377246737480164 | Test loss: 0.566869854927063\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7586]])), ('linear_layer.bias', tensor([0.8147]))])\n",
            "Loss:0.5375792384147644\n",
            "Loss:0.5374338030815125\n",
            "Loss:0.5372883677482605\n",
            "Loss:0.5371429324150085\n",
            "Loss:0.5369974374771118\n",
            "Loss:0.5368520021438599\n",
            "Loss:0.5367065668106079\n",
            "Loss:0.536561131477356\n",
            "Loss:0.536415696144104\n",
            "Loss:0.536270260810852\n",
            "Epoch: 130 | Loss: 0.536270260810852 | Test loss: 0.5651692748069763\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7581]])), ('linear_layer.bias', tensor([0.8135]))])\n",
            "Loss:0.5361248254776001\n",
            "Loss:0.5359793901443481\n",
            "Loss:0.5358339548110962\n",
            "Loss:0.5356885194778442\n",
            "Loss:0.5355430245399475\n",
            "Loss:0.5353975892066956\n",
            "Loss:0.5352521538734436\n",
            "Loss:0.5351066589355469\n",
            "Loss:0.5349612832069397\n",
            "Loss:0.534815788269043\n",
            "Epoch: 140 | Loss: 0.534815788269043 | Test loss: 0.5634686946868896\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7576]])), ('linear_layer.bias', tensor([0.8122]))])\n",
            "Loss:0.5346704125404358\n",
            "Loss:0.5345249176025391\n",
            "Loss:0.5343794822692871\n",
            "Loss:0.5342340469360352\n",
            "Loss:0.5340886116027832\n",
            "Loss:0.5339431166648865\n",
            "Loss:0.5337977409362793\n",
            "Loss:0.5336522459983826\n",
            "Loss:0.5335068106651306\n",
            "Loss:0.5333613157272339\n",
            "Epoch: 150 | Loss: 0.5333613157272339 | Test loss: 0.561768114566803\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7571]])), ('linear_layer.bias', tensor([0.8109]))])\n",
            "Loss:0.5332158803939819\n",
            "Loss:0.5330705046653748\n",
            "Loss:0.532925009727478\n",
            "Loss:0.5327795743942261\n",
            "Loss:0.5326341986656189\n",
            "Loss:0.5324887037277222\n",
            "Loss:0.5323432683944702\n",
            "Loss:0.5321978330612183\n",
            "Loss:0.5320523977279663\n",
            "Loss:0.5319069623947144\n",
            "Epoch: 160 | Loss: 0.5319069623947144 | Test loss: 0.5600675344467163\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7566]])), ('linear_layer.bias', tensor([0.8097]))])\n",
            "Loss:0.5317615270614624\n",
            "Loss:0.5316160321235657\n",
            "Loss:0.5314706563949585\n",
            "Loss:0.5313251614570618\n",
            "Loss:0.5311797261238098\n",
            "Loss:0.5310342907905579\n",
            "Loss:0.5308888554573059\n",
            "Loss:0.530743420124054\n",
            "Loss:0.5305979251861572\n",
            "Loss:0.53045254945755\n",
            "Epoch: 170 | Loss: 0.53045254945755 | Test loss: 0.5583668947219849\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7561]])), ('linear_layer.bias', tensor([0.8084]))])\n",
            "Loss:0.5303069949150085\n",
            "Loss:0.5301615595817566\n",
            "Loss:0.5300161242485046\n",
            "Loss:0.5298707485198975\n",
            "Loss:0.5297253131866455\n",
            "Loss:0.5295798778533936\n",
            "Loss:0.5294343829154968\n",
            "Loss:0.5292889475822449\n",
            "Loss:0.5291435122489929\n",
            "Loss:0.5289980173110962\n",
            "Epoch: 180 | Loss: 0.5289980173110962 | Test loss: 0.5566662549972534\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7556]])), ('linear_layer.bias', tensor([0.8072]))])\n",
            "Loss:0.5288525819778442\n",
            "Loss:0.5287072062492371\n",
            "Loss:0.5285617113113403\n",
            "Loss:0.5284162759780884\n",
            "Loss:0.5282708406448364\n",
            "Loss:0.5281254053115845\n",
            "Loss:0.5279799699783325\n",
            "Loss:0.5278345346450806\n",
            "Loss:0.5276890993118286\n",
            "Loss:0.5275436639785767\n",
            "Epoch: 190 | Loss: 0.5275436639785767 | Test loss: 0.5549656748771667\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7551]])), ('linear_layer.bias', tensor([0.8059]))])\n",
            "Loss:0.5273981690406799\n",
            "Loss:0.5272527933120728\n",
            "Loss:0.5271073579788208\n",
            "Loss:0.5269618630409241\n",
            "Loss:0.5268164277076721\n",
            "Loss:0.5266709327697754\n",
            "Loss:0.5265254974365234\n",
            "Loss:0.5263801217079163\n",
            "Loss:0.5262346267700195\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5872703194618225\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.555026650428772\n",
            "Loss:0.554875373840332\n",
            "Loss:0.5547240972518921\n",
            "Loss:0.5545728802680969\n",
            "Loss:0.5544215440750122\n",
            "Loss:0.5542702674865723\n",
            "Loss:0.5541189908981323\n",
            "Loss:0.5539677143096924\n",
            "Loss:0.5538164377212524\n",
            "Loss:0.5536651611328125\n",
            "Epoch: 10 | Loss: 0.5536651611328125 | Test loss: 0.5855016112327576\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7640]])), ('linear_layer.bias', tensor([0.8286]))])\n",
            "Loss:0.5535138845443726\n",
            "Loss:0.5533626079559326\n",
            "Loss:0.5532113313674927\n",
            "Loss:0.553059995174408\n",
            "Loss:0.5529087781906128\n",
            "Loss:0.5527575016021729\n",
            "Loss:0.5526062250137329\n",
            "Loss:0.552454948425293\n",
            "Loss:0.552303671836853\n",
            "Loss:0.5521523356437683\n",
            "Epoch: 20 | Loss: 0.5521523356437683 | Test loss: 0.5837327241897583\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7635]])), ('linear_layer.bias', tensor([0.8273]))])\n",
            "Loss:0.5520011186599731\n",
            "Loss:0.5518498420715332\n",
            "Loss:0.5516985654830933\n",
            "Loss:0.5515472888946533\n",
            "Loss:0.5513960123062134\n",
            "Loss:0.5512447357177734\n",
            "Loss:0.5510934591293335\n",
            "Loss:0.5509421825408936\n",
            "Loss:0.5507909059524536\n",
            "Loss:0.5506396889686584\n",
            "Epoch: 30 | Loss: 0.5506396889686584 | Test loss: 0.5819640159606934\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7630]])), ('linear_layer.bias', tensor([0.8259]))])\n",
            "Loss:0.5504883527755737\n",
            "Loss:0.5503370761871338\n",
            "Loss:0.5501857995986938\n",
            "Loss:0.5500345230102539\n",
            "Loss:0.549883246421814\n",
            "Loss:0.549731969833374\n",
            "Loss:0.5495806932449341\n",
            "Loss:0.5494293570518494\n",
            "Loss:0.5492781400680542\n",
            "Loss:0.5491268038749695\n",
            "Epoch: 40 | Loss: 0.5491268038749695 | Test loss: 0.5801953077316284\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7624]])), ('linear_layer.bias', tensor([0.8246]))])\n",
            "Loss:0.5489755868911743\n",
            "Loss:0.5488242506980896\n",
            "Loss:0.5486729741096497\n",
            "Loss:0.5485218167304993\n",
            "Loss:0.5483704805374146\n",
            "Loss:0.5482192039489746\n",
            "Loss:0.5480679273605347\n",
            "Loss:0.5479167103767395\n",
            "Loss:0.5477653741836548\n",
            "Loss:0.5476140975952148\n",
            "Epoch: 50 | Loss: 0.5476140975952148 | Test loss: 0.5784264802932739\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7619]])), ('linear_layer.bias', tensor([0.8233]))])\n",
            "Loss:0.5474628210067749\n",
            "Loss:0.5473114252090454\n",
            "Loss:0.547160267829895\n",
            "Loss:0.5470089912414551\n",
            "Loss:0.5468577146530151\n",
            "Loss:0.5467063784599304\n",
            "Loss:0.5465551614761353\n",
            "Loss:0.5464038848876953\n",
            "Loss:0.5462526082992554\n",
            "Loss:0.5461012721061707\n",
            "Epoch: 60 | Loss: 0.5461012721061707 | Test loss: 0.5766577124595642\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7614]])), ('linear_layer.bias', tensor([0.8220]))])\n",
            "Loss:0.5459499955177307\n",
            "Loss:0.5457987189292908\n",
            "Loss:0.5456475019454956\n",
            "Loss:0.5454961657524109\n",
            "Loss:0.5453449487686157\n",
            "Loss:0.5451936721801758\n",
            "Loss:0.5450423955917358\n",
            "Loss:0.5448910593986511\n",
            "Loss:0.544739842414856\n",
            "Loss:0.5445885062217712\n",
            "Epoch: 70 | Loss: 0.5445885062217712 | Test loss: 0.5748889446258545\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7609]])), ('linear_layer.bias', tensor([0.8207]))])\n",
            "Loss:0.5444372296333313\n",
            "Loss:0.5442859530448914\n",
            "Loss:0.5441347360610962\n",
            "Loss:0.5439834594726562\n",
            "Loss:0.5438321232795715\n",
            "Loss:0.5436809062957764\n",
            "Loss:0.5435296297073364\n",
            "Loss:0.5433782935142517\n",
            "Loss:0.5432270169258118\n",
            "Loss:0.5430757999420166\n",
            "Epoch: 80 | Loss: 0.5430757999420166 | Test loss: 0.5731201171875\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7604]])), ('linear_layer.bias', tensor([0.8194]))])\n",
            "Loss:0.5429245233535767\n",
            "Loss:0.5427731871604919\n",
            "Loss:0.5426219701766968\n",
            "Loss:0.5424706339836121\n",
            "Loss:0.5423194169998169\n",
            "Loss:0.5421680808067322\n",
            "Loss:0.542016863822937\n",
            "Loss:0.5418655276298523\n",
            "Loss:0.5417143106460571\n",
            "Loss:0.5415629744529724\n",
            "Epoch: 90 | Loss: 0.5415629744529724 | Test loss: 0.5713514089584351\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7599]])), ('linear_layer.bias', tensor([0.8181]))])\n",
            "Loss:0.5414116978645325\n",
            "Loss:0.5412604212760925\n",
            "Loss:0.5411091446876526\n",
            "Loss:0.5409578680992126\n",
            "Loss:0.5408065915107727\n",
            "Loss:0.5406553149223328\n",
            "Loss:0.540503978729248\n",
            "Loss:0.5403528213500977\n",
            "Loss:0.5402015447616577\n",
            "Loss:0.540050208568573\n",
            "Epoch: 100 | Loss: 0.540050208568573 | Test loss: 0.5695825815200806\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7594]])), ('linear_layer.bias', tensor([0.8167]))])\n",
            "Loss:0.5398989915847778\n",
            "Loss:0.5397476553916931\n",
            "Loss:0.539596438407898\n",
            "Loss:0.5394451022148132\n",
            "Loss:0.5392938852310181\n",
            "Loss:0.5391425490379333\n",
            "Loss:0.5389913320541382\n",
            "Loss:0.5388399958610535\n",
            "Loss:0.5386887192726135\n",
            "Loss:0.5385374426841736\n",
            "Epoch: 110 | Loss: 0.5385374426841736 | Test loss: 0.5678138136863708\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7589]])), ('linear_layer.bias', tensor([0.8154]))])\n",
            "Loss:0.5383861660957336\n",
            "Loss:0.5382348895072937\n",
            "Loss:0.5380836725234985\n",
            "Loss:0.537932276725769\n",
            "Loss:0.5377810597419739\n",
            "Loss:0.5376297831535339\n",
            "Loss:0.5374784469604492\n",
            "Loss:0.5373271703720093\n",
            "Loss:0.5371759533882141\n",
            "Loss:0.5370246767997742\n",
            "Epoch: 120 | Loss: 0.5370246767997742 | Test loss: 0.5660449862480164\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7583]])), ('linear_layer.bias', tensor([0.8141]))])\n",
            "Loss:0.536873459815979\n",
            "Loss:0.5367220640182495\n",
            "Loss:0.5365708470344543\n",
            "Loss:0.5364195704460144\n",
            "Loss:0.5362682342529297\n",
            "Loss:0.5361170172691345\n",
            "Loss:0.5359657406806946\n",
            "Loss:0.5358144640922546\n",
            "Loss:0.5356631875038147\n",
            "Loss:0.5355119109153748\n",
            "Epoch: 130 | Loss: 0.5355119109153748 | Test loss: 0.5642762780189514\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7578]])), ('linear_layer.bias', tensor([0.8128]))])\n",
            "Loss:0.5353606343269348\n",
            "Loss:0.5352093577384949\n",
            "Loss:0.5350580811500549\n",
            "Loss:0.534906804561615\n",
            "Loss:0.534755527973175\n",
            "Loss:0.5346041917800903\n",
            "Loss:0.5344529151916504\n",
            "Loss:0.5343016386032104\n",
            "Loss:0.5341503620147705\n",
            "Loss:0.5339990854263306\n",
            "Epoch: 140 | Loss: 0.5339990854263306 | Test loss: 0.5625075101852417\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7573]])), ('linear_layer.bias', tensor([0.8115]))])\n",
            "Loss:0.5338478684425354\n",
            "Loss:0.5336965322494507\n",
            "Loss:0.5335452556610107\n",
            "Loss:0.5333939790725708\n",
            "Loss:0.5332427024841309\n",
            "Loss:0.5330914258956909\n",
            "Loss:0.5329402089118958\n",
            "Loss:0.5327889323234558\n",
            "Loss:0.5326377153396606\n",
            "Loss:0.5324863791465759\n",
            "Epoch: 150 | Loss: 0.5324863791465759 | Test loss: 0.5607386827468872\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7568]])), ('linear_layer.bias', tensor([0.8102]))])\n",
            "Loss:0.532335102558136\n",
            "Loss:0.5321837663650513\n",
            "Loss:0.5320326089859009\n",
            "Loss:0.5318812131881714\n",
            "Loss:0.5317299962043762\n",
            "Loss:0.5315786600112915\n",
            "Loss:0.5314274430274963\n",
            "Loss:0.5312761068344116\n",
            "Loss:0.5311248302459717\n",
            "Loss:0.5309735536575317\n",
            "Epoch: 160 | Loss: 0.5309735536575317 | Test loss: 0.5589699745178223\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7563]])), ('linear_layer.bias', tensor([0.8089]))])\n",
            "Loss:0.5308223366737366\n",
            "Loss:0.5306710004806519\n",
            "Loss:0.5305197238922119\n",
            "Loss:0.530368447303772\n",
            "Loss:0.530217170715332\n",
            "Loss:0.5300658941268921\n",
            "Loss:0.5299146175384521\n",
            "Loss:0.5297633409500122\n",
            "Loss:0.5296120643615723\n",
            "Loss:0.5294609069824219\n",
            "Epoch: 170 | Loss: 0.5294609069824219 | Test loss: 0.5572012066841125\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7558]])), ('linear_layer.bias', tensor([0.8076]))])\n",
            "Loss:0.5293095111846924\n",
            "Loss:0.5291582345962524\n",
            "Loss:0.5290070176124573\n",
            "Loss:0.5288556814193726\n",
            "Loss:0.5287044644355774\n",
            "Loss:0.5285531282424927\n",
            "Loss:0.5284019112586975\n",
            "Loss:0.5282505750656128\n",
            "Loss:0.5280992984771729\n",
            "Loss:0.5279480218887329\n",
            "Epoch: 180 | Loss: 0.5279480218887329 | Test loss: 0.5554324388504028\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7553]])), ('linear_layer.bias', tensor([0.8062]))])\n",
            "Loss:0.5277968049049377\n",
            "Loss:0.527645468711853\n",
            "Loss:0.5274941921234131\n",
            "Loss:0.5273429155349731\n",
            "Loss:0.5271916389465332\n",
            "Loss:0.5270403623580933\n",
            "Loss:0.5268890857696533\n",
            "Loss:0.5267378091812134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|       | 27/100 [00:08<00:22,  3.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5265865325927734\n",
            "Loss:0.5264352560043335\n",
            "Epoch: 190 | Loss: 0.5264352560043335 | Test loss: 0.5536636114120483\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7548]])), ('linear_layer.bias', tensor([0.8049]))])\n",
            "Loss:0.5262839794158936\n",
            "Loss:0.5261327028274536\n",
            "Loss:0.5259814262390137\n",
            "Loss:0.5258301496505737\n",
            "Loss:0.5256789326667786\n",
            "Loss:0.5255275964736938\n",
            "Loss:0.5253763198852539\n",
            "Loss:0.525225043296814\n",
            "Loss:0.5250737071037292\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5872635245323181\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5550208687782288\n",
            "Loss:0.554863691329956\n",
            "Loss:0.5547066330909729\n",
            "Loss:0.554549515247345\n",
            "Loss:0.5543924570083618\n",
            "Loss:0.5542352795600891\n",
            "Loss:0.5540781617164612\n",
            "Loss:0.5539210438728333\n",
            "Loss:0.5537639260292053\n",
            "Loss:0.5536068081855774\n",
            "Epoch: 10 | Loss: 0.5536068081855774 | Test loss: 0.5854265689849854\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7640]])), ('linear_layer.bias', tensor([0.8285]))])\n",
            "Loss:0.5534497499465942\n",
            "Loss:0.5532925724983215\n",
            "Loss:0.5531355142593384\n",
            "Loss:0.5529783964157104\n",
            "Loss:0.5528212785720825\n",
            "Loss:0.5526641607284546\n",
            "Loss:0.5525070428848267\n",
            "Loss:0.5523499250411987\n",
            "Loss:0.5521928071975708\n",
            "Loss:0.5520356893539429\n",
            "Epoch: 20 | Loss: 0.5520356893539429 | Test loss: 0.5835895538330078\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7634]])), ('linear_layer.bias', tensor([0.8271]))])\n",
            "Loss:0.5518785715103149\n",
            "Loss:0.5517215132713318\n",
            "Loss:0.5515643358230591\n",
            "Loss:0.5514072775840759\n",
            "Loss:0.5512501001358032\n",
            "Loss:0.5510929822921753\n",
            "Loss:0.5509359836578369\n",
            "Loss:0.550778865814209\n",
            "Loss:0.550621747970581\n",
            "Loss:0.5504646301269531\n",
            "Epoch: 30 | Loss: 0.5504646301269531 | Test loss: 0.5817526578903198\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7629]])), ('linear_layer.bias', tensor([0.8258]))])\n",
            "Loss:0.5503075122833252\n",
            "Loss:0.5501503348350525\n",
            "Loss:0.5499932765960693\n",
            "Loss:0.5498362183570862\n",
            "Loss:0.5496790409088135\n",
            "Loss:0.5495219230651855\n",
            "Loss:0.5493648052215576\n",
            "Loss:0.5492076873779297\n",
            "Loss:0.5490506887435913\n",
            "Loss:0.5488935112953186\n",
            "Epoch: 40 | Loss: 0.5488935112953186 | Test loss: 0.5799157023429871\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7624]])), ('linear_layer.bias', tensor([0.8244]))])\n",
            "Loss:0.5487363934516907\n",
            "Loss:0.5485792756080627\n",
            "Loss:0.5484221577644348\n",
            "Loss:0.5482650995254517\n",
            "Loss:0.5481079816818237\n",
            "Loss:0.5479508638381958\n",
            "Loss:0.5477937459945679\n",
            "Loss:0.5476366281509399\n",
            "Loss:0.5474794507026672\n",
            "Loss:0.5473223924636841\n",
            "Epoch: 50 | Loss: 0.5473223924636841 | Test loss: 0.5780788064002991\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7618]])), ('linear_layer.bias', tensor([0.8231]))])\n",
            "Loss:0.5471652746200562\n",
            "Loss:0.547008216381073\n",
            "Loss:0.5468510389328003\n",
            "Loss:0.5466939210891724\n",
            "Loss:0.5465368032455444\n",
            "Loss:0.5463797450065613\n",
            "Loss:0.5462225675582886\n",
            "Loss:0.5460655093193054\n",
            "Loss:0.5459083318710327\n",
            "Loss:0.5457512736320496\n",
            "Epoch: 60 | Loss: 0.5457512736320496 | Test loss: 0.5762418508529663\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7613]])), ('linear_layer.bias', tensor([0.8217]))])\n",
            "Loss:0.5455942153930664\n",
            "Loss:0.5454370975494385\n",
            "Loss:0.5452799797058105\n",
            "Loss:0.5451228022575378\n",
            "Loss:0.5449657440185547\n",
            "Loss:0.544808566570282\n",
            "Loss:0.5446515083312988\n",
            "Loss:0.5444944500923157\n",
            "Loss:0.5443373322486877\n",
            "Loss:0.5441802144050598\n",
            "Epoch: 70 | Loss: 0.5441802144050598 | Test loss: 0.5744048953056335\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7608]])), ('linear_layer.bias', tensor([0.8203]))])\n",
            "Loss:0.5440230369567871\n",
            "Loss:0.543865978717804\n",
            "Loss:0.543708860874176\n",
            "Loss:0.5435517430305481\n",
            "Loss:0.5433946847915649\n",
            "Loss:0.5432375073432922\n",
            "Loss:0.5430803894996643\n",
            "Loss:0.5429232716560364\n",
            "Loss:0.5427662134170532\n",
            "Loss:0.5426090955734253\n",
            "Epoch: 80 | Loss: 0.5426090955734253 | Test loss: 0.5725679397583008\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7602]])), ('linear_layer.bias', tensor([0.8190]))])\n",
            "Loss:0.5424519777297974\n",
            "Loss:0.5422948598861694\n",
            "Loss:0.5421377420425415\n",
            "Loss:0.5419806838035583\n",
            "Loss:0.5418235659599304\n",
            "Loss:0.5416663885116577\n",
            "Loss:0.5415092706680298\n",
            "Loss:0.5413521528244019\n",
            "Loss:0.5411950349807739\n",
            "Loss:0.5410380363464355\n",
            "Epoch: 90 | Loss: 0.5410380363464355 | Test loss: 0.5707310438156128\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7597]])), ('linear_layer.bias', tensor([0.8176]))])\n",
            "Loss:0.5408808588981628\n",
            "Loss:0.5407237410545349\n",
            "Loss:0.540566623210907\n",
            "Loss:0.540409505367279\n",
            "Loss:0.5402523875236511\n",
            "Loss:0.540095329284668\n",
            "Loss:0.53993821144104\n",
            "Loss:0.5397811532020569\n",
            "Loss:0.539624035358429\n",
            "Loss:0.5394667983055115\n",
            "Epoch: 100 | Loss: 0.5394667983055115 | Test loss: 0.56889408826828\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7592]])), ('linear_layer.bias', tensor([0.8162]))])\n",
            "Loss:0.5393096804618835\n",
            "Loss:0.5391526818275452\n",
            "Loss:0.5389955639839172\n",
            "Loss:0.5388384461402893\n",
            "Loss:0.5386813282966614\n",
            "Loss:0.5385241508483887\n",
            "Loss:0.5383671522140503\n",
            "Loss:0.5382100343704224\n",
            "Loss:0.5380529165267944\n",
            "Loss:0.5378957390785217\n",
            "Epoch: 110 | Loss: 0.5378957390785217 | Test loss: 0.5670571327209473\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7586]])), ('linear_layer.bias', tensor([0.8149]))])\n",
            "Loss:0.5377386212348938\n",
            "Loss:0.5375815629959106\n",
            "Loss:0.5374243855476379\n",
            "Loss:0.5372673273086548\n",
            "Loss:0.5371102094650269\n",
            "Loss:0.5369530916213989\n",
            "Loss:0.536795973777771\n",
            "Loss:0.5366388559341431\n",
            "Loss:0.5364817976951599\n",
            "Loss:0.5363246202468872\n",
            "Epoch: 120 | Loss: 0.5363246202468872 | Test loss: 0.5652202367782593\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7581]])), ('linear_layer.bias', tensor([0.8135]))])\n",
            "Loss:0.5361675024032593\n",
            "Loss:0.5360104441642761\n",
            "Loss:0.5358533263206482\n",
            "Loss:0.5356962084770203\n",
            "Loss:0.5355390906333923\n",
            "Loss:0.5353819727897644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|       | 28/100 [00:08<00:21,  3.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5352248549461365\n",
            "Loss:0.5350677371025085\n",
            "Loss:0.5349105596542358\n",
            "Loss:0.5347535610198975\n",
            "Epoch: 130 | Loss: 0.5347535610198975 | Test loss: 0.5633832216262817\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7576]])), ('linear_layer.bias', tensor([0.8121]))])\n",
            "Loss:0.5345963835716248\n",
            "Loss:0.5344393253326416\n",
            "Loss:0.5342822074890137\n",
            "Loss:0.5341251492500305\n",
            "Loss:0.5339680314064026\n",
            "Loss:0.5338108539581299\n",
            "Loss:0.533653736114502\n",
            "Loss:0.5334966778755188\n",
            "Loss:0.5333395600318909\n",
            "Loss:0.5331824421882629\n",
            "Epoch: 140 | Loss: 0.5331824421882629 | Test loss: 0.561546266078949\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7570]])), ('linear_layer.bias', tensor([0.8108]))])\n",
            "Loss:0.5330252647399902\n",
            "Loss:0.5328682661056519\n",
            "Loss:0.5327110886573792\n",
            "Loss:0.5325539708137512\n",
            "Loss:0.5323969125747681\n",
            "Loss:0.5322397947311401\n",
            "Loss:0.532082736492157\n",
            "Loss:0.5319255590438843\n",
            "Loss:0.5317684412002563\n",
            "Loss:0.5316113233566284\n",
            "Epoch: 150 | Loss: 0.5316113233566284 | Test loss: 0.559709370136261\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7565]])), ('linear_layer.bias', tensor([0.8094]))])\n",
            "Loss:0.5314542055130005\n",
            "Loss:0.5312970876693726\n",
            "Loss:0.5311399698257446\n",
            "Loss:0.5309828519821167\n",
            "Loss:0.5308257937431335\n",
            "Loss:0.5306686758995056\n",
            "Loss:0.5305114984512329\n",
            "Loss:0.5303544998168945\n",
            "Loss:0.5301973223686218\n",
            "Loss:0.5300402641296387\n",
            "Epoch: 160 | Loss: 0.5300402641296387 | Test loss: 0.5578724145889282\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7560]])), ('linear_layer.bias', tensor([0.8081]))])\n",
            "Loss:0.529883086681366\n",
            "Loss:0.529725968837738\n",
            "Loss:0.5295688509941101\n",
            "Loss:0.529411792755127\n",
            "Loss:0.5292547345161438\n",
            "Loss:0.5290975570678711\n",
            "Loss:0.5289404392242432\n",
            "Loss:0.5287833213806152\n",
            "Loss:0.5286262035369873\n",
            "Loss:0.5284690856933594\n",
            "Epoch: 170 | Loss: 0.5284690856933594 | Test loss: 0.5560354590415955\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7554]])), ('linear_layer.bias', tensor([0.8067]))])\n",
            "Loss:0.528312087059021\n",
            "Loss:0.5281549096107483\n",
            "Loss:0.5279977917671204\n",
            "Loss:0.5278406739234924\n",
            "Loss:0.5276835560798645\n",
            "Loss:0.5275264978408813\n",
            "Loss:0.5273693203926086\n",
            "Loss:0.5272122621536255\n",
            "Loss:0.5270551443099976\n",
            "Loss:0.5268980264663696\n",
            "Epoch: 180 | Loss: 0.5268980264663696 | Test loss: 0.5541985034942627\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7549]])), ('linear_layer.bias', tensor([0.8053]))])\n",
            "Loss:0.5267409086227417\n",
            "Loss:0.5265837907791138\n",
            "Loss:0.5264266729354858\n",
            "Loss:0.5262695550918579\n",
            "Loss:0.52611243724823\n",
            "Loss:0.525955319404602\n",
            "Loss:0.5257982611656189\n",
            "Loss:0.5256410837173462\n",
            "Loss:0.525484025478363\n",
            "Loss:0.5253268480300903\n",
            "Epoch: 190 | Loss: 0.5253268480300903 | Test loss: 0.5523616075515747\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7544]])), ('linear_layer.bias', tensor([0.8040]))])\n",
            "Loss:0.5251697301864624\n",
            "Loss:0.5250126719474792\n",
            "Loss:0.5248555541038513\n",
            "Loss:0.5246984362602234\n",
            "Loss:0.5245413184165955\n",
            "Loss:0.5243842005729675\n",
            "Loss:0.5242270827293396\n",
            "Loss:0.5240700840950012\n",
            "Loss:0.5239129662513733\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5872567296028137\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.555014967918396\n",
            "Loss:0.5548520088195801\n",
            "Loss:0.5546891093254089\n",
            "Loss:0.554526150226593\n",
            "Loss:0.5543631911277771\n",
            "Loss:0.554200291633606\n",
            "Loss:0.5540372729301453\n",
            "Loss:0.5538743734359741\n",
            "Loss:0.5537113547325134\n",
            "Loss:0.5535484552383423\n",
            "Epoch: 10 | Loss: 0.5535484552383423 | Test loss: 0.5853515863418579\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7639]])), ('linear_layer.bias', tensor([0.8285]))])\n",
            "Loss:0.5533856153488159\n",
            "Loss:0.5532225370407104\n",
            "Loss:0.5530596971511841\n",
            "Loss:0.5528967380523682\n",
            "Loss:0.5527337193489075\n",
            "Loss:0.5525708198547363\n",
            "Loss:0.5524078607559204\n",
            "Loss:0.5522449612617493\n",
            "Loss:0.5520819425582886\n",
            "Loss:0.5519190430641174\n",
            "Epoch: 20 | Loss: 0.5519190430641174 | Test loss: 0.5834465026855469\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7634]])), ('linear_layer.bias', tensor([0.8270]))])\n",
            "Loss:0.5517560839653015\n",
            "Loss:0.5515931844711304\n",
            "Loss:0.5514301657676697\n",
            "Loss:0.5512672662734985\n",
            "Loss:0.5511042475700378\n",
            "Loss:0.5509414076805115\n",
            "Loss:0.5507784485816956\n",
            "Loss:0.5506154298782349\n",
            "Loss:0.5504525899887085\n",
            "Loss:0.5502896308898926\n",
            "Epoch: 30 | Loss: 0.5502896308898926 | Test loss: 0.5815414190292358\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7628]])), ('linear_layer.bias', tensor([0.8256]))])\n",
            "Loss:0.5501266717910767\n",
            "Loss:0.5499637126922607\n",
            "Loss:0.5498007535934448\n",
            "Loss:0.5496377944946289\n",
            "Loss:0.549474835395813\n",
            "Loss:0.5493119359016418\n",
            "Loss:0.5491490364074707\n",
            "Loss:0.5489860773086548\n",
            "Loss:0.5488230586051941\n",
            "Loss:0.548660159111023\n",
            "Epoch: 40 | Loss: 0.548660159111023 | Test loss: 0.5796362161636353\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7623]])), ('linear_layer.bias', tensor([0.8242]))])\n",
            "Loss:0.548497200012207\n",
            "Loss:0.5483343005180359\n",
            "Loss:0.5481712818145752\n",
            "Loss:0.548008382320404\n",
            "Loss:0.5478454828262329\n",
            "Loss:0.5476824641227722\n",
            "Loss:0.5475195646286011\n",
            "Loss:0.5473566651344299\n",
            "Loss:0.5471936464309692\n",
            "Loss:0.5470307469367981\n",
            "Epoch: 50 | Loss: 0.5470307469367981 | Test loss: 0.5777311325073242\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7617]])), ('linear_layer.bias', tensor([0.8228]))])\n",
            "Loss:0.5468677282333374\n",
            "Loss:0.5467047691345215\n",
            "Loss:0.5465418696403503\n",
            "Loss:0.5463789701461792\n",
            "Loss:0.5462159514427185\n",
            "Loss:0.5460530519485474\n",
            "Loss:0.5458900928497314\n",
            "Loss:0.5457271337509155\n",
            "Loss:0.5455642342567444\n",
            "Loss:0.5454012751579285\n",
            "Epoch: 60 | Loss: 0.5454012751579285 | Test loss: 0.5758260488510132\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7612]])), ('linear_layer.bias', tensor([0.8214]))])\n",
            "Loss:0.5452383756637573\n",
            "Loss:0.5450754165649414\n",
            "Loss:0.5449124574661255\n",
            "Loss:0.5447495579719543\n",
            "Loss:0.5445865392684937\n",
            "Loss:0.5444235801696777\n",
            "Loss:0.5442606806755066\n",
            "Loss:0.5440977215766907\n",
            "Loss:0.5439347624778748\n",
            "Loss:0.5437718629837036\n",
            "Epoch: 70 | Loss: 0.5437718629837036 | Test loss: 0.5739209055900574\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7606]])), ('linear_layer.bias', tensor([0.8200]))])\n",
            "Loss:0.5436088442802429\n",
            "Loss:0.5434459447860718\n",
            "Loss:0.5432829260826111\n",
            "Loss:0.5431200265884399\n",
            "Loss:0.5429571866989136\n",
            "Loss:0.5427941083908081\n",
            "Loss:0.5426312685012817\n",
            "Loss:0.5424683094024658\n",
            "Loss:0.5423052906990051\n",
            "Loss:0.542142391204834\n",
            "Epoch: 80 | Loss: 0.542142391204834 | Test loss: 0.5720158219337463\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7601]])), ('linear_layer.bias', tensor([0.8186]))])\n",
            "Loss:0.5419794321060181\n",
            "Loss:0.5418165922164917\n",
            "Loss:0.5416535139083862\n",
            "Loss:0.5414906144142151\n",
            "Loss:0.5413276553153992\n",
            "Loss:0.541164755821228\n",
            "Loss:0.5410017371177673\n",
            "Loss:0.5408388376235962\n",
            "Loss:0.5406758785247803\n",
            "Loss:0.5405129194259644\n",
            "Epoch: 90 | Loss: 0.5405129194259644 | Test loss: 0.5701106786727905\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7595]])), ('linear_layer.bias', tensor([0.8171]))])\n",
            "Loss:0.5403500199317932\n",
            "Loss:0.5401870608329773\n",
            "Loss:0.5400241613388062\n",
            "Loss:0.5398612022399902\n",
            "Loss:0.5396982431411743\n",
            "Loss:0.5395352840423584\n",
            "Loss:0.5393723249435425\n",
            "Loss:0.5392093658447266\n",
            "Loss:0.5390464067459106\n",
            "Loss:0.5388835072517395\n",
            "Epoch: 100 | Loss: 0.5388835072517395 | Test loss: 0.5682055950164795\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7590]])), ('linear_layer.bias', tensor([0.8157]))])\n",
            "Loss:0.5387206077575684\n",
            "Loss:0.5385576486587524\n",
            "Loss:0.5383946299552917\n",
            "Loss:0.5382317304611206\n",
            "Loss:0.5380687713623047\n",
            "Loss:0.5379058718681335\n",
            "Loss:0.5377428531646729\n",
            "Loss:0.5375799536705017\n",
            "Loss:0.5374170541763306\n",
            "Loss:0.5372540950775146\n",
            "Epoch: 110 | Loss: 0.5372540950775146 | Test loss: 0.5663005113601685\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7584]])), ('linear_layer.bias', tensor([0.8143]))])\n",
            "Loss:0.5370911359786987\n",
            "Loss:0.5369281768798828\n",
            "Loss:0.5367652773857117\n",
            "Loss:0.5366023182868958\n",
            "Loss:0.5364392995834351\n",
            "Loss:0.5362764000892639\n",
            "Loss:0.536113440990448\n",
            "Loss:0.5359505414962769\n",
            "Loss:0.5357875823974609\n",
            "Loss:0.535624623298645\n",
            "Epoch: 120 | Loss: 0.535624623298645 | Test loss: 0.5643953084945679\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7579]])), ('linear_layer.bias', tensor([0.8129]))])\n",
            "Loss:0.5354616045951843\n",
            "Loss:0.5352987051010132\n",
            "Loss:0.5351358652114868\n",
            "Loss:0.5349728465080261\n",
            "Loss:0.534809947013855\n",
            "Loss:0.5346469879150391\n",
            "Loss:0.5344840288162231\n",
            "Loss:0.534321129322052\n",
            "Loss:0.5341581106185913\n",
            "Loss:0.5339951515197754\n",
            "Epoch: 130 | Loss: 0.5339951515197754 | Test loss: 0.5624902248382568\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7573]])), ('linear_layer.bias', tensor([0.8115]))])\n",
            "Loss:0.5338321924209595\n",
            "Loss:0.5336692929267883\n",
            "Loss:0.5335063338279724\n",
            "Loss:0.5333434343338013\n",
            "Loss:0.5331804156303406\n",
            "Loss:0.5330175161361694\n",
            "Loss:0.5328545570373535\n",
            "Loss:0.5326915979385376\n",
            "Loss:0.5325287580490112\n",
            "Loss:0.5323656797409058\n",
            "Epoch: 140 | Loss: 0.5323656797409058 | Test loss: 0.5605851411819458\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7568]])), ('linear_layer.bias', tensor([0.8101]))])\n",
            "Loss:0.5322028398513794\n",
            "Loss:0.5320398807525635\n",
            "Loss:0.5318768620491028\n",
            "Loss:0.5317139625549316\n",
            "Loss:0.5315510034561157\n",
            "Loss:0.5313881635665894\n",
            "Loss:0.5312250852584839\n",
            "Loss:0.5310621857643127\n",
            "Loss:0.5308992266654968\n",
            "Loss:0.5307363271713257\n",
            "Epoch: 150 | Loss: 0.5307363271713257 | Test loss: 0.55867999792099\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7562]])), ('linear_layer.bias', tensor([0.8087]))])\n",
            "Loss:0.530573308467865\n",
            "Loss:0.5304104089736938\n",
            "Loss:0.5302474498748779\n",
            "Loss:0.5300845503807068\n",
            "Loss:0.5299215912818909\n",
            "Loss:0.529758632183075\n",
            "Loss:0.5295957326889038\n",
            "Loss:0.5294327735900879\n",
            "Loss:0.529269814491272\n",
            "Loss:0.529106855392456\n",
            "Epoch: 160 | Loss: 0.529106855392456 | Test loss: 0.556774914264679\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7557]])), ('linear_layer.bias', tensor([0.8072]))])\n",
            "Loss:0.5289438962936401\n",
            "Loss:0.5287809371948242\n",
            "Loss:0.5286179780960083\n",
            "Loss:0.5284550786018372\n",
            "Loss:0.528292179107666\n",
            "Loss:0.5281292200088501\n",
            "Loss:0.5279662013053894\n",
            "Loss:0.5278033018112183\n",
            "Loss:0.5276403427124023\n",
            "Loss:0.5274774432182312\n",
            "Epoch: 170 | Loss: 0.5274774432182312 | Test loss: 0.5548697710037231\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|       | 29/100 [00:09<00:22,  3.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('linear_layer.weight', tensor([[0.7551]])), ('linear_layer.bias', tensor([0.8058]))])\n",
            "Loss:0.5273144841194153\n",
            "Loss:0.5271515250205994\n",
            "Loss:0.5269886255264282\n",
            "Loss:0.5268256664276123\n",
            "Loss:0.5266627073287964\n",
            "Loss:0.5264997482299805\n",
            "Loss:0.5263367891311646\n",
            "Loss:0.5261738896369934\n",
            "Loss:0.5260108709335327\n",
            "Loss:0.5258479714393616\n",
            "Epoch: 180 | Loss: 0.5258479714393616 | Test loss: 0.5529646873474121\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7546]])), ('linear_layer.bias', tensor([0.8044]))])\n",
            "Loss:0.5256850123405457\n",
            "Loss:0.5255221128463745\n",
            "Loss:0.5253591537475586\n",
            "Loss:0.5251961946487427\n",
            "Loss:0.5250332355499268\n",
            "Loss:0.5248702764511108\n",
            "Loss:0.5247073769569397\n",
            "Loss:0.5245444178581238\n",
            "Loss:0.5243814587593079\n",
            "Loss:0.5242185592651367\n",
            "Epoch: 190 | Loss: 0.5242185592651367 | Test loss: 0.5510596036911011\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7540]])), ('linear_layer.bias', tensor([0.8030]))])\n",
            "Loss:0.5240556001663208\n",
            "Loss:0.5238927006721497\n",
            "Loss:0.523729681968689\n",
            "Loss:0.523566722869873\n",
            "Loss:0.5234037637710571\n",
            "Loss:0.523240864276886\n",
            "Loss:0.5230779051780701\n",
            "Loss:0.5229150056838989\n",
            "Loss:0.5227519869804382\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5872499346733093\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5550092458724976\n",
            "Loss:0.5548404455184937\n",
            "Loss:0.5546717643737793\n",
            "Loss:0.5545031428337097\n",
            "Loss:0.5543343424797058\n",
            "Loss:0.5541656613349915\n",
            "Loss:0.5539969205856323\n",
            "Loss:0.553828239440918\n",
            "Loss:0.5536594986915588\n",
            "Loss:0.5534907579421997\n",
            "Epoch: 10 | Loss: 0.5534907579421997 | Test loss: 0.585277259349823\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7639]])), ('linear_layer.bias', tensor([0.8284]))])\n",
            "Loss:0.5533219575881958\n",
            "Loss:0.5531532764434814\n",
            "Loss:0.5529845952987671\n",
            "Loss:0.5528159141540527\n",
            "Loss:0.5526471734046936\n",
            "Loss:0.5524784326553345\n",
            "Loss:0.5523096919059753\n",
            "Loss:0.552141010761261\n",
            "Loss:0.5519722700119019\n",
            "Loss:0.5518035292625427\n",
            "Epoch: 20 | Loss: 0.5518035292625427 | Test loss: 0.5833045840263367\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8269]))])\n",
            "Loss:0.5516349077224731\n",
            "Loss:0.551466166973114\n",
            "Loss:0.5512974262237549\n",
            "Loss:0.5511286854743958\n",
            "Loss:0.5509599447250366\n",
            "Loss:0.550791323184967\n",
            "Loss:0.5506225824356079\n",
            "Loss:0.550453782081604\n",
            "Loss:0.5502851605415344\n",
            "Loss:0.5501163601875305\n",
            "Epoch: 30 | Loss: 0.5501163601875305 | Test loss: 0.5813318490982056\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7628]])), ('linear_layer.bias', tensor([0.8255]))])\n",
            "Loss:0.5499476790428162\n",
            "Loss:0.549778938293457\n",
            "Loss:0.5496102571487427\n",
            "Loss:0.5494415163993835\n",
            "Loss:0.5492727756500244\n",
            "Loss:0.5491040945053101\n",
            "Loss:0.5489354133605957\n",
            "Loss:0.5487667322158813\n",
            "Loss:0.5485979318618774\n",
            "Loss:0.5484291315078735\n",
            "Epoch: 40 | Loss: 0.5484291315078735 | Test loss: 0.5793591737747192\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7622]])), ('linear_layer.bias', tensor([0.8240]))])\n",
            "Loss:0.5482604503631592\n",
            "Loss:0.5480917692184448\n",
            "Loss:0.5479230880737305\n",
            "Loss:0.5477543473243713\n",
            "Loss:0.5475856065750122\n",
            "Loss:0.5474168658256531\n",
            "Loss:0.5472482442855835\n",
            "Loss:0.5470794439315796\n",
            "Loss:0.5469107031822205\n",
            "Loss:0.5467419624328613\n",
            "Epoch: 50 | Loss: 0.5467419624328613 | Test loss: 0.5773864984512329\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7616]])), ('linear_layer.bias', tensor([0.8225]))])\n",
            "Loss:0.5465734004974365\n",
            "Loss:0.5464046001434326\n",
            "Loss:0.5462358593940735\n",
            "Loss:0.5460671186447144\n",
            "Loss:0.5458984375\n",
            "Loss:0.5457297563552856\n",
            "Loss:0.5455609560012817\n",
            "Loss:0.5453922152519226\n",
            "Loss:0.545223593711853\n",
            "Loss:0.5450548529624939\n",
            "Epoch: 60 | Loss: 0.5450548529624939 | Test loss: 0.5754138231277466\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7611]])), ('linear_layer.bias', tensor([0.8211]))])\n",
            "Loss:0.5448861718177795\n",
            "Loss:0.5447174310684204\n",
            "Loss:0.5445486307144165\n",
            "Loss:0.5443800091743469\n",
            "Loss:0.5442112684249878\n",
            "Loss:0.5440425276756287\n",
            "Loss:0.5438737869262695\n",
            "Loss:0.5437051057815552\n",
            "Loss:0.5435364246368408\n",
            "Loss:0.5433676838874817\n",
            "Epoch: 70 | Loss: 0.5433676838874817 | Test loss: 0.5734411478042603\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7605]])), ('linear_layer.bias', tensor([0.8196]))])\n",
            "Loss:0.5431989431381226\n",
            "Loss:0.5430302023887634\n",
            "Loss:0.5428615212440491\n",
            "Loss:0.5426927804946899\n",
            "Loss:0.5425240397453308\n",
            "Loss:0.5423553586006165\n",
            "Loss:0.5421866774559021\n",
            "Loss:0.542017936706543\n",
            "Loss:0.5418491959571838\n",
            "Loss:0.5416804552078247\n",
            "Epoch: 80 | Loss: 0.5416804552078247 | Test loss: 0.5714684724807739\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7599]])), ('linear_layer.bias', tensor([0.8181]))])\n",
            "Loss:0.5415117740631104\n",
            "Loss:0.5413430333137512\n",
            "Loss:0.5411742925643921\n",
            "Loss:0.5410056114196777\n",
            "Loss:0.5408369302749634\n",
            "Loss:0.5406681895256042\n",
            "Loss:0.5404994487762451\n",
            "Loss:0.540330708026886\n",
            "Loss:0.5401620268821716\n",
            "Loss:0.5399932861328125\n",
            "Epoch: 90 | Loss: 0.5399932861328125 | Test loss: 0.5694957971572876\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7593]])), ('linear_layer.bias', tensor([0.8167]))])\n",
            "Loss:0.5398246049880981\n",
            "Loss:0.5396558046340942\n",
            "Loss:0.5394870638847351\n",
            "Loss:0.5393184423446655\n",
            "Loss:0.5391497015953064\n",
            "Loss:0.5389809608459473\n",
            "Loss:0.5388122797012329\n",
            "Loss:0.5386435389518738\n",
            "Loss:0.5384748578071594\n",
            "Loss:0.5383061170578003\n",
            "Epoch: 100 | Loss: 0.5383061170578003 | Test loss: 0.5675231218338013\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7588]])), ('linear_layer.bias', tensor([0.8152]))])\n",
            "Loss:0.5381374359130859\n",
            "Loss:0.537968635559082\n",
            "Loss:0.5377999544143677\n",
            "Loss:0.5376312136650085\n",
            "Loss:0.5374624729156494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|       | 30/100 [00:09<00:22,  3.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5372937917709351\n",
            "Loss:0.5371251702308655\n",
            "Loss:0.5369564294815063\n",
            "Loss:0.5367876291275024\n",
            "Loss:0.5366189479827881\n",
            "Epoch: 110 | Loss: 0.5366189479827881 | Test loss: 0.5655504465103149\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7582]])), ('linear_layer.bias', tensor([0.8138]))])\n",
            "Loss:0.536450207233429\n",
            "Loss:0.5362814664840698\n",
            "Loss:0.5361127853393555\n",
            "Loss:0.5359441041946411\n",
            "Loss:0.5357754230499268\n",
            "Loss:0.5356066823005676\n",
            "Loss:0.5354379415512085\n",
            "Loss:0.5352692008018494\n",
            "Loss:0.5351004600524902\n",
            "Loss:0.5349317789077759\n",
            "Epoch: 120 | Loss: 0.5349317789077759 | Test loss: 0.5635777115821838\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7576]])), ('linear_layer.bias', tensor([0.8123]))])\n",
            "Loss:0.5347630381584167\n",
            "Loss:0.5345943570137024\n",
            "Loss:0.5344256162643433\n",
            "Loss:0.5342568755149841\n",
            "Loss:0.5340881943702698\n",
            "Loss:0.5339194536209106\n",
            "Loss:0.5337507128715515\n",
            "Loss:0.5335820317268372\n",
            "Loss:0.533413290977478\n",
            "Loss:0.5332445502281189\n",
            "Epoch: 130 | Loss: 0.5332445502281189 | Test loss: 0.5616050362586975\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7571]])), ('linear_layer.bias', tensor([0.8108]))])\n",
            "Loss:0.5330758690834045\n",
            "Loss:0.5329071283340454\n",
            "Loss:0.532738447189331\n",
            "Loss:0.5325697064399719\n",
            "Loss:0.5324009656906128\n",
            "Loss:0.5322322845458984\n",
            "Loss:0.5320636034011841\n",
            "Loss:0.5318948030471802\n",
            "Loss:0.531726062297821\n",
            "Loss:0.5315574407577515\n",
            "Epoch: 140 | Loss: 0.5315574407577515 | Test loss: 0.5596323013305664\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7565]])), ('linear_layer.bias', tensor([0.8094]))])\n",
            "Loss:0.5313887000083923\n",
            "Loss:0.5312199592590332\n",
            "Loss:0.5310512185096741\n",
            "Loss:0.5308825373649597\n",
            "Loss:0.5307137966156006\n",
            "Loss:0.5305451154708862\n",
            "Loss:0.5303763151168823\n",
            "Loss:0.530207633972168\n",
            "Loss:0.5300389528274536\n",
            "Loss:0.5298701524734497\n",
            "Epoch: 150 | Loss: 0.5298701524734497 | Test loss: 0.5576596260070801\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7559]])), ('linear_layer.bias', tensor([0.8079]))])\n",
            "Loss:0.5297015309333801\n",
            "Loss:0.529532790184021\n",
            "Loss:0.5293640494346619\n",
            "Loss:0.5291953086853027\n",
            "Loss:0.5290266275405884\n",
            "Loss:0.5288578867912292\n",
            "Loss:0.5286892652511597\n",
            "Loss:0.5285204648971558\n",
            "Loss:0.5283517241477966\n",
            "Loss:0.528183102607727\n",
            "Epoch: 160 | Loss: 0.528183102607727 | Test loss: 0.5556869506835938\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7553]])), ('linear_layer.bias', tensor([0.8064]))])\n",
            "Loss:0.5280143022537231\n",
            "Loss:0.5278456211090088\n",
            "Loss:0.5276768803596497\n",
            "Loss:0.5275081396102905\n",
            "Loss:0.5273394584655762\n",
            "Loss:0.5271707773208618\n",
            "Loss:0.5270019769668579\n",
            "Loss:0.5268332362174988\n",
            "Loss:0.5266646146774292\n",
            "Loss:0.5264958739280701\n",
            "Epoch: 170 | Loss: 0.5264958739280701 | Test loss: 0.5537142753601074\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7548]])), ('linear_layer.bias', tensor([0.8050]))])\n",
            "Loss:0.5263271331787109\n",
            "Loss:0.5261584520339966\n",
            "Loss:0.5259897112846375\n",
            "Loss:0.5258209705352783\n",
            "Loss:0.525652289390564\n",
            "Loss:0.5254834890365601\n",
            "Loss:0.5253148078918457\n",
            "Loss:0.5251461267471313\n",
            "Loss:0.5249773263931274\n",
            "Loss:0.5248086452484131\n",
            "Epoch: 180 | Loss: 0.5248086452484131 | Test loss: 0.5517415404319763\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7542]])), ('linear_layer.bias', tensor([0.8035]))])\n",
            "Loss:0.5246399641036987\n",
            "Loss:0.5244712233543396\n",
            "Loss:0.5243025422096252\n",
            "Loss:0.5241338014602661\n",
            "Loss:0.523965060710907\n",
            "Loss:0.5237963795661926\n",
            "Loss:0.5236276388168335\n",
            "Loss:0.5234588980674744\n",
            "Loss:0.5232901573181152\n",
            "Loss:0.5231214761734009\n",
            "Epoch: 190 | Loss: 0.5231214761734009 | Test loss: 0.5497689247131348\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7536]])), ('linear_layer.bias', tensor([0.8020]))])\n",
            "Loss:0.5229527950286865\n",
            "Loss:0.5227840542793274\n",
            "Loss:0.5226153135299683\n",
            "Loss:0.5224466323852539\n",
            "Loss:0.5222779512405396\n",
            "Loss:0.5221092104911804\n",
            "Loss:0.5219404697418213\n",
            "Loss:0.5217717885971069\n",
            "Loss:0.521602988243103\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5872431397438049\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5550033450126648\n",
            "Loss:0.5548288226127625\n",
            "Loss:0.5546543002128601\n",
            "Loss:0.554479718208313\n",
            "Loss:0.5543051958084106\n",
            "Loss:0.5541306734085083\n",
            "Loss:0.553956151008606\n",
            "Loss:0.5537814497947693\n",
            "Loss:0.5536069869995117\n",
            "Loss:0.5534324645996094\n",
            "Epoch: 10 | Loss: 0.5534324645996094 | Test loss: 0.5852022767066956\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7639]])), ('linear_layer.bias', tensor([0.8283]))])\n",
            "Loss:0.5532578229904175\n",
            "Loss:0.5530833005905151\n",
            "Loss:0.5529087781906128\n",
            "Loss:0.5527341961860657\n",
            "Loss:0.5525596737861633\n",
            "Loss:0.552385151386261\n",
            "Loss:0.5522106289863586\n",
            "Loss:0.5520359873771667\n",
            "Loss:0.5518615245819092\n",
            "Loss:0.5516868829727173\n",
            "Epoch: 20 | Loss: 0.5516868829727173 | Test loss: 0.5831614136695862\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8268]))])\n",
            "Loss:0.5515123605728149\n",
            "Loss:0.5513378381729126\n",
            "Loss:0.5511632561683655\n",
            "Loss:0.5509886741638184\n",
            "Loss:0.550814151763916\n",
            "Loss:0.5506395101547241\n",
            "Loss:0.5504649877548218\n",
            "Loss:0.5502904653549194\n",
            "Loss:0.5501158833503723\n",
            "Loss:0.5499414205551147\n",
            "Epoch: 30 | Loss: 0.5499414205551147 | Test loss: 0.5811205506324768\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7627]])), ('linear_layer.bias', tensor([0.8253]))])\n",
            "Loss:0.5497668981552124\n",
            "Loss:0.5495923161506653\n",
            "Loss:0.5494177341461182\n",
            "Loss:0.549243152141571\n",
            "Loss:0.5490686297416687\n",
            "Loss:0.5488940477371216\n",
            "Loss:0.5487195253372192\n",
            "Loss:0.5485450029373169\n",
            "Loss:0.5483704209327698\n",
            "Loss:0.5481958985328674\n",
            "Epoch: 40 | Loss: 0.5481958985328674 | Test loss: 0.5790796279907227\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7621]])), ('linear_layer.bias', tensor([0.8238]))])\n",
            "Loss:0.5480213165283203\n",
            "Loss:0.5478466749191284\n",
            "Loss:0.5476722121238708\n",
            "Loss:0.5474976897239685\n",
            "Loss:0.5473231077194214\n",
            "Loss:0.5471485257148743\n",
            "Loss:0.5469740629196167\n",
            "Loss:0.5467995405197144\n",
            "Loss:0.5466248989105225\n",
            "Loss:0.5464503765106201\n",
            "Epoch: 50 | Loss: 0.5464503765106201 | Test loss: 0.5770388841629028\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7615]])), ('linear_layer.bias', tensor([0.8223]))])\n",
            "Loss:0.5462757349014282\n",
            "Loss:0.5461012125015259\n",
            "Loss:0.5459267497062683\n",
            "Loss:0.5457521677017212\n",
            "Loss:0.5455776453018188\n",
            "Loss:0.545403003692627\n",
            "Loss:0.5452285408973694\n",
            "Loss:0.5450538396835327\n",
            "Loss:0.5448793768882751\n",
            "Loss:0.544704794883728\n",
            "Epoch: 60 | Loss: 0.544704794883728 | Test loss: 0.5749980211257935\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7609]])), ('linear_layer.bias', tensor([0.8208]))])\n",
            "Loss:0.5445303320884705\n",
            "Loss:0.5443557500839233\n",
            "Loss:0.5441811680793762\n",
            "Loss:0.5440066456794739\n",
            "Loss:0.5438321232795715\n",
            "Loss:0.5436575412750244\n",
            "Loss:0.5434829592704773\n",
            "Loss:0.5433083772659302\n",
            "Loss:0.5431338548660278\n",
            "Loss:0.5429593920707703\n",
            "Epoch: 70 | Loss: 0.5429593920707703 | Test loss: 0.5729571580886841\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7603]])), ('linear_layer.bias', tensor([0.8193]))])\n",
            "Loss:0.5427848100662231\n",
            "Loss:0.5426102876663208\n",
            "Loss:0.5424356460571289\n",
            "Loss:0.5422611236572266\n",
            "Loss:0.5420865416526794\n",
            "Loss:0.5419120192527771\n",
            "Loss:0.54173743724823\n",
            "Loss:0.5415629148483276\n",
            "Loss:0.5413883924484253\n",
            "Loss:0.5412138104438782\n",
            "Epoch: 80 | Loss: 0.5412138104438782 | Test loss: 0.5709162950515747\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7598]])), ('linear_layer.bias', tensor([0.8177]))])\n",
            "Loss:0.5410392880439758\n",
            "Loss:0.5408647656440735\n",
            "Loss:0.5406901240348816\n",
            "Loss:0.5405156016349792\n",
            "Loss:0.5403410196304321\n",
            "Loss:0.5401664972305298\n",
            "Loss:0.5399919152259827\n",
            "Loss:0.5398174524307251\n",
            "Loss:0.5396428108215332\n",
            "Loss:0.5394682288169861\n",
            "Epoch: 90 | Loss: 0.5394682288169861 | Test loss: 0.5688754320144653\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7592]])), ('linear_layer.bias', tensor([0.8162]))])\n",
            "Loss:0.5392937660217285\n",
            "Loss:0.5391191244125366\n",
            "Loss:0.5389446020126343\n",
            "Loss:0.5387700796127319\n",
            "Loss:0.5385955572128296\n",
            "Loss:0.5384209752082825\n",
            "Loss:0.5382464528083801\n",
            "Loss:0.5380719304084778\n",
            "Loss:0.5378972887992859\n",
            "Loss:0.5377227663993835\n",
            "Epoch: 100 | Loss: 0.5377227663993835 | Test loss: 0.566834568977356\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7586]])), ('linear_layer.bias', tensor([0.8147]))])\n",
            "Loss:0.5375481843948364\n",
            "Loss:0.5373736619949341\n",
            "Loss:0.5371991395950317\n",
            "Loss:0.5370245575904846\n",
            "Loss:0.5368500351905823\n",
            "Loss:0.5366754531860352\n",
            "Loss:0.536500871181488\n",
            "Loss:0.5363263487815857\n",
            "Loss:0.5361517667770386\n",
            "Loss:0.5359772443771362\n",
            "Epoch: 110 | Loss: 0.5359772443771362 | Test loss: 0.5647937059402466\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7580]])), ('linear_layer.bias', tensor([0.8132]))])\n",
            "Loss:0.5358026623725891\n",
            "Loss:0.5356281399726868\n",
            "Loss:0.5354536175727844\n",
            "Loss:0.5352790355682373\n",
            "Loss:0.535104513168335\n",
            "Loss:0.5349299311637878\n",
            "Loss:0.5347554087638855\n",
            "Loss:0.5345808267593384\n",
            "Loss:0.534406304359436\n",
            "Loss:0.5342317819595337\n",
            "Epoch: 120 | Loss: 0.5342317819595337 | Test loss: 0.5627528429031372\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7574]])), ('linear_layer.bias', tensor([0.8117]))])\n",
            "Loss:0.5340571999549866\n",
            "Loss:0.5338826179504395\n",
            "Loss:0.5337080359458923\n",
            "Loss:0.53353351354599\n",
            "Loss:0.5333589911460876\n",
            "Loss:0.5331844091415405\n",
            "Loss:0.5330098867416382\n",
            "Loss:0.5328353047370911\n",
            "Loss:0.5326607823371887\n",
            "Loss:0.5324861407279968\n",
            "Epoch: 130 | Loss: 0.5324861407279968 | Test loss: 0.5607119798660278\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7568]])), ('linear_layer.bias', tensor([0.8102]))])\n",
            "Loss:0.5323116779327393\n",
            "Loss:0.5321371555328369\n",
            "Loss:0.531962513923645\n",
            "Loss:0.5317879915237427\n",
            "Loss:0.5316134691238403\n",
            "Loss:0.531438946723938\n",
            "Loss:0.5312644243240356\n",
            "Loss:0.5310897827148438\n",
            "Loss:0.5309152603149414\n",
            "Loss:0.5307406783103943\n",
            "Epoch: 140 | Loss: 0.5307406783103943 | Test loss: 0.5586711168289185\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7562]])), ('linear_layer.bias', tensor([0.8086]))])\n",
            "Loss:0.5305661559104919\n",
            "Loss:0.5303915739059448\n",
            "Loss:0.5302170515060425\n",
            "Loss:0.5300425291061401\n",
            "Loss:0.529867947101593\n",
            "Loss:0.5296933650970459\n",
            "Loss:0.5295188426971436\n",
            "Loss:0.5293443202972412\n",
            "Loss:0.5291697382926941\n",
            "Loss:0.528995156288147\n",
            "Epoch: 150 | Loss: 0.528995156288147 | Test loss: 0.5566302537918091\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7556]])), ('linear_layer.bias', tensor([0.8071]))])\n",
            "Loss:0.5288206338882446\n",
            "Loss:0.5286461114883423\n",
            "Loss:0.5284715294837952\n",
            "Loss:0.5282970666885376\n",
            "Loss:0.5281224250793457\n",
            "Loss:0.5279479026794434\n",
            "Loss:0.5277733206748962\n",
            "Loss:0.5275987386703491\n",
            "Loss:0.5274242162704468\n",
            "Loss:0.5272496938705444\n",
            "Epoch: 160 | Loss: 0.5272496938705444 | Test loss: 0.5545893907546997\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7550]])), ('linear_layer.bias', tensor([0.8056]))])\n",
            "Loss:0.5270751118659973\n",
            "Loss:0.5269005298614502\n",
            "Loss:0.5267260074615479\n",
            "Loss:0.5265514254570007\n",
            "Loss:0.5263769030570984\n",
            "Loss:0.526202380657196\n",
            "Loss:0.5260277986526489\n",
            "Loss:0.5258532762527466\n",
            "Loss:0.5256786346435547\n",
            "Loss:0.5255041718482971\n",
            "Epoch: 170 | Loss: 0.5255041718482971 | Test loss: 0.5525485277175903\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7544]])), ('linear_layer.bias', tensor([0.8041]))])\n",
            "Loss:0.52532958984375\n",
            "Loss:0.5251550078392029\n",
            "Loss:0.5249805450439453\n",
            "Loss:0.5248059034347534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|       | 31/100 [00:09<00:21,  3.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5246313810348511\n",
            "Loss:0.5244568586349487\n",
            "Loss:0.5242822766304016\n",
            "Loss:0.5241077542304993\n",
            "Loss:0.5239332318305969\n",
            "Loss:0.5237587094306946\n",
            "Epoch: 180 | Loss: 0.5237587094306946 | Test loss: 0.550507664680481\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7538]])), ('linear_layer.bias', tensor([0.8026]))])\n",
            "Loss:0.5235840678215027\n",
            "Loss:0.5234095454216003\n",
            "Loss:0.5232349634170532\n",
            "Loss:0.5230604410171509\n",
            "Loss:0.5228859186172485\n",
            "Loss:0.5227113366127014\n",
            "Loss:0.5225368142127991\n",
            "Loss:0.5223621726036072\n",
            "Loss:0.5221875905990601\n",
            "Loss:0.5220130681991577\n",
            "Epoch: 190 | Loss: 0.5220130681991577 | Test loss: 0.5484668016433716\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7533]])), ('linear_layer.bias', tensor([0.8011]))])\n",
            "Loss:0.5218385457992554\n",
            "Loss:0.521664023399353\n",
            "Loss:0.5214894413948059\n",
            "Loss:0.5213149189949036\n",
            "Loss:0.5211403965950012\n",
            "Loss:0.5209658145904541\n",
            "Loss:0.520791232585907\n",
            "Loss:0.5206167101860046\n",
            "Loss:0.5204421281814575\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5872363448143005\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8299]))])\n",
            "Loss:0.5549975633621216\n",
            "Loss:0.5548170804977417\n",
            "Loss:0.5546367764472961\n",
            "Loss:0.554456353187561\n",
            "Loss:0.5542759299278259\n",
            "Loss:0.5540956258773804\n",
            "Loss:0.55391526222229\n",
            "Loss:0.5537348985671997\n",
            "Loss:0.5535544753074646\n",
            "Loss:0.5533741116523743\n",
            "Epoch: 10 | Loss: 0.5533741116523743 | Test loss: 0.5851272344589233\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7639]])), ('linear_layer.bias', tensor([0.8283]))])\n",
            "Loss:0.5531936883926392\n",
            "Loss:0.5530133247375488\n",
            "Loss:0.5528329014778137\n",
            "Loss:0.5526525378227234\n",
            "Loss:0.5524722337722778\n",
            "Loss:0.552291750907898\n",
            "Loss:0.5521113276481628\n",
            "Loss:0.5519309639930725\n",
            "Loss:0.5517506003379822\n",
            "Loss:0.5515701770782471\n",
            "Epoch: 20 | Loss: 0.5515701770782471 | Test loss: 0.5830182433128357\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8267]))])\n",
            "Loss:0.5513898730278015\n",
            "Loss:0.5512095093727112\n",
            "Loss:0.5510290861129761\n",
            "Loss:0.5508487224578857\n",
            "Loss:0.5506683588027954\n",
            "Loss:0.5504879355430603\n",
            "Loss:0.5503075122833252\n",
            "Loss:0.5501270890235901\n",
            "Loss:0.5499467849731445\n",
            "Loss:0.5497664213180542\n",
            "Epoch: 30 | Loss: 0.5497664213180542 | Test loss: 0.5809091925621033\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8252]))])\n",
            "Loss:0.5495859384536743\n",
            "Loss:0.5494056344032288\n",
            "Loss:0.5492252111434937\n",
            "Loss:0.5490448474884033\n",
            "Loss:0.548864483833313\n",
            "Loss:0.5486841201782227\n",
            "Loss:0.5485037565231323\n",
            "Loss:0.5483233332633972\n",
            "Loss:0.5481429100036621\n",
            "Loss:0.5479625463485718\n",
            "Epoch: 40 | Loss: 0.5479625463485718 | Test loss: 0.5788001418113708\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7620]])), ('linear_layer.bias', tensor([0.8236]))])\n",
            "Loss:0.5477821230888367\n",
            "Loss:0.5476017594337463\n",
            "Loss:0.5474213361740112\n",
            "Loss:0.5472410321235657\n",
            "Loss:0.5470606088638306\n",
            "Loss:0.5468802452087402\n",
            "Loss:0.5466998815536499\n",
            "Loss:0.54651939868927\n",
            "Loss:0.5463390350341797\n",
            "Loss:0.5461586713790894\n",
            "Epoch: 50 | Loss: 0.5461586713790894 | Test loss: 0.5766911506652832\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7614]])), ('linear_layer.bias', tensor([0.8220]))])\n",
            "Loss:0.545978307723999\n",
            "Loss:0.5457979440689087\n",
            "Loss:0.5456175208091736\n",
            "Loss:0.5454371571540833\n",
            "Loss:0.5452567338943481\n",
            "Loss:0.5450763702392578\n",
            "Loss:0.5448960065841675\n",
            "Loss:0.5447155237197876\n",
            "Loss:0.5445351600646973\n",
            "Loss:0.5443548560142517\n",
            "Epoch: 60 | Loss: 0.5443548560142517 | Test loss: 0.5745821595191956\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7608]])), ('linear_layer.bias', tensor([0.8205]))])\n",
            "Loss:0.5441744327545166\n",
            "Loss:0.5439940094947815\n",
            "Loss:0.5438136458396912\n",
            "Loss:0.5436332821846008\n",
            "Loss:0.5434528589248657\n",
            "Loss:0.5432724952697754\n",
            "Loss:0.5430921316146851\n",
            "Loss:0.5429117679595947\n",
            "Loss:0.5427314043045044\n",
            "Loss:0.5425509810447693\n",
            "Epoch: 70 | Loss: 0.5425509810447693 | Test loss: 0.5724731683731079\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7602]])), ('linear_layer.bias', tensor([0.8189]))])\n",
            "Loss:0.5423704981803894\n",
            "Loss:0.5421901941299438\n",
            "Loss:0.542009711265564\n",
            "Loss:0.5418294668197632\n",
            "Loss:0.5416490435600281\n",
            "Loss:0.5414686799049377\n",
            "Loss:0.5412882566452026\n",
            "Loss:0.5411078929901123\n",
            "Loss:0.540927529335022\n",
            "Loss:0.5407471060752869\n",
            "Epoch: 80 | Loss: 0.5407471060752869 | Test loss: 0.5703640580177307\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7596]])), ('linear_layer.bias', tensor([0.8173]))])\n",
            "Loss:0.5405666828155518\n",
            "Loss:0.5403863191604614\n",
            "Loss:0.5402060151100159\n",
            "Loss:0.5400255918502808\n",
            "Loss:0.5398452281951904\n",
            "Loss:0.5396648645401001\n",
            "Loss:0.539484441280365\n",
            "Loss:0.5393039584159851\n",
            "Loss:0.5391236543655396\n",
            "Loss:0.5389432311058044\n",
            "Epoch: 90 | Loss: 0.5389432311058044 | Test loss: 0.5682550668716431\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7590]])), ('linear_layer.bias', tensor([0.8158]))])\n",
            "Loss:0.5387629270553589\n",
            "Loss:0.5385825037956238\n",
            "Loss:0.5384021401405334\n",
            "Loss:0.5382217168807983\n",
            "Loss:0.538041353225708\n",
            "Loss:0.5378609299659729\n",
            "Loss:0.5376805663108826\n",
            "Loss:0.537500262260437\n",
            "Loss:0.5373197793960571\n",
            "Loss:0.5371394157409668\n",
            "Epoch: 100 | Loss: 0.5371394157409668 | Test loss: 0.5661460757255554\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7584]])), ('linear_layer.bias', tensor([0.8142]))])\n",
            "Loss:0.5369589924812317\n",
            "Loss:0.5367786288261414\n",
            "Loss:0.5365982055664062\n",
            "Loss:0.5364178419113159\n",
            "Loss:0.5362374782562256\n",
            "Loss:0.5360571146011353\n",
            "Loss:0.5358767509460449\n",
            "Loss:0.5356963276863098\n",
            "Loss:0.5355159044265747\n",
            "Loss:0.5353356003761292\n",
            "Epoch: 110 | Loss: 0.5353356003761292 | Test loss: 0.564037024974823\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7578]])), ('linear_layer.bias', tensor([0.8126]))])\n",
            "Loss:0.535155177116394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|      | 32/100 [00:10<00:20,  3.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5349748134613037\n",
            "Loss:0.5347944498062134\n",
            "Loss:0.5346140265464783\n",
            "Loss:0.5344336628913879\n",
            "Loss:0.5342532396316528\n",
            "Loss:0.5340728759765625\n",
            "Loss:0.5338924527168274\n",
            "Loss:0.5337120890617371\n",
            "Loss:0.5335317254066467\n",
            "Epoch: 120 | Loss: 0.5335317254066467 | Test loss: 0.5619279146194458\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7572]])), ('linear_layer.bias', tensor([0.8111]))])\n",
            "Loss:0.5333513021469116\n",
            "Loss:0.5331709384918213\n",
            "Loss:0.532990574836731\n",
            "Loss:0.5328101515769958\n",
            "Loss:0.5326297879219055\n",
            "Loss:0.5324494242668152\n",
            "Loss:0.5322690010070801\n",
            "Loss:0.5320886373519897\n",
            "Loss:0.5319082736968994\n",
            "Loss:0.5317278504371643\n",
            "Epoch: 130 | Loss: 0.5317278504371643 | Test loss: 0.5598189234733582\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7565]])), ('linear_layer.bias', tensor([0.8095]))])\n",
            "Loss:0.5315474271774292\n",
            "Loss:0.5313671231269836\n",
            "Loss:0.5311866998672485\n",
            "Loss:0.5310063362121582\n",
            "Loss:0.5308259725570679\n",
            "Loss:0.5306455492973328\n",
            "Loss:0.5304651260375977\n",
            "Loss:0.5302847623825073\n",
            "Loss:0.530104398727417\n",
            "Loss:0.5299240350723267\n",
            "Epoch: 140 | Loss: 0.5299240350723267 | Test loss: 0.5577099323272705\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7559]])), ('linear_layer.bias', tensor([0.8079]))])\n",
            "Loss:0.5297436714172363\n",
            "Loss:0.529563307762146\n",
            "Loss:0.5293828845024109\n",
            "Loss:0.5292025208473206\n",
            "Loss:0.5290220975875854\n",
            "Loss:0.5288416743278503\n",
            "Loss:0.5286613702774048\n",
            "Loss:0.5284808874130249\n",
            "Loss:0.5283005237579346\n",
            "Loss:0.5281201601028442\n",
            "Epoch: 150 | Loss: 0.5281201601028442 | Test loss: 0.5556008815765381\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7553]])), ('linear_layer.bias', tensor([0.8064]))])\n",
            "Loss:0.5279397964477539\n",
            "Loss:0.5277593731880188\n",
            "Loss:0.5275790095329285\n",
            "Loss:0.5273986458778381\n",
            "Loss:0.5272182822227478\n",
            "Loss:0.5270378589630127\n",
            "Loss:0.5268574953079224\n",
            "Loss:0.5266770124435425\n",
            "Loss:0.5264967083930969\n",
            "Loss:0.5263163447380066\n",
            "Epoch: 160 | Loss: 0.5263163447380066 | Test loss: 0.5534918308258057\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7547]])), ('linear_layer.bias', tensor([0.8048]))])\n",
            "Loss:0.5261359214782715\n",
            "Loss:0.5259555578231812\n",
            "Loss:0.525775134563446\n",
            "Loss:0.5255947709083557\n",
            "Loss:0.5254144072532654\n",
            "Loss:0.525234043598175\n",
            "Loss:0.5250536203384399\n",
            "Loss:0.5248732566833496\n",
            "Loss:0.5246928334236145\n",
            "Loss:0.5245124697685242\n",
            "Epoch: 170 | Loss: 0.5245124697685242 | Test loss: 0.5513828992843628\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7541]])), ('linear_layer.bias', tensor([0.8032]))])\n",
            "Loss:0.5243321061134338\n",
            "Loss:0.5241516828536987\n",
            "Loss:0.5239713191986084\n",
            "Loss:0.5237909555435181\n",
            "Loss:0.5236104726791382\n",
            "Loss:0.5234301686286926\n",
            "Loss:0.5232497453689575\n",
            "Loss:0.5230693221092224\n",
            "Loss:0.5228890180587769\n",
            "Loss:0.5227085947990417\n",
            "Epoch: 180 | Loss: 0.5227085947990417 | Test loss: 0.5492738485336304\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7535]])), ('linear_layer.bias', tensor([0.8017]))])\n",
            "Loss:0.5225282311439514\n",
            "Loss:0.5223478078842163\n",
            "Loss:0.5221675038337708\n",
            "Loss:0.5219870805740356\n",
            "Loss:0.5218067169189453\n",
            "Loss:0.521626353263855\n",
            "Loss:0.5214458703994751\n",
            "Loss:0.5212655067443848\n",
            "Loss:0.5210851430892944\n",
            "Loss:0.5209048390388489\n",
            "Epoch: 190 | Loss: 0.5209048390388489 | Test loss: 0.5471648573875427\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7529]])), ('linear_layer.bias', tensor([0.8001]))])\n",
            "Loss:0.5207244157791138\n",
            "Loss:0.5205439329147339\n",
            "Loss:0.5203635692596436\n",
            "Loss:0.5201832056045532\n",
            "Loss:0.5200028419494629\n",
            "Loss:0.5198224782943726\n",
            "Loss:0.5196420550346375\n",
            "Loss:0.5194616913795471\n",
            "Loss:0.519281268119812\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5872295498847961\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5549917817115784\n",
            "Loss:0.5548055768013\n",
            "Loss:0.5546194911003113\n",
            "Loss:0.554433286190033\n",
            "Loss:0.5542470812797546\n",
            "Loss:0.5540609955787659\n",
            "Loss:0.5538748502731323\n",
            "Loss:0.553688645362854\n",
            "Loss:0.5535024404525757\n",
            "Loss:0.5533163547515869\n",
            "Epoch: 10 | Loss: 0.5533163547515869 | Test loss: 0.5850529670715332\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7638]])), ('linear_layer.bias', tensor([0.8282]))])\n",
            "Loss:0.5531302094459534\n",
            "Loss:0.5529440641403198\n",
            "Loss:0.5527578592300415\n",
            "Loss:0.5525716543197632\n",
            "Loss:0.5523855090141296\n",
            "Loss:0.5521994829177856\n",
            "Loss:0.5520132184028625\n",
            "Loss:0.551827073097229\n",
            "Loss:0.5516409277915955\n",
            "Loss:0.5514547824859619\n",
            "Epoch: 20 | Loss: 0.5514547824859619 | Test loss: 0.5828763246536255\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7632]])), ('linear_layer.bias', tensor([0.8266]))])\n",
            "Loss:0.5512685775756836\n",
            "Loss:0.55108243227005\n",
            "Loss:0.5508963465690613\n",
            "Loss:0.550710141658783\n",
            "Loss:0.5505238771438599\n",
            "Loss:0.5503378510475159\n",
            "Loss:0.5501516461372375\n",
            "Loss:0.549965500831604\n",
            "Loss:0.5497792959213257\n",
            "Loss:0.5495932102203369\n",
            "Epoch: 30 | Loss: 0.5495932102203369 | Test loss: 0.5806997418403625\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8250]))])\n",
            "Loss:0.5494070649147034\n",
            "Loss:0.549220860004425\n",
            "Loss:0.5490346550941467\n",
            "Loss:0.5488485097885132\n",
            "Loss:0.5486623644828796\n",
            "Loss:0.5484761595726013\n",
            "Loss:0.5482900738716125\n",
            "Loss:0.548103928565979\n",
            "Loss:0.5479177236557007\n",
            "Loss:0.5477315187454224\n",
            "Epoch: 40 | Loss: 0.5477315187454224 | Test loss: 0.5785230994224548\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7620]])), ('linear_layer.bias', tensor([0.8234]))])\n",
            "Loss:0.5475453734397888\n",
            "Loss:0.5473592877388\n",
            "Loss:0.5471731424331665\n",
            "Loss:0.5469869375228882\n",
            "Loss:0.5468007326126099\n",
            "Loss:0.5466146469116211\n",
            "Loss:0.5464284420013428\n",
            "Loss:0.5462422966957092\n",
            "Loss:0.5460561513900757\n",
            "Loss:0.5458699464797974\n",
            "Epoch: 50 | Loss: 0.5458699464797974 | Test loss: 0.5763465166091919\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7613]])), ('linear_layer.bias', tensor([0.8218]))])\n",
            "Loss:0.5456838011741638\n",
            "Loss:0.5454976558685303\n",
            "Loss:0.5453115701675415\n",
            "Loss:0.5451253652572632\n",
            "Loss:0.5449391603469849\n",
            "Loss:0.5447530150413513\n",
            "Loss:0.5445668697357178\n",
            "Loss:0.544380784034729\n",
            "Loss:0.5441945791244507\n",
            "Loss:0.5440083742141724\n",
            "Epoch: 60 | Loss: 0.5440083742141724 | Test loss: 0.5741699934005737\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7607]])), ('linear_layer.bias', tensor([0.8202]))])\n",
            "Loss:0.5438222289085388\n",
            "Loss:0.54363614320755\n",
            "Loss:0.5434499382972717\n",
            "Loss:0.5432637333869934\n",
            "Loss:0.5430776476860046\n",
            "Loss:0.5428914427757263\n",
            "Loss:0.542705237865448\n",
            "Loss:0.5425191521644592\n",
            "Loss:0.5423329472541809\n",
            "Loss:0.5421467423439026\n",
            "Epoch: 70 | Loss: 0.5421467423439026 | Test loss: 0.5719932913780212\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7601]])), ('linear_layer.bias', tensor([0.8185]))])\n",
            "Loss:0.541960597038269\n",
            "Loss:0.5417744517326355\n",
            "Loss:0.5415883660316467\n",
            "Loss:0.5414021611213684\n",
            "Loss:0.5412160158157349\n",
            "Loss:0.5410298109054565\n",
            "Loss:0.5408437252044678\n",
            "Loss:0.5406574606895447\n",
            "Loss:0.5404714345932007\n",
            "Loss:0.5402852296829224\n",
            "Epoch: 80 | Loss: 0.5402852296829224 | Test loss: 0.5698167085647583\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7594]])), ('linear_layer.bias', tensor([0.8169]))])\n",
            "Loss:0.5400991439819336\n",
            "Loss:0.5399128198623657\n",
            "Loss:0.539726734161377\n",
            "Loss:0.5395405888557434\n",
            "Loss:0.5393544435501099\n",
            "Loss:0.5391682386398315\n",
            "Loss:0.5389820337295532\n",
            "Loss:0.5387960076332092\n",
            "Loss:0.5386097431182861\n",
            "Loss:0.5384236574172974\n",
            "Epoch: 90 | Loss: 0.5384236574172974 | Test loss: 0.5676401257514954\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7588]])), ('linear_layer.bias', tensor([0.8153]))])\n",
            "Loss:0.538237452507019\n",
            "Loss:0.5380512475967407\n",
            "Loss:0.5378651022911072\n",
            "Loss:0.5376789569854736\n",
            "Loss:0.5374928712844849\n",
            "Loss:0.5373066663742065\n",
            "Loss:0.537120521068573\n",
            "Loss:0.5369343161582947\n",
            "Loss:0.5367482304573059\n",
            "Loss:0.5365620851516724\n",
            "Epoch: 100 | Loss: 0.5365620851516724 | Test loss: 0.5654635429382324\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7582]])), ('linear_layer.bias', tensor([0.8137]))])\n",
            "Loss:0.5363758206367493\n",
            "Loss:0.5361896753311157\n",
            "Loss:0.5360035300254822\n",
            "Loss:0.5358174443244934\n",
            "Loss:0.5356312394142151\n",
            "Loss:0.5354450941085815\n",
            "Loss:0.535258948802948\n",
            "Loss:0.5350728034973145\n",
            "Loss:0.5348865389823914\n",
            "Loss:0.5347004532814026\n",
            "Epoch: 110 | Loss: 0.5347004532814026 | Test loss: 0.5632869005203247\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7575]])), ('linear_layer.bias', tensor([0.8121]))])\n",
            "Loss:0.534514307975769\n",
            "Loss:0.5343281030654907\n",
            "Loss:0.5341418981552124\n",
            "Loss:0.5339558124542236\n",
            "Loss:0.5337696075439453\n",
            "Loss:0.5335834622383118\n",
            "Loss:0.5333973169326782\n",
            "Loss:0.5332111120223999\n",
            "Loss:0.5330249667167664\n",
            "Loss:0.5328388214111328\n",
            "Epoch: 120 | Loss: 0.5328388214111328 | Test loss: 0.5611103177070618\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7569]])), ('linear_layer.bias', tensor([0.8105]))])\n",
            "Loss:0.5326526761054993\n",
            "Loss:0.5324665307998657\n",
            "Loss:0.5322803258895874\n",
            "Loss:0.5320941805839539\n",
            "Loss:0.5319080352783203\n",
            "Loss:0.5317219495773315\n",
            "Loss:0.5315357446670532\n",
            "Loss:0.5313495397567749\n",
            "Loss:0.5311633944511414\n",
            "Loss:0.5309772491455078\n",
            "Epoch: 130 | Loss: 0.5309772491455078 | Test loss: 0.5589337348937988\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7563]])), ('linear_layer.bias', tensor([0.8088]))])\n",
            "Loss:0.5307911038398743\n",
            "Loss:0.5306049585342407\n",
            "Loss:0.5304187536239624\n",
            "Loss:0.5302326083183289\n",
            "Loss:0.5300464630126953\n",
            "Loss:0.5298603177070618\n",
            "Loss:0.5296741724014282\n",
            "Loss:0.5294879674911499\n",
            "Loss:0.5293017625808716\n",
            "Loss:0.5291156768798828\n",
            "Epoch: 140 | Loss: 0.5291156768798828 | Test loss: 0.5567571520805359\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7557]])), ('linear_layer.bias', tensor([0.8072]))])\n",
            "Loss:0.5289295315742493\n",
            "Loss:0.5287433862686157\n",
            "Loss:0.5285571813583374\n",
            "Loss:0.5283709764480591\n",
            "Loss:0.5281848907470703\n",
            "Loss:0.527998685836792\n",
            "Loss:0.5278126001358032\n",
            "Loss:0.5276263952255249\n",
            "Loss:0.5274401903152466\n",
            "Loss:0.5272541046142578\n",
            "Epoch: 150 | Loss: 0.5272541046142578 | Test loss: 0.554580569267273\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7550]])), ('linear_layer.bias', tensor([0.8056]))])\n",
            "Loss:0.5270678997039795\n",
            "Loss:0.5268818140029907\n",
            "Loss:0.5266956090927124\n",
            "Loss:0.5265094041824341\n",
            "Loss:0.5263233184814453\n",
            "Loss:0.526137113571167\n",
            "Loss:0.5259510278701782\n",
            "Loss:0.5257648229598999\n",
            "Loss:0.5255786776542664\n",
            "Loss:0.525392472743988\n",
            "Epoch: 160 | Loss: 0.525392472743988 | Test loss: 0.5524039268493652\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7544]])), ('linear_layer.bias', tensor([0.8040]))])\n",
            "Loss:0.5252062678337097\n",
            "Loss:0.525020182132721\n",
            "Loss:0.5248339772224426\n",
            "Loss:0.5246478915214539\n",
            "Loss:0.5244616270065308\n",
            "Loss:0.524275541305542\n",
            "Loss:0.5240893959999084\n",
            "Loss:0.5239031910896301\n",
            "Loss:0.5237170457839966\n",
            "Loss:0.5235308408737183\n",
            "Epoch: 170 | Loss: 0.5235308408737183 | Test loss: 0.5502272844314575\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7538]])), ('linear_layer.bias', tensor([0.8024]))])\n",
            "Loss:0.5233447551727295\n",
            "Loss:0.523158609867096\n",
            "Loss:0.5229724049568176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|      | 33/100 [00:10<00:21,  3.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5227862596511841\n",
            "Loss:0.5226000547409058\n",
            "Loss:0.522413969039917\n",
            "Loss:0.5222277641296387\n",
            "Loss:0.5220416188240051\n",
            "Loss:0.5218554735183716\n",
            "Loss:0.521669328212738\n",
            "Epoch: 180 | Loss: 0.521669328212738 | Test loss: 0.5480507612228394\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7531]])), ('linear_layer.bias', tensor([0.8008]))])\n",
            "Loss:0.5214831829071045\n",
            "Loss:0.5212969779968262\n",
            "Loss:0.5211108922958374\n",
            "Loss:0.5209246873855591\n",
            "Loss:0.5207384824752808\n",
            "Loss:0.5205523371696472\n",
            "Loss:0.5203662514686584\n",
            "Loss:0.5201800465583801\n",
            "Loss:0.5199939012527466\n",
            "Loss:0.5198076963424683\n",
            "Epoch: 190 | Loss: 0.5198076963424683 | Test loss: 0.5458741784095764\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7525]])), ('linear_layer.bias', tensor([0.7991]))])\n",
            "Loss:0.5196215510368347\n",
            "Loss:0.5194354057312012\n",
            "Loss:0.5192492008209229\n",
            "Loss:0.5190631151199341\n",
            "Loss:0.5188769102096558\n",
            "Loss:0.5186907052993774\n",
            "Loss:0.5185045599937439\n",
            "Loss:0.5183184742927551\n",
            "Loss:0.5181322693824768\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.587222695350647\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5549858808517456\n",
            "Loss:0.5547938942909241\n",
            "Loss:0.5546019077301025\n",
            "Loss:0.5544098615646362\n",
            "Loss:0.5542178153991699\n",
            "Loss:0.5540257692337036\n",
            "Loss:0.5538338422775269\n",
            "Loss:0.5536417961120605\n",
            "Loss:0.5534497499465942\n",
            "Loss:0.5532577633857727\n",
            "Epoch: 10 | Loss: 0.5532577633857727 | Test loss: 0.584977388381958\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7638]])), ('linear_layer.bias', tensor([0.8282]))])\n",
            "Loss:0.5530657768249512\n",
            "Loss:0.5528737306594849\n",
            "Loss:0.5526817440986633\n",
            "Loss:0.5524896383285522\n",
            "Loss:0.5522977113723755\n",
            "Loss:0.552105724811554\n",
            "Loss:0.5519136786460876\n",
            "Loss:0.5517216324806213\n",
            "Loss:0.5515296459197998\n",
            "Loss:0.5513375997543335\n",
            "Epoch: 20 | Loss: 0.5513375997543335 | Test loss: 0.582732081413269\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7632]])), ('linear_layer.bias', tensor([0.8265]))])\n",
            "Loss:0.5511455535888672\n",
            "Loss:0.5509535670280457\n",
            "Loss:0.5507615804672241\n",
            "Loss:0.5505695343017578\n",
            "Loss:0.5503774881362915\n",
            "Loss:0.5501855611801147\n",
            "Loss:0.5499935150146484\n",
            "Loss:0.5498014688491821\n",
            "Loss:0.5496095418930054\n",
            "Loss:0.5494174361228943\n",
            "Epoch: 30 | Loss: 0.5494174361228943 | Test loss: 0.5804867148399353\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7625]])), ('linear_layer.bias', tensor([0.8248]))])\n",
            "Loss:0.5492254495620728\n",
            "Loss:0.5490334630012512\n",
            "Loss:0.5488414168357849\n",
            "Loss:0.5486494302749634\n",
            "Loss:0.5484573841094971\n",
            "Loss:0.5482653379440308\n",
            "Loss:0.5480733513832092\n",
            "Loss:0.5478813052177429\n",
            "Loss:0.5476893186569214\n",
            "Loss:0.5474973320960999\n",
            "Epoch: 40 | Loss: 0.5474973320960999 | Test loss: 0.5782414674758911\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7619]])), ('linear_layer.bias', tensor([0.8232]))])\n",
            "Loss:0.5473052859306335\n",
            "Loss:0.5471132397651672\n",
            "Loss:0.5469213128089905\n",
            "Loss:0.5467292666435242\n",
            "Loss:0.5465372204780579\n",
            "Loss:0.5463451743125916\n",
            "Loss:0.54615318775177\n",
            "Loss:0.5459612607955933\n",
            "Loss:0.545769214630127\n",
            "Loss:0.5455771684646606\n",
            "Epoch: 50 | Loss: 0.5455771684646606 | Test loss: 0.5759962201118469\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7612]])), ('linear_layer.bias', tensor([0.8215]))])\n",
            "Loss:0.5453851222991943\n",
            "Loss:0.545193076133728\n",
            "Loss:0.5450010895729065\n",
            "Loss:0.544809103012085\n",
            "Loss:0.5446170568466187\n",
            "Loss:0.5444250106811523\n",
            "Loss:0.5442330837249756\n",
            "Loss:0.5440410375595093\n",
            "Loss:0.543848991394043\n",
            "Loss:0.5436570048332214\n",
            "Epoch: 60 | Loss: 0.5436570048332214 | Test loss: 0.5737508535385132\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7606]])), ('linear_layer.bias', tensor([0.8198]))])\n",
            "Loss:0.5434649586677551\n",
            "Loss:0.543272852897644\n",
            "Loss:0.5430809259414673\n",
            "Loss:0.5428889393806458\n",
            "Loss:0.5426969528198242\n",
            "Loss:0.5425049066543579\n",
            "Loss:0.5423129200935364\n",
            "Loss:0.5421208739280701\n",
            "Loss:0.541928768157959\n",
            "Loss:0.5417368412017822\n",
            "Epoch: 70 | Loss: 0.5417368412017822 | Test loss: 0.571505606174469\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7599]])), ('linear_layer.bias', tensor([0.8182]))])\n",
            "Loss:0.5415447950363159\n",
            "Loss:0.5413527488708496\n",
            "Loss:0.5411607623100281\n",
            "Loss:0.5409687757492065\n",
            "Loss:0.540776789188385\n",
            "Loss:0.5405846834182739\n",
            "Loss:0.5403926968574524\n",
            "Loss:0.5402007102966309\n",
            "Loss:0.5400086641311646\n",
            "Loss:0.5398166179656982\n",
            "Epoch: 80 | Loss: 0.5398166179656982 | Test loss: 0.5692602396011353\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7593]])), ('linear_layer.bias', tensor([0.8165]))])\n",
            "Loss:0.5396246314048767\n",
            "Loss:0.5394325852394104\n",
            "Loss:0.5392405986785889\n",
            "Loss:0.5390486121177673\n",
            "Loss:0.5388566255569458\n",
            "Loss:0.5386645197868347\n",
            "Loss:0.5384725332260132\n",
            "Loss:0.5382805466651917\n",
            "Loss:0.5380885004997253\n",
            "Loss:0.5378965139389038\n",
            "Epoch: 90 | Loss: 0.5378965139389038 | Test loss: 0.5670149326324463\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7586]])), ('linear_layer.bias', tensor([0.8148]))])\n",
            "Loss:0.5377045273780823\n",
            "Loss:0.537512481212616\n",
            "Loss:0.5373204946517944\n",
            "Loss:0.5371284484863281\n",
            "Loss:0.5369364023208618\n",
            "Loss:0.5367444157600403\n",
            "Loss:0.536552369594574\n",
            "Loss:0.5363603830337524\n",
            "Loss:0.5361683368682861\n",
            "Loss:0.5359764099121094\n",
            "Epoch: 100 | Loss: 0.5359764099121094 | Test loss: 0.5647696256637573\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7580]])), ('linear_layer.bias', tensor([0.8132]))])\n",
            "Loss:0.5357843041419983\n",
            "Loss:0.5355923771858215\n",
            "Loss:0.5354003310203552\n",
            "Loss:0.5352082848548889\n",
            "Loss:0.5350162386894226\n",
            "Loss:0.5348242521286011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|      | 34/100 [00:10<00:20,  3.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5346323251724243\n",
            "Loss:0.5344402194023132\n",
            "Loss:0.5342482328414917\n",
            "Loss:0.5340562462806702\n",
            "Epoch: 110 | Loss: 0.5340562462806702 | Test loss: 0.5625243782997131\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7573]])), ('linear_layer.bias', tensor([0.8115]))])\n",
            "Loss:0.5338641405105591\n",
            "Loss:0.5336721539497375\n",
            "Loss:0.533480167388916\n",
            "Loss:0.5332880616188049\n",
            "Loss:0.5330961346626282\n",
            "Loss:0.5329040884971619\n",
            "Loss:0.5327121019363403\n",
            "Loss:0.532520055770874\n",
            "Loss:0.5323280096054077\n",
            "Loss:0.532136082649231\n",
            "Epoch: 120 | Loss: 0.532136082649231 | Test loss: 0.5602790713310242\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7567]])), ('linear_layer.bias', tensor([0.8098]))])\n",
            "Loss:0.5319439768791199\n",
            "Loss:0.5317519903182983\n",
            "Loss:0.5315600037574768\n",
            "Loss:0.5313679575920105\n",
            "Loss:0.531175971031189\n",
            "Loss:0.5309839844703674\n",
            "Loss:0.5307919383049011\n",
            "Loss:0.5305998921394348\n",
            "Loss:0.5304079055786133\n",
            "Loss:0.530215859413147\n",
            "Epoch: 130 | Loss: 0.530215859413147 | Test loss: 0.55803382396698\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7560]])), ('linear_layer.bias', tensor([0.8082]))])\n",
            "Loss:0.5300238728523254\n",
            "Loss:0.5298318862915039\n",
            "Loss:0.5296398401260376\n",
            "Loss:0.5294478535652161\n",
            "Loss:0.529255747795105\n",
            "Loss:0.5290638208389282\n",
            "Loss:0.5288718342781067\n",
            "Loss:0.5286797285079956\n",
            "Loss:0.5284877419471741\n",
            "Loss:0.5282956957817078\n",
            "Epoch: 140 | Loss: 0.5282956957817078 | Test loss: 0.5557884573936462\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7554]])), ('linear_layer.bias', tensor([0.8065]))])\n",
            "Loss:0.5281037092208862\n",
            "Loss:0.5279116630554199\n",
            "Loss:0.5277196764945984\n",
            "Loss:0.5275276899337769\n",
            "Loss:0.5273356437683105\n",
            "Loss:0.5271435976028442\n",
            "Loss:0.5269516110420227\n",
            "Loss:0.5267595052719116\n",
            "Loss:0.5265675783157349\n",
            "Loss:0.5263755321502686\n",
            "Epoch: 150 | Loss: 0.5263755321502686 | Test loss: 0.553543210029602\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7547]])), ('linear_layer.bias', tensor([0.8048]))])\n",
            "Loss:0.526183545589447\n",
            "Loss:0.5259915590286255\n",
            "Loss:0.5257995128631592\n",
            "Loss:0.5256075263023376\n",
            "Loss:0.5254155397415161\n",
            "Loss:0.525223433971405\n",
            "Loss:0.5250314474105835\n",
            "Loss:0.5248394012451172\n",
            "Loss:0.5246474146842957\n",
            "Loss:0.5244554281234741\n",
            "Epoch: 160 | Loss: 0.5244554281234741 | Test loss: 0.5512978434562683\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7541]])), ('linear_layer.bias', tensor([0.8032]))])\n",
            "Loss:0.5242633819580078\n",
            "Loss:0.5240713953971863\n",
            "Loss:0.52387934923172\n",
            "Loss:0.5236873030662537\n",
            "Loss:0.5234953165054321\n",
            "Loss:0.5233033299446106\n",
            "Loss:0.5231112837791443\n",
            "Loss:0.5229192972183228\n",
            "Loss:0.5227272510528564\n",
            "Loss:0.5225352644920349\n",
            "Epoch: 170 | Loss: 0.5225352644920349 | Test loss: 0.5490525364875793\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7534]])), ('linear_layer.bias', tensor([0.8015]))])\n",
            "Loss:0.5223432779312134\n",
            "Loss:0.5221512317657471\n",
            "Loss:0.5219591856002808\n",
            "Loss:0.5217671990394592\n",
            "Loss:0.5215751528739929\n",
            "Loss:0.5213831663131714\n",
            "Loss:0.5211911797523499\n",
            "Loss:0.5209991335868835\n",
            "Loss:0.520807147026062\n",
            "Loss:0.5206150412559509\n",
            "Epoch: 180 | Loss: 0.5206150412559509 | Test loss: 0.5468072891235352\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7528]])), ('linear_layer.bias', tensor([0.7998]))])\n",
            "Loss:0.5204230546951294\n",
            "Loss:0.5202310681343079\n",
            "Loss:0.5200390219688416\n",
            "Loss:0.51984703540802\n",
            "Loss:0.5196550488471985\n",
            "Loss:0.5194629430770874\n",
            "Loss:0.5192710161209106\n",
            "Loss:0.5190790295600891\n",
            "Loss:0.518886923789978\n",
            "Loss:0.5186948776245117\n",
            "Epoch: 190 | Loss: 0.5186948776245117 | Test loss: 0.5445619821548462\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7521]])), ('linear_layer.bias', tensor([0.7982]))])\n",
            "Loss:0.5185028910636902\n",
            "Loss:0.5183109045028687\n",
            "Loss:0.5181188583374023\n",
            "Loss:0.517926812171936\n",
            "Loss:0.5177348852157593\n",
            "Loss:0.517542839050293\n",
            "Loss:0.5173507928848267\n",
            "Loss:0.5171588063240051\n",
            "Loss:0.5169668197631836\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5872158408164978\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5549800992012024\n",
            "Loss:0.5547822713851929\n",
            "Loss:0.5545843839645386\n",
            "Loss:0.5543864965438843\n",
            "Loss:0.5541887283325195\n",
            "Loss:0.5539908409118652\n",
            "Loss:0.5537930130958557\n",
            "Loss:0.5535951256752014\n",
            "Loss:0.5533972978591919\n",
            "Loss:0.5531994104385376\n",
            "Epoch: 10 | Loss: 0.5531994104385376 | Test loss: 0.5849023461341858\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7638]])), ('linear_layer.bias', tensor([0.8281]))])\n",
            "Loss:0.5530015826225281\n",
            "Loss:0.5528037548065186\n",
            "Loss:0.5526058673858643\n",
            "Loss:0.5524080395698547\n",
            "Loss:0.5522102117538452\n",
            "Loss:0.5520123243331909\n",
            "Loss:0.5518144369125366\n",
            "Loss:0.5516166687011719\n",
            "Loss:0.5514189004898071\n",
            "Loss:0.5512209534645081\n",
            "Epoch: 20 | Loss: 0.5512209534645081 | Test loss: 0.5825889110565186\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7631]])), ('linear_layer.bias', tensor([0.8264]))])\n",
            "Loss:0.5510231256484985\n",
            "Loss:0.5508252382278442\n",
            "Loss:0.5506274104118347\n",
            "Loss:0.5504295229911804\n",
            "Loss:0.5502316951751709\n",
            "Loss:0.5500339269638062\n",
            "Loss:0.5498360395431519\n",
            "Loss:0.5496381521224976\n",
            "Loss:0.5494402647018433\n",
            "Loss:0.549242377281189\n",
            "Epoch: 30 | Loss: 0.549242377281189 | Test loss: 0.5802754759788513\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7625]])), ('linear_layer.bias', tensor([0.8247]))])\n",
            "Loss:0.5490446090698242\n",
            "Loss:0.5488467812538147\n",
            "Loss:0.5486489534378052\n",
            "Loss:0.5484510064125061\n",
            "Loss:0.5482532382011414\n",
            "Loss:0.5480553507804871\n",
            "Loss:0.5478575825691223\n",
            "Loss:0.5476596355438232\n",
            "Loss:0.5474618673324585\n",
            "Loss:0.5472639799118042\n",
            "Epoch: 40 | Loss: 0.5472639799118042 | Test loss: 0.5779619812965393\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7618]])), ('linear_layer.bias', tensor([0.8230]))])\n",
            "Loss:0.5470660924911499\n",
            "Loss:0.5468682646751404\n",
            "Loss:0.5466703772544861\n",
            "Loss:0.5464725494384766\n",
            "Loss:0.546274721622467\n",
            "Loss:0.5460768938064575\n",
            "Loss:0.545879065990448\n",
            "Loss:0.5456811189651489\n",
            "Loss:0.5454832911491394\n",
            "Loss:0.5452854037284851\n",
            "Epoch: 50 | Loss: 0.5452854037284851 | Test loss: 0.5756484270095825\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7611]])), ('linear_layer.bias', tensor([0.8213]))])\n",
            "Loss:0.5450876355171204\n",
            "Loss:0.5448897480964661\n",
            "Loss:0.5446919202804565\n",
            "Loss:0.5444940328598022\n",
            "Loss:0.5442962646484375\n",
            "Loss:0.5440983772277832\n",
            "Loss:0.5439005494117737\n",
            "Loss:0.5437027215957642\n",
            "Loss:0.5435048341751099\n",
            "Loss:0.5433069467544556\n",
            "Epoch: 60 | Loss: 0.5433069467544556 | Test loss: 0.5733350515365601\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7605]])), ('linear_layer.bias', tensor([0.8195]))])\n",
            "Loss:0.5431090593338013\n",
            "Loss:0.5429112315177917\n",
            "Loss:0.542713463306427\n",
            "Loss:0.5425155758857727\n",
            "Loss:0.5423177480697632\n",
            "Loss:0.5421198606491089\n",
            "Loss:0.5419219732284546\n",
            "Loss:0.5417242050170898\n",
            "Loss:0.5415263175964355\n",
            "Loss:0.5413285493850708\n",
            "Epoch: 70 | Loss: 0.5413285493850708 | Test loss: 0.5710216164588928\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7598]])), ('linear_layer.bias', tensor([0.8178]))])\n",
            "Loss:0.5411306619644165\n",
            "Loss:0.540932834148407\n",
            "Loss:0.5407348871231079\n",
            "Loss:0.5405370593070984\n",
            "Loss:0.5403392910957336\n",
            "Loss:0.5401414036750793\n",
            "Loss:0.5399435758590698\n",
            "Loss:0.5397456884384155\n",
            "Loss:0.539547860622406\n",
            "Loss:0.5393499732017517\n",
            "Epoch: 80 | Loss: 0.5393499732017517 | Test loss: 0.568708062171936\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7591]])), ('linear_layer.bias', tensor([0.8161]))])\n",
            "Loss:0.5391521453857422\n",
            "Loss:0.5389542579650879\n",
            "Loss:0.5387564301490784\n",
            "Loss:0.5385586023330688\n",
            "Loss:0.5383607149124146\n",
            "Loss:0.538162887096405\n",
            "Loss:0.5379649996757507\n",
            "Loss:0.537767231464386\n",
            "Loss:0.5375693440437317\n",
            "Loss:0.5373715162277222\n",
            "Epoch: 90 | Loss: 0.5373715162277222 | Test loss: 0.5663946270942688\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7584]])), ('linear_layer.bias', tensor([0.8144]))])\n",
            "Loss:0.5371736288070679\n",
            "Loss:0.5369758009910583\n",
            "Loss:0.5367780327796936\n",
            "Loss:0.5365800857543945\n",
            "Loss:0.5363823175430298\n",
            "Loss:0.5361843705177307\n",
            "Loss:0.5359865427017212\n",
            "Loss:0.5357887148857117\n",
            "Loss:0.5355908274650574\n",
            "Loss:0.5353929996490479\n",
            "Epoch: 100 | Loss: 0.5353929996490479 | Test loss: 0.5640811920166016\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7578]])), ('linear_layer.bias', tensor([0.8127]))])\n",
            "Loss:0.5351951122283936\n",
            "Loss:0.5349973440170288\n",
            "Loss:0.5347993969917297\n",
            "Loss:0.5346015691757202\n",
            "Loss:0.5344038009643555\n",
            "Loss:0.5342058539390564\n",
            "Loss:0.5340080261230469\n",
            "Loss:0.5338102579116821\n",
            "Loss:0.5336123704910278\n",
            "Loss:0.5334144830703735\n",
            "Epoch: 110 | Loss: 0.5334144830703735 | Test loss: 0.5617676973342896\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7571]])), ('linear_layer.bias', tensor([0.8109]))])\n",
            "Loss:0.533216655254364\n",
            "Loss:0.5330188274383545\n",
            "Loss:0.5328209400177002\n",
            "Loss:0.5326231718063354\n",
            "Loss:0.5324252843856812\n",
            "Loss:0.5322273969650269\n",
            "Loss:0.5320295691490173\n",
            "Loss:0.531831681728363\n",
            "Loss:0.5316338539123535\n",
            "Loss:0.531436026096344\n",
            "Epoch: 120 | Loss: 0.531436026096344 | Test loss: 0.5594542026519775\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7564]])), ('linear_layer.bias', tensor([0.8092]))])\n",
            "Loss:0.5312381982803345\n",
            "Loss:0.5310403108596802\n",
            "Loss:0.5308424830436707\n",
            "Loss:0.5306445956230164\n",
            "Loss:0.5304467678070068\n",
            "Loss:0.5302489399909973\n",
            "Loss:0.5300511121749878\n",
            "Loss:0.5298532247543335\n",
            "Loss:0.5296553373336792\n",
            "Loss:0.5294575095176697\n",
            "Epoch: 130 | Loss: 0.5294575095176697 | Test loss: 0.5571407079696655\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7558]])), ('linear_layer.bias', tensor([0.8075]))])\n",
            "Loss:0.5292596817016602\n",
            "Loss:0.5290618538856506\n",
            "Loss:0.5288640260696411\n",
            "Loss:0.5286661386489868\n",
            "Loss:0.5284682512283325\n",
            "Loss:0.5282703638076782\n",
            "Loss:0.5280725955963135\n",
            "Loss:0.5278747081756592\n",
            "Loss:0.5276768803596497\n",
            "Loss:0.5274789929389954\n",
            "Epoch: 140 | Loss: 0.5274789929389954 | Test loss: 0.5548273324966431\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7551]])), ('linear_layer.bias', tensor([0.8058]))])\n",
            "Loss:0.5272811651229858\n",
            "Loss:0.5270833969116211\n",
            "Loss:0.5268855094909668\n",
            "Loss:0.5266876816749573\n",
            "Loss:0.526489794254303\n",
            "Loss:0.5262919664382935\n",
            "Loss:0.5260941386222839\n",
            "Loss:0.5258962512016296\n",
            "Loss:0.5256983637809753\n",
            "Loss:0.5255005359649658\n",
            "Epoch: 150 | Loss: 0.5255005359649658 | Test loss: 0.5525137782096863\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7544]])), ('linear_layer.bias', tensor([0.8041]))])\n",
            "Loss:0.5253027081489563\n",
            "Loss:0.5251048803329468\n",
            "Loss:0.5249069929122925\n",
            "Loss:0.5247091054916382\n",
            "Loss:0.5245112776756287\n",
            "Loss:0.5243134498596191\n",
            "Loss:0.5241156220436096\n",
            "Loss:0.5239177346229553\n",
            "Loss:0.5237199068069458\n",
            "Loss:0.5235220789909363\n",
            "Epoch: 160 | Loss: 0.5235220789909363 | Test loss: 0.5502002835273743\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7538]])), ('linear_layer.bias', tensor([0.8024]))])\n",
            "Loss:0.523324191570282\n",
            "Loss:0.5231263637542725\n",
            "Loss:0.5229285359382629\n",
            "Loss:0.5227307081222534\n",
            "Loss:0.5225328207015991\n",
            "Loss:0.5223349332809448\n",
            "Loss:0.5221371054649353\n",
            "Loss:0.521939218044281\n",
            "Loss:0.5217413902282715\n",
            "Loss:0.521543562412262\n",
            "Epoch: 170 | Loss: 0.521543562412262 | Test loss: 0.547886848449707\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7531]])), ('linear_layer.bias', tensor([0.8006]))])\n",
            "Loss:0.5213457345962524\n",
            "Loss:0.5211478471755981\n",
            "Loss:0.5209499597549438\n",
            "Loss:0.5207521319389343\n",
            "Loss:0.5205543637275696\n",
            "Loss:0.5203564763069153\n",
            "Loss:0.520158588886261\n",
            "Loss:0.5199607014656067\n",
            "Loss:0.5197629332542419\n",
            "Loss:0.5195650458335876\n",
            "Epoch: 180 | Loss: 0.5195650458335876 | Test loss: 0.5455734133720398\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7524]])), ('linear_layer.bias', tensor([0.7989]))])\n",
            "Loss:0.5193672180175781\n",
            "Loss:0.5191693902015686\n",
            "Loss:0.5189715623855591\n",
            "Loss:0.5187736749649048\n",
            "Loss:0.5185757875442505\n",
            "Loss:0.5183780193328857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|      | 35/100 [00:11<00:20,  3.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5181801319122314\n",
            "Loss:0.5179823040962219\n",
            "Loss:0.5177844166755676\n",
            "Loss:0.5175865888595581\n",
            "Epoch: 190 | Loss: 0.5175865888595581 | Test loss: 0.5432599186897278\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7517]])), ('linear_layer.bias', tensor([0.7972]))])\n",
            "Loss:0.5173887014389038\n",
            "Loss:0.5171908140182495\n",
            "Loss:0.51699298620224\n",
            "Loss:0.5167951583862305\n",
            "Loss:0.5165973901748657\n",
            "Loss:0.5163995027542114\n",
            "Loss:0.5162016153335571\n",
            "Loss:0.5160037875175476\n",
            "Loss:0.5158059000968933\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5872091054916382\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5549743175506592\n",
            "Loss:0.5547705888748169\n",
            "Loss:0.5545669198036194\n",
            "Loss:0.5543631911277771\n",
            "Loss:0.5541594624519348\n",
            "Loss:0.5539558529853821\n",
            "Loss:0.5537521243095398\n",
            "Loss:0.5535485148429871\n",
            "Loss:0.5533448457717896\n",
            "Loss:0.5531411170959473\n",
            "Epoch: 10 | Loss: 0.5531411170959473 | Test loss: 0.5848274230957031\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7638]])), ('linear_layer.bias', tensor([0.8281]))])\n",
            "Loss:0.552937388420105\n",
            "Loss:0.5527337789535522\n",
            "Loss:0.55253005027771\n",
            "Loss:0.5523263216018677\n",
            "Loss:0.5521227121353149\n",
            "Loss:0.5519190430641174\n",
            "Loss:0.5517152547836304\n",
            "Loss:0.5515116453170776\n",
            "Loss:0.5513079762458801\n",
            "Loss:0.5511042475700378\n",
            "Epoch: 20 | Loss: 0.5511042475700378 | Test loss: 0.5824457406997681\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7631]])), ('linear_layer.bias', tensor([0.8263]))])\n",
            "Loss:0.5509005784988403\n",
            "Loss:0.5506969094276428\n",
            "Loss:0.5504932403564453\n",
            "Loss:0.550289511680603\n",
            "Loss:0.5500859022140503\n",
            "Loss:0.549882173538208\n",
            "Loss:0.5496784448623657\n",
            "Loss:0.5494747757911682\n",
            "Loss:0.5492711663246155\n",
            "Loss:0.5490674376487732\n",
            "Epoch: 30 | Loss: 0.5490674376487732 | Test loss: 0.5800641179084778\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7624]])), ('linear_layer.bias', tensor([0.8245]))])\n",
            "Loss:0.5488637089729309\n",
            "Loss:0.5486600995063782\n",
            "Loss:0.5484564304351807\n",
            "Loss:0.5482527017593384\n",
            "Loss:0.5480490922927856\n",
            "Loss:0.5478454232215881\n",
            "Loss:0.5476416349411011\n",
            "Loss:0.5474379658699036\n",
            "Loss:0.547234296798706\n",
            "Loss:0.5470306873321533\n",
            "Epoch: 40 | Loss: 0.5470306873321533 | Test loss: 0.5776824355125427\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7617]])), ('linear_layer.bias', tensor([0.8228]))])\n",
            "Loss:0.546826958656311\n",
            "Loss:0.5466232299804688\n",
            "Loss:0.546419620513916\n",
            "Loss:0.5462158918380737\n",
            "Loss:0.546012282371521\n",
            "Loss:0.5458084940910339\n",
            "Loss:0.5456048846244812\n",
            "Loss:0.5454012155532837\n",
            "Loss:0.5451974868774414\n",
            "Loss:0.5449938178062439\n",
            "Epoch: 50 | Loss: 0.5449938178062439 | Test loss: 0.5753008723258972\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7610]])), ('linear_layer.bias', tensor([0.8210]))])\n",
            "Loss:0.5447901487350464\n",
            "Loss:0.5445864796638489\n",
            "Loss:0.5443827509880066\n",
            "Loss:0.5441790223121643\n",
            "Loss:0.5439754128456116\n",
            "Loss:0.5437716841697693\n",
            "Loss:0.5435680150985718\n",
            "Loss:0.5433643460273743\n",
            "Loss:0.543160617351532\n",
            "Loss:0.5429570078849792\n",
            "Epoch: 60 | Loss: 0.5429570078849792 | Test loss: 0.5729192495346069\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7603]])), ('linear_layer.bias', tensor([0.8192]))])\n",
            "Loss:0.542753279209137\n",
            "Loss:0.5425496101379395\n",
            "Loss:0.5423458814620972\n",
            "Loss:0.5421422123908997\n",
            "Loss:0.5419385433197021\n",
            "Loss:0.5417348742485046\n",
            "Loss:0.5415312051773071\n",
            "Loss:0.5413275361061096\n",
            "Loss:0.5411237478256226\n",
            "Loss:0.5409201383590698\n",
            "Epoch: 70 | Loss: 0.5409201383590698 | Test loss: 0.5705375671386719\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7596]])), ('linear_layer.bias', tensor([0.8175]))])\n",
            "Loss:0.5407164096832275\n",
            "Loss:0.54051274061203\n",
            "Loss:0.5403090715408325\n",
            "Loss:0.540105402469635\n",
            "Loss:0.5399017333984375\n",
            "Loss:0.5396980047225952\n",
            "Loss:0.5394943356513977\n",
            "Loss:0.5392906665802002\n",
            "Loss:0.5390869379043579\n",
            "Loss:0.5388833284378052\n",
            "Epoch: 80 | Loss: 0.5388833284378052 | Test loss: 0.5681558847427368\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7590]])), ('linear_layer.bias', tensor([0.8157]))])\n",
            "Loss:0.5386795997619629\n",
            "Loss:0.5384758710861206\n",
            "Loss:0.5382722616195679\n",
            "Loss:0.5380685925483704\n",
            "Loss:0.5378648638725281\n",
            "Loss:0.5376611948013306\n",
            "Loss:0.5374575257301331\n",
            "Loss:0.5372538566589355\n",
            "Loss:0.5370502471923828\n",
            "Loss:0.5368465185165405\n",
            "Epoch: 90 | Loss: 0.5368465185165405 | Test loss: 0.5657743215560913\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7583]])), ('linear_layer.bias', tensor([0.8139]))])\n",
            "Loss:0.5366427898406982\n",
            "Loss:0.5364391207695007\n",
            "Loss:0.5362354516983032\n",
            "Loss:0.5360318422317505\n",
            "Loss:0.5358281135559082\n",
            "Loss:0.5356243848800659\n",
            "Loss:0.5354207754135132\n",
            "Loss:0.5352170467376709\n",
            "Loss:0.5350133776664734\n",
            "Loss:0.5348097085952759\n",
            "Epoch: 100 | Loss: 0.5348097085952759 | Test loss: 0.5633926391601562\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7576]])), ('linear_layer.bias', tensor([0.8122]))])\n",
            "Loss:0.5346059799194336\n",
            "Loss:0.5344023108482361\n",
            "Loss:0.5341985821723938\n",
            "Loss:0.5339949727058411\n",
            "Loss:0.5337912440299988\n",
            "Loss:0.5335875749588013\n",
            "Loss:0.5333839058876038\n",
            "Loss:0.5331801772117615\n",
            "Loss:0.532976508140564\n",
            "Loss:0.5327728390693665\n",
            "Epoch: 110 | Loss: 0.5327728390693665 | Test loss: 0.5610109567642212\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7569]])), ('linear_layer.bias', tensor([0.8104]))])\n",
            "Loss:0.5325691103935242\n",
            "Loss:0.5323654413223267\n",
            "Loss:0.5321618318557739\n",
            "Loss:0.5319581031799316\n",
            "Loss:0.5317543745040894\n",
            "Loss:0.5315507054328918\n",
            "Loss:0.5313470363616943\n",
            "Loss:0.5311433672904968\n",
            "Loss:0.5309396982192993\n",
            "Loss:0.5307360291481018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|      | 36/100 [00:11<00:19,  3.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 120 | Loss: 0.5307360291481018 | Test loss: 0.5586293935775757\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7562]])), ('linear_layer.bias', tensor([0.8086]))])\n",
            "Loss:0.5305323004722595\n",
            "Loss:0.530328631401062\n",
            "Loss:0.5301249623298645\n",
            "Loss:0.5299212336540222\n",
            "Loss:0.5297176241874695\n",
            "Loss:0.529513955116272\n",
            "Loss:0.5293102264404297\n",
            "Loss:0.5291064977645874\n",
            "Loss:0.5289028286933899\n",
            "Loss:0.5286991596221924\n",
            "Epoch: 130 | Loss: 0.5286991596221924 | Test loss: 0.5562477111816406\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7555]])), ('linear_layer.bias', tensor([0.8068]))])\n",
            "Loss:0.5284954905509949\n",
            "Loss:0.5282918214797974\n",
            "Loss:0.5280881524085999\n",
            "Loss:0.5278844237327576\n",
            "Loss:0.5276807546615601\n",
            "Loss:0.5274770855903625\n",
            "Loss:0.5272733569145203\n",
            "Loss:0.5270696878433228\n",
            "Loss:0.52686607837677\n",
            "Loss:0.5266623497009277\n",
            "Epoch: 140 | Loss: 0.5266623497009277 | Test loss: 0.5538660287857056\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7548]])), ('linear_layer.bias', tensor([0.8051]))])\n",
            "Loss:0.5264586210250854\n",
            "Loss:0.5262549519538879\n",
            "Loss:0.5260512828826904\n",
            "Loss:0.5258476138114929\n",
            "Loss:0.5256439447402954\n",
            "Loss:0.5254402756690979\n",
            "Loss:0.5252365469932556\n",
            "Loss:0.5250328779220581\n",
            "Loss:0.5248292088508606\n",
            "Loss:0.5246255397796631\n",
            "Epoch: 150 | Loss: 0.5246255397796631 | Test loss: 0.5514844655990601\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7541]])), ('linear_layer.bias', tensor([0.8033]))])\n",
            "Loss:0.5244218707084656\n",
            "Loss:0.5242182016372681\n",
            "Loss:0.5240144729614258\n",
            "Loss:0.5238107442855835\n",
            "Loss:0.5236071348190308\n",
            "Loss:0.5234034061431885\n",
            "Loss:0.5231997966766357\n",
            "Loss:0.5229960680007935\n",
            "Loss:0.522792398929596\n",
            "Loss:0.5225886702537537\n",
            "Epoch: 160 | Loss: 0.5225886702537537 | Test loss: 0.549102783203125\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7534]])), ('linear_layer.bias', tensor([0.8015]))])\n",
            "Loss:0.5223850011825562\n",
            "Loss:0.5221813321113586\n",
            "Loss:0.5219776034355164\n",
            "Loss:0.5217739939689636\n",
            "Loss:0.5215703248977661\n",
            "Loss:0.5213665962219238\n",
            "Loss:0.5211629271507263\n",
            "Loss:0.520959198474884\n",
            "Loss:0.5207555294036865\n",
            "Loss:0.5205518007278442\n",
            "Epoch: 170 | Loss: 0.5205518007278442 | Test loss: 0.5467211604118347\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7527]])), ('linear_layer.bias', tensor([0.7998]))])\n",
            "Loss:0.5203481912612915\n",
            "Loss:0.520144522190094\n",
            "Loss:0.5199407935142517\n",
            "Loss:0.5197371244430542\n",
            "Loss:0.5195334553718567\n",
            "Loss:0.5193297266960144\n",
            "Loss:0.5191260576248169\n",
            "Loss:0.5189223885536194\n",
            "Loss:0.5187187194824219\n",
            "Loss:0.5185150504112244\n",
            "Epoch: 180 | Loss: 0.5185150504112244 | Test loss: 0.5443395376205444\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7521]])), ('linear_layer.bias', tensor([0.7980]))])\n",
            "Loss:0.5183113813400269\n",
            "Loss:0.5181076526641846\n",
            "Loss:0.5179039239883423\n",
            "Loss:0.5177003145217896\n",
            "Loss:0.517496645450592\n",
            "Loss:0.517292857170105\n",
            "Loss:0.5170892477035522\n",
            "Loss:0.5168855786323547\n",
            "Loss:0.5166818499565125\n",
            "Loss:0.5164781808853149\n",
            "Epoch: 190 | Loss: 0.5164781808853149 | Test loss: 0.5419578552246094\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7514]])), ('linear_layer.bias', tensor([0.7962]))])\n",
            "Loss:0.5162744522094727\n",
            "Loss:0.5160708427429199\n",
            "Loss:0.5158671140670776\n",
            "Loss:0.5156635046005249\n",
            "Loss:0.5154597163200378\n",
            "Loss:0.5152561068534851\n",
            "Loss:0.5150524377822876\n",
            "Loss:0.5148487091064453\n",
            "Loss:0.5146450400352478\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.587202250957489\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5549684166908264\n",
            "Loss:0.5547589659690857\n",
            "Loss:0.5545495748519897\n",
            "Loss:0.554340124130249\n",
            "Loss:0.5541306734085083\n",
            "Loss:0.5539212226867676\n",
            "Loss:0.5537117123603821\n",
            "Loss:0.5535022616386414\n",
            "Loss:0.5532928109169006\n",
            "Loss:0.5530833005905151\n",
            "Epoch: 10 | Loss: 0.5530833005905151 | Test loss: 0.584753155708313\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7638]])), ('linear_layer.bias', tensor([0.8280]))])\n",
            "Loss:0.5528739094734192\n",
            "Loss:0.5526643991470337\n",
            "Loss:0.5524550080299377\n",
            "Loss:0.552245557308197\n",
            "Loss:0.5520360469818115\n",
            "Loss:0.5518266558647156\n",
            "Loss:0.5516172051429749\n",
            "Loss:0.5514076948165894\n",
            "Loss:0.5511983036994934\n",
            "Loss:0.5509887933731079\n",
            "Epoch: 20 | Loss: 0.5509887933731079 | Test loss: 0.5823038816452026\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7630]])), ('linear_layer.bias', tensor([0.8262]))])\n",
            "Loss:0.5507793426513672\n",
            "Loss:0.5505698919296265\n",
            "Loss:0.550360381603241\n",
            "Loss:0.550150990486145\n",
            "Loss:0.5499415397644043\n",
            "Loss:0.5497320294380188\n",
            "Loss:0.5495225787162781\n",
            "Loss:0.5493131279945374\n",
            "Loss:0.5491037368774414\n",
            "Loss:0.5488942861557007\n",
            "Epoch: 30 | Loss: 0.5488942861557007 | Test loss: 0.5798546671867371\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7623]])), ('linear_layer.bias', tensor([0.8244]))])\n",
            "Loss:0.5486847758293152\n",
            "Loss:0.5484753847122192\n",
            "Loss:0.548265814781189\n",
            "Loss:0.5480563640594482\n",
            "Loss:0.5478469133377075\n",
            "Loss:0.5476374626159668\n",
            "Loss:0.5474280714988708\n",
            "Loss:0.5472186207771301\n",
            "Loss:0.5470091104507446\n",
            "Loss:0.5467997193336487\n",
            "Epoch: 40 | Loss: 0.5467997193336487 | Test loss: 0.5774053931236267\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7616]])), ('linear_layer.bias', tensor([0.8226]))])\n",
            "Loss:0.5465902090072632\n",
            "Loss:0.5463807582855225\n",
            "Loss:0.5461713075637817\n",
            "Loss:0.5459617376327515\n",
            "Loss:0.5457523465156555\n",
            "Loss:0.5455428957939148\n",
            "Loss:0.5453334450721741\n",
            "Loss:0.5451239943504333\n",
            "Loss:0.5449145436286926\n",
            "Loss:0.5447050929069519\n",
            "Epoch: 50 | Loss: 0.5447050929069519 | Test loss: 0.5749562978744507\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7609]])), ('linear_layer.bias', tensor([0.8207]))])\n",
            "Loss:0.544495701789856\n",
            "Loss:0.5442861318588257\n",
            "Loss:0.5440767407417297\n",
            "Loss:0.543867290019989\n",
            "Loss:0.5436577796936035\n",
            "Loss:0.5434483289718628\n",
            "Loss:0.5432388782501221\n",
            "Loss:0.5430294275283813\n",
            "Loss:0.5428199768066406\n",
            "Loss:0.5426105260848999\n",
            "Epoch: 60 | Loss: 0.5426105260848999 | Test loss: 0.5725070238113403\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7602]])), ('linear_layer.bias', tensor([0.8189]))])\n",
            "Loss:0.5424010753631592\n",
            "Loss:0.5421916246414185\n",
            "Loss:0.5419821739196777\n",
            "Loss:0.541772723197937\n",
            "Loss:0.5415632128715515\n",
            "Loss:0.5413538217544556\n",
            "Loss:0.5411443114280701\n",
            "Loss:0.5409349203109741\n",
            "Loss:0.5407254099845886\n",
            "Loss:0.5405160188674927\n",
            "Epoch: 70 | Loss: 0.5405160188674927 | Test loss: 0.5700578093528748\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7595]])), ('linear_layer.bias', tensor([0.8171]))])\n",
            "Loss:0.5403064489364624\n",
            "Loss:0.5400970578193665\n",
            "Loss:0.5398876070976257\n",
            "Loss:0.5396782159805298\n",
            "Loss:0.5394686460494995\n",
            "Loss:0.539259135723114\n",
            "Loss:0.5390498042106628\n",
            "Loss:0.5388402938842773\n",
            "Loss:0.5386308431625366\n",
            "Loss:0.5384213924407959\n",
            "Epoch: 80 | Loss: 0.5384213924407959 | Test loss: 0.5676085352897644\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7588]])), ('linear_layer.bias', tensor([0.8153]))])\n",
            "Loss:0.5382118821144104\n",
            "Loss:0.5380024909973145\n",
            "Loss:0.5377930998802185\n",
            "Loss:0.537583589553833\n",
            "Loss:0.5373741388320923\n",
            "Loss:0.537164568901062\n",
            "Loss:0.5369551777839661\n",
            "Loss:0.5367457270622253\n",
            "Loss:0.5365362763404846\n",
            "Loss:0.5363267660140991\n",
            "Epoch: 90 | Loss: 0.5363267660140991 | Test loss: 0.5651594400405884\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7581]])), ('linear_layer.bias', tensor([0.8135]))])\n",
            "Loss:0.536117434501648\n",
            "Loss:0.5359078645706177\n",
            "Loss:0.5356984734535217\n",
            "Loss:0.5354890823364258\n",
            "Loss:0.5352795720100403\n",
            "Loss:0.5350701212882996\n",
            "Loss:0.5348607301712036\n",
            "Loss:0.5346511602401733\n",
            "Loss:0.5344417095184326\n",
            "Loss:0.5342322587966919\n",
            "Epoch: 100 | Loss: 0.5342322587966919 | Test loss: 0.562710165977478\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7574]])), ('linear_layer.bias', tensor([0.8116]))])\n",
            "Loss:0.5340228080749512\n",
            "Loss:0.5338133573532104\n",
            "Loss:0.5336039066314697\n",
            "Loss:0.533394455909729\n",
            "Loss:0.5331849455833435\n",
            "Loss:0.5329754948616028\n",
            "Loss:0.5327660441398621\n",
            "Loss:0.5325565338134766\n",
            "Loss:0.5323471426963806\n",
            "Loss:0.5321376919746399\n",
            "Epoch: 110 | Loss: 0.5321376919746399 | Test loss: 0.5602609515190125\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7567]])), ('linear_layer.bias', tensor([0.8098]))])\n",
            "Loss:0.5319281816482544\n",
            "Loss:0.5317187905311584\n",
            "Loss:0.531509280204773\n",
            "Loss:0.531299889087677\n",
            "Loss:0.5310904383659363\n",
            "Loss:0.5308809280395508\n",
            "Loss:0.5306714773178101\n",
            "Loss:0.5304620862007141\n",
            "Loss:0.5302525758743286\n",
            "Loss:0.5300431251525879\n",
            "Epoch: 120 | Loss: 0.5300431251525879 | Test loss: 0.5578116774559021\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7560]])), ('linear_layer.bias', tensor([0.8080]))])\n",
            "Loss:0.5298336744308472\n",
            "Loss:0.5296241641044617\n",
            "Loss:0.5294147729873657\n",
            "Loss:0.5292052626609802\n",
            "Loss:0.5289958715438843\n",
            "Loss:0.5287863612174988\n",
            "Loss:0.5285769701004028\n",
            "Loss:0.5283675193786621\n",
            "Loss:0.5281580090522766\n",
            "Loss:0.5279484987258911\n",
            "Epoch: 130 | Loss: 0.5279484987258911 | Test loss: 0.5553625822067261\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7552]])), ('linear_layer.bias', tensor([0.8062]))])\n",
            "Loss:0.5277391076087952\n",
            "Loss:0.5275296568870544\n",
            "Loss:0.5273202061653137\n",
            "Loss:0.5271106958389282\n",
            "Loss:0.5269013047218323\n",
            "Loss:0.5266917943954468\n",
            "Loss:0.5264824032783508\n",
            "Loss:0.5262728929519653\n",
            "Loss:0.5260635018348694\n",
            "Loss:0.5258539915084839\n",
            "Epoch: 140 | Loss: 0.5258539915084839 | Test loss: 0.5529133081436157\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7545]])), ('linear_layer.bias', tensor([0.8044]))])\n",
            "Loss:0.5256444811820984\n",
            "Loss:0.5254350900650024\n",
            "Loss:0.5252256393432617\n",
            "Loss:0.525016188621521\n",
            "Loss:0.5248067378997803\n",
            "Loss:0.5245972871780396\n",
            "Loss:0.524387776851654\n",
            "Loss:0.5241783261299133\n",
            "Loss:0.5239689350128174\n",
            "Loss:0.5237594842910767\n",
            "Epoch: 150 | Loss: 0.5237594842910767 | Test loss: 0.5504640936851501\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7538]])), ('linear_layer.bias', tensor([0.8026]))])\n",
            "Loss:0.5235499143600464\n",
            "Loss:0.5233405232429504\n",
            "Loss:0.5231310725212097\n",
            "Loss:0.522921621799469\n",
            "Loss:0.5227121114730835\n",
            "Loss:0.5225026607513428\n",
            "Loss:0.522293210029602\n",
            "Loss:0.5220838189125061\n",
            "Loss:0.5218743085861206\n",
            "Loss:0.5216649174690247\n",
            "Epoch: 160 | Loss: 0.5216649174690247 | Test loss: 0.5480148196220398\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7531]])), ('linear_layer.bias', tensor([0.8007]))])\n",
            "Loss:0.5214553475379944\n",
            "Loss:0.5212459564208984\n",
            "Loss:0.5210365056991577\n",
            "Loss:0.520827054977417\n",
            "Loss:0.5206176042556763\n",
            "Loss:0.5204080939292908\n",
            "Loss:0.5201987028121948\n",
            "Loss:0.5199891924858093\n",
            "Loss:0.5197798013687134\n",
            "Loss:0.5195702314376831\n",
            "Epoch: 170 | Loss: 0.5195702314376831 | Test loss: 0.5455657243728638\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7524]])), ('linear_layer.bias', tensor([0.7989]))])\n",
            "Loss:0.5193608403205872\n",
            "Loss:0.5191513299942017\n",
            "Loss:0.5189419388771057\n",
            "Loss:0.5187324285507202\n",
            "Loss:0.5185229778289795\n",
            "Loss:0.5183135271072388\n",
            "Loss:0.5181041359901428\n",
            "Loss:0.5178946256637573\n",
            "Loss:0.5176851749420166\n",
            "Loss:0.5174757242202759\n",
            "Epoch: 180 | Loss: 0.5174757242202759 | Test loss: 0.5431164503097534\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7517]])), ('linear_layer.bias', tensor([0.7971]))])\n",
            "Loss:0.5172662734985352\n",
            "Loss:0.5170568227767944\n",
            "Loss:0.5168473124504089\n",
            "Loss:0.516637921333313\n",
            "Loss:0.5164284110069275\n",
            "Loss:0.5162189602851868\n",
            "Loss:0.516009509563446\n",
            "Loss:0.5158000588417053\n",
            "Loss:0.5155906677246094\n",
            "Loss:0.5153812170028687\n",
            "Epoch: 190 | Loss: 0.5153812170028687 | Test loss: 0.5406672358512878\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7510]])), ('linear_layer.bias', tensor([0.7953]))])\n",
            "Loss:0.5151717066764832\n",
            "Loss:0.5149623155593872\n",
            "Loss:0.5147527456283569\n",
            "Loss:0.514543354511261\n",
            "Loss:0.5143338441848755\n",
            "Loss:0.5141244530677795\n",
            "Loss:0.513914942741394\n",
            "Loss:0.5137054920196533\n",
            "Loss:0.5134960412979126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|      | 37/100 [00:11<00:19,  3.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5871955156326294\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5549626350402832\n",
            "Loss:0.5547474026679993\n",
            "Loss:0.5545320510864258\n",
            "Loss:0.5543168187141418\n",
            "Loss:0.5541014671325684\n",
            "Loss:0.5538861751556396\n",
            "Loss:0.5536708235740662\n",
            "Loss:0.5534555315971375\n",
            "Loss:0.5532403588294983\n",
            "Loss:0.5530250668525696\n",
            "Epoch: 10 | Loss: 0.5530250668525696 | Test loss: 0.5846781134605408\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7637]])), ('linear_layer.bias', tensor([0.8280]))])\n",
            "Loss:0.5528097748756409\n",
            "Loss:0.5525944828987122\n",
            "Loss:0.5523791909217834\n",
            "Loss:0.5521638989448547\n",
            "Loss:0.5519485473632812\n",
            "Loss:0.5517333745956421\n",
            "Loss:0.5515180230140686\n",
            "Loss:0.5513027310371399\n",
            "Loss:0.5510873794555664\n",
            "Loss:0.5508721470832825\n",
            "Epoch: 20 | Loss: 0.5508721470832825 | Test loss: 0.5821606516838074\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7630]])), ('linear_layer.bias', tensor([0.8261]))])\n",
            "Loss:0.550656795501709\n",
            "Loss:0.550441563129425\n",
            "Loss:0.5502262115478516\n",
            "Loss:0.5500109791755676\n",
            "Loss:0.5497957468032837\n",
            "Loss:0.5495803952217102\n",
            "Loss:0.5493650436401367\n",
            "Loss:0.5491498112678528\n",
            "Loss:0.5489345192909241\n",
            "Loss:0.5487192273139954\n",
            "Epoch: 30 | Loss: 0.5487192273139954 | Test loss: 0.5796432495117188\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7623]])), ('linear_layer.bias', tensor([0.8242]))])\n",
            "Loss:0.5485039949417114\n",
            "Loss:0.5482886433601379\n",
            "Loss:0.5480733513832092\n",
            "Loss:0.5478580594062805\n",
            "Loss:0.5476428270339966\n",
            "Loss:0.5474274754524231\n",
            "Loss:0.5472121834754944\n",
            "Loss:0.5469969511032104\n",
            "Loss:0.5467816591262817\n",
            "Loss:0.546566367149353\n",
            "Epoch: 40 | Loss: 0.546566367149353 | Test loss: 0.5771259665489197\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7615]])), ('linear_layer.bias', tensor([0.8223]))])\n",
            "Loss:0.5463510751724243\n",
            "Loss:0.5461357831954956\n",
            "Loss:0.5459204316139221\n",
            "Loss:0.5457051992416382\n",
            "Loss:0.5454899072647095\n",
            "Loss:0.5452746152877808\n",
            "Loss:0.5450592637062073\n",
            "Loss:0.5448440313339233\n",
            "Loss:0.5446287393569946\n",
            "Loss:0.5444134473800659\n",
            "Epoch: 50 | Loss: 0.5444134473800659 | Test loss: 0.5746085047721863\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7608]])), ('linear_layer.bias', tensor([0.8205]))])\n",
            "Loss:0.5441981554031372\n",
            "Loss:0.5439828634262085\n",
            "Loss:0.5437675714492798\n",
            "Loss:0.5435522794723511\n",
            "Loss:0.5433369874954224\n",
            "Loss:0.5431216955184937\n",
            "Loss:0.5429064035415649\n",
            "Loss:0.5426911115646362\n",
            "Loss:0.5424758195877075\n",
            "Loss:0.5422605276107788\n",
            "Epoch: 60 | Loss: 0.5422605276107788 | Test loss: 0.5720911622047424\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7601]])), ('linear_layer.bias', tensor([0.8186]))])\n",
            "Loss:0.5420452356338501\n",
            "Loss:0.5418298840522766\n",
            "Loss:0.5416146516799927\n",
            "Loss:0.541399359703064\n",
            "Loss:0.5411840677261353\n",
            "Loss:0.5409687757492065\n",
            "Loss:0.5407534837722778\n",
            "Loss:0.5405381917953491\n",
            "Loss:0.5403228998184204\n",
            "Loss:0.5401076078414917\n",
            "Epoch: 70 | Loss: 0.5401076078414917 | Test loss: 0.5695737600326538\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7594]])), ('linear_layer.bias', tensor([0.8167]))])\n",
            "Loss:0.539892315864563\n",
            "Loss:0.5396770238876343\n",
            "Loss:0.5394617319107056\n",
            "Loss:0.5392464399337769\n",
            "Loss:0.5390312075614929\n",
            "Loss:0.5388158559799194\n",
            "Loss:0.5386005640029907\n",
            "Loss:0.538385272026062\n",
            "Loss:0.5381700396537781\n",
            "Loss:0.5379546880722046\n",
            "Epoch: 80 | Loss: 0.5379546880722046 | Test loss: 0.5670563578605652\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7586]])), ('linear_layer.bias', tensor([0.8149]))])\n",
            "Loss:0.5377393960952759\n",
            "Loss:0.5375241041183472\n",
            "Loss:0.5373088717460632\n",
            "Loss:0.5370935797691345\n",
            "Loss:0.536878228187561\n",
            "Loss:0.5366629362106323\n",
            "Loss:0.5364477038383484\n",
            "Loss:0.5362323522567749\n",
            "Loss:0.5360170602798462\n",
            "Loss:0.5358018279075623\n",
            "Epoch: 90 | Loss: 0.5358018279075623 | Test loss: 0.5645390748977661\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7579]])), ('linear_layer.bias', tensor([0.8130]))])\n",
            "Loss:0.5355865359306335\n",
            "Loss:0.5353712439537048\n",
            "Loss:0.5351559519767761\n",
            "Loss:0.5349406003952026\n",
            "Loss:0.5347253680229187\n",
            "Loss:0.53451007604599\n",
            "Loss:0.5342947244644165\n",
            "Loss:0.5340794324874878\n",
            "Loss:0.5338642001152039\n",
            "Loss:0.5336489081382751\n",
            "Epoch: 100 | Loss: 0.5336489081382751 | Test loss: 0.5620216131210327\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7572]])), ('linear_layer.bias', tensor([0.8111]))])\n",
            "Loss:0.5334335565567017\n",
            "Loss:0.533218264579773\n",
            "Loss:0.533003032207489\n",
            "Loss:0.5327877402305603\n",
            "Loss:0.5325725078582764\n",
            "Loss:0.5323572158813477\n",
            "Loss:0.5321418642997742\n",
            "Loss:0.5319265723228455\n",
            "Loss:0.5317112803459167\n",
            "Loss:0.531495988368988\n",
            "Epoch: 110 | Loss: 0.531495988368988 | Test loss: 0.5595042109489441\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7564]])), ('linear_layer.bias', tensor([0.8093]))])\n",
            "Loss:0.5312806963920593\n",
            "Loss:0.5310654640197754\n",
            "Loss:0.5308501720428467\n",
            "Loss:0.5306348204612732\n",
            "Loss:0.5304195284843445\n",
            "Loss:0.5302042961120605\n",
            "Loss:0.5299889445304871\n",
            "Loss:0.5297737121582031\n",
            "Loss:0.5295584201812744\n",
            "Loss:0.5293431282043457\n",
            "Epoch: 120 | Loss: 0.5293431282043457 | Test loss: 0.5569868087768555\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7557]])), ('linear_layer.bias', tensor([0.8074]))])\n",
            "Loss:0.529127836227417\n",
            "Loss:0.5289125442504883\n",
            "Loss:0.5286971926689148\n",
            "Loss:0.5284819602966309\n",
            "Loss:0.5282666087150574\n",
            "Loss:0.5280513167381287\n",
            "Loss:0.5278360843658447\n",
            "Loss:0.5276207327842712\n",
            "Loss:0.5274055004119873\n",
            "Loss:0.5271901488304138\n",
            "Epoch: 130 | Loss: 0.5271901488304138 | Test loss: 0.5544695258140564\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7550]])), ('linear_layer.bias', tensor([0.8055]))])\n",
            "Loss:0.5269749164581299\n",
            "Loss:0.526759684085846\n",
            "Loss:0.5265443325042725\n",
            "Loss:0.5263290405273438\n",
            "Loss:0.5261138081550598\n",
            "Loss:0.5258984565734863\n",
            "Loss:0.5256831645965576\n",
            "Loss:0.5254678726196289\n",
            "Loss:0.5252525806427002\n",
            "Loss:0.5250372886657715\n",
            "Epoch: 140 | Loss: 0.5250372886657715 | Test loss: 0.551952064037323\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7543]])), ('linear_layer.bias', tensor([0.8037]))])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|      | 38/100 [00:11<00:18,  3.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5248219966888428\n",
            "Loss:0.5246067047119141\n",
            "Loss:0.5243914723396301\n",
            "Loss:0.5241761803627014\n",
            "Loss:0.5239608287811279\n",
            "Loss:0.5237455368041992\n",
            "Loss:0.5235303044319153\n",
            "Loss:0.5233150124549866\n",
            "Loss:0.5230997204780579\n",
            "Loss:0.5228843688964844\n",
            "Epoch: 150 | Loss: 0.5228843688964844 | Test loss: 0.5494346618652344\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7535]])), ('linear_layer.bias', tensor([0.8018]))])\n",
            "Loss:0.5226691365242004\n",
            "Loss:0.5224538445472717\n",
            "Loss:0.522238552570343\n",
            "Loss:0.5220232009887695\n",
            "Loss:0.5218079090118408\n",
            "Loss:0.5215926766395569\n",
            "Loss:0.5213773846626282\n",
            "Loss:0.5211621522903442\n",
            "Loss:0.5209468603134155\n",
            "Loss:0.520731508731842\n",
            "Epoch: 160 | Loss: 0.520731508731842 | Test loss: 0.5469173192977905\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7528]])), ('linear_layer.bias', tensor([0.7999]))])\n",
            "Loss:0.5205162167549133\n",
            "Loss:0.5203008651733398\n",
            "Loss:0.5200856328010559\n",
            "Loss:0.519870400428772\n",
            "Loss:0.5196550488471985\n",
            "Loss:0.519439697265625\n",
            "Loss:0.5192244648933411\n",
            "Loss:0.5190091729164124\n",
            "Loss:0.5187939405441284\n",
            "Loss:0.5185786485671997\n",
            "Epoch: 170 | Loss: 0.5185786485671997 | Test loss: 0.5443999171257019\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7521]])), ('linear_layer.bias', tensor([0.7981]))])\n",
            "Loss:0.518363356590271\n",
            "Loss:0.5181480050086975\n",
            "Loss:0.5179327726364136\n",
            "Loss:0.5177174806594849\n",
            "Loss:0.5175021886825562\n",
            "Loss:0.5172868371009827\n",
            "Loss:0.5170716047286987\n",
            "Loss:0.51685631275177\n",
            "Loss:0.5166410207748413\n",
            "Loss:0.5164257287979126\n",
            "Epoch: 180 | Loss: 0.5164257287979126 | Test loss: 0.5418826341629028\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7513]])), ('linear_layer.bias', tensor([0.7962]))])\n",
            "Loss:0.5162103772163391\n",
            "Loss:0.5159951448440552\n",
            "Loss:0.5157798528671265\n",
            "Loss:0.5155645608901978\n",
            "Loss:0.515349268913269\n",
            "Loss:0.5151339769363403\n",
            "Loss:0.5149186849594116\n",
            "Loss:0.5147033929824829\n",
            "Loss:0.5144881010055542\n",
            "Loss:0.5142728090286255\n",
            "Epoch: 190 | Loss: 0.5142728090286255 | Test loss: 0.5393651723861694\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7506]])), ('linear_layer.bias', tensor([0.7943]))])\n",
            "Loss:0.5140575170516968\n",
            "Loss:0.5138422250747681\n",
            "Loss:0.5136268734931946\n",
            "Loss:0.5134116411209106\n",
            "Loss:0.5131963491439819\n",
            "Loss:0.5129810571670532\n",
            "Loss:0.5127657651901245\n",
            "Loss:0.5125504732131958\n",
            "Loss:0.5123351812362671\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5871886610984802\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5549567937850952\n",
            "Loss:0.5547357201576233\n",
            "Loss:0.5545145273208618\n",
            "Loss:0.5542934536933899\n",
            "Loss:0.554072380065918\n",
            "Loss:0.5538511872291565\n",
            "Loss:0.5536300539970398\n",
            "Loss:0.5534089207649231\n",
            "Loss:0.5531878471374512\n",
            "Loss:0.5529667139053345\n",
            "Epoch: 10 | Loss: 0.5529667139053345 | Test loss: 0.5846030712127686\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7637]])), ('linear_layer.bias', tensor([0.8279]))])\n",
            "Loss:0.5527455806732178\n",
            "Loss:0.5525244474411011\n",
            "Loss:0.5523033142089844\n",
            "Loss:0.5520821809768677\n",
            "Loss:0.5518611073493958\n",
            "Loss:0.5516399145126343\n",
            "Loss:0.5514189004898071\n",
            "Loss:0.5511976480484009\n",
            "Loss:0.5509766340255737\n",
            "Loss:0.5507554411888123\n",
            "Epoch: 20 | Loss: 0.5507554411888123 | Test loss: 0.5820176005363464\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7630]])), ('linear_layer.bias', tensor([0.8260]))])\n",
            "Loss:0.5505343675613403\n",
            "Loss:0.5503132343292236\n",
            "Loss:0.5500921010971069\n",
            "Loss:0.5498709082603455\n",
            "Loss:0.5496498942375183\n",
            "Loss:0.5494286417961121\n",
            "Loss:0.5492076277732849\n",
            "Loss:0.5489864945411682\n",
            "Loss:0.5487653017044067\n",
            "Loss:0.5485442876815796\n",
            "Epoch: 30 | Loss: 0.5485442876815796 | Test loss: 0.57943195104599\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7622]])), ('linear_layer.bias', tensor([0.8241]))])\n",
            "Loss:0.5483230352401733\n",
            "Loss:0.5481020212173462\n",
            "Loss:0.5478808283805847\n",
            "Loss:0.5476597547531128\n",
            "Loss:0.5474385023117065\n",
            "Loss:0.5472174882888794\n",
            "Loss:0.5469963550567627\n",
            "Loss:0.546775221824646\n",
            "Loss:0.5465540885925293\n",
            "Loss:0.5463330149650574\n",
            "Epoch: 40 | Loss: 0.5463330149650574 | Test loss: 0.5768464207649231\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7615]])), ('linear_layer.bias', tensor([0.8221]))])\n",
            "Loss:0.5461118817329407\n",
            "Loss:0.545890748500824\n",
            "Loss:0.5456696152687073\n",
            "Loss:0.5454484820365906\n",
            "Loss:0.5452274084091187\n",
            "Loss:0.545006275177002\n",
            "Loss:0.5447851419448853\n",
            "Loss:0.5445639491081238\n",
            "Loss:0.5443428754806519\n",
            "Loss:0.5441218018531799\n",
            "Epoch: 50 | Loss: 0.5441218018531799 | Test loss: 0.5742608308792114\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7607]])), ('linear_layer.bias', tensor([0.8202]))])\n",
            "Loss:0.5439006090164185\n",
            "Loss:0.5436795353889465\n",
            "Loss:0.5434583425521851\n",
            "Loss:0.5432372093200684\n",
            "Loss:0.5430161356925964\n",
            "Loss:0.5427950024604797\n",
            "Loss:0.5425739288330078\n",
            "Loss:0.5423527359962463\n",
            "Loss:0.5421316623687744\n",
            "Loss:0.5419104695320129\n",
            "Epoch: 60 | Loss: 0.5419104695320129 | Test loss: 0.5716753005981445\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7600]])), ('linear_layer.bias', tensor([0.8183]))])\n",
            "Loss:0.541689395904541\n",
            "Loss:0.5414682626724243\n",
            "Loss:0.5412471890449524\n",
            "Loss:0.5410259962081909\n",
            "Loss:0.5408048629760742\n",
            "Loss:0.5405837297439575\n",
            "Loss:0.5403626561164856\n",
            "Loss:0.5401415228843689\n",
            "Loss:0.539920449256897\n",
            "Loss:0.539699375629425\n",
            "Epoch: 70 | Loss: 0.539699375629425 | Test loss: 0.5690898299217224\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7592]])), ('linear_layer.bias', tensor([0.8164]))])\n",
            "Loss:0.5394781231880188\n",
            "Loss:0.5392571091651917\n",
            "Loss:0.5390359163284302\n",
            "Loss:0.5388147830963135\n",
            "Loss:0.5385936498641968\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|      | 39/100 [00:12<00:18,  3.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5383725762367249\n",
            "Loss:0.5381513833999634\n",
            "Loss:0.5379303693771362\n",
            "Loss:0.53770911693573\n",
            "Loss:0.5374881029129028\n",
            "Epoch: 80 | Loss: 0.5374881029129028 | Test loss: 0.5665042400360107\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7585]])), ('linear_layer.bias', tensor([0.8145]))])\n",
            "Loss:0.5372669100761414\n",
            "Loss:0.5370458364486694\n",
            "Loss:0.5368247032165527\n",
            "Loss:0.536603569984436\n",
            "Loss:0.5363823771476746\n",
            "Loss:0.5361613035202026\n",
            "Loss:0.5359401702880859\n",
            "Loss:0.5357190370559692\n",
            "Loss:0.5354979634284973\n",
            "Loss:0.5352767705917358\n",
            "Epoch: 90 | Loss: 0.5352767705917358 | Test loss: 0.5639186501502991\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7577]])), ('linear_layer.bias', tensor([0.8125]))])\n",
            "Loss:0.5350556969642639\n",
            "Loss:0.5348345637321472\n",
            "Loss:0.5346134305000305\n",
            "Loss:0.5343923568725586\n",
            "Loss:0.5341712236404419\n",
            "Loss:0.5339500308036804\n",
            "Loss:0.5337289571762085\n",
            "Loss:0.533507764339447\n",
            "Loss:0.5332866907119751\n",
            "Loss:0.5330655574798584\n",
            "Epoch: 100 | Loss: 0.5330655574798584 | Test loss: 0.5613331198692322\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7570]])), ('linear_layer.bias', tensor([0.8106]))])\n",
            "Loss:0.5328444242477417\n",
            "Loss:0.5326233506202698\n",
            "Loss:0.5324021577835083\n",
            "Loss:0.5321810841560364\n",
            "Loss:0.5319600105285645\n",
            "Loss:0.5317388772964478\n",
            "Loss:0.5315176844596863\n",
            "Loss:0.5312966108322144\n",
            "Loss:0.5310754179954529\n",
            "Loss:0.530854344367981\n",
            "Epoch: 110 | Loss: 0.530854344367981 | Test loss: 0.5587475299835205\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7562]])), ('linear_layer.bias', tensor([0.8087]))])\n",
            "Loss:0.5306332111358643\n",
            "Loss:0.5304120779037476\n",
            "Loss:0.5301909446716309\n",
            "Loss:0.5299698114395142\n",
            "Loss:0.5297487378120422\n",
            "Loss:0.5295275449752808\n",
            "Loss:0.5293064713478088\n",
            "Loss:0.5290853381156921\n",
            "Loss:0.5288642048835754\n",
            "Loss:0.5286431312561035\n",
            "Epoch: 120 | Loss: 0.5286431312561035 | Test loss: 0.5561620593070984\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7555]])), ('linear_layer.bias', tensor([0.8068]))])\n",
            "Loss:0.5284219980239868\n",
            "Loss:0.5282008647918701\n",
            "Loss:0.5279797315597534\n",
            "Loss:0.5277585983276367\n",
            "Loss:0.5275375247001648\n",
            "Loss:0.5273163318634033\n",
            "Loss:0.5270952582359314\n",
            "Loss:0.5268741250038147\n",
            "Loss:0.526652991771698\n",
            "Loss:0.5264318585395813\n",
            "Epoch: 130 | Loss: 0.5264318585395813 | Test loss: 0.5535764098167419\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7547]])), ('linear_layer.bias', tensor([0.8049]))])\n",
            "Loss:0.5262107253074646\n",
            "Loss:0.5259896516799927\n",
            "Loss:0.5257684588432312\n",
            "Loss:0.5255473852157593\n",
            "Loss:0.5253262519836426\n",
            "Loss:0.5251051187515259\n",
            "Loss:0.524884045124054\n",
            "Loss:0.5246628522872925\n",
            "Loss:0.5244417786598206\n",
            "Loss:0.5242206454277039\n",
            "Epoch: 140 | Loss: 0.5242206454277039 | Test loss: 0.550990879535675\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7540]])), ('linear_layer.bias', tensor([0.8029]))])\n",
            "Loss:0.5239994525909424\n",
            "Loss:0.5237783193588257\n",
            "Loss:0.5235572457313538\n",
            "Loss:0.5233361124992371\n",
            "Loss:0.5231150388717651\n",
            "Loss:0.5228938460350037\n",
            "Loss:0.5226727724075317\n",
            "Loss:0.522451639175415\n",
            "Loss:0.5222305059432983\n",
            "Loss:0.5220094323158264\n",
            "Epoch: 150 | Loss: 0.5220094323158264 | Test loss: 0.5484052896499634\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7532]])), ('linear_layer.bias', tensor([0.8010]))])\n",
            "Loss:0.5217882394790649\n",
            "Loss:0.521567165851593\n",
            "Loss:0.5213459730148315\n",
            "Loss:0.5211248993873596\n",
            "Loss:0.5209037661552429\n",
            "Loss:0.520682692527771\n",
            "Loss:0.5204614996910095\n",
            "Loss:0.5202404260635376\n",
            "Loss:0.5200192332267761\n",
            "Loss:0.5197981595993042\n",
            "Epoch: 160 | Loss: 0.5197981595993042 | Test loss: 0.5458197593688965\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7525]])), ('linear_layer.bias', tensor([0.7991]))])\n",
            "Loss:0.5195770263671875\n",
            "Loss:0.5193558931350708\n",
            "Loss:0.5191347599029541\n",
            "Loss:0.5189136266708374\n",
            "Loss:0.5186924934387207\n",
            "Loss:0.518471360206604\n",
            "Loss:0.5182502865791321\n",
            "Loss:0.5180290937423706\n",
            "Loss:0.5178080797195435\n",
            "Loss:0.5175869464874268\n",
            "Epoch: 170 | Loss: 0.5175869464874268 | Test loss: 0.5432342886924744\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7517]])), ('linear_layer.bias', tensor([0.7972]))])\n",
            "Loss:0.5173657536506653\n",
            "Loss:0.5171446800231934\n",
            "Loss:0.5169235467910767\n",
            "Loss:0.51670241355896\n",
            "Loss:0.5164812803268433\n",
            "Loss:0.5162601470947266\n",
            "Loss:0.5160390734672546\n",
            "Loss:0.5158179402351379\n",
            "Loss:0.5155967473983765\n",
            "Loss:0.5153756141662598\n",
            "Epoch: 180 | Loss: 0.5153756141662598 | Test loss: 0.5406486988067627\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7510]])), ('linear_layer.bias', tensor([0.7953]))])\n",
            "Loss:0.5151545405387878\n",
            "Loss:0.5149334669113159\n",
            "Loss:0.5147122740745544\n",
            "Loss:0.5144912004470825\n",
            "Loss:0.514270007610321\n",
            "Loss:0.5140489339828491\n",
            "Loss:0.5138278007507324\n",
            "Loss:0.5136066675186157\n",
            "Loss:0.513385534286499\n",
            "Loss:0.5131644010543823\n",
            "Epoch: 190 | Loss: 0.5131644010543823 | Test loss: 0.538063108921051\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7502]])), ('linear_layer.bias', tensor([0.7933]))])\n",
            "Loss:0.5129433274269104\n",
            "Loss:0.5127221941947937\n",
            "Loss:0.512501060962677\n",
            "Loss:0.5122799277305603\n",
            "Loss:0.5120588541030884\n",
            "Loss:0.5118376612663269\n",
            "Loss:0.511616587638855\n",
            "Loss:0.5113953948020935\n",
            "Loss:0.5111743211746216\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5871818661689758\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.554951012134552\n",
            "Loss:0.5547240376472473\n",
            "Loss:0.5544970631599426\n",
            "Loss:0.5542700886726379\n",
            "Loss:0.554043173789978\n",
            "Loss:0.5538161993026733\n",
            "Loss:0.5535892248153687\n",
            "Loss:0.553362250328064\n",
            "Loss:0.5531352758407593\n",
            "Loss:0.5529083013534546\n",
            "Epoch: 10 | Loss: 0.5529083013534546 | Test loss: 0.5845280885696411\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7637]])), ('linear_layer.bias', tensor([0.8278]))])\n",
            "Loss:0.5526813864707947\n",
            "Loss:0.5524544715881348\n",
            "Loss:0.5522274374961853\n",
            "Loss:0.5520005226135254\n",
            "Loss:0.5517735481262207\n",
            "Loss:0.5515466332435608\n",
            "Loss:0.5513196587562561\n",
            "Loss:0.5510927438735962\n",
            "Loss:0.5508657693862915\n",
            "Loss:0.5506387948989868\n",
            "Epoch: 20 | Loss: 0.5506387948989868 | Test loss: 0.5818743705749512\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7629]])), ('linear_layer.bias', tensor([0.8259]))])\n",
            "Loss:0.5504118204116821\n",
            "Loss:0.5501848459243774\n",
            "Loss:0.5499578714370728\n",
            "Loss:0.5497308969497681\n",
            "Loss:0.5495039224624634\n",
            "Loss:0.5492770075798035\n",
            "Loss:0.5490500926971436\n",
            "Loss:0.5488231182098389\n",
            "Loss:0.5485961437225342\n",
            "Loss:0.5483692288398743\n",
            "Epoch: 30 | Loss: 0.5483692288398743 | Test loss: 0.5792206525802612\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7622]])), ('linear_layer.bias', tensor([0.8239]))])\n",
            "Loss:0.5481422543525696\n",
            "Loss:0.5479153394699097\n",
            "Loss:0.547688364982605\n",
            "Loss:0.5474613308906555\n",
            "Loss:0.5472344160079956\n",
            "Loss:0.5470074415206909\n",
            "Loss:0.546780526638031\n",
            "Loss:0.5465536117553711\n",
            "Loss:0.5463265776634216\n",
            "Loss:0.5460996031761169\n",
            "Epoch: 40 | Loss: 0.5460996031761169 | Test loss: 0.5765669345855713\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7614]])), ('linear_layer.bias', tensor([0.8219]))])\n",
            "Loss:0.545872688293457\n",
            "Loss:0.5456457138061523\n",
            "Loss:0.5454188585281372\n",
            "Loss:0.5451918244361877\n",
            "Loss:0.5449648499488831\n",
            "Loss:0.5447379350662231\n",
            "Loss:0.5445109605789185\n",
            "Loss:0.5442840456962585\n",
            "Loss:0.5440570116043091\n",
            "Loss:0.5438300967216492\n",
            "Epoch: 50 | Loss: 0.5438300967216492 | Test loss: 0.5739132165908813\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7606]])), ('linear_layer.bias', tensor([0.8200]))])\n",
            "Loss:0.5436031222343445\n",
            "Loss:0.5433761477470398\n",
            "Loss:0.5431492328643799\n",
            "Loss:0.54292231798172\n",
            "Loss:0.5426952242851257\n",
            "Loss:0.542468249797821\n",
            "Loss:0.5422412753105164\n",
            "Loss:0.5420144200325012\n",
            "Loss:0.5417874455451965\n",
            "Loss:0.5415604710578918\n",
            "Epoch: 60 | Loss: 0.5415604710578918 | Test loss: 0.5712594985961914\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7599]])), ('linear_layer.bias', tensor([0.8180]))])\n",
            "Loss:0.5413335561752319\n",
            "Loss:0.5411065816879272\n",
            "Loss:0.5408796072006226\n",
            "Loss:0.5406526327133179\n",
            "Loss:0.540425717830658\n",
            "Loss:0.5401987433433533\n",
            "Loss:0.5399717688560486\n",
            "Loss:0.5397448539733887\n",
            "Loss:0.539517879486084\n",
            "Loss:0.5392910242080688\n",
            "Epoch: 70 | Loss: 0.5392910242080688 | Test loss: 0.5686057806015015\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7591]])), ('linear_layer.bias', tensor([0.8160]))])\n",
            "Loss:0.5390639901161194\n",
            "Loss:0.5388370752334595\n",
            "Loss:0.5386101007461548\n",
            "Loss:0.5383831262588501\n",
            "Loss:0.5381561517715454\n",
            "Loss:0.5379292368888855\n",
            "Loss:0.5377022624015808\n",
            "Loss:0.5374752879142761\n",
            "Loss:0.5372482538223267\n",
            "Loss:0.5370213389396667\n",
            "Epoch: 80 | Loss: 0.5370213389396667 | Test loss: 0.5659520030021667\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7583]])), ('linear_layer.bias', tensor([0.8141]))])\n",
            "Loss:0.5367943644523621\n",
            "Loss:0.5365674495697021\n",
            "Loss:0.5363404750823975\n",
            "Loss:0.536113440990448\n",
            "Loss:0.5358865857124329\n",
            "Loss:0.5356596112251282\n",
            "Loss:0.5354326963424683\n",
            "Loss:0.5352057218551636\n",
            "Loss:0.5349788069725037\n",
            "Loss:0.5347517728805542\n",
            "Epoch: 90 | Loss: 0.5347517728805542 | Test loss: 0.5632982850074768\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7575]])), ('linear_layer.bias', tensor([0.8121]))])\n",
            "Loss:0.5345248579978943\n",
            "Loss:0.5342978239059448\n",
            "Loss:0.5340708494186401\n",
            "Loss:0.533843994140625\n",
            "Loss:0.5336170196533203\n",
            "Loss:0.5333900451660156\n",
            "Loss:0.5331630706787109\n",
            "Loss:0.5329360961914062\n",
            "Loss:0.5327091813087463\n",
            "Loss:0.5324822068214417\n",
            "Epoch: 100 | Loss: 0.5324822068214417 | Test loss: 0.5606446266174316\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7568]])), ('linear_layer.bias', tensor([0.8101]))])\n",
            "Loss:0.5322552919387817\n",
            "Loss:0.532028317451477\n",
            "Loss:0.5318013429641724\n",
            "Loss:0.5315743684768677\n",
            "Loss:0.5313474535942078\n",
            "Loss:0.5311204791069031\n",
            "Loss:0.5308935046195984\n",
            "Loss:0.5306665897369385\n",
            "Loss:0.5304396152496338\n",
            "Loss:0.5302126407623291\n",
            "Epoch: 110 | Loss: 0.5302126407623291 | Test loss: 0.5579909086227417\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7560]])), ('linear_layer.bias', tensor([0.8081]))])\n",
            "Loss:0.5299857258796692\n",
            "Loss:0.5297588109970093\n",
            "Loss:0.5295317769050598\n",
            "Loss:0.5293048024177551\n",
            "Loss:0.5290778279304504\n",
            "Loss:0.5288509130477905\n",
            "Loss:0.5286239385604858\n",
            "Loss:0.5283969640731812\n",
            "Loss:0.5281699895858765\n",
            "Loss:0.5279430150985718\n",
            "Epoch: 120 | Loss: 0.5279430150985718 | Test loss: 0.555337131023407\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7552]])), ('linear_layer.bias', tensor([0.8062]))])\n",
            "Loss:0.5277160406112671\n",
            "Loss:0.5274891257286072\n",
            "Loss:0.5272621512413025\n",
            "Loss:0.5270352959632874\n",
            "Loss:0.5268083214759827\n",
            "Loss:0.526581346988678\n",
            "Loss:0.5263543725013733\n",
            "Loss:0.5261274576187134\n",
            "Loss:0.5259004831314087\n",
            "Loss:0.525673508644104\n",
            "Epoch: 130 | Loss: 0.525673508644104 | Test loss: 0.552683413028717\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7545]])), ('linear_layer.bias', tensor([0.8042]))])\n",
            "Loss:0.5254465341567993\n",
            "Loss:0.5252195596694946\n",
            "Loss:0.5249925851821899\n",
            "Loss:0.5247656106948853\n",
            "Loss:0.5245386958122253\n",
            "Loss:0.5243117213249207\n",
            "Loss:0.5240848064422607\n",
            "Loss:0.523857831954956\n",
            "Loss:0.5236308574676514\n",
            "Loss:0.5234039425849915\n",
            "Epoch: 140 | Loss: 0.5234039425849915 | Test loss: 0.5500296950340271\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7537]])), ('linear_layer.bias', tensor([0.8022]))])\n",
            "Loss:0.5231769680976868\n",
            "Loss:0.5229500532150269\n",
            "Loss:0.5227230787277222\n",
            "Loss:0.5224961042404175\n",
            "Loss:0.5222691297531128\n",
            "Loss:0.5220421552658081\n",
            "Loss:0.5218152403831482\n",
            "Loss:0.5215882658958435\n",
            "Loss:0.5213613510131836\n",
            "Loss:0.5211343765258789\n",
            "Epoch: 150 | Loss: 0.5211343765258789 | Test loss: 0.5473759174346924\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7529]])), ('linear_layer.bias', tensor([0.8003]))])\n",
            "Loss:0.5209074020385742\n",
            "Loss:0.5206804275512695\n",
            "Loss:0.5204533934593201\n",
            "Loss:0.5202264785766602\n",
            "Loss:0.5199995636940002\n",
            "Loss:0.5197725892066956\n",
            "Loss:0.5195456743240356\n",
            "Loss:0.519318699836731\n",
            "Loss:0.5190917253494263\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|      | 40/100 [00:12<00:18,  3.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5188647508621216\n",
            "Epoch: 160 | Loss: 0.5188647508621216 | Test loss: 0.5447222590446472\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7522]])), ('linear_layer.bias', tensor([0.7983]))])\n",
            "Loss:0.5186377763748169\n",
            "Loss:0.518410861492157\n",
            "Loss:0.5181838870048523\n",
            "Loss:0.5179569721221924\n",
            "Loss:0.5177299976348877\n",
            "Loss:0.5175030827522278\n",
            "Loss:0.5172761082649231\n",
            "Loss:0.5170491337776184\n",
            "Loss:0.5168221592903137\n",
            "Loss:0.516595184803009\n",
            "Epoch: 170 | Loss: 0.516595184803009 | Test loss: 0.542068600654602\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7514]])), ('linear_layer.bias', tensor([0.7963]))])\n",
            "Loss:0.5163682699203491\n",
            "Loss:0.5161412954330444\n",
            "Loss:0.5159143209457397\n",
            "Loss:0.5156873464584351\n",
            "Loss:0.5154603719711304\n",
            "Loss:0.5152334570884705\n",
            "Loss:0.5150065422058105\n",
            "Loss:0.5147795081138611\n",
            "Loss:0.5145525932312012\n",
            "Loss:0.5143256187438965\n",
            "Epoch: 180 | Loss: 0.5143256187438965 | Test loss: 0.5394147634506226\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7506]])), ('linear_layer.bias', tensor([0.7944]))])\n",
            "Loss:0.5140987038612366\n",
            "Loss:0.5138717293739319\n",
            "Loss:0.5136447548866272\n",
            "Loss:0.5134178400039673\n",
            "Loss:0.5131908655166626\n",
            "Loss:0.5129638910293579\n",
            "Loss:0.5127369165420532\n",
            "Loss:0.5125100016593933\n",
            "Loss:0.5122830271720886\n",
            "Loss:0.5120560526847839\n",
            "Epoch: 190 | Loss: 0.5120560526847839 | Test loss: 0.5367611050605774\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7499]])), ('linear_layer.bias', tensor([0.7924]))])\n",
            "Loss:0.5118290781974792\n",
            "Loss:0.5116021037101746\n",
            "Loss:0.5113751888275146\n",
            "Loss:0.5111482739448547\n",
            "Loss:0.51092129945755\n",
            "Loss:0.5106943249702454\n",
            "Loss:0.5104674100875854\n",
            "Loss:0.5102404356002808\n",
            "Loss:0.5100134611129761\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5871750116348267\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.554945170879364\n",
            "Loss:0.5547124743461609\n",
            "Loss:0.554479718208313\n",
            "Loss:0.5542470216751099\n",
            "Loss:0.5540143251419067\n",
            "Loss:0.5537815093994141\n",
            "Loss:0.5535488128662109\n",
            "Loss:0.553316056728363\n",
            "Loss:0.5530833005905151\n",
            "Loss:0.552850604057312\n",
            "Epoch: 10 | Loss: 0.552850604057312 | Test loss: 0.5844537615776062\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7637]])), ('linear_layer.bias', tensor([0.8278]))])\n",
            "Loss:0.5526178479194641\n",
            "Loss:0.5523852109909058\n",
            "Loss:0.5521523952484131\n",
            "Loss:0.55191969871521\n",
            "Loss:0.5516869425773621\n",
            "Loss:0.5514542460441589\n",
            "Loss:0.551221489906311\n",
            "Loss:0.5509887933731079\n",
            "Loss:0.55075603723526\n",
            "Loss:0.5505232810974121\n",
            "Epoch: 20 | Loss: 0.5505232810974121 | Test loss: 0.581732451915741\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7629]])), ('linear_layer.bias', tensor([0.8258]))])\n",
            "Loss:0.550290584564209\n",
            "Loss:0.5500578880310059\n",
            "Loss:0.549825131893158\n",
            "Loss:0.5495923757553101\n",
            "Loss:0.5493596792221069\n",
            "Loss:0.549126923084259\n",
            "Loss:0.5488941669464111\n",
            "Loss:0.5486614108085632\n",
            "Loss:0.5484287738800049\n",
            "Loss:0.5481959581375122\n",
            "Epoch: 30 | Loss: 0.5481959581375122 | Test loss: 0.5790112018585205\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7621]])), ('linear_layer.bias', tensor([0.8237]))])\n",
            "Loss:0.5479632616043091\n",
            "Loss:0.547730565071106\n",
            "Loss:0.5474978685379028\n",
            "Loss:0.5472651124000549\n",
            "Loss:0.5470322966575623\n",
            "Loss:0.5467996597290039\n",
            "Loss:0.546566903591156\n",
            "Loss:0.5463341474533081\n",
            "Loss:0.546101450920105\n",
            "Loss:0.5458686947822571\n",
            "Epoch: 40 | Loss: 0.5458686947822571 | Test loss: 0.5762898325920105\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7613]])), ('linear_layer.bias', tensor([0.8217]))])\n",
            "Loss:0.545635998249054\n",
            "Loss:0.5454031825065613\n",
            "Loss:0.5451705455780029\n",
            "Loss:0.5449377298355103\n",
            "Loss:0.5447050333023071\n",
            "Loss:0.5444722771644592\n",
            "Loss:0.5442395806312561\n",
            "Loss:0.544006884098053\n",
            "Loss:0.5437741279602051\n",
            "Loss:0.5435413718223572\n",
            "Epoch: 50 | Loss: 0.5435413718223572 | Test loss: 0.57356858253479\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7605]])), ('linear_layer.bias', tensor([0.8197]))])\n",
            "Loss:0.543308675289154\n",
            "Loss:0.5430759191513062\n",
            "Loss:0.542843222618103\n",
            "Loss:0.5426104664802551\n",
            "Loss:0.542377769947052\n",
            "Loss:0.5421450138092041\n",
            "Loss:0.5419121980667114\n",
            "Loss:0.5416795611381531\n",
            "Loss:0.5414467453956604\n",
            "Loss:0.541214108467102\n",
            "Epoch: 60 | Loss: 0.541214108467102 | Test loss: 0.5708472728729248\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7597]])), ('linear_layer.bias', tensor([0.8177]))])\n",
            "Loss:0.5409813523292542\n",
            "Loss:0.5407485961914062\n",
            "Loss:0.5405158996582031\n",
            "Loss:0.5402830839157104\n",
            "Loss:0.5400504469871521\n",
            "Loss:0.5398176908493042\n",
            "Loss:0.5395849943161011\n",
            "Loss:0.5393522381782532\n",
            "Loss:0.5391194820404053\n",
            "Loss:0.5388867259025574\n",
            "Epoch: 70 | Loss: 0.5388867259025574 | Test loss: 0.5681260228157043\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7589]])), ('linear_layer.bias', tensor([0.8157]))])\n",
            "Loss:0.5386540293693542\n",
            "Loss:0.5384213328361511\n",
            "Loss:0.5381885766983032\n",
            "Loss:0.5379558801651001\n",
            "Loss:0.5377230644226074\n",
            "Loss:0.5374903678894043\n",
            "Loss:0.5372575521469116\n",
            "Loss:0.5370249152183533\n",
            "Loss:0.5367921590805054\n",
            "Loss:0.5365594029426575\n",
            "Epoch: 80 | Loss: 0.5365594029426575 | Test loss: 0.5654047131538391\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7582]])), ('linear_layer.bias', tensor([0.8136]))])\n",
            "Loss:0.5363267660140991\n",
            "Loss:0.5360940098762512\n",
            "Loss:0.5358612537384033\n",
            "Loss:0.5356284976005554\n",
            "Loss:0.5353957414627075\n",
            "Loss:0.5351630449295044\n",
            "Loss:0.5349303483963013\n",
            "Loss:0.5346976518630981\n",
            "Loss:0.5344648361206055\n",
            "Loss:0.5342321395874023\n",
            "Epoch: 90 | Loss: 0.5342321395874023 | Test loss: 0.5626834034919739\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7574]])), ('linear_layer.bias', tensor([0.8116]))])\n",
            "Loss:0.5339993834495544\n",
            "Loss:0.5337666273117065\n",
            "Loss:0.5335339307785034\n",
            "Loss:0.5333012342453003\n",
            "Loss:0.5330684781074524\n",
            "Loss:0.5328357815742493\n",
            "Loss:0.5326029658317566\n",
            "Loss:0.5323702692985535\n",
            "Loss:0.5321375131607056\n",
            "Loss:0.5319048762321472\n",
            "Epoch: 100 | Loss: 0.5319048762321472 | Test loss: 0.5599620938301086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|      | 41/100 [00:12<00:17,  3.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('linear_layer.weight', tensor([[0.7566]])), ('linear_layer.bias', tensor([0.8096]))])\n",
            "Loss:0.5316720604896545\n",
            "Loss:0.5314393043518066\n",
            "Loss:0.5312066674232483\n",
            "Loss:0.5309738516807556\n",
            "Loss:0.5307411551475525\n",
            "Loss:0.5305083990097046\n",
            "Loss:0.5302757024765015\n",
            "Loss:0.5300429463386536\n",
            "Loss:0.5298102498054504\n",
            "Loss:0.5295774936676025\n",
            "Epoch: 110 | Loss: 0.5295774936676025 | Test loss: 0.5572408437728882\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7558]])), ('linear_layer.bias', tensor([0.8076]))])\n",
            "Loss:0.5293447375297546\n",
            "Loss:0.5291120409965515\n",
            "Loss:0.5288792848587036\n",
            "Loss:0.5286465883255005\n",
            "Loss:0.5284138321876526\n",
            "Loss:0.5281811356544495\n",
            "Loss:0.5279483795166016\n",
            "Loss:0.5277156829833984\n",
            "Loss:0.5274829268455505\n",
            "Loss:0.5272501707077026\n",
            "Epoch: 120 | Loss: 0.5272501707077026 | Test loss: 0.5545194745063782\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7550]])), ('linear_layer.bias', tensor([0.8056]))])\n",
            "Loss:0.5270174741744995\n",
            "Loss:0.5267847180366516\n",
            "Loss:0.5265520215034485\n",
            "Loss:0.5263192653656006\n",
            "Loss:0.5260865092277527\n",
            "Loss:0.5258538126945496\n",
            "Loss:0.5256210565567017\n",
            "Loss:0.5253883600234985\n",
            "Loss:0.5251556634902954\n",
            "Loss:0.5249229073524475\n",
            "Epoch: 130 | Loss: 0.5249229073524475 | Test loss: 0.5517982840538025\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7542]])), ('linear_layer.bias', tensor([0.8035]))])\n",
            "Loss:0.5246901512145996\n",
            "Loss:0.5244574546813965\n",
            "Loss:0.5242247581481934\n",
            "Loss:0.5239919424057007\n",
            "Loss:0.5237591862678528\n",
            "Loss:0.5235265493392944\n",
            "Loss:0.5232937932014465\n",
            "Loss:0.5230610370635986\n",
            "Loss:0.5228283405303955\n",
            "Loss:0.5225955843925476\n",
            "Epoch: 140 | Loss: 0.5225955843925476 | Test loss: 0.5490769147872925\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7534]])), ('linear_layer.bias', tensor([0.8015]))])\n",
            "Loss:0.5223628878593445\n",
            "Loss:0.5221301317214966\n",
            "Loss:0.5218974351882935\n",
            "Loss:0.5216646790504456\n",
            "Loss:0.5214319825172424\n",
            "Loss:0.5211992263793945\n",
            "Loss:0.5209664702415466\n",
            "Loss:0.5207337141036987\n",
            "Loss:0.5205010175704956\n",
            "Loss:0.5202682614326477\n",
            "Epoch: 150 | Loss: 0.5202682614326477 | Test loss: 0.5463556051254272\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7526]])), ('linear_layer.bias', tensor([0.7995]))])\n",
            "Loss:0.5200355648994446\n",
            "Loss:0.5198028087615967\n",
            "Loss:0.5195700526237488\n",
            "Loss:0.5193372964859009\n",
            "Loss:0.5191045999526978\n",
            "Loss:0.5188719034194946\n",
            "Loss:0.5186391472816467\n",
            "Loss:0.5184064507484436\n",
            "Loss:0.5181736350059509\n",
            "Loss:0.5179409980773926\n",
            "Epoch: 160 | Loss: 0.5179409980773926 | Test loss: 0.543634295463562\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7519]])), ('linear_layer.bias', tensor([0.7975]))])\n",
            "Loss:0.5177082419395447\n",
            "Loss:0.5174754858016968\n",
            "Loss:0.5172427892684937\n",
            "Loss:0.5170100331306458\n",
            "Loss:0.5167773365974426\n",
            "Loss:0.5165445804595947\n",
            "Loss:0.5163118243217468\n",
            "Loss:0.5160790681838989\n",
            "Loss:0.5158463716506958\n",
            "Loss:0.5156136751174927\n",
            "Epoch: 170 | Loss: 0.5156136751174927 | Test loss: 0.5409130454063416\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7511]])), ('linear_layer.bias', tensor([0.7955]))])\n",
            "Loss:0.515380859375\n",
            "Loss:0.5151482224464417\n",
            "Loss:0.514915406703949\n",
            "Loss:0.5146827101707458\n",
            "Loss:0.514449954032898\n",
            "Loss:0.5142172574996948\n",
            "Loss:0.5139845013618469\n",
            "Loss:0.5137518048286438\n",
            "Loss:0.5135190486907959\n",
            "Loss:0.513286292552948\n",
            "Epoch: 180 | Loss: 0.513286292552948 | Test loss: 0.5381916761398315\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7503]])), ('linear_layer.bias', tensor([0.7934]))])\n",
            "Loss:0.5130535960197449\n",
            "Loss:0.5128208994865417\n",
            "Loss:0.5125881433486938\n",
            "Loss:0.5123554468154907\n",
            "Loss:0.5121226906776428\n",
            "Loss:0.5118898749351501\n",
            "Loss:0.5116572380065918\n",
            "Loss:0.5114244818687439\n",
            "Loss:0.511191725730896\n",
            "Loss:0.5109590291976929\n",
            "Epoch: 190 | Loss: 0.5109590291976929 | Test loss: 0.5354703664779663\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7495]])), ('linear_layer.bias', tensor([0.7914]))])\n",
            "Loss:0.510726273059845\n",
            "Loss:0.5104935169219971\n",
            "Loss:0.510260820388794\n",
            "Loss:0.510028064250946\n",
            "Loss:0.5097953081130981\n",
            "Loss:0.5095626711845398\n",
            "Loss:0.5093298554420471\n",
            "Loss:0.5090972185134888\n",
            "Loss:0.5088644623756409\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5871683359146118\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5549393892288208\n",
            "Loss:0.5547007918357849\n",
            "Loss:0.5544622540473938\n",
            "Loss:0.5542237162590027\n",
            "Loss:0.5539851188659668\n",
            "Loss:0.5537465214729309\n",
            "Loss:0.5535079836845398\n",
            "Loss:0.5532694458961487\n",
            "Loss:0.5530308485031128\n",
            "Loss:0.5527922511100769\n",
            "Epoch: 10 | Loss: 0.5527922511100769 | Test loss: 0.5843787789344788\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7637]])), ('linear_layer.bias', tensor([0.8277]))])\n",
            "Loss:0.5525537133216858\n",
            "Loss:0.5523151755332947\n",
            "Loss:0.5520765781402588\n",
            "Loss:0.5518380403518677\n",
            "Loss:0.5515995025634766\n",
            "Loss:0.5513609051704407\n",
            "Loss:0.5511223077774048\n",
            "Loss:0.5508837699890137\n",
            "Loss:0.5506452322006226\n",
            "Loss:0.5504066348075867\n",
            "Epoch: 20 | Loss: 0.5504066348075867 | Test loss: 0.5815893411636353\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7628]])), ('linear_layer.bias', tensor([0.8257]))])\n",
            "Loss:0.5501680374145508\n",
            "Loss:0.5499294996261597\n",
            "Loss:0.5496909618377686\n",
            "Loss:0.5494524240493774\n",
            "Loss:0.5492138862609863\n",
            "Loss:0.5489752292633057\n",
            "Loss:0.5487366914749146\n",
            "Loss:0.5484981536865234\n",
            "Loss:0.5482596158981323\n",
            "Loss:0.5480210185050964\n",
            "Epoch: 30 | Loss: 0.5480210185050964 | Test loss: 0.578799843788147\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7620]])), ('linear_layer.bias', tensor([0.8236]))])\n",
            "Loss:0.5477824211120605\n",
            "Loss:0.5475438833236694\n",
            "Loss:0.5473052859306335\n",
            "Loss:0.5470668077468872\n",
            "Loss:0.5468281507492065\n",
            "Loss:0.5465895533561707\n",
            "Loss:0.5463510751724243\n",
            "Loss:0.5461124181747437\n",
            "Loss:0.5458739399909973\n",
            "Loss:0.5456353425979614\n",
            "Epoch: 40 | Loss: 0.5456353425979614 | Test loss: 0.5760103464126587\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7612]])), ('linear_layer.bias', tensor([0.8215]))])\n",
            "Loss:0.5453967452049255\n",
            "Loss:0.5451582074165344\n",
            "Loss:0.5449196696281433\n",
            "Loss:0.5446810722351074\n",
            "Loss:0.5444425344467163\n",
            "Loss:0.5442039370536804\n",
            "Loss:0.5439653992652893\n",
            "Loss:0.5437268018722534\n",
            "Loss:0.5434882640838623\n",
            "Loss:0.5432497262954712\n",
            "Epoch: 50 | Loss: 0.5432497262954712 | Test loss: 0.57322096824646\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7604]])), ('linear_layer.bias', tensor([0.8194]))])\n",
            "Loss:0.5430111885070801\n",
            "Loss:0.5427725911140442\n",
            "Loss:0.5425339937210083\n",
            "Loss:0.5422954559326172\n",
            "Loss:0.5420569181442261\n",
            "Loss:0.5418183207511902\n",
            "Loss:0.5415797829627991\n",
            "Loss:0.5413411855697632\n",
            "Loss:0.5411025881767273\n",
            "Loss:0.5408640503883362\n",
            "Epoch: 60 | Loss: 0.5408640503883362 | Test loss: 0.5704314708709717\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7596]])), ('linear_layer.bias', tensor([0.8174]))])\n",
            "Loss:0.5406255125999451\n",
            "Loss:0.540386974811554\n",
            "Loss:0.5401483774185181\n",
            "Loss:0.539909839630127\n",
            "Loss:0.5396712422370911\n",
            "Loss:0.5394326448440552\n",
            "Loss:0.5391941070556641\n",
            "Loss:0.538955569267273\n",
            "Loss:0.5387169718742371\n",
            "Loss:0.5384783744812012\n",
            "Epoch: 70 | Loss: 0.5384783744812012 | Test loss: 0.5676420331001282\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7588]])), ('linear_layer.bias', tensor([0.8153]))])\n",
            "Loss:0.5382398366928101\n",
            "Loss:0.538001298904419\n",
            "Loss:0.5377627611160278\n",
            "Loss:0.5375241041183472\n",
            "Loss:0.537285566329956\n",
            "Loss:0.5370470285415649\n",
            "Loss:0.536808431148529\n",
            "Loss:0.5365698933601379\n",
            "Loss:0.536331295967102\n",
            "Loss:0.5360926985740662\n",
            "Epoch: 80 | Loss: 0.5360926985740662 | Test loss: 0.5648525953292847\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7580]])), ('linear_layer.bias', tensor([0.8132]))])\n",
            "Loss:0.5358542203903198\n",
            "Loss:0.5356155633926392\n",
            "Loss:0.5353771448135376\n",
            "Loss:0.5351384878158569\n",
            "Loss:0.5348999500274658\n",
            "Loss:0.5346613526344299\n",
            "Loss:0.5344228148460388\n",
            "Loss:0.5341842770576477\n",
            "Loss:0.5339457392692566\n",
            "Loss:0.5337070822715759\n",
            "Epoch: 90 | Loss: 0.5337070822715759 | Test loss: 0.5620630383491516\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7572]])), ('linear_layer.bias', tensor([0.8112]))])\n",
            "Loss:0.5334686040878296\n",
            "Loss:0.5332300066947937\n",
            "Loss:0.5329914689064026\n",
            "Loss:0.5327528715133667\n",
            "Loss:0.5325142741203308\n",
            "Loss:0.5322757363319397\n",
            "Loss:0.5320371389389038\n",
            "Loss:0.5317986607551575\n",
            "Loss:0.5315600633621216\n",
            "Loss:0.5313214659690857\n",
            "Epoch: 100 | Loss: 0.5313214659690857 | Test loss: 0.5592736005783081\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7564]])), ('linear_layer.bias', tensor([0.8091]))])\n",
            "Loss:0.5310829281806946\n",
            "Loss:0.5308443307876587\n",
            "Loss:0.5306057929992676\n",
            "Loss:0.5303671956062317\n",
            "Loss:0.5301286578178406\n",
            "Loss:0.5298900604248047\n",
            "Loss:0.5296515226364136\n",
            "Loss:0.5294129252433777\n",
            "Loss:0.5291744470596313\n",
            "Loss:0.5289357900619507\n",
            "Epoch: 110 | Loss: 0.5289357900619507 | Test loss: 0.5564841032028198\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7556]])), ('linear_layer.bias', tensor([0.8070]))])\n",
            "Loss:0.5286972522735596\n",
            "Loss:0.5284587144851685\n",
            "Loss:0.5282201170921326\n",
            "Loss:0.5279815793037415\n",
            "Loss:0.5277429819107056\n",
            "Loss:0.5275044441223145\n",
            "Loss:0.5272659063339233\n",
            "Loss:0.5270273089408875\n",
            "Loss:0.5267887711524963\n",
            "Loss:0.5265501737594604\n",
            "Epoch: 120 | Loss: 0.5265501737594604 | Test loss: 0.5536946058273315\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7548]])), ('linear_layer.bias', tensor([0.8050]))])\n",
            "Loss:0.5263116359710693\n",
            "Loss:0.5260730981826782\n",
            "Loss:0.5258344411849976\n",
            "Loss:0.5255959630012512\n",
            "Loss:0.5253573656082153\n",
            "Loss:0.5251188278198242\n",
            "Loss:0.5248802900314331\n",
            "Loss:0.5246416926383972\n",
            "Loss:0.5244030952453613\n",
            "Loss:0.5241645574569702\n",
            "Epoch: 130 | Loss: 0.5241645574569702 | Test loss: 0.5509052276611328\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7540]])), ('linear_layer.bias', tensor([0.8029]))])\n",
            "Loss:0.5239259600639343\n",
            "Loss:0.5236874222755432\n",
            "Loss:0.5234488248825073\n",
            "Loss:0.5232102274894714\n",
            "Loss:0.5229717493057251\n",
            "Loss:0.5227331519126892\n",
            "Loss:0.5224946141242981\n",
            "Loss:0.5222560167312622\n",
            "Loss:0.5220174193382263\n",
            "Loss:0.5217788815498352\n",
            "Epoch: 140 | Loss: 0.5217788815498352 | Test loss: 0.5481157302856445\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7532]])), ('linear_layer.bias', tensor([0.8008]))])\n",
            "Loss:0.5215402841567993\n",
            "Loss:0.521301805973053\n",
            "Loss:0.5210632085800171\n",
            "Loss:0.5208246111869812\n",
            "Loss:0.5205860733985901\n",
            "Loss:0.5203474760055542\n",
            "Loss:0.5201089382171631\n",
            "Loss:0.5198703408241272\n",
            "Loss:0.5196317434310913\n",
            "Loss:0.519393265247345\n",
            "Epoch: 150 | Loss: 0.519393265247345 | Test loss: 0.545326292514801\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7523]])), ('linear_layer.bias', tensor([0.7987]))])\n",
            "Loss:0.5191546678543091\n",
            "Loss:0.518916130065918\n",
            "Loss:0.5186775326728821\n",
            "Loss:0.518438994884491\n",
            "Loss:0.5182004570960999\n",
            "Loss:0.517961859703064\n",
            "Loss:0.5177232623100281\n",
            "Loss:0.5174846649169922\n",
            "Loss:0.5172461271286011\n",
            "Loss:0.51700758934021\n",
            "Epoch: 160 | Loss: 0.51700758934021 | Test loss: 0.5425368547439575\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7515]])), ('linear_layer.bias', tensor([0.7967]))])\n",
            "Loss:0.5167690515518188\n",
            "Loss:0.516530454158783\n",
            "Loss:0.5162919163703918\n",
            "Loss:0.516053318977356\n",
            "Loss:0.5158147811889648\n",
            "Loss:0.5155762434005737\n",
            "Loss:0.5153376460075378\n",
            "Loss:0.515099048614502\n",
            "Loss:0.5148605108261108\n",
            "Loss:0.514621913433075\n",
            "Epoch: 170 | Loss: 0.514621913433075 | Test loss: 0.5397472977638245\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|     | 42/100 [00:13<00:17,  3.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('linear_layer.weight', tensor([[0.7507]])), ('linear_layer.bias', tensor([0.7946]))])\n",
            "Loss:0.5143834352493286\n",
            "Loss:0.514144778251648\n",
            "Loss:0.5139061808586121\n",
            "Loss:0.5136677026748657\n",
            "Loss:0.5134291052818298\n",
            "Loss:0.5131905674934387\n",
            "Loss:0.5129520297050476\n",
            "Loss:0.5127134323120117\n",
            "Loss:0.5124748349189758\n",
            "Loss:0.5122362971305847\n",
            "Epoch: 180 | Loss: 0.5122362971305847 | Test loss: 0.536957859992981\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7499]])), ('linear_layer.bias', tensor([0.7925]))])\n",
            "Loss:0.5119978189468384\n",
            "Loss:0.5117591619491577\n",
            "Loss:0.5115206241607666\n",
            "Loss:0.5112820267677307\n",
            "Loss:0.5110434889793396\n",
            "Loss:0.5108049511909485\n",
            "Loss:0.5105663537979126\n",
            "Loss:0.5103277564048767\n",
            "Loss:0.5100892186164856\n",
            "Loss:0.5098506212234497\n",
            "Epoch: 190 | Loss: 0.5098506212234497 | Test loss: 0.5341683626174927\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7491]])), ('linear_layer.bias', tensor([0.7905]))])\n",
            "Loss:0.5096121430397034\n",
            "Loss:0.5093735456466675\n",
            "Loss:0.5091349482536316\n",
            "Loss:0.5088964104652405\n",
            "Loss:0.5086578130722046\n",
            "Loss:0.5084192752838135\n",
            "Loss:0.5081807374954224\n",
            "Loss:0.5079420804977417\n",
            "Loss:0.5077036023139954\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5871614217758179\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5549335479736328\n",
            "Loss:0.5546891689300537\n",
            "Loss:0.5544447302818298\n",
            "Loss:0.5542003512382507\n",
            "Loss:0.5539559125900269\n",
            "Loss:0.5537115335464478\n",
            "Loss:0.5534671545028687\n",
            "Loss:0.5532227754592896\n",
            "Loss:0.5529783964157104\n",
            "Loss:0.5527339577674866\n",
            "Epoch: 10 | Loss: 0.5527339577674866 | Test loss: 0.5843037962913513\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7636]])), ('linear_layer.bias', tensor([0.8277]))])\n",
            "Loss:0.5524895787239075\n",
            "Loss:0.5522451400756836\n",
            "Loss:0.5520007014274597\n",
            "Loss:0.5517562627792358\n",
            "Loss:0.5515120029449463\n",
            "Loss:0.5512675642967224\n",
            "Loss:0.5510231256484985\n",
            "Loss:0.5507787466049194\n",
            "Loss:0.5505343675613403\n",
            "Loss:0.5502899289131165\n",
            "Epoch: 20 | Loss: 0.5502899289131165 | Test loss: 0.5814461708068848\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7628]])), ('linear_layer.bias', tensor([0.8256]))])\n",
            "Loss:0.5500456094741821\n",
            "Loss:0.5498011708259583\n",
            "Loss:0.5495567917823792\n",
            "Loss:0.5493123531341553\n",
            "Loss:0.5490679740905762\n",
            "Loss:0.5488235354423523\n",
            "Loss:0.5485791563987732\n",
            "Loss:0.5483347773551941\n",
            "Loss:0.548090398311615\n",
            "Loss:0.5478459596633911\n",
            "Epoch: 30 | Loss: 0.5478459596633911 | Test loss: 0.5785884857177734\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7620]])), ('linear_layer.bias', tensor([0.8234]))])\n",
            "Loss:0.547601580619812\n",
            "Loss:0.5473572015762329\n",
            "Loss:0.547112762928009\n",
            "Loss:0.5468683242797852\n",
            "Loss:0.5466240644454956\n",
            "Loss:0.5463796257972717\n",
            "Loss:0.5461351871490479\n",
            "Loss:0.5458908081054688\n",
            "Loss:0.5456463694572449\n",
            "Loss:0.5454019904136658\n",
            "Epoch: 40 | Loss: 0.5454019904136658 | Test loss: 0.5757309198379517\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7611]])), ('linear_layer.bias', tensor([0.8213]))])\n",
            "Loss:0.5451576113700867\n",
            "Loss:0.5449131727218628\n",
            "Loss:0.5446687936782837\n",
            "Loss:0.5444244146347046\n",
            "Loss:0.5441799759864807\n",
            "Loss:0.5439356565475464\n",
            "Loss:0.5436912178993225\n",
            "Loss:0.5434468388557434\n",
            "Loss:0.5432024002075195\n",
            "Loss:0.5429580807685852\n",
            "Epoch: 50 | Loss: 0.5429580807685852 | Test loss: 0.5728732347488403\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7603]])), ('linear_layer.bias', tensor([0.8192]))])\n",
            "Loss:0.5427135825157166\n",
            "Loss:0.5424692630767822\n",
            "Loss:0.5422247648239136\n",
            "Loss:0.5419803857803345\n",
            "Loss:0.5417360067367554\n",
            "Loss:0.541491687297821\n",
            "Loss:0.5412472486495972\n",
            "Loss:0.5410028696060181\n",
            "Loss:0.5407584309577942\n",
            "Loss:0.5405140519142151\n",
            "Epoch: 60 | Loss: 0.5405140519142151 | Test loss: 0.570015549659729\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7595]])), ('linear_layer.bias', tensor([0.8171]))])\n",
            "Loss:0.5402696132659912\n",
            "Loss:0.5400252342224121\n",
            "Loss:0.539780855178833\n",
            "Loss:0.5395364761352539\n",
            "Loss:0.53929203748703\n",
            "Loss:0.5390476584434509\n",
            "Loss:0.538803219795227\n",
            "Loss:0.538558840751648\n",
            "Loss:0.5383145213127136\n",
            "Loss:0.538070023059845\n",
            "Epoch: 70 | Loss: 0.538070023059845 | Test loss: 0.567158043384552\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7587]])), ('linear_layer.bias', tensor([0.8149]))])\n",
            "Loss:0.5378257036209106\n",
            "Loss:0.5375813245773315\n",
            "Loss:0.5373368859291077\n",
            "Loss:0.5370924472808838\n",
            "Loss:0.5368480682373047\n",
            "Loss:0.5366037487983704\n",
            "Loss:0.5363593101501465\n",
            "Loss:0.5361148715019226\n",
            "Loss:0.5358704924583435\n",
            "Loss:0.5356260538101196\n",
            "Epoch: 80 | Loss: 0.5356260538101196 | Test loss: 0.5643004179000854\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7578]])), ('linear_layer.bias', tensor([0.8128]))])\n",
            "Loss:0.5353817343711853\n",
            "Loss:0.5351372361183167\n",
            "Loss:0.5348929166793823\n",
            "Loss:0.5346484184265137\n",
            "Loss:0.5344040989875793\n",
            "Loss:0.5341597199440002\n",
            "Loss:0.5339152812957764\n",
            "Loss:0.5336708426475525\n",
            "Loss:0.5334264636039734\n",
            "Loss:0.5331820845603943\n",
            "Epoch: 90 | Loss: 0.5331820845603943 | Test loss: 0.5614427328109741\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7570]])), ('linear_layer.bias', tensor([0.8107]))])\n",
            "Loss:0.5329377055168152\n",
            "Loss:0.5326932668685913\n",
            "Loss:0.5324488878250122\n",
            "Loss:0.5322045087814331\n",
            "Loss:0.531960129737854\n",
            "Loss:0.5317156910896301\n",
            "Loss:0.5314712524414062\n",
            "Loss:0.5312269926071167\n",
            "Loss:0.5309825539588928\n",
            "Loss:0.530738115310669\n",
            "Epoch: 100 | Loss: 0.530738115310669 | Test loss: 0.5585850477218628\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7562]])), ('linear_layer.bias', tensor([0.8086]))])\n",
            "Loss:0.5304936766624451\n",
            "Loss:0.530249297618866\n",
            "Loss:0.5300049185752869\n",
            "Loss:0.529760479927063\n",
            "Loss:0.5295161008834839\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|     | 43/100 [00:13<00:17,  3.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5292717218399048\n",
            "Loss:0.5290273427963257\n",
            "Loss:0.5287829637527466\n",
            "Loss:0.5285385251045227\n",
            "Loss:0.5282941460609436\n",
            "Epoch: 110 | Loss: 0.5282941460609436 | Test loss: 0.5557274222373962\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7554]])), ('linear_layer.bias', tensor([0.8065]))])\n",
            "Loss:0.5280497670173645\n",
            "Loss:0.5278053879737854\n",
            "Loss:0.5275609493255615\n",
            "Loss:0.5273165106773376\n",
            "Loss:0.5270721912384033\n",
            "Loss:0.5268277525901794\n",
            "Loss:0.5265833139419556\n",
            "Loss:0.5263389348983765\n",
            "Loss:0.5260945558547974\n",
            "Loss:0.5258501768112183\n",
            "Epoch: 120 | Loss: 0.5258501768112183 | Test loss: 0.5528697967529297\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7545]])), ('linear_layer.bias', tensor([0.8043]))])\n",
            "Loss:0.5256057381629944\n",
            "Loss:0.5253613591194153\n",
            "Loss:0.5251169800758362\n",
            "Loss:0.5248726010322571\n",
            "Loss:0.5246281623840332\n",
            "Loss:0.5243837237358093\n",
            "Loss:0.5241393446922302\n",
            "Loss:0.5238949656486511\n",
            "Loss:0.5236505270004272\n",
            "Loss:0.5234061479568481\n",
            "Epoch: 130 | Loss: 0.5234061479568481 | Test loss: 0.5500121116638184\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7537]])), ('linear_layer.bias', tensor([0.8022]))])\n",
            "Loss:0.523161768913269\n",
            "Loss:0.5229173898696899\n",
            "Loss:0.5226729512214661\n",
            "Loss:0.5224286317825317\n",
            "Loss:0.5221841931343079\n",
            "Loss:0.5219398140907288\n",
            "Loss:0.5216953754425049\n",
            "Loss:0.521450936794281\n",
            "Loss:0.5212065577507019\n",
            "Loss:0.5209621787071228\n",
            "Epoch: 140 | Loss: 0.5209621787071228 | Test loss: 0.5471544861793518\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7529]])), ('linear_layer.bias', tensor([0.8001]))])\n",
            "Loss:0.5207177996635437\n",
            "Loss:0.5204733610153198\n",
            "Loss:0.5202289819717407\n",
            "Loss:0.5199846029281616\n",
            "Loss:0.5197402238845825\n",
            "Loss:0.5194957852363586\n",
            "Loss:0.5192514657974243\n",
            "Loss:0.5190070271492004\n",
            "Loss:0.5187625885009766\n",
            "Loss:0.5185182094573975\n",
            "Epoch: 150 | Loss: 0.5185182094573975 | Test loss: 0.54429692029953\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7520]])), ('linear_layer.bias', tensor([0.7980]))])\n",
            "Loss:0.5182738304138184\n",
            "Loss:0.5180293917655945\n",
            "Loss:0.5177850723266602\n",
            "Loss:0.5175406336784363\n",
            "Loss:0.5172962546348572\n",
            "Loss:0.5170518159866333\n",
            "Loss:0.5168074369430542\n",
            "Loss:0.5165630578994751\n",
            "Loss:0.5163186192512512\n",
            "Loss:0.5160742998123169\n",
            "Epoch: 160 | Loss: 0.5160742998123169 | Test loss: 0.5414392352104187\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7512]])), ('linear_layer.bias', tensor([0.7959]))])\n",
            "Loss:0.515829861164093\n",
            "Loss:0.5155854821205139\n",
            "Loss:0.51534104347229\n",
            "Loss:0.5150966048240662\n",
            "Loss:0.5148522257804871\n",
            "Loss:0.514607846736908\n",
            "Loss:0.5143634676933289\n",
            "Loss:0.514119029045105\n",
            "Loss:0.5138746500015259\n",
            "Loss:0.5136302709579468\n",
            "Epoch: 170 | Loss: 0.5136302709579468 | Test loss: 0.5385815501213074\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7504]])), ('linear_layer.bias', tensor([0.7937]))])\n",
            "Loss:0.5133858323097229\n",
            "Loss:0.5131414532661438\n",
            "Loss:0.5128970146179199\n",
            "Loss:0.5126526951789856\n",
            "Loss:0.5124082565307617\n",
            "Loss:0.5121638774871826\n",
            "Loss:0.5119194388389587\n",
            "Loss:0.5116750597953796\n",
            "Loss:0.5114306211471558\n",
            "Loss:0.5111862421035767\n",
            "Epoch: 180 | Loss: 0.5111862421035767 | Test loss: 0.5357240438461304\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7496]])), ('linear_layer.bias', tensor([0.7916]))])\n",
            "Loss:0.5109419226646423\n",
            "Loss:0.5106974840164185\n",
            "Loss:0.5104531049728394\n",
            "Loss:0.5102086663246155\n",
            "Loss:0.5099642872810364\n",
            "Loss:0.5097199082374573\n",
            "Loss:0.5094755291938782\n",
            "Loss:0.5092310905456543\n",
            "Loss:0.5089867115020752\n",
            "Loss:0.5087422728538513\n",
            "Epoch: 190 | Loss: 0.5087422728538513 | Test loss: 0.532866358757019\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7487]])), ('linear_layer.bias', tensor([0.7895]))])\n",
            "Loss:0.5084978938102722\n",
            "Loss:0.5082534551620483\n",
            "Loss:0.5080090761184692\n",
            "Loss:0.5077646970748901\n",
            "Loss:0.507520318031311\n",
            "Loss:0.5072759389877319\n",
            "Loss:0.5070315003395081\n",
            "Loss:0.5067871809005737\n",
            "Loss:0.5065426826477051\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5871546268463135\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5549277067184448\n",
            "Loss:0.5546774864196777\n",
            "Loss:0.5544272661209106\n",
            "Loss:0.5541769862174988\n",
            "Loss:0.5539268255233765\n",
            "Loss:0.5536766052246094\n",
            "Loss:0.5534263253211975\n",
            "Loss:0.5531760454177856\n",
            "Loss:0.5529258847236633\n",
            "Loss:0.5526756048202515\n",
            "Epoch: 10 | Loss: 0.5526756048202515 | Test loss: 0.5842288732528687\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7636]])), ('linear_layer.bias', tensor([0.8276]))])\n",
            "Loss:0.5524253845214844\n",
            "Loss:0.5521751642227173\n",
            "Loss:0.5519248843193054\n",
            "Loss:0.5516746640205383\n",
            "Loss:0.5514244437217712\n",
            "Loss:0.5511742830276489\n",
            "Loss:0.5509240031242371\n",
            "Loss:0.5506737232208252\n",
            "Loss:0.5504235029220581\n",
            "Loss:0.550173282623291\n",
            "Epoch: 20 | Loss: 0.550173282623291 | Test loss: 0.5813030004501343\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7628]])), ('linear_layer.bias', tensor([0.8254]))])\n",
            "Loss:0.5499230623245239\n",
            "Loss:0.5496727824211121\n",
            "Loss:0.5494226217269897\n",
            "Loss:0.5491723418235779\n",
            "Loss:0.5489221215248108\n",
            "Loss:0.5486718416213989\n",
            "Loss:0.5484216809272766\n",
            "Loss:0.5481714606285095\n",
            "Loss:0.5479212403297424\n",
            "Loss:0.5476709604263306\n",
            "Epoch: 30 | Loss: 0.5476709604263306 | Test loss: 0.5783771872520447\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7619]])), ('linear_layer.bias', tensor([0.8233]))])\n",
            "Loss:0.5474207997322083\n",
            "Loss:0.5471705198287964\n",
            "Loss:0.5469203591346741\n",
            "Loss:0.5466700196266174\n",
            "Loss:0.5464197993278503\n",
            "Loss:0.5461695790290833\n",
            "Loss:0.5459192991256714\n",
            "Loss:0.5456691384315491\n",
            "Loss:0.545418918132782\n",
            "Loss:0.5451686978340149\n",
            "Epoch: 40 | Loss: 0.5451686978340149 | Test loss: 0.5754514336585999\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7611]])), ('linear_layer.bias', tensor([0.8211]))])\n",
            "Loss:0.544918417930603\n",
            "Loss:0.5446682572364807\n",
            "Loss:0.5444179773330688\n",
            "Loss:0.5441677570343018\n",
            "Loss:0.5439175367355347\n",
            "Loss:0.5436673164367676\n",
            "Loss:0.5434170961380005\n",
            "Loss:0.5431668162345886\n",
            "Loss:0.5429165363311768\n",
            "Loss:0.5426663160324097\n",
            "Epoch: 50 | Loss: 0.5426663160324097 | Test loss: 0.5725256204605103\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7602]])), ('linear_layer.bias', tensor([0.8189]))])\n",
            "Loss:0.5424161553382874\n",
            "Loss:0.5421658754348755\n",
            "Loss:0.5419157147407532\n",
            "Loss:0.5416654348373413\n",
            "Loss:0.5414152145385742\n",
            "Loss:0.5411649942398071\n",
            "Loss:0.5409147143363953\n",
            "Loss:0.540664553642273\n",
            "Loss:0.5404142141342163\n",
            "Loss:0.540164053440094\n",
            "Epoch: 60 | Loss: 0.540164053440094 | Test loss: 0.5695997476577759\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7594]])), ('linear_layer.bias', tensor([0.8168]))])\n",
            "Loss:0.5399138331413269\n",
            "Loss:0.539663553237915\n",
            "Loss:0.539413332939148\n",
            "Loss:0.5391631126403809\n",
            "Loss:0.5389128923416138\n",
            "Loss:0.5386626124382019\n",
            "Loss:0.5384123921394348\n",
            "Loss:0.5381622314453125\n",
            "Loss:0.5379118919372559\n",
            "Loss:0.5376617312431335\n",
            "Epoch: 70 | Loss: 0.5376617312431335 | Test loss: 0.5666739344596863\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7585]])), ('linear_layer.bias', tensor([0.8146]))])\n",
            "Loss:0.5374115109443665\n",
            "Loss:0.5371612310409546\n",
            "Loss:0.5369110107421875\n",
            "Loss:0.5366607904434204\n",
            "Loss:0.5364105105400085\n",
            "Loss:0.5361603498458862\n",
            "Loss:0.5359100103378296\n",
            "Loss:0.5356598496437073\n",
            "Loss:0.5354095697402954\n",
            "Loss:0.5351594090461731\n",
            "Epoch: 80 | Loss: 0.5351594090461731 | Test loss: 0.5637481212615967\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7577]])), ('linear_layer.bias', tensor([0.8124]))])\n",
            "Loss:0.5349091291427612\n",
            "Loss:0.5346589088439941\n",
            "Loss:0.534408688545227\n",
            "Loss:0.5341585278511047\n",
            "Loss:0.5339082479476929\n",
            "Loss:0.5336580276489258\n",
            "Loss:0.5334077477455139\n",
            "Loss:0.5331575274467468\n",
            "Loss:0.5329073667526245\n",
            "Loss:0.5326570868492126\n",
            "Epoch: 90 | Loss: 0.5326570868492126 | Test loss: 0.5608223676681519\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7568]])), ('linear_layer.bias', tensor([0.8102]))])\n",
            "Loss:0.5324068665504456\n",
            "Loss:0.5321566462516785\n",
            "Loss:0.5319064259529114\n",
            "Loss:0.5316561460494995\n",
            "Loss:0.5314058661460876\n",
            "Loss:0.5311557054519653\n",
            "Loss:0.5309054255485535\n",
            "Loss:0.5306552648544312\n",
            "Loss:0.5304049849510193\n",
            "Loss:0.530154824256897\n",
            "Epoch: 100 | Loss: 0.530154824256897 | Test loss: 0.5578964948654175\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7560]])), ('linear_layer.bias', tensor([0.8081]))])\n",
            "Loss:0.5299045443534851\n",
            "Loss:0.529654324054718\n",
            "Loss:0.5294040441513062\n",
            "Loss:0.5291538238525391\n",
            "Loss:0.528903603553772\n",
            "Loss:0.5286534428596497\n",
            "Loss:0.5284031629562378\n",
            "Loss:0.5281528234481812\n",
            "Loss:0.5279027223587036\n",
            "Loss:0.5276524424552917\n",
            "Epoch: 110 | Loss: 0.5276524424552917 | Test loss: 0.5549706816673279\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7551]])), ('linear_layer.bias', tensor([0.8059]))])\n",
            "Loss:0.5274022817611694\n",
            "Loss:0.5271519422531128\n",
            "Loss:0.5269017815589905\n",
            "Loss:0.5266515016555786\n",
            "Loss:0.5264012813568115\n",
            "Loss:0.5261510610580444\n",
            "Loss:0.5259008407592773\n",
            "Loss:0.5256506204605103\n",
            "Loss:0.5254004001617432\n",
            "Loss:0.5251501202583313\n",
            "Epoch: 120 | Loss: 0.5251501202583313 | Test loss: 0.5520449876785278\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7543]])), ('linear_layer.bias', tensor([0.8037]))])\n",
            "Loss:0.5248998403549194\n",
            "Loss:0.5246497392654419\n",
            "Loss:0.5243993997573853\n",
            "Loss:0.5241491198539734\n",
            "Loss:0.5238989591598511\n",
            "Loss:0.5236486792564392\n",
            "Loss:0.5233985185623169\n",
            "Loss:0.523148238658905\n",
            "Loss:0.5228980779647827\n",
            "Loss:0.5226478576660156\n",
            "Epoch: 130 | Loss: 0.5226478576660156 | Test loss: 0.5491191148757935\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7534]])), ('linear_layer.bias', tensor([0.8016]))])\n",
            "Loss:0.5223976373672485\n",
            "Loss:0.5221472978591919\n",
            "Loss:0.5218971371650696\n",
            "Loss:0.5216468572616577\n",
            "Loss:0.5213966965675354\n",
            "Loss:0.5211464166641235\n",
            "Loss:0.5208961963653564\n",
            "Loss:0.5206459760665894\n",
            "Loss:0.5203957557678223\n",
            "Loss:0.5201454758644104\n",
            "Epoch: 140 | Loss: 0.5201454758644104 | Test loss: 0.5461933612823486\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7526]])), ('linear_layer.bias', tensor([0.7994]))])\n",
            "Loss:0.5198953151702881\n",
            "Loss:0.5196450352668762\n",
            "Loss:0.5193948149681091\n",
            "Loss:0.5191445350646973\n",
            "Loss:0.5188943147659302\n",
            "Loss:0.5186440944671631\n",
            "Loss:0.518393874168396\n",
            "Loss:0.5181436538696289\n",
            "Loss:0.5178934335708618\n",
            "Loss:0.51764315366745\n",
            "Epoch: 150 | Loss: 0.51764315366745 | Test loss: 0.5432674884796143\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7517]])), ('linear_layer.bias', tensor([0.7972]))])\n",
            "Loss:0.5173929929733276\n",
            "Loss:0.5171427130699158\n",
            "Loss:0.5168924927711487\n",
            "Loss:0.5166422128677368\n",
            "Loss:0.5163920521736145\n",
            "Loss:0.5161417722702026\n",
            "Loss:0.5158915519714355\n",
            "Loss:0.5156413316726685\n",
            "Loss:0.5153910517692566\n",
            "Loss:0.5151408910751343\n",
            "Epoch: 160 | Loss: 0.5151408910751343 | Test loss: 0.5403417348861694\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7509]])), ('linear_layer.bias', tensor([0.7950]))])\n",
            "Loss:0.5148906707763672\n",
            "Loss:0.5146404504776001\n",
            "Loss:0.5143901705741882\n",
            "Loss:0.5141400098800659\n",
            "Loss:0.5138896703720093\n",
            "Loss:0.513639509677887\n",
            "Loss:0.5133892297744751\n",
            "Loss:0.513139009475708\n",
            "Loss:0.5128887891769409\n",
            "Loss:0.5126385688781738\n",
            "Epoch: 170 | Loss: 0.5126385688781738 | Test loss: 0.5374158620834351\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7501]])), ('linear_layer.bias', tensor([0.7929]))])\n",
            "Loss:0.512388288974762\n",
            "Loss:0.5121380686759949\n",
            "Loss:0.5118878483772278\n",
            "Loss:0.5116376280784607\n",
            "Loss:0.5113874077796936\n",
            "Loss:0.5111371278762817\n",
            "Loss:0.5108869671821594\n",
            "Loss:0.5106366872787476\n",
            "Loss:0.5103864669799805\n",
            "Loss:0.5101362466812134\n",
            "Epoch: 180 | Loss: 0.5101362466812134 | Test loss: 0.5344901084899902\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7492]])), ('linear_layer.bias', tensor([0.7907]))])\n",
            "Loss:0.5098859667778015\n",
            "Loss:0.5096358060836792\n",
            "Loss:0.5093854665756226\n",
            "Loss:0.509135365486145\n",
            "Loss:0.5088850259780884\n",
            "Loss:0.5086348652839661\n",
            "Loss:0.5083845853805542\n",
            "Loss:0.5081344246864319\n",
            "Loss:0.50788414478302\n",
            "Loss:0.5076339840888977\n",
            "Epoch: 190 | Loss: 0.5076339840888977 | Test loss: 0.5315642952919006\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7484]])), ('linear_layer.bias', tensor([0.7885]))])\n",
            "Loss:0.5073837041854858\n",
            "Loss:0.5071334838867188\n",
            "Loss:0.5068832635879517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|     | 44/100 [00:13<00:16,  3.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5066329836845398\n",
            "Loss:0.5063827633857727\n",
            "Loss:0.5061325430870056\n",
            "Loss:0.5058822631835938\n",
            "Loss:0.5056320428848267\n",
            "Loss:0.5053818225860596\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5871478319168091\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7645]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5549219250679016\n",
            "Loss:0.5546659231185913\n",
            "Loss:0.554409921169281\n",
            "Loss:0.5541539192199707\n",
            "Loss:0.5538979768753052\n",
            "Loss:0.5536419153213501\n",
            "Loss:0.553385853767395\n",
            "Loss:0.5531298518180847\n",
            "Loss:0.5528739094734192\n",
            "Loss:0.5526178479194641\n",
            "Epoch: 10 | Loss: 0.5526178479194641 | Test loss: 0.584154486656189\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7636]])), ('linear_layer.bias', tensor([0.8276]))])\n",
            "Loss:0.5523618459701538\n",
            "Loss:0.5521057844161987\n",
            "Loss:0.5518498420715332\n",
            "Loss:0.5515937805175781\n",
            "Loss:0.5513378977775574\n",
            "Loss:0.5510818362236023\n",
            "Loss:0.5508258938789368\n",
            "Loss:0.5505697727203369\n",
            "Loss:0.5503138303756714\n",
            "Loss:0.5500578880310059\n",
            "Epoch: 20 | Loss: 0.5500578880310059 | Test loss: 0.5811611413955688\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7627]])), ('linear_layer.bias', tensor([0.8253]))])\n",
            "Loss:0.5498018264770508\n",
            "Loss:0.5495458245277405\n",
            "Loss:0.5492898225784302\n",
            "Loss:0.5490338206291199\n",
            "Loss:0.5487777590751648\n",
            "Loss:0.5485217571258545\n",
            "Loss:0.5482657551765442\n",
            "Loss:0.5480097532272339\n",
            "Loss:0.5477537512779236\n",
            "Loss:0.5474977493286133\n",
            "Epoch: 30 | Loss: 0.5474977493286133 | Test loss: 0.578167736530304\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7619]])), ('linear_layer.bias', tensor([0.8231]))])\n",
            "Loss:0.547241747379303\n",
            "Loss:0.5469857454299927\n",
            "Loss:0.5467297434806824\n",
            "Loss:0.5464737415313721\n",
            "Loss:0.5462177395820618\n",
            "Loss:0.5459617376327515\n",
            "Loss:0.5457056760787964\n",
            "Loss:0.5454496741294861\n",
            "Loss:0.5451937317848206\n",
            "Loss:0.5449377298355103\n",
            "Epoch: 40 | Loss: 0.5449377298355103 | Test loss: 0.5751743316650391\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7610]])), ('linear_layer.bias', tensor([0.8209]))])\n",
            "Loss:0.5446816682815552\n",
            "Loss:0.5444256067276001\n",
            "Loss:0.5441696643829346\n",
            "Loss:0.5439136624336243\n",
            "Loss:0.543657660484314\n",
            "Loss:0.5434015989303589\n",
            "Loss:0.5431456565856934\n",
            "Loss:0.5428897142410278\n",
            "Loss:0.5426336526870728\n",
            "Loss:0.5423776507377625\n",
            "Epoch: 50 | Loss: 0.5423776507377625 | Test loss: 0.5721809267997742\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7601]])), ('linear_layer.bias', tensor([0.8187]))])\n",
            "Loss:0.5421216487884521\n",
            "Loss:0.5418656468391418\n",
            "Loss:0.5416096448898315\n",
            "Loss:0.5413535833358765\n",
            "Loss:0.5410976409912109\n",
            "Loss:0.5408415794372559\n",
            "Loss:0.5405855774879456\n",
            "Loss:0.5403295755386353\n",
            "Loss:0.5400735139846802\n",
            "Loss:0.5398175716400146\n",
            "Epoch: 60 | Loss: 0.5398175716400146 | Test loss: 0.5691876411437988\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7593]])), ('linear_layer.bias', tensor([0.8165]))])\n",
            "Loss:0.5395615696907043\n",
            "Loss:0.539305567741394\n",
            "Loss:0.5390495657920837\n",
            "Loss:0.5387935638427734\n",
            "Loss:0.5385375618934631\n",
            "Loss:0.5382815599441528\n",
            "Loss:0.5380255579948425\n",
            "Loss:0.5377694964408875\n",
            "Loss:0.5375136137008667\n",
            "Loss:0.5372575521469116\n",
            "Epoch: 70 | Loss: 0.5372575521469116 | Test loss: 0.5661941766738892\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7584]])), ('linear_layer.bias', tensor([0.8142]))])\n",
            "Loss:0.5370015501976013\n",
            "Loss:0.536745548248291\n",
            "Loss:0.5364894866943359\n",
            "Loss:0.5362335443496704\n",
            "Loss:0.5359774827957153\n",
            "Loss:0.535721480846405\n",
            "Loss:0.5354654788970947\n",
            "Loss:0.5352095365524292\n",
            "Loss:0.5349534749984741\n",
            "Loss:0.5346974730491638\n",
            "Epoch: 80 | Loss: 0.5346974730491638 | Test loss: 0.563200831413269\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7575]])), ('linear_layer.bias', tensor([0.8120]))])\n",
            "Loss:0.5344414710998535\n",
            "Loss:0.534185528755188\n",
            "Loss:0.5339294672012329\n",
            "Loss:0.5336734652519226\n",
            "Loss:0.5334174633026123\n",
            "Loss:0.533161461353302\n",
            "Loss:0.5329054594039917\n",
            "Loss:0.5326494574546814\n",
            "Loss:0.5323934555053711\n",
            "Loss:0.5321374535560608\n",
            "Epoch: 90 | Loss: 0.5321374535560608 | Test loss: 0.5602073669433594\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7567]])), ('linear_layer.bias', tensor([0.8098]))])\n",
            "Loss:0.5318814516067505\n",
            "Loss:0.5316253900527954\n",
            "Loss:0.5313693881034851\n",
            "Loss:0.5311133861541748\n",
            "Loss:0.5308574438095093\n",
            "Loss:0.5306013822555542\n",
            "Loss:0.5303453803062439\n",
            "Loss:0.5300893783569336\n",
            "Loss:0.5298333764076233\n",
            "Loss:0.529577374458313\n",
            "Epoch: 100 | Loss: 0.529577374458313 | Test loss: 0.557214081287384\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7558]])), ('linear_layer.bias', tensor([0.8076]))])\n",
            "Loss:0.5293213725090027\n",
            "Loss:0.5290653705596924\n",
            "Loss:0.5288094282150269\n",
            "Loss:0.5285533666610718\n",
            "Loss:0.5282973647117615\n",
            "Loss:0.5280413627624512\n",
            "Loss:0.5277853608131409\n",
            "Loss:0.5275293588638306\n",
            "Loss:0.5272732973098755\n",
            "Loss:0.52701735496521\n",
            "Epoch: 110 | Loss: 0.52701735496521 | Test loss: 0.5542206764221191\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7549]])), ('linear_layer.bias', tensor([0.8053]))])\n",
            "Loss:0.5267612934112549\n",
            "Loss:0.5265053510665894\n",
            "Loss:0.5262492895126343\n",
            "Loss:0.525993287563324\n",
            "Loss:0.5257372856140137\n",
            "Loss:0.5254813432693481\n",
            "Loss:0.5252252817153931\n",
            "Loss:0.524969220161438\n",
            "Loss:0.5247133374214172\n",
            "Loss:0.5244572758674622\n",
            "Epoch: 120 | Loss: 0.5244572758674622 | Test loss: 0.5512272715568542\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7541]])), ('linear_layer.bias', tensor([0.8031]))])\n",
            "Loss:0.5242012739181519\n",
            "Loss:0.5239452123641968\n",
            "Loss:0.5236892700195312\n",
            "Loss:0.5234332084655762\n",
            "Loss:0.5231772661209106\n",
            "Loss:0.5229212045669556\n",
            "Loss:0.52266526222229\n",
            "Loss:0.5224092602729797\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|     | 45/100 [00:14<00:16,  3.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5221532583236694\n",
            "Loss:0.5218971967697144\n",
            "Epoch: 130 | Loss: 0.5218971967697144 | Test loss: 0.5482338666915894\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7532]])), ('linear_layer.bias', tensor([0.8009]))])\n",
            "Loss:0.521641194820404\n",
            "Loss:0.5213852524757385\n",
            "Loss:0.5211292505264282\n",
            "Loss:0.5208731889724731\n",
            "Loss:0.5206171274185181\n",
            "Loss:0.5203611850738525\n",
            "Loss:0.520105242729187\n",
            "Loss:0.5198491811752319\n",
            "Loss:0.5195931196212769\n",
            "Loss:0.5193371772766113\n",
            "Epoch: 140 | Loss: 0.5193371772766113 | Test loss: 0.5452405214309692\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7523]])), ('linear_layer.bias', tensor([0.7987]))])\n",
            "Loss:0.519081175327301\n",
            "Loss:0.5188251733779907\n",
            "Loss:0.5185691714286804\n",
            "Loss:0.5183131098747253\n",
            "Loss:0.5180571675300598\n",
            "Loss:0.5178011655807495\n",
            "Loss:0.5175451040267944\n",
            "Loss:0.5172890424728394\n",
            "Loss:0.5170331001281738\n",
            "Loss:0.5167771577835083\n",
            "Epoch: 150 | Loss: 0.5167771577835083 | Test loss: 0.5422471761703491\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7515]])), ('linear_layer.bias', tensor([0.7965]))])\n",
            "Loss:0.5165210962295532\n",
            "Loss:0.5162650942802429\n",
            "Loss:0.5160090923309326\n",
            "Loss:0.5157530903816223\n",
            "Loss:0.515497088432312\n",
            "Loss:0.5152410864830017\n",
            "Loss:0.5149850249290466\n",
            "Loss:0.5147290229797363\n",
            "Loss:0.5144730806350708\n",
            "Loss:0.5142170786857605\n",
            "Epoch: 160 | Loss: 0.5142170786857605 | Test loss: 0.5392537713050842\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7506]])), ('linear_layer.bias', tensor([0.7942]))])\n",
            "Loss:0.5139610171318054\n",
            "Loss:0.5137050747871399\n",
            "Loss:0.5134490132331848\n",
            "Loss:0.5131930112838745\n",
            "Loss:0.5129370093345642\n",
            "Loss:0.5126810073852539\n",
            "Loss:0.5124249458312988\n",
            "Loss:0.5121690034866333\n",
            "Loss:0.511913001537323\n",
            "Loss:0.5116569399833679\n",
            "Epoch: 170 | Loss: 0.5116569399833679 | Test loss: 0.5362603664398193\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7497]])), ('linear_layer.bias', tensor([0.7920]))])\n",
            "Loss:0.5114009976387024\n",
            "Loss:0.5111449360847473\n",
            "Loss:0.510888934135437\n",
            "Loss:0.5106328725814819\n",
            "Loss:0.5103769302368164\n",
            "Loss:0.5101209878921509\n",
            "Loss:0.5098649263381958\n",
            "Loss:0.5096089839935303\n",
            "Loss:0.50935298204422\n",
            "Loss:0.5090969204902649\n",
            "Epoch: 180 | Loss: 0.5090969204902649 | Test loss: 0.5332670211791992\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7489]])), ('linear_layer.bias', tensor([0.7898]))])\n",
            "Loss:0.5088409185409546\n",
            "Loss:0.5085849761962891\n",
            "Loss:0.508328914642334\n",
            "Loss:0.5080729126930237\n",
            "Loss:0.5078169107437134\n",
            "Loss:0.5075608491897583\n",
            "Loss:0.507304847240448\n",
            "Loss:0.5070489048957825\n",
            "Loss:0.5067928433418274\n",
            "Loss:0.5065369009971619\n",
            "Epoch: 190 | Loss: 0.5065369009971619 | Test loss: 0.5302736163139343\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7480]])), ('linear_layer.bias', tensor([0.7876]))])\n",
            "Loss:0.5062808990478516\n",
            "Loss:0.5060248970985413\n",
            "Loss:0.505768895149231\n",
            "Loss:0.5055128335952759\n",
            "Loss:0.5052568316459656\n",
            "Loss:0.5050008296966553\n",
            "Loss:0.5047448873519897\n",
            "Loss:0.5044888257980347\n",
            "Loss:0.5042327642440796\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5871410369873047\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5549160838127136\n",
            "Loss:0.5546542406082153\n",
            "Loss:0.5543924570083618\n",
            "Loss:0.5541306138038635\n",
            "Loss:0.5538687109947205\n",
            "Loss:0.5536068677902222\n",
            "Loss:0.5533450841903687\n",
            "Loss:0.5530832409858704\n",
            "Loss:0.5528213977813721\n",
            "Loss:0.552559494972229\n",
            "Epoch: 10 | Loss: 0.552559494972229 | Test loss: 0.5840795040130615\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7636]])), ('linear_layer.bias', tensor([0.8275]))])\n",
            "Loss:0.5522977113723755\n",
            "Loss:0.552035927772522\n",
            "Loss:0.5517740845680237\n",
            "Loss:0.5515121817588806\n",
            "Loss:0.5512503385543823\n",
            "Loss:0.550988495349884\n",
            "Loss:0.5507267117500305\n",
            "Loss:0.5504648685455322\n",
            "Loss:0.5502029657363892\n",
            "Loss:0.5499411225318909\n",
            "Epoch: 20 | Loss: 0.5499411225318909 | Test loss: 0.5810179114341736\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7627]])), ('linear_layer.bias', tensor([0.8252]))])\n",
            "Loss:0.5496792793273926\n",
            "Loss:0.5494174957275391\n",
            "Loss:0.549155592918396\n",
            "Loss:0.5488938093185425\n",
            "Loss:0.5486319661140442\n",
            "Loss:0.5483701825141907\n",
            "Loss:0.5481083393096924\n",
            "Loss:0.5478464365005493\n",
            "Loss:0.5475846529006958\n",
            "Loss:0.5473227500915527\n",
            "Epoch: 30 | Loss: 0.5473227500915527 | Test loss: 0.5779563784599304\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7618]])), ('linear_layer.bias', tensor([0.8230]))])\n",
            "Loss:0.5470609068870544\n",
            "Loss:0.5467990636825562\n",
            "Loss:0.5465372204780579\n",
            "Loss:0.5462753772735596\n",
            "Loss:0.5460135340690613\n",
            "Loss:0.5457517504692078\n",
            "Loss:0.5454899072647095\n",
            "Loss:0.5452280044555664\n",
            "Loss:0.5449661612510681\n",
            "Loss:0.5447043180465698\n",
            "Epoch: 40 | Loss: 0.5447043180465698 | Test loss: 0.5748947858810425\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7609]])), ('linear_layer.bias', tensor([0.8207]))])\n",
            "Loss:0.5444425344467163\n",
            "Loss:0.544180691242218\n",
            "Loss:0.5439188480377197\n",
            "Loss:0.5436570048332214\n",
            "Loss:0.5433951616287231\n",
            "Loss:0.5431333780288696\n",
            "Loss:0.5428714752197266\n",
            "Loss:0.5426096320152283\n",
            "Loss:0.54234778881073\n",
            "Loss:0.5420860052108765\n",
            "Epoch: 50 | Loss: 0.5420860052108765 | Test loss: 0.5718333721160889\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7600]])), ('linear_layer.bias', tensor([0.8184]))])\n",
            "Loss:0.5418241024017334\n",
            "Loss:0.5415622591972351\n",
            "Loss:0.5413004755973816\n",
            "Loss:0.5410386323928833\n",
            "Loss:0.540776789188385\n",
            "Loss:0.5405149459838867\n",
            "Loss:0.5402531027793884\n",
            "Loss:0.5399912595748901\n",
            "Loss:0.5397294163703918\n",
            "Loss:0.5394675731658936\n",
            "Epoch: 60 | Loss: 0.5394675731658936 | Test loss: 0.5687717199325562\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7591]])), ('linear_layer.bias', tensor([0.8161]))])\n",
            "Loss:0.5392057299613953\n",
            "Loss:0.5389439463615417\n",
            "Loss:0.5386820435523987\n",
            "Loss:0.5384202003479004\n",
            "Loss:0.5381584167480469\n",
            "Loss:0.5378965735435486\n",
            "Loss:0.5376347303390503\n",
            "Loss:0.537372887134552\n",
            "Loss:0.5371110439300537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|     | 46/100 [00:14<00:16,  3.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5368492007255554\n",
            "Epoch: 70 | Loss: 0.5368492007255554 | Test loss: 0.5657102465629578\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7582]])), ('linear_layer.bias', tensor([0.8139]))])\n",
            "Loss:0.5365874171257019\n",
            "Loss:0.5363255739212036\n",
            "Loss:0.5360636711120605\n",
            "Loss:0.5358018279075623\n",
            "Loss:0.535539984703064\n",
            "Loss:0.5352781414985657\n",
            "Loss:0.5350163578987122\n",
            "Loss:0.5347545146942139\n",
            "Loss:0.5344926714897156\n",
            "Loss:0.5342308282852173\n",
            "Epoch: 80 | Loss: 0.5342308282852173 | Test loss: 0.562648594379425\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7574]])), ('linear_layer.bias', tensor([0.8116]))])\n",
            "Loss:0.5339689254760742\n",
            "Loss:0.5337071418762207\n",
            "Loss:0.5334453582763672\n",
            "Loss:0.5331834554672241\n",
            "Loss:0.5329216122627258\n",
            "Loss:0.5326597690582275\n",
            "Loss:0.5323979258537292\n",
            "Loss:0.532136082649231\n",
            "Loss:0.5318742990493774\n",
            "Loss:0.5316124558448792\n",
            "Epoch: 90 | Loss: 0.5316124558448792 | Test loss: 0.5595871210098267\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7565]])), ('linear_layer.bias', tensor([0.8093]))])\n",
            "Loss:0.5313506126403809\n",
            "Loss:0.5310887694358826\n",
            "Loss:0.5308269262313843\n",
            "Loss:0.5305651426315308\n",
            "Loss:0.5303031802177429\n",
            "Loss:0.5300413370132446\n",
            "Loss:0.5297795534133911\n",
            "Loss:0.529517650604248\n",
            "Loss:0.5292558670043945\n",
            "Loss:0.5289939641952515\n",
            "Epoch: 100 | Loss: 0.5289939641952515 | Test loss: 0.5565255284309387\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7556]])), ('linear_layer.bias', tensor([0.8071]))])\n",
            "Loss:0.528732180595398\n",
            "Loss:0.5284703969955444\n",
            "Loss:0.5282084941864014\n",
            "Loss:0.5279466509819031\n",
            "Loss:0.5276848077774048\n",
            "Loss:0.5274230241775513\n",
            "Loss:0.5271611213684082\n",
            "Loss:0.5268993377685547\n",
            "Loss:0.5266374945640564\n",
            "Loss:0.5263756513595581\n",
            "Epoch: 110 | Loss: 0.5263756513595581 | Test loss: 0.5534640550613403\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7547]])), ('linear_layer.bias', tensor([0.8048]))])\n",
            "Loss:0.5261138081550598\n",
            "Loss:0.5258519649505615\n",
            "Loss:0.5255901217460632\n",
            "Loss:0.5253282785415649\n",
            "Loss:0.5250664353370667\n",
            "Loss:0.5248045921325684\n",
            "Loss:0.5245426893234253\n",
            "Loss:0.5242809057235718\n",
            "Loss:0.5240191221237183\n",
            "Loss:0.5237571597099304\n",
            "Epoch: 120 | Loss: 0.5237571597099304 | Test loss: 0.5504024028778076\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7538]])), ('linear_layer.bias', tensor([0.8025]))])\n",
            "Loss:0.5234954357147217\n",
            "Loss:0.5232335329055786\n",
            "Loss:0.5229717493057251\n",
            "Loss:0.5227099061012268\n",
            "Loss:0.5224480628967285\n",
            "Loss:0.5221861600875854\n",
            "Loss:0.5219243764877319\n",
            "Loss:0.5216625332832336\n",
            "Loss:0.5214006304740906\n",
            "Loss:0.5211388468742371\n",
            "Epoch: 130 | Loss: 0.5211388468742371 | Test loss: 0.5473408699035645\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7529]])), ('linear_layer.bias', tensor([0.8002]))])\n",
            "Loss:0.5208770036697388\n",
            "Loss:0.5206152200698853\n",
            "Loss:0.520353376865387\n",
            "Loss:0.5200914740562439\n",
            "Loss:0.5198296308517456\n",
            "Loss:0.5195678472518921\n",
            "Loss:0.5193060040473938\n",
            "Loss:0.5190441012382507\n",
            "Loss:0.5187823176383972\n",
            "Loss:0.5185204744338989\n",
            "Epoch: 140 | Loss: 0.5185204744338989 | Test loss: 0.5442793369293213\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7520]])), ('linear_layer.bias', tensor([0.7980]))])\n",
            "Loss:0.5182586908340454\n",
            "Loss:0.5179967880249023\n",
            "Loss:0.517734944820404\n",
            "Loss:0.5174731016159058\n",
            "Loss:0.5172112584114075\n",
            "Loss:0.5169494152069092\n",
            "Loss:0.5166875720024109\n",
            "Loss:0.5164257287979126\n",
            "Loss:0.5161639451980591\n",
            "Loss:0.5159021019935608\n",
            "Epoch: 150 | Loss: 0.5159021019935608 | Test loss: 0.5412178039550781\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7512]])), ('linear_layer.bias', tensor([0.7957]))])\n",
            "Loss:0.5156402587890625\n",
            "Loss:0.5153783559799194\n",
            "Loss:0.5151165723800659\n",
            "Loss:0.5148547887802124\n",
            "Loss:0.5145928859710693\n",
            "Loss:0.514331042766571\n",
            "Loss:0.5140691995620728\n",
            "Loss:0.5138073563575745\n",
            "Loss:0.513545572757721\n",
            "Loss:0.5132836699485779\n",
            "Epoch: 160 | Loss: 0.5132836699485779 | Test loss: 0.5381562113761902\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7503]])), ('linear_layer.bias', tensor([0.7934]))])\n",
            "Loss:0.5130218267440796\n",
            "Loss:0.5127600431442261\n",
            "Loss:0.512498140335083\n",
            "Loss:0.5122362971305847\n",
            "Loss:0.5119745135307312\n",
            "Loss:0.5117126703262329\n",
            "Loss:0.5114507675170898\n",
            "Loss:0.5111890435218811\n",
            "Loss:0.510927140712738\n",
            "Loss:0.5106652975082397\n",
            "Epoch: 170 | Loss: 0.5106652975082397 | Test loss: 0.5350947380065918\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7494]])), ('linear_layer.bias', tensor([0.7911]))])\n",
            "Loss:0.5104034543037415\n",
            "Loss:0.5101416707038879\n",
            "Loss:0.5098798274993896\n",
            "Loss:0.5096179246902466\n",
            "Loss:0.5093560814857483\n",
            "Loss:0.5090943574905396\n",
            "Loss:0.5088323950767517\n",
            "Loss:0.5085705518722534\n",
            "Loss:0.5083087682723999\n",
            "Loss:0.5080469250679016\n",
            "Epoch: 180 | Loss: 0.5080469250679016 | Test loss: 0.5320330858230591\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7485]])), ('linear_layer.bias', tensor([0.7889]))])\n",
            "Loss:0.5077850818634033\n",
            "Loss:0.5075232982635498\n",
            "Loss:0.5072613954544067\n",
            "Loss:0.5069995522499084\n",
            "Loss:0.5067377090454102\n",
            "Loss:0.5064758658409119\n",
            "Loss:0.5062140226364136\n",
            "Loss:0.5059521794319153\n",
            "Loss:0.505690336227417\n",
            "Loss:0.5054284930229187\n",
            "Epoch: 190 | Loss: 0.5054284930229187 | Test loss: 0.5289715528488159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7476]])), ('linear_layer.bias', tensor([0.7866]))])\n",
            "Loss:0.5051667094230652\n",
            "Loss:0.5049048662185669\n",
            "Loss:0.5046429634094238\n",
            "Loss:0.5043811798095703\n",
            "Loss:0.5041192770004272\n",
            "Loss:0.5038574934005737\n",
            "Loss:0.5035956501960754\n",
            "Loss:0.5033337473869324\n",
            "Loss:0.5030719637870789\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5871342420578003\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5549102425575256\n",
            "Loss:0.5546425580978394\n",
            "Loss:0.5543748736381531\n",
            "Loss:0.5541072487831116\n",
            "Loss:0.5538395643234253\n",
            "Loss:0.5535719394683838\n",
            "Loss:0.5533041954040527\n",
            "Loss:0.5530365705490112\n",
            "Loss:0.552768886089325\n",
            "Loss:0.5525012016296387\n",
            "Epoch: 10 | Loss: 0.5525012016296387 | Test loss: 0.5840045213699341\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7635]])), ('linear_layer.bias', tensor([0.8275]))])\n",
            "Loss:0.5522335767745972\n",
            "Loss:0.5519658327102661\n",
            "Loss:0.5516982078552246\n",
            "Loss:0.5514305233955383\n",
            "Loss:0.551162838935852\n",
            "Loss:0.5508952140808105\n",
            "Loss:0.5506274700164795\n",
            "Loss:0.550359845161438\n",
            "Loss:0.5500921607017517\n",
            "Loss:0.5498244762420654\n",
            "Epoch: 20 | Loss: 0.5498244762420654 | Test loss: 0.5808747410774231\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8251]))])\n",
            "Loss:0.5495567917823792\n",
            "Loss:0.5492891073226929\n",
            "Loss:0.5490214228630066\n",
            "Loss:0.5487537980079651\n",
            "Loss:0.5484861135482788\n",
            "Loss:0.5482184290885925\n",
            "Loss:0.547950804233551\n",
            "Loss:0.5476831197738647\n",
            "Loss:0.547415554523468\n",
            "Loss:0.5471477508544922\n",
            "Epoch: 30 | Loss: 0.5471477508544922 | Test loss: 0.5777450799942017\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7617]])), ('linear_layer.bias', tensor([0.8228]))])\n",
            "Loss:0.5468800663948059\n",
            "Loss:0.5466124415397644\n",
            "Loss:0.5463446974754333\n",
            "Loss:0.5460770726203918\n",
            "Loss:0.5458093881607056\n",
            "Loss:0.5455417037010193\n",
            "Loss:0.545274019241333\n",
            "Loss:0.5450063943862915\n",
            "Loss:0.5447386503219604\n",
            "Loss:0.544471025466919\n",
            "Epoch: 40 | Loss: 0.544471025466919 | Test loss: 0.5746153593063354\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7608]])), ('linear_layer.bias', tensor([0.8205]))])\n",
            "Loss:0.5442034006118774\n",
            "Loss:0.5439356565475464\n",
            "Loss:0.5436680316925049\n",
            "Loss:0.5434003472328186\n",
            "Loss:0.5431326627731323\n",
            "Loss:0.542864978313446\n",
            "Loss:0.5425973534584045\n",
            "Loss:0.5423296689987183\n",
            "Loss:0.5420619249343872\n",
            "Loss:0.5417943000793457\n",
            "Epoch: 50 | Loss: 0.5417943000793457 | Test loss: 0.5714856386184692\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7599]])), ('linear_layer.bias', tensor([0.8182]))])\n",
            "Loss:0.5415266752243042\n",
            "Loss:0.5412589311599731\n",
            "Loss:0.5409913063049316\n",
            "Loss:0.5407236218452454\n",
            "Loss:0.5404559373855591\n",
            "Loss:0.5401882529258728\n",
            "Loss:0.5399206280708313\n",
            "Loss:0.539652943611145\n",
            "Loss:0.5393852591514587\n",
            "Loss:0.5391175746917725\n",
            "Epoch: 60 | Loss: 0.5391175746917725 | Test loss: 0.5683558583259583\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7590]])), ('linear_layer.bias', tensor([0.8158]))])\n",
            "Loss:0.538849949836731\n",
            "Loss:0.5385822057723999\n",
            "Loss:0.5383145809173584\n",
            "Loss:0.5380469560623169\n",
            "Loss:0.5377792119979858\n",
            "Loss:0.5375115275382996\n",
            "Loss:0.5372438430786133\n",
            "Loss:0.5369762182235718\n",
            "Loss:0.5367084741592407\n",
            "Loss:0.536440908908844\n",
            "Epoch: 70 | Loss: 0.536440908908844 | Test loss: 0.5652261972427368\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7581]])), ('linear_layer.bias', tensor([0.8135]))])\n",
            "Loss:0.5361731648445129\n",
            "Loss:0.5359054803848267\n",
            "Loss:0.5356379151344299\n",
            "Loss:0.5353701710700989\n",
            "Loss:0.5351024866104126\n",
            "Loss:0.5348348021507263\n",
            "Loss:0.5345670580863953\n",
            "Loss:0.5342994928359985\n",
            "Loss:0.5340318083763123\n",
            "Loss:0.5337641835212708\n",
            "Epoch: 80 | Loss: 0.5337641835212708 | Test loss: 0.5620964765548706\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7572]])), ('linear_layer.bias', tensor([0.8112]))])\n",
            "Loss:0.5334964394569397\n",
            "Loss:0.5332287549972534\n",
            "Loss:0.5329610705375671\n",
            "Loss:0.5326934456825256\n",
            "Loss:0.5324257612228394\n",
            "Loss:0.5321580767631531\n",
            "Loss:0.5318903923034668\n",
            "Loss:0.5316227674484253\n",
            "Loss:0.531355082988739\n",
            "Loss:0.5310873985290527\n",
            "Epoch: 90 | Loss: 0.5310873985290527 | Test loss: 0.5589667558670044\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7563]])), ('linear_layer.bias', tensor([0.8089]))])\n",
            "Loss:0.5308197736740112\n",
            "Loss:0.5305520296096802\n",
            "Loss:0.5302844047546387\n",
            "Loss:0.5300167202949524\n",
            "Loss:0.5297490358352661\n",
            "Loss:0.5294814109802246\n",
            "Loss:0.5292136669158936\n",
            "Loss:0.528946042060852\n",
            "Loss:0.5286783576011658\n",
            "Loss:0.5284106731414795\n",
            "Epoch: 100 | Loss: 0.5284106731414795 | Test loss: 0.5558369755744934\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7554]])), ('linear_layer.bias', tensor([0.8065]))])\n",
            "Loss:0.5281429886817932\n",
            "Loss:0.5278753042221069\n",
            "Loss:0.5276076197624207\n",
            "Loss:0.5273399949073792\n",
            "Loss:0.5270723104476929\n",
            "Loss:0.5268046259880066\n",
            "Loss:0.5265370011329651\n",
            "Loss:0.5262693166732788\n",
            "Loss:0.5260016322135925\n",
            "Loss:0.5257339477539062\n",
            "Epoch: 110 | Loss: 0.5257339477539062 | Test loss: 0.552707314491272\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7545]])), ('linear_layer.bias', tensor([0.8042]))])\n",
            "Loss:0.5254663228988647\n",
            "Loss:0.5251986384391785\n",
            "Loss:0.5249309539794922\n",
            "Loss:0.5246632695198059\n",
            "Loss:0.5243955850601196\n",
            "Loss:0.5241279006004333\n",
            "Loss:0.5238602161407471\n",
            "Loss:0.5235925912857056\n",
            "Loss:0.5233248472213745\n",
            "Loss:0.523057222366333\n",
            "Epoch: 120 | Loss: 0.523057222366333 | Test loss: 0.5495775938034058\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7536]])), ('linear_layer.bias', tensor([0.8019]))])\n",
            "Loss:0.5227895975112915\n",
            "Loss:0.5225218534469604\n",
            "Loss:0.522254228591919\n",
            "Loss:0.5219866037368774\n",
            "Loss:0.5217188596725464\n",
            "Loss:0.5214511752128601\n",
            "Loss:0.5211835503578186\n",
            "Loss:0.5209158658981323\n",
            "Loss:0.520648181438446\n",
            "Loss:0.5203804969787598\n",
            "Epoch: 130 | Loss: 0.5203804969787598 | Test loss: 0.5464478731155396\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7527]])), ('linear_layer.bias', tensor([0.7996]))])\n",
            "Loss:0.5201128721237183\n",
            "Loss:0.5198451280593872\n",
            "Loss:0.5195775032043457\n",
            "Loss:0.5193098783493042\n",
            "Loss:0.5190421342849731\n",
            "Loss:0.5187744498252869\n",
            "Loss:0.5185068249702454\n",
            "Loss:0.5182391405105591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|     | 47/100 [00:14<00:15,  3.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5179714560508728\n",
            "Loss:0.5177038311958313\n",
            "Epoch: 140 | Loss: 0.5177038311958313 | Test loss: 0.5433180928230286\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7518]])), ('linear_layer.bias', tensor([0.7972]))])\n",
            "Loss:0.517436146736145\n",
            "Loss:0.517168402671814\n",
            "Loss:0.5169007778167725\n",
            "Loss:0.516633152961731\n",
            "Loss:0.5163654088973999\n",
            "Loss:0.5160977244377136\n",
            "Loss:0.5158300399780273\n",
            "Loss:0.5155623555183411\n",
            "Loss:0.5152947306632996\n",
            "Loss:0.5150270462036133\n",
            "Epoch: 150 | Loss: 0.5150270462036133 | Test loss: 0.5401884317398071\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7509]])), ('linear_layer.bias', tensor([0.7949]))])\n",
            "Loss:0.514759361743927\n",
            "Loss:0.5144916772842407\n",
            "Loss:0.5142240524291992\n",
            "Loss:0.5139563679695129\n",
            "Loss:0.5136886835098267\n",
            "Loss:0.5134210586547852\n",
            "Loss:0.5131533145904541\n",
            "Loss:0.5128856897354126\n",
            "Loss:0.5126180052757263\n",
            "Loss:0.5123503804206848\n",
            "Epoch: 160 | Loss: 0.5123503804206848 | Test loss: 0.5370587110519409\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7500]])), ('linear_layer.bias', tensor([0.7926]))])\n",
            "Loss:0.5120826363563538\n",
            "Loss:0.5118149518966675\n",
            "Loss:0.5115472674369812\n",
            "Loss:0.5112796425819397\n",
            "Loss:0.5110119581222534\n",
            "Loss:0.5107443332672119\n",
            "Loss:0.5104765892028809\n",
            "Loss:0.5102089643478394\n",
            "Loss:0.5099412798881531\n",
            "Loss:0.5096735954284668\n",
            "Epoch: 170 | Loss: 0.5096735954284668 | Test loss: 0.5339289903640747\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7490]])), ('linear_layer.bias', tensor([0.7903]))])\n",
            "Loss:0.5094059705734253\n",
            "Loss:0.5091382265090942\n",
            "Loss:0.5088706016540527\n",
            "Loss:0.5086029171943665\n",
            "Loss:0.5083352327346802\n",
            "Loss:0.5080676078796387\n",
            "Loss:0.5077998638153076\n",
            "Loss:0.5075322389602661\n",
            "Loss:0.5072645545005798\n",
            "Loss:0.5069968700408936\n",
            "Epoch: 180 | Loss: 0.5069968700408936 | Test loss: 0.5307992100715637\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7481]])), ('linear_layer.bias', tensor([0.7880]))])\n",
            "Loss:0.5067291855812073\n",
            "Loss:0.506461501121521\n",
            "Loss:0.5061938166618347\n",
            "Loss:0.5059261918067932\n",
            "Loss:0.5056585073471069\n",
            "Loss:0.5053908228874207\n",
            "Loss:0.5051231980323792\n",
            "Loss:0.5048555135726929\n",
            "Loss:0.5045878291130066\n",
            "Loss:0.5043201446533203\n",
            "Epoch: 190 | Loss: 0.5043201446533203 | Test loss: 0.5276695489883423\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7472]])), ('linear_layer.bias', tensor([0.7856]))])\n",
            "Loss:0.5040525197982788\n",
            "Loss:0.5037848353385925\n",
            "Loss:0.5035171508789062\n",
            "Loss:0.50324946641922\n",
            "Loss:0.5029817819595337\n",
            "Loss:0.5027140974998474\n",
            "Loss:0.5024464726448059\n",
            "Loss:0.5021787881851196\n",
            "Loss:0.5019110441207886\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5871274471282959\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5549045205116272\n",
            "Loss:0.5546310544013977\n",
            "Loss:0.5543575882911682\n",
            "Loss:0.5540841221809387\n",
            "Loss:0.553810715675354\n",
            "Loss:0.5535372495651245\n",
            "Loss:0.5532638430595398\n",
            "Loss:0.5529903173446655\n",
            "Loss:0.5527169108390808\n",
            "Loss:0.5524435043334961\n",
            "Epoch: 10 | Loss: 0.5524435043334961 | Test loss: 0.5839301943778992\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7635]])), ('linear_layer.bias', tensor([0.8274]))])\n",
            "Loss:0.5521699786186218\n",
            "Loss:0.5518965721130371\n",
            "Loss:0.5516231060028076\n",
            "Loss:0.5513496398925781\n",
            "Loss:0.5510762333869934\n",
            "Loss:0.5508028268814087\n",
            "Loss:0.5505293011665344\n",
            "Loss:0.5502558946609497\n",
            "Loss:0.5499824285507202\n",
            "Loss:0.5497090220451355\n",
            "Epoch: 20 | Loss: 0.5497090220451355 | Test loss: 0.5807328820228577\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8250]))])\n",
            "Loss:0.5494356155395508\n",
            "Loss:0.5491621494293213\n",
            "Loss:0.5488886833190918\n",
            "Loss:0.5486151576042175\n",
            "Loss:0.5483417510986328\n",
            "Loss:0.5480683445930481\n",
            "Loss:0.5477948784828186\n",
            "Loss:0.5475214719772339\n",
            "Loss:0.5472480058670044\n",
            "Loss:0.5469745397567749\n",
            "Epoch: 30 | Loss: 0.5469745397567749 | Test loss: 0.5775355696678162\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7617]])), ('linear_layer.bias', tensor([0.8227]))])\n",
            "Loss:0.5467010736465454\n",
            "Loss:0.5464276075363159\n",
            "Loss:0.5461542010307312\n",
            "Loss:0.5458807349205017\n",
            "Loss:0.5456072688102722\n",
            "Loss:0.5453338027000427\n",
            "Loss:0.5450604557991028\n",
            "Loss:0.5447870492935181\n",
            "Loss:0.5445135235786438\n",
            "Loss:0.5442400574684143\n",
            "Epoch: 40 | Loss: 0.5442400574684143 | Test loss: 0.5743383169174194\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7607]])), ('linear_layer.bias', tensor([0.8203]))])\n",
            "Loss:0.5439666509628296\n",
            "Loss:0.5436931848526001\n",
            "Loss:0.5434197783470154\n",
            "Loss:0.5431462526321411\n",
            "Loss:0.5428728461265564\n",
            "Loss:0.5425993800163269\n",
            "Loss:0.5423259139060974\n",
            "Loss:0.5420525074005127\n",
            "Loss:0.5417790412902832\n",
            "Loss:0.5415056347846985\n",
            "Epoch: 50 | Loss: 0.5415056347846985 | Test loss: 0.5711410045623779\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7598]])), ('linear_layer.bias', tensor([0.8179]))])\n",
            "Loss:0.541232168674469\n",
            "Loss:0.5409587025642395\n",
            "Loss:0.5406852960586548\n",
            "Loss:0.5404118299484253\n",
            "Loss:0.5401383638381958\n",
            "Loss:0.5398648977279663\n",
            "Loss:0.5395914316177368\n",
            "Loss:0.5393179655075073\n",
            "Loss:0.5390445590019226\n",
            "Loss:0.5387711524963379\n",
            "Epoch: 60 | Loss: 0.5387711524963379 | Test loss: 0.5679436326026917\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7589]])), ('linear_layer.bias', tensor([0.8155]))])\n",
            "Loss:0.5384976863861084\n",
            "Loss:0.5382242202758789\n",
            "Loss:0.5379506945610046\n",
            "Loss:0.5376774072647095\n",
            "Loss:0.53740394115448\n",
            "Loss:0.5371304750442505\n",
            "Loss:0.536857008934021\n",
            "Loss:0.5365835428237915\n",
            "Loss:0.5363101363182068\n",
            "Loss:0.5360366702079773\n",
            "Epoch: 70 | Loss: 0.5360366702079773 | Test loss: 0.5647464394569397\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7580]])), ('linear_layer.bias', tensor([0.8132]))])\n",
            "Loss:0.5357632637023926\n",
            "Loss:0.5354897379875183\n",
            "Loss:0.5352163314819336\n",
            "Loss:0.5349429249763489\n",
            "Loss:0.5346695184707642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|     | 48/100 [00:14<00:15,  3.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5343960523605347\n",
            "Loss:0.5341225266456604\n",
            "Loss:0.5338491201400757\n",
            "Loss:0.5335756540298462\n",
            "Loss:0.5333021879196167\n",
            "Epoch: 80 | Loss: 0.5333021879196167 | Test loss: 0.5615491271018982\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7570]])), ('linear_layer.bias', tensor([0.8108]))])\n",
            "Loss:0.5330287218093872\n",
            "Loss:0.5327553153038025\n",
            "Loss:0.532481849193573\n",
            "Loss:0.5322084426879883\n",
            "Loss:0.5319350361824036\n",
            "Loss:0.5316615700721741\n",
            "Loss:0.5313881039619446\n",
            "Loss:0.5311146378517151\n",
            "Loss:0.5308412313461304\n",
            "Loss:0.5305677652359009\n",
            "Epoch: 90 | Loss: 0.5305677652359009 | Test loss: 0.5583518743515015\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7561]])), ('linear_layer.bias', tensor([0.8084]))])\n",
            "Loss:0.5302942991256714\n",
            "Loss:0.5300208330154419\n",
            "Loss:0.5297474265098572\n",
            "Loss:0.5294739603996277\n",
            "Loss:0.529200553894043\n",
            "Loss:0.5289270877838135\n",
            "Loss:0.528653621673584\n",
            "Loss:0.5283801555633545\n",
            "Loss:0.528106689453125\n",
            "Loss:0.5278332829475403\n",
            "Epoch: 100 | Loss: 0.5278332829475403 | Test loss: 0.5551545023918152\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7552]])), ('linear_layer.bias', tensor([0.8060]))])\n",
            "Loss:0.5275598764419556\n",
            "Loss:0.5272864103317261\n",
            "Loss:0.5270129442214966\n",
            "Loss:0.5267394781112671\n",
            "Loss:0.5264660716056824\n",
            "Loss:0.5261926054954529\n",
            "Loss:0.5259191989898682\n",
            "Loss:0.5256456732749939\n",
            "Loss:0.5253722667694092\n",
            "Loss:0.5250988006591797\n",
            "Epoch: 110 | Loss: 0.5250988006591797 | Test loss: 0.5519572496414185\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7543]])), ('linear_layer.bias', tensor([0.8037]))])\n",
            "Loss:0.524825394153595\n",
            "Loss:0.5245519876480103\n",
            "Loss:0.524278461933136\n",
            "Loss:0.5240050554275513\n",
            "Loss:0.5237315893173218\n",
            "Loss:0.5234581828117371\n",
            "Loss:0.5231847167015076\n",
            "Loss:0.5229112505912781\n",
            "Loss:0.5226377844810486\n",
            "Loss:0.5223643183708191\n",
            "Epoch: 120 | Loss: 0.5223643183708191 | Test loss: 0.548759937286377\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7533]])), ('linear_layer.bias', tensor([0.8013]))])\n",
            "Loss:0.5220909714698792\n",
            "Loss:0.5218175053596497\n",
            "Loss:0.5215440392494202\n",
            "Loss:0.5212705731391907\n",
            "Loss:0.5209971070289612\n",
            "Loss:0.5207237005233765\n",
            "Loss:0.520450234413147\n",
            "Loss:0.5201767683029175\n",
            "Loss:0.519903302192688\n",
            "Loss:0.5196298956871033\n",
            "Epoch: 130 | Loss: 0.5196298956871033 | Test loss: 0.5455626249313354\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7524]])), ('linear_layer.bias', tensor([0.7989]))])\n",
            "Loss:0.5193565487861633\n",
            "Loss:0.5190830230712891\n",
            "Loss:0.5188095569610596\n",
            "Loss:0.5185360908508301\n",
            "Loss:0.5182626843452454\n",
            "Loss:0.5179892778396606\n",
            "Loss:0.5177158117294312\n",
            "Loss:0.5174423456192017\n",
            "Loss:0.5171688795089722\n",
            "Loss:0.5168954133987427\n",
            "Epoch: 140 | Loss: 0.5168954133987427 | Test loss: 0.542365312576294\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7515]])), ('linear_layer.bias', tensor([0.7965]))])\n",
            "Loss:0.5166219472885132\n",
            "Loss:0.5163485407829285\n",
            "Loss:0.5160751342773438\n",
            "Loss:0.5158016681671143\n",
            "Loss:0.51552814245224\n",
            "Loss:0.5152547955513\n",
            "Loss:0.5149812698364258\n",
            "Loss:0.5147078633308411\n",
            "Loss:0.5144343972206116\n",
            "Loss:0.5141609311103821\n",
            "Epoch: 150 | Loss: 0.5141609311103821 | Test loss: 0.5391680002212524\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7506]])), ('linear_layer.bias', tensor([0.7942]))])\n",
            "Loss:0.5138875246047974\n",
            "Loss:0.5136140584945679\n",
            "Loss:0.5133405923843384\n",
            "Loss:0.5130671262741089\n",
            "Loss:0.5127937197685242\n",
            "Loss:0.5125202536582947\n",
            "Loss:0.51224684715271\n",
            "Loss:0.5119734406471252\n",
            "Loss:0.511699914932251\n",
            "Loss:0.5114265084266663\n",
            "Epoch: 160 | Loss: 0.5114265084266663 | Test loss: 0.5359708070755005\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7496]])), ('linear_layer.bias', tensor([0.7918]))])\n",
            "Loss:0.5111530423164368\n",
            "Loss:0.5108795762062073\n",
            "Loss:0.5106061100959778\n",
            "Loss:0.5103327035903931\n",
            "Loss:0.5100592374801636\n",
            "Loss:0.5097857713699341\n",
            "Loss:0.5095124244689941\n",
            "Loss:0.5092389583587646\n",
            "Loss:0.5089654922485352\n",
            "Loss:0.5086920261383057\n",
            "Epoch: 170 | Loss: 0.5086920261383057 | Test loss: 0.532773494720459\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7487]])), ('linear_layer.bias', tensor([0.7894]))])\n",
            "Loss:0.508418619632721\n",
            "Loss:0.5081451535224915\n",
            "Loss:0.5078716278076172\n",
            "Loss:0.5075982213020325\n",
            "Loss:0.5073248147964478\n",
            "Loss:0.5070513486862183\n",
            "Loss:0.5067779421806335\n",
            "Loss:0.5065045356750488\n",
            "Loss:0.5062310099601746\n",
            "Loss:0.5059576034545898\n",
            "Epoch: 180 | Loss: 0.5059576034545898 | Test loss: 0.5295761823654175\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7478]])), ('linear_layer.bias', tensor([0.7870]))])\n",
            "Loss:0.5056841373443604\n",
            "Loss:0.5054106712341309\n",
            "Loss:0.5051372647285461\n",
            "Loss:0.5048638582229614\n",
            "Loss:0.5045903921127319\n",
            "Loss:0.5043169260025024\n",
            "Loss:0.504043459892273\n",
            "Loss:0.5037699937820435\n",
            "Loss:0.503496527671814\n",
            "Loss:0.5032231211662292\n",
            "Epoch: 190 | Loss: 0.5032231211662292 | Test loss: 0.5263788104057312\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7469]])), ('linear_layer.bias', tensor([0.7847]))])\n",
            "Loss:0.5029497146606445\n",
            "Loss:0.5026761889457703\n",
            "Loss:0.5024027824401855\n",
            "Loss:0.5021292567253113\n",
            "Loss:0.5018559098243713\n",
            "Loss:0.5015823841094971\n",
            "Loss:0.5013089776039124\n",
            "Loss:0.5010355114936829\n",
            "Loss:0.5007621049880981\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5871207118034363\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5548986196517944\n",
            "Loss:0.5546193718910217\n",
            "Loss:0.5543400645256042\n",
            "Loss:0.5540608167648315\n",
            "Loss:0.5537814497947693\n",
            "Loss:0.5535022616386414\n",
            "Loss:0.5532230138778687\n",
            "Loss:0.552943766117096\n",
            "Loss:0.5526643991470337\n",
            "Loss:0.552385151386261\n",
            "Epoch: 10 | Loss: 0.552385151386261 | Test loss: 0.583855152130127\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7635]])), ('linear_layer.bias', tensor([0.8273]))])\n",
            "Loss:0.5521057844161987\n",
            "Loss:0.5518265962600708\n",
            "Loss:0.5515472292900085\n",
            "Loss:0.5512679815292358\n",
            "Loss:0.5509886741638184\n",
            "Loss:0.5507093667984009\n",
            "Loss:0.550430178642273\n",
            "Loss:0.5501508712768555\n",
            "Loss:0.5498716235160828\n",
            "Loss:0.5495923757553101\n",
            "Epoch: 20 | Loss: 0.5495923757553101 | Test loss: 0.580589771270752\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8249]))])\n",
            "Loss:0.5493130683898926\n",
            "Loss:0.5490337610244751\n",
            "Loss:0.5487545132637024\n",
            "Loss:0.5484752655029297\n",
            "Loss:0.5481959581375122\n",
            "Loss:0.5479167103767395\n",
            "Loss:0.5476373434066772\n",
            "Loss:0.5473581552505493\n",
            "Loss:0.5470787882804871\n",
            "Loss:0.5467996001243591\n",
            "Epoch: 30 | Loss: 0.5467996001243591 | Test loss: 0.5773243308067322\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7616]])), ('linear_layer.bias', tensor([0.8225]))])\n",
            "Loss:0.5465202331542969\n",
            "Loss:0.5462409853935242\n",
            "Loss:0.5459617376327515\n",
            "Loss:0.5456824898719788\n",
            "Loss:0.5454031229019165\n",
            "Loss:0.5451238751411438\n",
            "Loss:0.5448445081710815\n",
            "Loss:0.5445653200149536\n",
            "Loss:0.5442860126495361\n",
            "Loss:0.5440067052841187\n",
            "Epoch: 40 | Loss: 0.5440067052841187 | Test loss: 0.5740587711334229\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7607]])), ('linear_layer.bias', tensor([0.8201]))])\n",
            "Loss:0.5437275171279907\n",
            "Loss:0.5434482097625732\n",
            "Loss:0.5431689023971558\n",
            "Loss:0.5428895950317383\n",
            "Loss:0.5426102876663208\n",
            "Loss:0.5423310995101929\n",
            "Loss:0.5420517921447754\n",
            "Loss:0.5417724847793579\n",
            "Loss:0.5414932370185852\n",
            "Loss:0.541213870048523\n",
            "Epoch: 50 | Loss: 0.541213870048523 | Test loss: 0.5707933306694031\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7597]])), ('linear_layer.bias', tensor([0.8176]))])\n",
            "Loss:0.540934681892395\n",
            "Loss:0.5406553745269775\n",
            "Loss:0.5403760671615601\n",
            "Loss:0.5400968790054321\n",
            "Loss:0.5398175120353699\n",
            "Loss:0.5395382642745972\n",
            "Loss:0.5392589569091797\n",
            "Loss:0.538979709148407\n",
            "Loss:0.5387004017829895\n",
            "Loss:0.538421094417572\n",
            "Epoch: 60 | Loss: 0.538421094417572 | Test loss: 0.5675278902053833\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7588]])), ('linear_layer.bias', tensor([0.8152]))])\n",
            "Loss:0.5381419062614441\n",
            "Loss:0.5378625392913818\n",
            "Loss:0.5375832319259644\n",
            "Loss:0.5373039841651917\n",
            "Loss:0.5370246767997742\n",
            "Loss:0.5367454290390015\n",
            "Loss:0.5364662408828735\n",
            "Loss:0.5361868739128113\n",
            "Loss:0.5359076261520386\n",
            "Loss:0.5356283187866211\n",
            "Epoch: 70 | Loss: 0.5356283187866211 | Test loss: 0.5642624497413635\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7578]])), ('linear_layer.bias', tensor([0.8128]))])\n",
            "Loss:0.5353490710258484\n",
            "Loss:0.5350698232650757\n",
            "Loss:0.5347905158996582\n",
            "Loss:0.5345112085342407\n",
            "Loss:0.534231960773468\n",
            "Loss:0.5339525938034058\n",
            "Loss:0.5336734056472778\n",
            "Loss:0.5333941578865051\n",
            "Loss:0.5331147909164429\n",
            "Loss:0.5328354835510254\n",
            "Epoch: 80 | Loss: 0.5328354835510254 | Test loss: 0.5609968900680542\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7569]])), ('linear_layer.bias', tensor([0.8104]))])\n",
            "Loss:0.5325562357902527\n",
            "Loss:0.53227698802948\n",
            "Loss:0.5319976806640625\n",
            "Loss:0.5317184329032898\n",
            "Loss:0.5314391255378723\n",
            "Loss:0.5311598777770996\n",
            "Loss:0.5308805704116821\n",
            "Loss:0.5306013226509094\n",
            "Loss:0.5303220152854919\n",
            "Loss:0.5300427675247192\n",
            "Epoch: 90 | Loss: 0.5300427675247192 | Test loss: 0.5577315092086792\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7559]])), ('linear_layer.bias', tensor([0.8079]))])\n",
            "Loss:0.5297635197639465\n",
            "Loss:0.529484212398529\n",
            "Loss:0.5292049646377563\n",
            "Loss:0.5289255976676941\n",
            "Loss:0.5286463499069214\n",
            "Loss:0.5283670425415039\n",
            "Loss:0.5280877947807312\n",
            "Loss:0.5278084874153137\n",
            "Loss:0.5275292992591858\n",
            "Loss:0.5272499322891235\n",
            "Epoch: 100 | Loss: 0.5272499322891235 | Test loss: 0.5544660687446594\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7550]])), ('linear_layer.bias', tensor([0.8055]))])\n",
            "Loss:0.5269706845283508\n",
            "Loss:0.5266913175582886\n",
            "Loss:0.5264121294021606\n",
            "Loss:0.5261327624320984\n",
            "Loss:0.5258535146713257\n",
            "Loss:0.525574266910553\n",
            "Loss:0.5252949595451355\n",
            "Loss:0.5250157117843628\n",
            "Loss:0.5247364044189453\n",
            "Loss:0.5244571566581726\n",
            "Epoch: 110 | Loss: 0.5244571566581726 | Test loss: 0.5512005686759949\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7540]])), ('linear_layer.bias', tensor([0.8031]))])\n",
            "Loss:0.5241778492927551\n",
            "Loss:0.5238986015319824\n",
            "Loss:0.5236192941665649\n",
            "Loss:0.5233400464057922\n",
            "Loss:0.52306067943573\n",
            "Loss:0.522781491279602\n",
            "Loss:0.5225021839141846\n",
            "Loss:0.5222228765487671\n",
            "Loss:0.5219435691833496\n",
            "Loss:0.5216643214225769\n",
            "Epoch: 120 | Loss: 0.5216643214225769 | Test loss: 0.5479351282119751\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7531]])), ('linear_layer.bias', tensor([0.8007]))])\n",
            "Loss:0.5213850736618042\n",
            "Loss:0.5211057662963867\n",
            "Loss:0.520826518535614\n",
            "Loss:0.5205472707748413\n",
            "Loss:0.5202679634094238\n",
            "Loss:0.5199886560440063\n",
            "Loss:0.5197093486785889\n",
            "Loss:0.5194300413131714\n",
            "Loss:0.5191507935523987\n",
            "Loss:0.5188716053962708\n",
            "Epoch: 130 | Loss: 0.5188716053962708 | Test loss: 0.5446696281433105\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7522]])), ('linear_layer.bias', tensor([0.7983]))])\n",
            "Loss:0.5185922980308533\n",
            "Loss:0.5183129906654358\n",
            "Loss:0.5180336833000183\n",
            "Loss:0.5177544355392456\n",
            "Loss:0.5174751877784729\n",
            "Loss:0.5171958208084106\n",
            "Loss:0.5169165730476379\n",
            "Loss:0.5166373252868652\n",
            "Loss:0.5163580179214478\n",
            "Loss:0.516078770160675\n",
            "Epoch: 140 | Loss: 0.516078770160675 | Test loss: 0.541404128074646\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7512]])), ('linear_layer.bias', tensor([0.7958]))])\n",
            "Loss:0.5157994031906128\n",
            "Loss:0.5155202150344849\n",
            "Loss:0.5152408480644226\n",
            "Loss:0.5149616003036499\n",
            "Loss:0.5146823525428772\n",
            "Loss:0.5144031047821045\n",
            "Loss:0.5141237378120422\n",
            "Loss:0.5138444900512695\n",
            "Loss:0.513565182685852\n",
            "Loss:0.5132859945297241\n",
            "Epoch: 150 | Loss: 0.5132859945297241 | Test loss: 0.5381386876106262\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7503]])), ('linear_layer.bias', tensor([0.7934]))])\n",
            "Loss:0.5130066275596619\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|     | 49/100 [00:15<00:15,  3.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5127273797988892\n",
            "Loss:0.5124481320381165\n",
            "Loss:0.5121687650680542\n",
            "Loss:0.5118895769119263\n",
            "Loss:0.5116103291511536\n",
            "Loss:0.5113309621810913\n",
            "Loss:0.5110517740249634\n",
            "Loss:0.5107724070549011\n",
            "Loss:0.5104931592941284\n",
            "Epoch: 160 | Loss: 0.5104931592941284 | Test loss: 0.5348731875419617\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7493]])), ('linear_layer.bias', tensor([0.7910]))])\n",
            "Loss:0.5102138519287109\n",
            "Loss:0.5099346041679382\n",
            "Loss:0.5096552968025208\n",
            "Loss:0.509376049041748\n",
            "Loss:0.5090967416763306\n",
            "Loss:0.5088174939155579\n",
            "Loss:0.5085381269454956\n",
            "Loss:0.5082589387893677\n",
            "Loss:0.5079795718193054\n",
            "Loss:0.5077003240585327\n",
            "Epoch: 170 | Loss: 0.5077003240585327 | Test loss: 0.5316077470779419\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7484]])), ('linear_layer.bias', tensor([0.7886]))])\n",
            "Loss:0.5074210166931152\n",
            "Loss:0.5071417689323425\n",
            "Loss:0.506862461566925\n",
            "Loss:0.5065832138061523\n",
            "Loss:0.5063039660453796\n",
            "Loss:0.5060247182846069\n",
            "Loss:0.5057454109191895\n",
            "Loss:0.505466103553772\n",
            "Loss:0.5051868557929993\n",
            "Loss:0.5049075484275818\n",
            "Epoch: 180 | Loss: 0.5049075484275818 | Test loss: 0.5283423066139221\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7474]])), ('linear_layer.bias', tensor([0.7861]))])\n",
            "Loss:0.5046283006668091\n",
            "Loss:0.5043489933013916\n",
            "Loss:0.5040696859359741\n",
            "Loss:0.5037904977798462\n",
            "Loss:0.5035111308097839\n",
            "Loss:0.5032318830490112\n",
            "Loss:0.5029525756835938\n",
            "Loss:0.502673327922821\n",
            "Loss:0.5023940205574036\n",
            "Loss:0.5021147727966309\n",
            "Epoch: 190 | Loss: 0.5021147727966309 | Test loss: 0.5250768661499023\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7465]])), ('linear_layer.bias', tensor([0.7837]))])\n",
            "Loss:0.5018354654312134\n",
            "Loss:0.5015562176704407\n",
            "Loss:0.5012769103050232\n",
            "Loss:0.5009976625442505\n",
            "Loss:0.5007184147834778\n",
            "Loss:0.5004390478134155\n",
            "Loss:0.500159740447998\n",
            "Loss:0.4998805522918701\n",
            "Loss:0.499601274728775\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5871137976646423\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5548928380012512\n",
            "Loss:0.5546077489852905\n",
            "Loss:0.5543226003646851\n",
            "Loss:0.5540374517440796\n",
            "Loss:0.5537523627281189\n",
            "Loss:0.5534672737121582\n",
            "Loss:0.5531821250915527\n",
            "Loss:0.5528969764709473\n",
            "Loss:0.5526119470596313\n",
            "Loss:0.5523267984390259\n",
            "Epoch: 10 | Loss: 0.5523267984390259 | Test loss: 0.5837801694869995\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7635]])), ('linear_layer.bias', tensor([0.8273]))])\n",
            "Loss:0.5520416498184204\n",
            "Loss:0.5517565011978149\n",
            "Loss:0.5514714121818542\n",
            "Loss:0.5511863231658936\n",
            "Loss:0.5509012341499329\n",
            "Loss:0.5506161451339722\n",
            "Loss:0.5503309965133667\n",
            "Loss:0.5500458478927612\n",
            "Loss:0.5497607588768005\n",
            "Loss:0.5494756698608398\n",
            "Epoch: 20 | Loss: 0.5494756698608398 | Test loss: 0.5804466009140015\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7625]])), ('linear_layer.bias', tensor([0.8248]))])\n",
            "Loss:0.5491905808448792\n",
            "Loss:0.5489053726196289\n",
            "Loss:0.548620343208313\n",
            "Loss:0.5483352541923523\n",
            "Loss:0.5480501651763916\n",
            "Loss:0.5477649569511414\n",
            "Loss:0.5474798083305359\n",
            "Loss:0.5471947193145752\n",
            "Loss:0.5469096302986145\n",
            "Loss:0.5466245412826538\n",
            "Epoch: 30 | Loss: 0.5466245412826538 | Test loss: 0.5771129131317139\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7615]])), ('linear_layer.bias', tensor([0.8223]))])\n",
            "Loss:0.5463393926620483\n",
            "Loss:0.5460543036460876\n",
            "Loss:0.545769214630127\n",
            "Loss:0.5454840660095215\n",
            "Loss:0.545198917388916\n",
            "Loss:0.5449138283729553\n",
            "Loss:0.5446287393569946\n",
            "Loss:0.5443435907363892\n",
            "Loss:0.5440585017204285\n",
            "Loss:0.543773353099823\n",
            "Epoch: 40 | Loss: 0.543773353099823 | Test loss: 0.573779284954071\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7606]])), ('linear_layer.bias', tensor([0.8199]))])\n",
            "Loss:0.5434882640838623\n",
            "Loss:0.5432031750679016\n",
            "Loss:0.5429180264472961\n",
            "Loss:0.5426328778266907\n",
            "Loss:0.54234778881073\n",
            "Loss:0.5420626401901245\n",
            "Loss:0.5417775511741638\n",
            "Loss:0.5414925217628479\n",
            "Loss:0.5412074327468872\n",
            "Loss:0.5409222841262817\n",
            "Epoch: 50 | Loss: 0.5409222841262817 | Test loss: 0.5704456567764282\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7596]])), ('linear_layer.bias', tensor([0.8174]))])\n",
            "Loss:0.5406371355056763\n",
            "Loss:0.5403520464897156\n",
            "Loss:0.5400668978691101\n",
            "Loss:0.5397818088531494\n",
            "Loss:0.539496660232544\n",
            "Loss:0.539211630821228\n",
            "Loss:0.5389264822006226\n",
            "Loss:0.5386413335800171\n",
            "Loss:0.5383562445640564\n",
            "Loss:0.5380710363388062\n",
            "Epoch: 60 | Loss: 0.5380710363388062 | Test loss: 0.5671119689941406\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7587]])), ('linear_layer.bias', tensor([0.8149]))])\n",
            "Loss:0.5377860069274902\n",
            "Loss:0.5375008583068848\n",
            "Loss:0.5372157692909241\n",
            "Loss:0.5369306802749634\n",
            "Loss:0.5366455316543579\n",
            "Loss:0.5363604426383972\n",
            "Loss:0.5360752940177917\n",
            "Loss:0.5357902646064758\n",
            "Loss:0.5355051159858704\n",
            "Loss:0.5352200269699097\n",
            "Epoch: 70 | Loss: 0.5352200269699097 | Test loss: 0.5637784004211426\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7577]])), ('linear_layer.bias', tensor([0.8124]))])\n",
            "Loss:0.5349348783493042\n",
            "Loss:0.5346497297286987\n",
            "Loss:0.534364640712738\n",
            "Loss:0.5340795516967773\n",
            "Loss:0.5337944626808167\n",
            "Loss:0.533509373664856\n",
            "Loss:0.5332242250442505\n",
            "Loss:0.532939076423645\n",
            "Loss:0.5326539278030396\n",
            "Loss:0.5323688387870789\n",
            "Epoch: 80 | Loss: 0.5323688387870789 | Test loss: 0.5604448318481445\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7567]])), ('linear_layer.bias', tensor([0.8100]))])\n",
            "Loss:0.5320837497711182\n",
            "Loss:0.5317986607551575\n",
            "Loss:0.531513512134552\n",
            "Loss:0.5312284231185913\n",
            "Loss:0.5309433341026306\n",
            "Loss:0.5306581258773804\n",
            "Loss:0.5303730964660645\n",
            "Loss:0.530087947845459\n",
            "Loss:0.5298027992248535\n",
            "Loss:0.5295177102088928\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|     | 50/100 [00:15<00:15,  3.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 90 | Loss: 0.5295177102088928 | Test loss: 0.5571111440658569\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7558]])), ('linear_layer.bias', tensor([0.8075]))])\n",
            "Loss:0.5292326211929321\n",
            "Loss:0.5289474725723267\n",
            "Loss:0.528662383556366\n",
            "Loss:0.5283772349357605\n",
            "Loss:0.528092086315155\n",
            "Loss:0.5278070569038391\n",
            "Loss:0.5275219082832336\n",
            "Loss:0.527236819267273\n",
            "Loss:0.5269516706466675\n",
            "Loss:0.5266665816307068\n",
            "Epoch: 100 | Loss: 0.5266665816307068 | Test loss: 0.5537775158882141\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7548]])), ('linear_layer.bias', tensor([0.8050]))])\n",
            "Loss:0.5263814926147461\n",
            "Loss:0.5260964035987854\n",
            "Loss:0.5258113145828247\n",
            "Loss:0.5255261659622192\n",
            "Loss:0.5252410173416138\n",
            "Loss:0.5249558687210083\n",
            "Loss:0.5246707797050476\n",
            "Loss:0.5243856310844421\n",
            "Loss:0.5241006016731262\n",
            "Loss:0.5238154530525208\n",
            "Epoch: 110 | Loss: 0.5238154530525208 | Test loss: 0.5504438877105713\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7538]])), ('linear_layer.bias', tensor([0.8025]))])\n",
            "Loss:0.5235303640365601\n",
            "Loss:0.5232452154159546\n",
            "Loss:0.5229600667953491\n",
            "Loss:0.5226749777793884\n",
            "Loss:0.522389829158783\n",
            "Loss:0.522104799747467\n",
            "Loss:0.5218197107315063\n",
            "Loss:0.5215345621109009\n",
            "Loss:0.5212494730949402\n",
            "Loss:0.5209643244743347\n",
            "Epoch: 120 | Loss: 0.5209643244743347 | Test loss: 0.5471101999282837\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7529]])), ('linear_layer.bias', tensor([0.8001]))])\n",
            "Loss:0.5206791758537292\n",
            "Loss:0.5203940272331238\n",
            "Loss:0.5201089382171631\n",
            "Loss:0.5198238492012024\n",
            "Loss:0.5195387601852417\n",
            "Loss:0.5192536115646362\n",
            "Loss:0.5189685225486755\n",
            "Loss:0.5186834335327148\n",
            "Loss:0.5183983445167542\n",
            "Loss:0.5181132555007935\n",
            "Epoch: 130 | Loss: 0.5181132555007935 | Test loss: 0.5437766313552856\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7519]])), ('linear_layer.bias', tensor([0.7976]))])\n",
            "Loss:0.5178280472755432\n",
            "Loss:0.5175429582595825\n",
            "Loss:0.517257809638977\n",
            "Loss:0.5169727206230164\n",
            "Loss:0.5166876316070557\n",
            "Loss:0.5164024829864502\n",
            "Loss:0.5161173939704895\n",
            "Loss:0.515832245349884\n",
            "Loss:0.5155471563339233\n",
            "Loss:0.5152620673179626\n",
            "Epoch: 140 | Loss: 0.5152620673179626 | Test loss: 0.540442943572998\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7509]])), ('linear_layer.bias', tensor([0.7951]))])\n",
            "Loss:0.5149768590927124\n",
            "Loss:0.5146918296813965\n",
            "Loss:0.5144067406654358\n",
            "Loss:0.5141216516494751\n",
            "Loss:0.5138365030288696\n",
            "Loss:0.5135513544082642\n",
            "Loss:0.5132662653923035\n",
            "Loss:0.5129811763763428\n",
            "Loss:0.5126960277557373\n",
            "Loss:0.5124109387397766\n",
            "Epoch: 150 | Loss: 0.5124109387397766 | Test loss: 0.5371093153953552\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7500]])), ('linear_layer.bias', tensor([0.7926]))])\n",
            "Loss:0.5121258497238159\n",
            "Loss:0.5118407011032104\n",
            "Loss:0.511555552482605\n",
            "Loss:0.5112704634666443\n",
            "Loss:0.5109853744506836\n",
            "Loss:0.5107002258300781\n",
            "Loss:0.5104150772094727\n",
            "Loss:0.5101300477981567\n",
            "Loss:0.5098448991775513\n",
            "Loss:0.5095597505569458\n",
            "Epoch: 160 | Loss: 0.5095597505569458 | Test loss: 0.5337757468223572\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7490]])), ('linear_layer.bias', tensor([0.7902]))])\n",
            "Loss:0.5092746615409851\n",
            "Loss:0.5089895725250244\n",
            "Loss:0.5087044835090637\n",
            "Loss:0.508419394493103\n",
            "Loss:0.5081342458724976\n",
            "Loss:0.5078490972518921\n",
            "Loss:0.5075639486312866\n",
            "Loss:0.5072788596153259\n",
            "Loss:0.5069937705993652\n",
            "Loss:0.5067086219787598\n",
            "Epoch: 170 | Loss: 0.5067086219787598 | Test loss: 0.5304421186447144\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7480]])), ('linear_layer.bias', tensor([0.7877]))])\n",
            "Loss:0.5064235329627991\n",
            "Loss:0.5061384439468384\n",
            "Loss:0.5058532953262329\n",
            "Loss:0.5055682063102722\n",
            "Loss:0.505282998085022\n",
            "Loss:0.5049979090690613\n",
            "Loss:0.5047128796577454\n",
            "Loss:0.5044277906417847\n",
            "Loss:0.5041426420211792\n",
            "Loss:0.5038574934005737\n",
            "Epoch: 180 | Loss: 0.5038574934005737 | Test loss: 0.5271084308624268\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7471]])), ('linear_layer.bias', tensor([0.7852]))])\n",
            "Loss:0.5035724639892578\n",
            "Loss:0.5032873153686523\n",
            "Loss:0.5030021667480469\n",
            "Loss:0.5027170181274414\n",
            "Loss:0.5024319887161255\n",
            "Loss:0.50214684009552\n",
            "Loss:0.5018616914749146\n",
            "Loss:0.5015766024589539\n",
            "Loss:0.5012915134429932\n",
            "Loss:0.5010064244270325\n",
            "Epoch: 190 | Loss: 0.5010064244270325 | Test loss: 0.5237747430801392\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7461]])), ('linear_layer.bias', tensor([0.7827]))])\n",
            "Loss:0.500721275806427\n",
            "Loss:0.5004361271858215\n",
            "Loss:0.5001510381698608\n",
            "Loss:0.49986594915390015\n",
            "Loss:0.49958086013793945\n",
            "Loss:0.499295711517334\n",
            "Loss:0.4990106225013733\n",
            "Loss:0.4987255036830902\n",
            "Loss:0.4984404146671295\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5871070623397827\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.5548869371414185\n",
            "Loss:0.5545960664749146\n",
            "Loss:0.5543050765991211\n",
            "Loss:0.5540142059326172\n",
            "Loss:0.5537232160568237\n",
            "Loss:0.5534322261810303\n",
            "Loss:0.5531413555145264\n",
            "Loss:0.5528503656387329\n",
            "Loss:0.5525594353675842\n",
            "Loss:0.5522685050964355\n",
            "Epoch: 10 | Loss: 0.5522685050964355 | Test loss: 0.5837051868438721\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7635]])), ('linear_layer.bias', tensor([0.8272]))])\n",
            "Loss:0.5519775152206421\n",
            "Loss:0.5516865253448486\n",
            "Loss:0.5513955950737\n",
            "Loss:0.5511046648025513\n",
            "Loss:0.5508137941360474\n",
            "Loss:0.5505227446556091\n",
            "Loss:0.5502318143844604\n",
            "Loss:0.5499409437179565\n",
            "Loss:0.5496498942375183\n",
            "Loss:0.5493589639663696\n",
            "Epoch: 20 | Loss: 0.5493589639663696 | Test loss: 0.580303430557251\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7625]])), ('linear_layer.bias', tensor([0.8247]))])\n",
            "Loss:0.5490680932998657\n",
            "Loss:0.5487771034240723\n",
            "Loss:0.5484861731529236\n",
            "Loss:0.5481951832771301\n",
            "Loss:0.5479043126106262\n",
            "Loss:0.547613263130188\n",
            "Loss:0.5473223924636841\n",
            "Loss:0.5470314025878906\n",
            "Loss:0.5467404127120972\n",
            "Loss:0.5464495420455933\n",
            "Epoch: 30 | Loss: 0.5464495420455933 | Test loss: 0.5769016146659851\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7615]])), ('linear_layer.bias', tensor([0.8222]))])\n",
            "Loss:0.5461586117744446\n",
            "Loss:0.5458675622940063\n",
            "Loss:0.5455766916275024\n",
            "Loss:0.545285701751709\n",
            "Loss:0.5449948310852051\n",
            "Loss:0.5447038412094116\n",
            "Loss:0.5444129109382629\n",
            "Loss:0.5441219210624695\n",
            "Loss:0.5438309907913208\n",
            "Loss:0.5435400605201721\n",
            "Epoch: 40 | Loss: 0.5435400605201721 | Test loss: 0.5734997987747192\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7605]])), ('linear_layer.bias', tensor([0.8197]))])\n",
            "Loss:0.5432491302490234\n",
            "Loss:0.54295814037323\n",
            "Loss:0.5426672101020813\n",
            "Loss:0.5423762798309326\n",
            "Loss:0.5420853495597839\n",
            "Loss:0.5417943596839905\n",
            "Loss:0.5415033102035522\n",
            "Loss:0.5412124991416931\n",
            "Loss:0.5409215688705444\n",
            "Loss:0.5406305193901062\n",
            "Epoch: 50 | Loss: 0.5406305193901062 | Test loss: 0.5700980424880981\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7595]])), ('linear_layer.bias', tensor([0.8171]))])\n",
            "Loss:0.5403396487236023\n",
            "Loss:0.5400487184524536\n",
            "Loss:0.5397577881813049\n",
            "Loss:0.5394667983055115\n",
            "Loss:0.539175808429718\n",
            "Loss:0.5388849377632141\n",
            "Loss:0.5385939478874207\n",
            "Loss:0.538303017616272\n",
            "Loss:0.5380120873451233\n",
            "Loss:0.5377210378646851\n",
            "Epoch: 60 | Loss: 0.5377210378646851 | Test loss: 0.5666961669921875\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7585]])), ('linear_layer.bias', tensor([0.8146]))])\n",
            "Loss:0.5374301671981812\n",
            "Loss:0.5371392369270325\n",
            "Loss:0.5368483066558838\n",
            "Loss:0.5365573167800903\n",
            "Loss:0.5362663865089417\n",
            "Loss:0.535975456237793\n",
            "Loss:0.5356844663619995\n",
            "Loss:0.5353935360908508\n",
            "Loss:0.5351026654243469\n",
            "Loss:0.5348116159439087\n",
            "Epoch: 70 | Loss: 0.5348116159439087 | Test loss: 0.5632944107055664\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7575]])), ('linear_layer.bias', tensor([0.8121]))])\n",
            "Loss:0.5345207452774048\n",
            "Loss:0.5342296957969666\n",
            "Loss:0.5339387655258179\n",
            "Loss:0.533647894859314\n",
            "Loss:0.5333569049835205\n",
            "Loss:0.5330659747123718\n",
            "Loss:0.5327749848365784\n",
            "Loss:0.5324840545654297\n",
            "Loss:0.532193124294281\n",
            "Loss:0.5319021940231323\n",
            "Epoch: 80 | Loss: 0.5319021940231323 | Test loss: 0.5598925948143005\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7566]])), ('linear_layer.bias', tensor([0.8096]))])\n",
            "Loss:0.5316112041473389\n",
            "Loss:0.5313202738761902\n",
            "Loss:0.5310293436050415\n",
            "Loss:0.5307384133338928\n",
            "Loss:0.5304474234580994\n",
            "Loss:0.5301564931869507\n",
            "Loss:0.529865562915802\n",
            "Loss:0.5295745730400085\n",
            "Loss:0.5292836427688599\n",
            "Loss:0.5289926528930664\n",
            "Epoch: 90 | Loss: 0.5289926528930664 | Test loss: 0.5564907789230347\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7556]])), ('linear_layer.bias', tensor([0.8070]))])\n",
            "Loss:0.5287017822265625\n",
            "Loss:0.528410792350769\n",
            "Loss:0.5281198620796204\n",
            "Loss:0.5278289318084717\n",
            "Loss:0.5275379419326782\n",
            "Loss:0.5272470712661743\n",
            "Loss:0.5269560813903809\n",
            "Loss:0.5266650915145874\n",
            "Loss:0.5263741612434387\n",
            "Loss:0.5260832905769348\n",
            "Epoch: 100 | Loss: 0.5260832905769348 | Test loss: 0.5530889630317688\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7546]])), ('linear_layer.bias', tensor([0.8045]))])\n",
            "Loss:0.5257923007011414\n",
            "Loss:0.5255013704299927\n",
            "Loss:0.5252103805541992\n",
            "Loss:0.5249193906784058\n",
            "Loss:0.5246285200119019\n",
            "Loss:0.5243375301361084\n",
            "Loss:0.5240465998649597\n",
            "Loss:0.523755669593811\n",
            "Loss:0.5234647989273071\n",
            "Loss:0.5231737494468689\n",
            "Epoch: 110 | Loss: 0.5231737494468689 | Test loss: 0.5496871471405029\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7536]])), ('linear_layer.bias', tensor([0.8020]))])\n",
            "Loss:0.5228828191757202\n",
            "Loss:0.5225918889045715\n",
            "Loss:0.5223008990287781\n",
            "Loss:0.5220099687576294\n",
            "Loss:0.5217190384864807\n",
            "Loss:0.5214280486106873\n",
            "Loss:0.5211371183395386\n",
            "Loss:0.5208461880683899\n",
            "Loss:0.5205552577972412\n",
            "Loss:0.5202642679214478\n",
            "Epoch: 120 | Loss: 0.5202642679214478 | Test loss: 0.5462853312492371\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7526]])), ('linear_layer.bias', tensor([0.7994]))])\n",
            "Loss:0.5199733972549438\n",
            "Loss:0.5196824073791504\n",
            "Loss:0.5193914771080017\n",
            "Loss:0.519100546836853\n",
            "Loss:0.5188096165657043\n",
            "Loss:0.5185186266899109\n",
            "Loss:0.5182276964187622\n",
            "Loss:0.5179367065429688\n",
            "Loss:0.5176457762718201\n",
            "Loss:0.5173547863960266\n",
            "Epoch: 130 | Loss: 0.5173547863960266 | Test loss: 0.5428835153579712\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7516]])), ('linear_layer.bias', tensor([0.7969]))])\n",
            "Loss:0.5170639157295227\n",
            "Loss:0.5167729258537292\n",
            "Loss:0.5164819955825806\n",
            "Loss:0.5161910057067871\n",
            "Loss:0.5159001350402832\n",
            "Loss:0.5156091451644897\n",
            "Loss:0.5153182148933411\n",
            "Loss:0.5150272250175476\n",
            "Loss:0.5147363543510437\n",
            "Loss:0.5144453644752502\n",
            "Epoch: 140 | Loss: 0.5144453644752502 | Test loss: 0.5394817590713501\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7507]])), ('linear_layer.bias', tensor([0.7944]))])\n",
            "Loss:0.5141543745994568\n",
            "Loss:0.5138634443283081\n",
            "Loss:0.5135725140571594\n",
            "Loss:0.5132815837860107\n",
            "Loss:0.5129905939102173\n",
            "Loss:0.5126996636390686\n",
            "Loss:0.5124087333679199\n",
            "Loss:0.5121178030967712\n",
            "Loss:0.5118268132209778\n",
            "Loss:0.5115358233451843\n",
            "Epoch: 150 | Loss: 0.5115358233451843 | Test loss: 0.536080002784729\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7497]])), ('linear_layer.bias', tensor([0.7919]))])\n",
            "Loss:0.5112449526786804\n",
            "Loss:0.5109540224075317\n",
            "Loss:0.5106630325317383\n",
            "Loss:0.5103720426559448\n",
            "Loss:0.5100811719894409\n",
            "Loss:0.5097902417182922\n",
            "Loss:0.5094992518424988\n",
            "Loss:0.5092083215713501\n",
            "Loss:0.5089173316955566\n",
            "Loss:0.5086264610290527\n",
            "Epoch: 160 | Loss: 0.5086264610290527 | Test loss: 0.5326781272888184\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7487]])), ('linear_layer.bias', tensor([0.7893]))])\n",
            "Loss:0.5083354711532593\n",
            "Loss:0.5080446004867554\n",
            "Loss:0.5077535510063171\n",
            "Loss:0.5074626207351685\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|     | 51/100 [00:15<00:14,  3.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5071717500686646\n",
            "Loss:0.5068807005882263\n",
            "Loss:0.5065897703170776\n",
            "Loss:0.5062988996505737\n",
            "Loss:0.5060079097747803\n",
            "Loss:0.5057169198989868\n",
            "Epoch: 170 | Loss: 0.5057169198989868 | Test loss: 0.5292763710021973\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7477]])), ('linear_layer.bias', tensor([0.7868]))])\n",
            "Loss:0.5054259896278381\n",
            "Loss:0.5051350593566895\n",
            "Loss:0.504844069480896\n",
            "Loss:0.5045531988143921\n",
            "Loss:0.5042622089385986\n",
            "Loss:0.5039712190628052\n",
            "Loss:0.5036803483963013\n",
            "Loss:0.5033893585205078\n",
            "Loss:0.5030984282493591\n",
            "Loss:0.5028074979782104\n",
            "Epoch: 180 | Loss: 0.5028074979782104 | Test loss: 0.5258745551109314\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7467]])), ('linear_layer.bias', tensor([0.7843]))])\n",
            "Loss:0.5025165677070618\n",
            "Loss:0.5022255778312683\n",
            "Loss:0.5019346475601196\n",
            "Loss:0.501643717288971\n",
            "Loss:0.5013527274131775\n",
            "Loss:0.5010617971420288\n",
            "Loss:0.5007708072662354\n",
            "Loss:0.5004798769950867\n",
            "Loss:0.5001888871192932\n",
            "Loss:0.4998980462551117\n",
            "Epoch: 190 | Loss: 0.4998980462551117 | Test loss: 0.5224727392196655\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7457]])), ('linear_layer.bias', tensor([0.7818]))])\n",
            "Loss:0.4996070861816406\n",
            "Loss:0.49931612610816956\n",
            "Loss:0.4990251660346985\n",
            "Loss:0.49873417615890503\n",
            "Loss:0.4984433054924011\n",
            "Loss:0.49815231561660767\n",
            "Loss:0.497861385345459\n",
            "Loss:0.4975704252719879\n",
            "Loss:0.49727946519851685\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5871002674102783\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8298]))])\n",
            "Loss:0.55488121509552\n",
            "Loss:0.5545845031738281\n",
            "Loss:0.5542877912521362\n",
            "Loss:0.5539910197257996\n",
            "Loss:0.5536943078041077\n",
            "Loss:0.5533975958824158\n",
            "Loss:0.5531009435653687\n",
            "Loss:0.552804172039032\n",
            "Loss:0.5525074601173401\n",
            "Loss:0.5522107481956482\n",
            "Epoch: 10 | Loss: 0.5522107481956482 | Test loss: 0.5836308598518372\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7634]])), ('linear_layer.bias', tensor([0.8272]))])\n",
            "Loss:0.5519140362739563\n",
            "Loss:0.5516172647476196\n",
            "Loss:0.551320493221283\n",
            "Loss:0.5510238409042358\n",
            "Loss:0.5507270693778992\n",
            "Loss:0.550430417060852\n",
            "Loss:0.5501336455345154\n",
            "Loss:0.5498369932174683\n",
            "Loss:0.5495402216911316\n",
            "Loss:0.5492435693740845\n",
            "Epoch: 20 | Loss: 0.5492435693740845 | Test loss: 0.5801615118980408\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7624]])), ('linear_layer.bias', tensor([0.8246]))])\n",
            "Loss:0.5489467978477478\n",
            "Loss:0.5486501455307007\n",
            "Loss:0.5483533143997192\n",
            "Loss:0.5480566620826721\n",
            "Loss:0.5477599501609802\n",
            "Loss:0.5474632382392883\n",
            "Loss:0.5471664667129517\n",
            "Loss:0.5468697547912598\n",
            "Loss:0.5465730428695679\n",
            "Loss:0.546276330947876\n",
            "Epoch: 30 | Loss: 0.546276330947876 | Test loss: 0.5766921043395996\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7614]])), ('linear_layer.bias', tensor([0.8220]))])\n",
            "Loss:0.5459796190261841\n",
            "Loss:0.5456828474998474\n",
            "Loss:0.5453861355781555\n",
            "Loss:0.5450894236564636\n",
            "Loss:0.5447927117347717\n",
            "Loss:0.5444959998130798\n",
            "Loss:0.5441992878913879\n",
            "Loss:0.543902575969696\n",
            "Loss:0.5436058044433594\n",
            "Loss:0.5433090925216675\n",
            "Epoch: 40 | Loss: 0.5433090925216675 | Test loss: 0.5732226967811584\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7604]])), ('linear_layer.bias', tensor([0.8194]))])\n",
            "Loss:0.5430123209953308\n",
            "Loss:0.5427156686782837\n",
            "Loss:0.5424189567565918\n",
            "Loss:0.5421222448348999\n",
            "Loss:0.541825532913208\n",
            "Loss:0.5415287613868713\n",
            "Loss:0.5412320494651794\n",
            "Loss:0.5409353971481323\n",
            "Loss:0.5406386256217957\n",
            "Loss:0.540341854095459\n",
            "Epoch: 50 | Loss: 0.540341854095459 | Test loss: 0.5697534680366516\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7594]])), ('linear_layer.bias', tensor([0.8169]))])\n",
            "Loss:0.5400451421737671\n",
            "Loss:0.5397484302520752\n",
            "Loss:0.5394517183303833\n",
            "Loss:0.5391549468040466\n",
            "Loss:0.5388582944869995\n",
            "Loss:0.5385615825653076\n",
            "Loss:0.5382648706436157\n",
            "Loss:0.5379681587219238\n",
            "Loss:0.5376714468002319\n",
            "Loss:0.5373746752738953\n",
            "Epoch: 60 | Loss: 0.5373746752738953 | Test loss: 0.5662840008735657\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7584]])), ('linear_layer.bias', tensor([0.8143]))])\n",
            "Loss:0.5370779633522034\n",
            "Loss:0.5367812514305115\n",
            "Loss:0.5364845395088196\n",
            "Loss:0.5361878275871277\n",
            "Loss:0.5358911156654358\n",
            "Loss:0.5355943441390991\n",
            "Loss:0.535297691822052\n",
            "Loss:0.5350009202957153\n",
            "Loss:0.5347042083740234\n",
            "Loss:0.5344074964523315\n",
            "Epoch: 70 | Loss: 0.5344074964523315 | Test loss: 0.5628145933151245\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7574]])), ('linear_layer.bias', tensor([0.8117]))])\n",
            "Loss:0.5341107845306396\n",
            "Loss:0.5338140726089478\n",
            "Loss:0.5335172414779663\n",
            "Loss:0.533220648765564\n",
            "Loss:0.5329238772392273\n",
            "Loss:0.5326271057128906\n",
            "Loss:0.5323303937911987\n",
            "Loss:0.5320337414741516\n",
            "Loss:0.5317370295524597\n",
            "Loss:0.531440258026123\n",
            "Epoch: 80 | Loss: 0.531440258026123 | Test loss: 0.5593452453613281\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7564]])), ('linear_layer.bias', tensor([0.8091]))])\n",
            "Loss:0.5311435461044312\n",
            "Loss:0.5308468341827393\n",
            "Loss:0.5305501222610474\n",
            "Loss:0.5302533507347107\n",
            "Loss:0.5299566984176636\n",
            "Loss:0.5296599864959717\n",
            "Loss:0.529363214969635\n",
            "Loss:0.5290664434432983\n",
            "Loss:0.528769850730896\n",
            "Loss:0.5284730792045593\n",
            "Epoch: 90 | Loss: 0.5284730792045593 | Test loss: 0.555875837802887\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7554]])), ('linear_layer.bias', tensor([0.8066]))])\n",
            "Loss:0.5281763076782227\n",
            "Loss:0.5278795957565308\n",
            "Loss:0.5275829434394836\n",
            "Loss:0.527286171913147\n",
            "Loss:0.5269894003868103\n",
            "Loss:0.5266927480697632\n",
            "Loss:0.5263960361480713\n",
            "Loss:0.5260993242263794\n",
            "Loss:0.5258025527000427\n",
            "Loss:0.5255058407783508\n",
            "Epoch: 100 | Loss: 0.5255058407783508 | Test loss: 0.5524064898490906\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7544]])), ('linear_layer.bias', tensor([0.8040]))])\n",
            "Loss:0.5252091288566589\n",
            "Loss:0.5249124765396118\n",
            "Loss:0.5246156454086304\n",
            "Loss:0.5243189930915833\n",
            "Loss:0.5240222215652466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|    | 52/100 [00:16<00:14,  3.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5237255096435547\n",
            "Loss:0.5234287977218628\n",
            "Loss:0.5231320858001709\n",
            "Loss:0.522835373878479\n",
            "Loss:0.5225386619567871\n",
            "Epoch: 110 | Loss: 0.5225386619567871 | Test loss: 0.5489370822906494\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7534]])), ('linear_layer.bias', tensor([0.8014]))])\n",
            "Loss:0.5222419500350952\n",
            "Loss:0.5219451785087585\n",
            "Loss:0.5216484665870667\n",
            "Loss:0.52135169506073\n",
            "Loss:0.5210550427436829\n",
            "Loss:0.520758330821991\n",
            "Loss:0.5204615592956543\n",
            "Loss:0.5201648473739624\n",
            "Loss:0.5198681354522705\n",
            "Loss:0.5195714235305786\n",
            "Epoch: 120 | Loss: 0.5195714235305786 | Test loss: 0.5454676747322083\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7524]])), ('linear_layer.bias', tensor([0.7988]))])\n",
            "Loss:0.5192747116088867\n",
            "Loss:0.5189779996871948\n",
            "Loss:0.5186812877655029\n",
            "Loss:0.518384575843811\n",
            "Loss:0.5180878043174744\n",
            "Loss:0.5177911520004272\n",
            "Loss:0.5174943804740906\n",
            "Loss:0.5171977281570435\n",
            "Loss:0.516900897026062\n",
            "Loss:0.5166042447090149\n",
            "Epoch: 130 | Loss: 0.5166042447090149 | Test loss: 0.5419984459877014\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7514]])), ('linear_layer.bias', tensor([0.7963]))])\n",
            "Loss:0.5163074731826782\n",
            "Loss:0.5160107612609863\n",
            "Loss:0.5157140493392944\n",
            "Loss:0.5154173374176025\n",
            "Loss:0.5151206254959106\n",
            "Loss:0.514823853969574\n",
            "Loss:0.5145271420478821\n",
            "Loss:0.514230489730835\n",
            "Loss:0.5139337778091431\n",
            "Loss:0.5136370062828064\n",
            "Epoch: 140 | Loss: 0.5136370062828064 | Test loss: 0.5385289788246155\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7504]])), ('linear_layer.bias', tensor([0.7937]))])\n",
            "Loss:0.5133402347564697\n",
            "Loss:0.5130435824394226\n",
            "Loss:0.5127468109130859\n",
            "Loss:0.512450098991394\n",
            "Loss:0.5121534466743469\n",
            "Loss:0.5118566751480103\n",
            "Loss:0.5115599632263184\n",
            "Loss:0.5112632513046265\n",
            "Loss:0.5109665393829346\n",
            "Loss:0.5106698274612427\n",
            "Epoch: 150 | Loss: 0.5106698274612427 | Test loss: 0.5350595712661743\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7494]])), ('linear_layer.bias', tensor([0.7911]))])\n",
            "Loss:0.5103731155395508\n",
            "Loss:0.5100763440132141\n",
            "Loss:0.5097796320915222\n",
            "Loss:0.5094829201698303\n",
            "Loss:0.5091861486434937\n",
            "Loss:0.5088894963264465\n",
            "Loss:0.5085927844047546\n",
            "Loss:0.5082961320877075\n",
            "Loss:0.5079993009567261\n",
            "Loss:0.5077025890350342\n",
            "Epoch: 160 | Loss: 0.5077025890350342 | Test loss: 0.5315902233123779\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7484]])), ('linear_layer.bias', tensor([0.7885]))])\n",
            "Loss:0.5074058771133423\n",
            "Loss:0.5071091651916504\n",
            "Loss:0.5068124532699585\n",
            "Loss:0.5065156817436218\n",
            "Loss:0.5062190294265747\n",
            "Loss:0.5059223175048828\n",
            "Loss:0.5056255459785461\n",
            "Loss:0.5053288340568542\n",
            "Loss:0.5050321221351624\n",
            "Loss:0.5047353506088257\n",
            "Epoch: 170 | Loss: 0.5047353506088257 | Test loss: 0.5281208157539368\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7474]])), ('linear_layer.bias', tensor([0.7860]))])\n",
            "Loss:0.5044386386871338\n",
            "Loss:0.5041419267654419\n",
            "Loss:0.50384521484375\n",
            "Loss:0.5035485029220581\n",
            "Loss:0.5032517313957214\n",
            "Loss:0.5029550790786743\n",
            "Loss:0.5026583671569824\n",
            "Loss:0.5023616552352905\n",
            "Loss:0.5020648837089539\n",
            "Loss:0.501768171787262\n",
            "Epoch: 180 | Loss: 0.501768171787262 | Test loss: 0.5246514678001404\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7464]])), ('linear_layer.bias', tensor([0.7834]))])\n",
            "Loss:0.5014714002609253\n",
            "Loss:0.5011747479438782\n",
            "Loss:0.5008780360221863\n",
            "Loss:0.5005812644958496\n",
            "Loss:0.5002845525741577\n",
            "Loss:0.4999878406524658\n",
            "Loss:0.4996911585330963\n",
            "Loss:0.49939441680908203\n",
            "Loss:0.4990977346897125\n",
            "Loss:0.49880099296569824\n",
            "Epoch: 190 | Loss: 0.49880099296569824 | Test loss: 0.5211820602416992\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7454]])), ('linear_layer.bias', tensor([0.7808]))])\n",
            "Loss:0.49850425124168396\n",
            "Loss:0.49820756912231445\n",
            "Loss:0.4979107975959778\n",
            "Loss:0.4976140856742859\n",
            "Loss:0.497317373752594\n",
            "Loss:0.4970206320285797\n",
            "Loss:0.49672389030456543\n",
            "Loss:0.4964272379875183\n",
            "Loss:0.4961305260658264\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5870934724807739\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.554875373840332\n",
            "Loss:0.5545728802680969\n",
            "Loss:0.5542702674865723\n",
            "Loss:0.5539677143096924\n",
            "Loss:0.5536651611328125\n",
            "Loss:0.5533626079559326\n",
            "Loss:0.553059995174408\n",
            "Loss:0.5527575016021729\n",
            "Loss:0.552454948425293\n",
            "Loss:0.5521523356437683\n",
            "Epoch: 10 | Loss: 0.5521523356437683 | Test loss: 0.5835559368133545\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7634]])), ('linear_layer.bias', tensor([0.8271]))])\n",
            "Loss:0.5518498420715332\n",
            "Loss:0.5515472888946533\n",
            "Loss:0.5512447357177734\n",
            "Loss:0.5509421825408936\n",
            "Loss:0.5506396889686584\n",
            "Loss:0.5503370761871338\n",
            "Loss:0.5500345230102539\n",
            "Loss:0.549731969833374\n",
            "Loss:0.5494293570518494\n",
            "Loss:0.5491268038749695\n",
            "Epoch: 20 | Loss: 0.5491268038749695 | Test loss: 0.5800184011459351\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7624]])), ('linear_layer.bias', tensor([0.8245]))])\n",
            "Loss:0.5488242506980896\n",
            "Loss:0.5485218167304993\n",
            "Loss:0.5482192039489746\n",
            "Loss:0.5479167103767395\n",
            "Loss:0.5476140975952148\n",
            "Loss:0.5473114252090454\n",
            "Loss:0.5470089912414551\n",
            "Loss:0.5467063784599304\n",
            "Loss:0.5464038848876953\n",
            "Loss:0.5461012721061707\n",
            "Epoch: 30 | Loss: 0.5461012721061707 | Test loss: 0.5764808654785156\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7614]])), ('linear_layer.bias', tensor([0.8219]))])\n",
            "Loss:0.5457987189292908\n",
            "Loss:0.5454961657524109\n",
            "Loss:0.5451936721801758\n",
            "Loss:0.5448910593986511\n",
            "Loss:0.5445885062217712\n",
            "Loss:0.5442859530448914\n",
            "Loss:0.5439834594726562\n",
            "Loss:0.5436809062957764\n",
            "Loss:0.5433782935142517\n",
            "Loss:0.5430757999420166\n",
            "Epoch: 40 | Loss: 0.5430757999420166 | Test loss: 0.5729433298110962\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7603]])), ('linear_layer.bias', tensor([0.8192]))])\n",
            "Loss:0.5427731871604919\n",
            "Loss:0.5424706339836121\n",
            "Loss:0.5421680808067322\n",
            "Loss:0.5418655276298523\n",
            "Loss:0.5415629744529724\n",
            "Loss:0.5412604212760925\n",
            "Loss:0.5409578680992126\n",
            "Loss:0.5406553149223328\n",
            "Loss:0.5403528213500977\n",
            "Loss:0.540050208568573\n",
            "Epoch: 50 | Loss: 0.540050208568573 | Test loss: 0.5694056749343872\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7593]])), ('linear_layer.bias', tensor([0.8166]))])\n",
            "Loss:0.5397476553916931\n",
            "Loss:0.5394451022148132\n",
            "Loss:0.5391425490379333\n",
            "Loss:0.5388399958610535\n",
            "Loss:0.5385374426841736\n",
            "Loss:0.5382348895072937\n",
            "Loss:0.537932276725769\n",
            "Loss:0.5376297831535339\n",
            "Loss:0.5373271703720093\n",
            "Loss:0.5370246767997742\n",
            "Epoch: 60 | Loss: 0.5370246767997742 | Test loss: 0.5658681392669678\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7583]])), ('linear_layer.bias', tensor([0.8140]))])\n",
            "Loss:0.5367220640182495\n",
            "Loss:0.5364195704460144\n",
            "Loss:0.5361170172691345\n",
            "Loss:0.5358144640922546\n",
            "Loss:0.5355119109153748\n",
            "Loss:0.5352093577384949\n",
            "Loss:0.534906804561615\n",
            "Loss:0.5346041917800903\n",
            "Loss:0.5343016386032104\n",
            "Loss:0.5339990854263306\n",
            "Epoch: 70 | Loss: 0.5339990854263306 | Test loss: 0.5623306632041931\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7573]])), ('linear_layer.bias', tensor([0.8114]))])\n",
            "Loss:0.5336965322494507\n",
            "Loss:0.5333939790725708\n",
            "Loss:0.5330914258956909\n",
            "Loss:0.5327889323234558\n",
            "Loss:0.5324863791465759\n",
            "Loss:0.5321837663650513\n",
            "Loss:0.5318812131881714\n",
            "Loss:0.5315786600112915\n",
            "Loss:0.5312761068344116\n",
            "Loss:0.5309735536575317\n",
            "Epoch: 80 | Loss: 0.5309735536575317 | Test loss: 0.5587930679321289\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7562]])), ('linear_layer.bias', tensor([0.8087]))])\n",
            "Loss:0.5306710004806519\n",
            "Loss:0.530368447303772\n",
            "Loss:0.5300658941268921\n",
            "Loss:0.5297633409500122\n",
            "Loss:0.5294609069824219\n",
            "Loss:0.5291582345962524\n",
            "Loss:0.5288556814193726\n",
            "Loss:0.5285531282424927\n",
            "Loss:0.5282505750656128\n",
            "Loss:0.5279480218887329\n",
            "Epoch: 90 | Loss: 0.5279480218887329 | Test loss: 0.5552554726600647\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7552]])), ('linear_layer.bias', tensor([0.8061]))])\n",
            "Loss:0.527645468711853\n",
            "Loss:0.5273429155349731\n",
            "Loss:0.5270403623580933\n",
            "Loss:0.5267378091812134\n",
            "Loss:0.5264352560043335\n",
            "Loss:0.5261327028274536\n",
            "Loss:0.5258301496505737\n",
            "Loss:0.5255275964736938\n",
            "Loss:0.525225043296814\n",
            "Loss:0.5249224901199341\n",
            "Epoch: 100 | Loss: 0.5249224901199341 | Test loss: 0.5517179369926453\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7542]])), ('linear_layer.bias', tensor([0.8035]))])\n",
            "Loss:0.5246199369430542\n",
            "Loss:0.5243173837661743\n",
            "Loss:0.5240148305892944\n",
            "Loss:0.5237122774124146\n",
            "Loss:0.5234097242355347\n",
            "Loss:0.52310711145401\n",
            "Loss:0.5228045582771301\n",
            "Loss:0.522502064704895\n",
            "Loss:0.5221995115280151\n",
            "Loss:0.5218969583511353\n",
            "Epoch: 110 | Loss: 0.5218969583511353 | Test loss: 0.5481804609298706\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7532]])), ('linear_layer.bias', tensor([0.8009]))])\n",
            "Loss:0.5215944051742554\n",
            "Loss:0.5212918519973755\n",
            "Loss:0.5209893584251404\n",
            "Loss:0.5206867456436157\n",
            "Loss:0.5203841924667358\n",
            "Loss:0.520081639289856\n",
            "Loss:0.5197790861129761\n",
            "Loss:0.5194765329360962\n",
            "Loss:0.5191739797592163\n",
            "Loss:0.5188714265823364\n",
            "Epoch: 120 | Loss: 0.5188714265823364 | Test loss: 0.5446429252624512\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7521]])), ('linear_layer.bias', tensor([0.7982]))])\n",
            "Loss:0.5185688734054565\n",
            "Loss:0.5182663202285767\n",
            "Loss:0.5179637670516968\n",
            "Loss:0.5176612138748169\n",
            "Loss:0.517358660697937\n",
            "Loss:0.5170561075210571\n",
            "Loss:0.5167535543441772\n",
            "Loss:0.5164510011672974\n",
            "Loss:0.5161484479904175\n",
            "Loss:0.5158458948135376\n",
            "Epoch: 130 | Loss: 0.5158458948135376 | Test loss: 0.541105329990387\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7511]])), ('linear_layer.bias', tensor([0.7956]))])\n",
            "Loss:0.5155433416366577\n",
            "Loss:0.5152407288551331\n",
            "Loss:0.514938235282898\n",
            "Loss:0.5146356821060181\n",
            "Loss:0.5143330693244934\n",
            "Loss:0.5140305757522583\n",
            "Loss:0.5137280225753784\n",
            "Loss:0.5134254693984985\n",
            "Loss:0.5131229162216187\n",
            "Loss:0.5128203630447388\n",
            "Epoch: 140 | Loss: 0.5128203630447388 | Test loss: 0.5375678539276123\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7501]])), ('linear_layer.bias', tensor([0.7930]))])\n",
            "Loss:0.5125178098678589\n",
            "Loss:0.5122151970863342\n",
            "Loss:0.5119126439094543\n",
            "Loss:0.5116101503372192\n",
            "Loss:0.5113075971603394\n",
            "Loss:0.5110050439834595\n",
            "Loss:0.5107024312019348\n",
            "Loss:0.5103998780250549\n",
            "Loss:0.5100973844528198\n",
            "Loss:0.5097947716712952\n",
            "Epoch: 150 | Loss: 0.5097947716712952 | Test loss: 0.5340301990509033\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7491]])), ('linear_layer.bias', tensor([0.7904]))])\n",
            "Loss:0.5094922780990601\n",
            "Loss:0.5091897249221802\n",
            "Loss:0.5088871121406555\n",
            "Loss:0.5085845589637756\n",
            "Loss:0.5082820057868958\n",
            "Loss:0.5079794526100159\n",
            "Loss:0.5076768398284912\n",
            "Loss:0.5073743462562561\n",
            "Loss:0.5070717930793762\n",
            "Loss:0.5067692995071411\n",
            "Epoch: 160 | Loss: 0.5067692995071411 | Test loss: 0.5304926633834839\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7481]])), ('linear_layer.bias', tensor([0.7877]))])\n",
            "Loss:0.5064666867256165\n",
            "Loss:0.5061641931533813\n",
            "Loss:0.5058615803718567\n",
            "Loss:0.5055590271949768\n",
            "Loss:0.5052564740180969\n",
            "Loss:0.5049538612365723\n",
            "Loss:0.5046513676643372\n",
            "Loss:0.5043487548828125\n",
            "Loss:0.5040462017059326\n",
            "Loss:0.5037437081336975\n",
            "Epoch: 170 | Loss: 0.5037437081336975 | Test loss: 0.5269551277160645\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7470]])), ('linear_layer.bias', tensor([0.7851]))])\n",
            "Loss:0.5034411549568176\n",
            "Loss:0.503138542175293\n",
            "Loss:0.5028361082077026\n",
            "Loss:0.502533495426178\n",
            "Loss:0.5022309422492981\n",
            "Loss:0.5019283890724182\n",
            "Loss:0.5016257762908936\n",
            "Loss:0.5013232827186584\n",
            "Loss:0.5010206699371338\n",
            "Loss:0.5007181167602539\n",
            "Epoch: 180 | Loss: 0.5007181167602539 | Test loss: 0.523417592048645\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7460]])), ('linear_layer.bias', tensor([0.7825]))])\n",
            "Loss:0.500415563583374\n",
            "Loss:0.5001129508018494\n",
            "Loss:0.49981045722961426\n",
            "Loss:0.4995079040527344\n",
            "Loss:0.49920541048049927\n",
            "Loss:0.4989027976989746\n",
            "Loss:0.4986003041267395\n",
            "Loss:0.49829769134521484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|    | 53/100 [00:16<00:14,  3.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.49799519777297974\n",
            "Loss:0.4976925849914551\n",
            "Epoch: 190 | Loss: 0.4976925849914551 | Test loss: 0.5198799967765808\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7450]])), ('linear_layer.bias', tensor([0.7798]))])\n",
            "Loss:0.4973900318145752\n",
            "Loss:0.4970874786376953\n",
            "Loss:0.49678492546081543\n",
            "Loss:0.49648237228393555\n",
            "Loss:0.49617987871170044\n",
            "Loss:0.4958772659301758\n",
            "Loss:0.4955747723579407\n",
            "Loss:0.4952722191810608\n",
            "Loss:0.49496960639953613\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5870866179466248\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.554869532585144\n",
            "Loss:0.5545611381530762\n",
            "Loss:0.5542528033256531\n",
            "Loss:0.5539443492889404\n",
            "Loss:0.5536359548568726\n",
            "Loss:0.5533276200294495\n",
            "Loss:0.5530192255973816\n",
            "Loss:0.5527108311653137\n",
            "Loss:0.5524023771286011\n",
            "Loss:0.5520941019058228\n",
            "Epoch: 10 | Loss: 0.5520941019058228 | Test loss: 0.583480954170227\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7634]])), ('linear_layer.bias', tensor([0.8271]))])\n",
            "Loss:0.5517856478691101\n",
            "Loss:0.551477313041687\n",
            "Loss:0.5511689186096191\n",
            "Loss:0.5508604049682617\n",
            "Loss:0.5505520701408386\n",
            "Loss:0.5502436757087708\n",
            "Loss:0.5499354004859924\n",
            "Loss:0.5496269464492798\n",
            "Loss:0.5493186116218567\n",
            "Loss:0.549010157585144\n",
            "Epoch: 20 | Loss: 0.549010157585144 | Test loss: 0.5798751711845398\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7623]])), ('linear_layer.bias', tensor([0.8244]))])\n",
            "Loss:0.5487017631530762\n",
            "Loss:0.5483933687210083\n",
            "Loss:0.5480850338935852\n",
            "Loss:0.5477765798568726\n",
            "Loss:0.5474682450294495\n",
            "Loss:0.5471598505973816\n",
            "Loss:0.5468514561653137\n",
            "Loss:0.5465431213378906\n",
            "Loss:0.5462347269058228\n",
            "Loss:0.5459262728691101\n",
            "Epoch: 30 | Loss: 0.5459262728691101 | Test loss: 0.5762695074081421\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7613]])), ('linear_layer.bias', tensor([0.8217]))])\n",
            "Loss:0.545617938041687\n",
            "Loss:0.5453095436096191\n",
            "Loss:0.5450011491775513\n",
            "Loss:0.5446926951408386\n",
            "Loss:0.5443843603134155\n",
            "Loss:0.5440760254859924\n",
            "Loss:0.5437675714492798\n",
            "Loss:0.5434592366218567\n",
            "Loss:0.543150782585144\n",
            "Loss:0.5428423881530762\n",
            "Epoch: 40 | Loss: 0.5428423881530762 | Test loss: 0.5726637840270996\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7603]])), ('linear_layer.bias', tensor([0.8190]))])\n",
            "Loss:0.5425339937210083\n",
            "Loss:0.5422256588935852\n",
            "Loss:0.5419172644615173\n",
            "Loss:0.5416088700294495\n",
            "Loss:0.5413004755973816\n",
            "Loss:0.5409920811653137\n",
            "Loss:0.5406836867332458\n",
            "Loss:0.540375292301178\n",
            "Loss:0.5400670170783997\n",
            "Loss:0.539758563041687\n",
            "Epoch: 50 | Loss: 0.539758563041687 | Test loss: 0.5690580606460571\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7592]])), ('linear_layer.bias', tensor([0.8164]))])\n",
            "Loss:0.5394501686096191\n",
            "Loss:0.5391417741775513\n",
            "Loss:0.5388333797454834\n",
            "Loss:0.5385249257087708\n",
            "Loss:0.5382165312767029\n",
            "Loss:0.5379081964492798\n",
            "Loss:0.5375998616218567\n",
            "Loss:0.537291407585144\n",
            "Loss:0.536983072757721\n",
            "Loss:0.5366746187210083\n",
            "Epoch: 60 | Loss: 0.5366746187210083 | Test loss: 0.5654523372650146\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7582]])), ('linear_layer.bias', tensor([0.8137]))])\n",
            "Loss:0.53636634349823\n",
            "Loss:0.5360578894615173\n",
            "Loss:0.5357495546340942\n",
            "Loss:0.5354411005973816\n",
            "Loss:0.5351327061653137\n",
            "Loss:0.5348243117332458\n",
            "Loss:0.5345159769058228\n",
            "Loss:0.5342075228691101\n",
            "Loss:0.533899188041687\n",
            "Loss:0.5335907936096191\n",
            "Epoch: 70 | Loss: 0.5335907936096191 | Test loss: 0.5618466138839722\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7571]])), ('linear_layer.bias', tensor([0.8110]))])\n",
            "Loss:0.5332823991775513\n",
            "Loss:0.5329739451408386\n",
            "Loss:0.5326656103134155\n",
            "Loss:0.5323572158813477\n",
            "Loss:0.5320488214492798\n",
            "Loss:0.5317404270172119\n",
            "Loss:0.5314320921897888\n",
            "Loss:0.5311236381530762\n",
            "Loss:0.5308152437210083\n",
            "Loss:0.5305069088935852\n",
            "Epoch: 80 | Loss: 0.5305069088935852 | Test loss: 0.5582408308982849\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7561]])), ('linear_layer.bias', tensor([0.8083]))])\n",
            "Loss:0.5301985144615173\n",
            "Loss:0.5298901796340942\n",
            "Loss:0.5295817255973816\n",
            "Loss:0.5292733311653137\n",
            "Loss:0.5289649367332458\n",
            "Loss:0.5286566019058228\n",
            "Loss:0.5283482074737549\n",
            "Loss:0.528039813041687\n",
            "Loss:0.5277314782142639\n",
            "Loss:0.5274230241775513\n",
            "Epoch: 90 | Loss: 0.5274230241775513 | Test loss: 0.554635226726532\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7550]])), ('linear_layer.bias', tensor([0.8056]))])\n",
            "Loss:0.5271146297454834\n",
            "Loss:0.5268062353134155\n",
            "Loss:0.5264978408813477\n",
            "Loss:0.5261894464492798\n",
            "Loss:0.5258811116218567\n",
            "Loss:0.5255727171897888\n",
            "Loss:0.5252642631530762\n",
            "Loss:0.5249559283256531\n",
            "Loss:0.5246475338935852\n",
            "Loss:0.5243391394615173\n",
            "Epoch: 100 | Loss: 0.5243391394615173 | Test loss: 0.5510294437408447\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7540]])), ('linear_layer.bias', tensor([0.8030]))])\n",
            "Loss:0.5240308046340942\n",
            "Loss:0.5237223505973816\n",
            "Loss:0.5234140157699585\n",
            "Loss:0.5231055617332458\n",
            "Loss:0.5227972269058228\n",
            "Loss:0.5224888324737549\n",
            "Loss:0.522180438041687\n",
            "Loss:0.5218721032142639\n",
            "Loss:0.5215636491775513\n",
            "Loss:0.5212553143501282\n",
            "Epoch: 110 | Loss: 0.5212553143501282 | Test loss: 0.547423779964447\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7530]])), ('linear_layer.bias', tensor([0.8003]))])\n",
            "Loss:0.5209468603134155\n",
            "Loss:0.5206385850906372\n",
            "Loss:0.5203300714492798\n",
            "Loss:0.5200217366218567\n",
            "Loss:0.5197133421897888\n",
            "Loss:0.519404947757721\n",
            "Loss:0.5190965533256531\n",
            "Loss:0.5187881588935852\n",
            "Loss:0.5184798240661621\n",
            "Loss:0.5181714296340942\n",
            "Epoch: 120 | Loss: 0.5181714296340942 | Test loss: 0.5438179969787598\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7519]])), ('linear_layer.bias', tensor([0.7976]))])\n",
            "Loss:0.5178629755973816\n",
            "Loss:0.5175546407699585\n",
            "Loss:0.5172461867332458\n",
            "Loss:0.5169378519058228\n",
            "Loss:0.5166294574737549\n",
            "Loss:0.5163210034370422\n",
            "Loss:0.5160126686096191\n",
            "Loss:0.5157042741775513\n",
            "Loss:0.5153958797454834\n",
            "Loss:0.5150874853134155\n",
            "Epoch: 130 | Loss: 0.5150874853134155 | Test loss: 0.5402122735977173\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7509]])), ('linear_layer.bias', tensor([0.7949]))])\n",
            "Loss:0.5147790908813477\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|    | 54/100 [00:16<00:13,  3.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5144707560539246\n",
            "Loss:0.5141623616218567\n",
            "Loss:0.513853907585144\n",
            "Loss:0.513545572757721\n",
            "Loss:0.5132371783256531\n",
            "Loss:0.5129287838935852\n",
            "Loss:0.5126204490661621\n",
            "Loss:0.5123120546340942\n",
            "Loss:0.5120036005973816\n",
            "Epoch: 140 | Loss: 0.5120036005973816 | Test loss: 0.5366066098213196\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7498]])), ('linear_layer.bias', tensor([0.7923]))])\n",
            "Loss:0.5116952657699585\n",
            "Loss:0.5113868117332458\n",
            "Loss:0.5110784769058228\n",
            "Loss:0.5107700228691101\n",
            "Loss:0.510461688041687\n",
            "Loss:0.5101532936096191\n",
            "Loss:0.509844958782196\n",
            "Loss:0.5095365643501282\n",
            "Loss:0.5092281103134155\n",
            "Loss:0.5089197754859924\n",
            "Epoch: 150 | Loss: 0.5089197754859924 | Test loss: 0.5330009460449219\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7488]])), ('linear_layer.bias', tensor([0.7896]))])\n",
            "Loss:0.5086113214492798\n",
            "Loss:0.5083029866218567\n",
            "Loss:0.5079945921897888\n",
            "Loss:0.5076862573623657\n",
            "Loss:0.5073777437210083\n",
            "Loss:0.5070694088935852\n",
            "Loss:0.5067610740661621\n",
            "Loss:0.5064526796340942\n",
            "Loss:0.5061442852020264\n",
            "Loss:0.5058358907699585\n",
            "Epoch: 160 | Loss: 0.5058358907699585 | Test loss: 0.5293951630592346\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7477]])), ('linear_layer.bias', tensor([0.7869]))])\n",
            "Loss:0.5055274963378906\n",
            "Loss:0.5052191019058228\n",
            "Loss:0.5049107670783997\n",
            "Loss:0.504602313041687\n",
            "Loss:0.5042939186096191\n",
            "Loss:0.5039855241775513\n",
            "Loss:0.5036771297454834\n",
            "Loss:0.5033687353134155\n",
            "Loss:0.5030604004859924\n",
            "Loss:0.5027519464492798\n",
            "Epoch: 170 | Loss: 0.5027519464492798 | Test loss: 0.5257894992828369\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7467]])), ('linear_layer.bias', tensor([0.7842]))])\n",
            "Loss:0.5024436712265015\n",
            "Loss:0.502135157585144\n",
            "Loss:0.501826822757721\n",
            "Loss:0.5015183687210083\n",
            "Loss:0.5012100338935852\n",
            "Loss:0.5009016394615173\n",
            "Loss:0.5005933046340942\n",
            "Loss:0.5002849102020264\n",
            "Loss:0.4999764859676361\n",
            "Loss:0.4996681213378906\n",
            "Epoch: 180 | Loss: 0.4996681213378906 | Test loss: 0.5221836566925049\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7456]])), ('linear_layer.bias', tensor([0.7816]))])\n",
            "Loss:0.49935969710350037\n",
            "Loss:0.49905139207839966\n",
            "Loss:0.4987429082393646\n",
            "Loss:0.49843454360961914\n",
            "Loss:0.49812617897987366\n",
            "Loss:0.4978177547454834\n",
            "Loss:0.4975094199180603\n",
            "Loss:0.49720102548599243\n",
            "Loss:0.49689263105392456\n",
            "Loss:0.4965842664241791\n",
            "Epoch: 190 | Loss: 0.4965842664241791 | Test loss: 0.5185779333114624\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7446]])), ('linear_layer.bias', tensor([0.7789]))])\n",
            "Loss:0.4962758421897888\n",
            "Loss:0.49596747756004333\n",
            "Loss:0.4956590235233307\n",
            "Loss:0.49535074830055237\n",
            "Loss:0.49504226446151733\n",
            "Loss:0.49473389983177185\n",
            "Loss:0.49442553520202637\n",
            "Loss:0.4941171109676361\n",
            "Loss:0.4938087463378906\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5870798230171204\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.554863691329956\n",
            "Loss:0.554549515247345\n",
            "Loss:0.5542352795600891\n",
            "Loss:0.5539210438728333\n",
            "Loss:0.5536068081855774\n",
            "Loss:0.5532925724983215\n",
            "Loss:0.5529783964157104\n",
            "Loss:0.5526641607284546\n",
            "Loss:0.5523499250411987\n",
            "Loss:0.5520356893539429\n",
            "Epoch: 10 | Loss: 0.5520356893539429 | Test loss: 0.5834059715270996\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7634]])), ('linear_layer.bias', tensor([0.8270]))])\n",
            "Loss:0.5517215132713318\n",
            "Loss:0.5514072775840759\n",
            "Loss:0.5510929822921753\n",
            "Loss:0.550778865814209\n",
            "Loss:0.5504646301269531\n",
            "Loss:0.5501503348350525\n",
            "Loss:0.5498362183570862\n",
            "Loss:0.5495219230651855\n",
            "Loss:0.5492076873779297\n",
            "Loss:0.5488935112953186\n",
            "Epoch: 20 | Loss: 0.5488935112953186 | Test loss: 0.5797320604324341\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7623]])), ('linear_layer.bias', tensor([0.8243]))])\n",
            "Loss:0.5485792756080627\n",
            "Loss:0.5482650995254517\n",
            "Loss:0.5479508638381958\n",
            "Loss:0.5476366281509399\n",
            "Loss:0.5473223924636841\n",
            "Loss:0.547008216381073\n",
            "Loss:0.5466939210891724\n",
            "Loss:0.5463797450065613\n",
            "Loss:0.5460655093193054\n",
            "Loss:0.5457512736320496\n",
            "Epoch: 30 | Loss: 0.5457512736320496 | Test loss: 0.5760581493377686\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7612]])), ('linear_layer.bias', tensor([0.8216]))])\n",
            "Loss:0.5454370975494385\n",
            "Loss:0.5451228022575378\n",
            "Loss:0.544808566570282\n",
            "Loss:0.5444944500923157\n",
            "Loss:0.5441802144050598\n",
            "Loss:0.543865978717804\n",
            "Loss:0.5435517430305481\n",
            "Loss:0.5432375073432922\n",
            "Loss:0.5429232716560364\n",
            "Loss:0.5426090955734253\n",
            "Epoch: 40 | Loss: 0.5426090955734253 | Test loss: 0.572384238243103\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7602]])), ('linear_layer.bias', tensor([0.8188]))])\n",
            "Loss:0.5422948598861694\n",
            "Loss:0.5419806838035583\n",
            "Loss:0.5416663885116577\n",
            "Loss:0.5413521528244019\n",
            "Loss:0.5410380363464355\n",
            "Loss:0.5407237410545349\n",
            "Loss:0.540409505367279\n",
            "Loss:0.540095329284668\n",
            "Loss:0.5397811532020569\n",
            "Loss:0.5394667983055115\n",
            "Epoch: 50 | Loss: 0.5394667983055115 | Test loss: 0.5687103867530823\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7591]])), ('linear_layer.bias', tensor([0.8161]))])\n",
            "Loss:0.5391526818275452\n",
            "Loss:0.5388384461402893\n",
            "Loss:0.5385241508483887\n",
            "Loss:0.5382100343704224\n",
            "Loss:0.5378957390785217\n",
            "Loss:0.5375815629959106\n",
            "Loss:0.5372673273086548\n",
            "Loss:0.5369530916213989\n",
            "Loss:0.5366388559341431\n",
            "Loss:0.5363246202468872\n",
            "Epoch: 60 | Loss: 0.5363246202468872 | Test loss: 0.5650365352630615\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7581]])), ('linear_layer.bias', tensor([0.8134]))])\n",
            "Loss:0.5360104441642761\n",
            "Loss:0.5356962084770203\n",
            "Loss:0.5353819727897644\n",
            "Loss:0.5350677371025085\n",
            "Loss:0.5347535610198975\n",
            "Loss:0.5344393253326416\n",
            "Loss:0.5341251492500305\n",
            "Loss:0.5338108539581299\n",
            "Loss:0.5334966778755188\n",
            "Loss:0.5331824421882629\n",
            "Epoch: 70 | Loss: 0.5331824421882629 | Test loss: 0.561362624168396\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7570]])), ('linear_layer.bias', tensor([0.8106]))])\n",
            "Loss:0.5328682661056519\n",
            "Loss:0.5325539708137512\n",
            "Loss:0.5322397947311401\n",
            "Loss:0.5319255590438843\n",
            "Loss:0.5316113233566284\n",
            "Loss:0.5312970876693726\n",
            "Loss:0.5309828519821167\n",
            "Loss:0.5306686758995056\n",
            "Loss:0.5303544998168945\n",
            "Loss:0.5300402641296387\n",
            "Epoch: 80 | Loss: 0.5300402641296387 | Test loss: 0.5576887130737305\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7559]])), ('linear_layer.bias', tensor([0.8079]))])\n",
            "Loss:0.529725968837738\n",
            "Loss:0.529411792755127\n",
            "Loss:0.5290975570678711\n",
            "Loss:0.5287833213806152\n",
            "Loss:0.5284690856933594\n",
            "Loss:0.5281549096107483\n",
            "Loss:0.5278406739234924\n",
            "Loss:0.5275264978408813\n",
            "Loss:0.5272122621536255\n",
            "Loss:0.5268980264663696\n",
            "Epoch: 90 | Loss: 0.5268980264663696 | Test loss: 0.5540148019790649\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7549]])), ('linear_layer.bias', tensor([0.8052]))])\n",
            "Loss:0.5265837907791138\n",
            "Loss:0.5262695550918579\n",
            "Loss:0.525955319404602\n",
            "Loss:0.5256410837173462\n",
            "Loss:0.5253268480300903\n",
            "Loss:0.5250126719474792\n",
            "Loss:0.5246984362602234\n",
            "Loss:0.5243842005729675\n",
            "Loss:0.5240700840950012\n",
            "Loss:0.5237557888031006\n",
            "Epoch: 100 | Loss: 0.5237557888031006 | Test loss: 0.5503409504890442\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7538]])), ('linear_layer.bias', tensor([0.8025]))])\n",
            "Loss:0.5234415531158447\n",
            "Loss:0.5231273770332336\n",
            "Loss:0.5228131413459778\n",
            "Loss:0.5224989056587219\n",
            "Loss:0.5221847295761108\n",
            "Loss:0.521870493888855\n",
            "Loss:0.5215561985969543\n",
            "Loss:0.5212420225143433\n",
            "Loss:0.5209277868270874\n",
            "Loss:0.5206135511398315\n",
            "Epoch: 110 | Loss: 0.5206135511398315 | Test loss: 0.5466670989990234\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7527]])), ('linear_layer.bias', tensor([0.7997]))])\n",
            "Loss:0.5202993750572205\n",
            "Loss:0.5199850797653198\n",
            "Loss:0.5196709036827087\n",
            "Loss:0.5193566679954529\n",
            "Loss:0.5190424919128418\n",
            "Loss:0.5187282562255859\n",
            "Loss:0.5184140205383301\n",
            "Loss:0.518099844455719\n",
            "Loss:0.5177855491638184\n",
            "Loss:0.517471432685852\n",
            "Epoch: 120 | Loss: 0.517471432685852 | Test loss: 0.5429931879043579\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7517]])), ('linear_layer.bias', tensor([0.7970]))])\n",
            "Loss:0.5171571373939514\n",
            "Loss:0.5168429017066956\n",
            "Loss:0.5165287256240845\n",
            "Loss:0.5162144899368286\n",
            "Loss:0.5159002542495728\n",
            "Loss:0.5155860185623169\n",
            "Loss:0.515271782875061\n",
            "Loss:0.51495760679245\n",
            "Loss:0.5146433711051941\n",
            "Loss:0.5143291354179382\n",
            "Epoch: 130 | Loss: 0.5143291354179382 | Test loss: 0.5393192768096924\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7506]])), ('linear_layer.bias', tensor([0.7943]))])\n",
            "Loss:0.5140148997306824\n",
            "Loss:0.5137007236480713\n",
            "Loss:0.5133864879608154\n",
            "Loss:0.5130722522735596\n",
            "Loss:0.5127580165863037\n",
            "Loss:0.5124437808990479\n",
            "Loss:0.5121296048164368\n",
            "Loss:0.5118153095245361\n",
            "Loss:0.511501133441925\n",
            "Loss:0.511186957359314\n",
            "Epoch: 140 | Loss: 0.511186957359314 | Test loss: 0.5356453657150269\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7495]])), ('linear_layer.bias', tensor([0.7916]))])\n",
            "Loss:0.5108727216720581\n",
            "Loss:0.510558545589447\n",
            "Loss:0.5102442502975464\n",
            "Loss:0.5099300146102905\n",
            "Loss:0.5096158385276794\n",
            "Loss:0.5093016624450684\n",
            "Loss:0.508987307548523\n",
            "Loss:0.5086731910705566\n",
            "Loss:0.5083589553833008\n",
            "Loss:0.5080447196960449\n",
            "Epoch: 150 | Loss: 0.5080447196960449 | Test loss: 0.5319715142250061\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7485]])), ('linear_layer.bias', tensor([0.7888]))])\n",
            "Loss:0.5077304840087891\n",
            "Loss:0.5074162483215332\n",
            "Loss:0.5071020722389221\n",
            "Loss:0.506787896156311\n",
            "Loss:0.5064736604690552\n",
            "Loss:0.5061594247817993\n",
            "Loss:0.5058451890945435\n",
            "Loss:0.5055309534072876\n",
            "Loss:0.5052167177200317\n",
            "Loss:0.5049025416374207\n",
            "Epoch: 160 | Loss: 0.5049025416374207 | Test loss: 0.5282976627349854\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7474]])), ('linear_layer.bias', tensor([0.7861]))])\n",
            "Loss:0.50458824634552\n",
            "Loss:0.5042740702629089\n",
            "Loss:0.5039598345756531\n",
            "Loss:0.5036455988883972\n",
            "Loss:0.5033314228057861\n",
            "Loss:0.5030171871185303\n",
            "Loss:0.5027029514312744\n",
            "Loss:0.5023887753486633\n",
            "Loss:0.5020745396614075\n",
            "Loss:0.5017603039741516\n",
            "Epoch: 170 | Loss: 0.5017603039741516 | Test loss: 0.5246237516403198\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7464]])), ('linear_layer.bias', tensor([0.7834]))])\n",
            "Loss:0.5014461278915405\n",
            "Loss:0.5011318922042847\n",
            "Loss:0.5008176565170288\n",
            "Loss:0.5005033612251282\n",
            "Loss:0.5001891851425171\n",
            "Loss:0.4998749792575836\n",
            "Loss:0.49956074357032776\n",
            "Loss:0.4992465078830719\n",
            "Loss:0.4989323019981384\n",
            "Loss:0.49861806631088257\n",
            "Epoch: 180 | Loss: 0.49861806631088257 | Test loss: 0.5209498405456543\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7453]])), ('linear_layer.bias', tensor([0.7806]))])\n",
            "Loss:0.4983038902282715\n",
            "Loss:0.4979896545410156\n",
            "Loss:0.49767541885375977\n",
            "Loss:0.4973611831665039\n",
            "Loss:0.49704694747924805\n",
            "Loss:0.49673277139663696\n",
            "Loss:0.49641847610473633\n",
            "Loss:0.49610432982444763\n",
            "Loss:0.4957900941371918\n",
            "Loss:0.4954758584499359"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|    | 55/100 [00:17<00:13,  3.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 190 | Loss: 0.4954758584499359 | Test loss: 0.5172759294509888\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7442]])), ('linear_layer.bias', tensor([0.7779]))])\n",
            "Loss:0.49516168236732483\n",
            "Loss:0.4948473870754242\n",
            "Loss:0.4945332109928131\n",
            "Loss:0.49421897530555725\n",
            "Loss:0.4939047694206238\n",
            "Loss:0.4935905337333679\n",
            "Loss:0.49327629804611206\n",
            "Loss:0.492962121963501\n",
            "Loss:0.4926478862762451\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.587073028087616\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5548579692840576\n",
            "Loss:0.5545378923416138\n",
            "Loss:0.5542179346084595\n",
            "Loss:0.5538978576660156\n",
            "Loss:0.5535777807235718\n",
            "Loss:0.5532578229904175\n",
            "Loss:0.5529378056526184\n",
            "Loss:0.5526177287101746\n",
            "Loss:0.5522977709770203\n",
            "Loss:0.5519777536392212\n",
            "Epoch: 10 | Loss: 0.5519777536392212 | Test loss: 0.5833309888839722\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8270]))])\n",
            "Loss:0.5516577363014221\n",
            "Loss:0.5513377785682678\n",
            "Loss:0.5510176420211792\n",
            "Loss:0.5506976842880249\n",
            "Loss:0.5503777265548706\n",
            "Loss:0.5500576496124268\n",
            "Loss:0.5497375726699829\n",
            "Loss:0.5494176149368286\n",
            "Loss:0.5490976572036743\n",
            "Loss:0.5487775206565857\n",
            "Epoch: 20 | Loss: 0.5487775206565857 | Test loss: 0.5795890092849731\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7623]])), ('linear_layer.bias', tensor([0.8242]))])\n",
            "Loss:0.5484575033187866\n",
            "Loss:0.5481375455856323\n",
            "Loss:0.5478174686431885\n",
            "Loss:0.5474974513053894\n",
            "Loss:0.5471774339675903\n",
            "Loss:0.546857476234436\n",
            "Loss:0.5465373992919922\n",
            "Loss:0.5462174415588379\n",
            "Loss:0.545897364616394\n",
            "Loss:0.5455774068832397\n",
            "Epoch: 30 | Loss: 0.5455774068832397 | Test loss: 0.5758470296859741\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7612]])), ('linear_layer.bias', tensor([0.8214]))])\n",
            "Loss:0.5452573299407959\n",
            "Loss:0.5449373126029968\n",
            "Loss:0.5446172952651978\n",
            "Loss:0.5442973375320435\n",
            "Loss:0.5439773201942444\n",
            "Loss:0.5436572432518005\n",
            "Loss:0.5433372259140015\n",
            "Loss:0.5430172085762024\n",
            "Loss:0.5426972508430481\n",
            "Loss:0.5423771739006042\n",
            "Epoch: 40 | Loss: 0.5423771739006042 | Test loss: 0.5721050500869751\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7601]])), ('linear_layer.bias', tensor([0.8186]))])\n",
            "Loss:0.5420571565628052\n",
            "Loss:0.5417371392250061\n",
            "Loss:0.5414170622825623\n",
            "Loss:0.5410971641540527\n",
            "Loss:0.5407770872116089\n",
            "Loss:0.5404571294784546\n",
            "Loss:0.540136992931366\n",
            "Loss:0.5398170351982117\n",
            "Loss:0.5394970178604126\n",
            "Loss:0.5391770601272583\n",
            "Epoch: 50 | Loss: 0.5391770601272583 | Test loss: 0.5683630704879761\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7590]])), ('linear_layer.bias', tensor([0.8158]))])\n",
            "Loss:0.5388569831848145\n",
            "Loss:0.5385369062423706\n",
            "Loss:0.5382169485092163\n",
            "Loss:0.537896990776062\n",
            "Loss:0.5375769138336182\n",
            "Loss:0.5372568964958191\n",
            "Loss:0.53693687915802\n",
            "Loss:0.536616861820221\n",
            "Loss:0.5362968444824219\n",
            "Loss:0.5359768271446228\n",
            "Epoch: 60 | Loss: 0.5359768271446228 | Test loss: 0.5646210312843323\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7579]])), ('linear_layer.bias', tensor([0.8131]))])\n",
            "Loss:0.5356568098068237\n",
            "Loss:0.5353367924690247\n",
            "Loss:0.5350168347358704\n",
            "Loss:0.5346967577934265\n",
            "Loss:0.5343767404556274\n",
            "Loss:0.5340567231178284\n",
            "Loss:0.5337365865707397\n",
            "Loss:0.5334166884422302\n",
            "Loss:0.5330966711044312\n",
            "Loss:0.5327766537666321\n",
            "Epoch: 70 | Loss: 0.5327766537666321 | Test loss: 0.5608790516853333\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7568]])), ('linear_layer.bias', tensor([0.8103]))])\n",
            "Loss:0.5324565768241882\n",
            "Loss:0.5321365594863892\n",
            "Loss:0.5318166613578796\n",
            "Loss:0.531496524810791\n",
            "Loss:0.5311765074729919\n",
            "Loss:0.5308564901351929\n",
            "Loss:0.5305365324020386\n",
            "Loss:0.53021639585495\n",
            "Loss:0.5298964381217957\n",
            "Loss:0.5295764207839966\n",
            "Epoch: 80 | Loss: 0.5295764207839966 | Test loss: 0.557137131690979\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7558]])), ('linear_layer.bias', tensor([0.8075]))])\n",
            "Loss:0.5292564630508423\n",
            "Loss:0.5289363861083984\n",
            "Loss:0.5286163687705994\n",
            "Loss:0.5282963514328003\n",
            "Loss:0.527976393699646\n",
            "Loss:0.5276563167572021\n",
            "Loss:0.5273362994194031\n",
            "Loss:0.527016282081604\n",
            "Loss:0.5266963243484497\n",
            "Loss:0.5263762474060059\n",
            "Epoch: 90 | Loss: 0.5263762474060059 | Test loss: 0.5533950328826904\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7547]])), ('linear_layer.bias', tensor([0.8047]))])\n",
            "Loss:0.526056170463562\n",
            "Loss:0.5257362127304077\n",
            "Loss:0.5254161953926086\n",
            "Loss:0.5250961780548096\n",
            "Loss:0.5247761011123657\n",
            "Loss:0.5244561433792114\n",
            "Loss:0.5241361856460571\n",
            "Loss:0.5238161087036133\n",
            "Loss:0.5234960913658142\n",
            "Loss:0.5231760740280151\n",
            "Epoch: 100 | Loss: 0.5231760740280151 | Test loss: 0.549653172492981\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7536]])), ('linear_layer.bias', tensor([0.8020]))])\n",
            "Loss:0.5228560566902161\n",
            "Loss:0.5225359797477722\n",
            "Loss:0.5222160220146179\n",
            "Loss:0.5218960046768188\n",
            "Loss:0.5215759873390198\n",
            "Loss:0.5212559103965759\n",
            "Loss:0.5209358930587769\n",
            "Loss:0.5206159353256226\n",
            "Loss:0.5202959179878235\n",
            "Loss:0.5199759006500244\n",
            "Epoch: 110 | Loss: 0.5199759006500244 | Test loss: 0.5459111332893372\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7525]])), ('linear_layer.bias', tensor([0.7992]))])\n",
            "Loss:0.5196558237075806\n",
            "Loss:0.5193358659744263\n",
            "Loss:0.5190158486366272\n",
            "Loss:0.5186958312988281\n",
            "Loss:0.5183757543563843\n",
            "Loss:0.5180557370185852\n",
            "Loss:0.5177357792854309\n",
            "Loss:0.5174157619476318\n",
            "Loss:0.517095685005188\n",
            "Loss:0.5167757272720337\n",
            "Epoch: 120 | Loss: 0.5167757272720337 | Test loss: 0.5421690344810486\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7514]])), ('linear_layer.bias', tensor([0.7964]))])\n",
            "Loss:0.5164556503295898\n",
            "Loss:0.5161356925964355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|    | 56/100 [00:17<00:13,  3.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5158156156539917\n",
            "Loss:0.5154956579208374\n",
            "Loss:0.5151756405830383\n",
            "Loss:0.5148555636405945\n",
            "Loss:0.5145356059074402\n",
            "Loss:0.5142155885696411\n",
            "Loss:0.5138955116271973\n",
            "Loss:0.5135754942893982\n",
            "Epoch: 130 | Loss: 0.5135754942893982 | Test loss: 0.5384270548820496\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7503]])), ('linear_layer.bias', tensor([0.7936]))])\n",
            "Loss:0.5132554769515991\n",
            "Loss:0.5129355192184448\n",
            "Loss:0.512615442276001\n",
            "Loss:0.5122954249382019\n",
            "Loss:0.5119754076004028\n",
            "Loss:0.5116554498672485\n",
            "Loss:0.5113353729248047\n",
            "Loss:0.5110153555870056\n",
            "Loss:0.5106953382492065\n",
            "Loss:0.5103753209114075\n",
            "Epoch: 140 | Loss: 0.5103753209114075 | Test loss: 0.5346850752830505\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7493]])), ('linear_layer.bias', tensor([0.7908]))])\n",
            "Loss:0.5100553035736084\n",
            "Loss:0.5097352862358093\n",
            "Loss:0.5094152688980103\n",
            "Loss:0.509095311164856\n",
            "Loss:0.5087753534317017\n",
            "Loss:0.508455216884613\n",
            "Loss:0.508135199546814\n",
            "Loss:0.5078151822090149\n",
            "Loss:0.5074951648712158\n",
            "Loss:0.5071751475334167\n",
            "Epoch: 150 | Loss: 0.5071751475334167 | Test loss: 0.5309430956840515\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7482]])), ('linear_layer.bias', tensor([0.7881]))])\n",
            "Loss:0.5068551301956177\n",
            "Loss:0.5065351724624634\n",
            "Loss:0.5062150955200195\n",
            "Loss:0.5058950185775757\n",
            "Loss:0.5055750012397766\n",
            "Loss:0.5052550435066223\n",
            "Loss:0.5049350261688232\n",
            "Loss:0.5046149492263794\n",
            "Loss:0.5042949914932251\n",
            "Loss:0.5039750337600708\n",
            "Epoch: 160 | Loss: 0.5039750337600708 | Test loss: 0.5272011756896973\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7471]])), ('linear_layer.bias', tensor([0.7853]))])\n",
            "Loss:0.5036550164222717\n",
            "Loss:0.5033349394798279\n",
            "Loss:0.5030149221420288\n",
            "Loss:0.5026949048042297\n",
            "Loss:0.5023748278617859\n",
            "Loss:0.5020548701286316\n",
            "Loss:0.5017348527908325\n",
            "Loss:0.5014147758483887\n",
            "Loss:0.5010948181152344\n",
            "Loss:0.5007747411727905\n",
            "Epoch: 170 | Loss: 0.5007747411727905 | Test loss: 0.5234591364860535\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7460]])), ('linear_layer.bias', tensor([0.7825]))])\n",
            "Loss:0.5004547834396362\n",
            "Loss:0.5001347661018372\n",
            "Loss:0.4998147487640381\n",
            "Loss:0.499494731426239\n",
            "Loss:0.49917468428611755\n",
            "Loss:0.49885469675064087\n",
            "Loss:0.4985346794128418\n",
            "Loss:0.49821463227272034\n",
            "Loss:0.49789467453956604\n",
            "Loss:0.4975746273994446\n",
            "Epoch: 180 | Loss: 0.4975746273994446 | Test loss: 0.5197171568870544\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7449]])), ('linear_layer.bias', tensor([0.7797]))])\n",
            "Loss:0.4972546100616455\n",
            "Loss:0.49693456292152405\n",
            "Loss:0.4966145157814026\n",
            "Loss:0.4962944984436035\n",
            "Loss:0.4959745407104492\n",
            "Loss:0.49565449357032776\n",
            "Loss:0.4953344464302063\n",
            "Loss:0.4950144290924072\n",
            "Loss:0.49469441175460815\n",
            "Loss:0.49437442421913147\n",
            "Epoch: 190 | Loss: 0.49437442421913147 | Test loss: 0.5159751176834106\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7438]])), ('linear_layer.bias', tensor([0.7770]))])\n",
            "Loss:0.49405437707901\n",
            "Loss:0.49373435974121094\n",
            "Loss:0.49341434240341187\n",
            "Loss:0.4930943548679352\n",
            "Loss:0.4927743375301361\n",
            "Loss:0.49245429039001465\n",
            "Loss:0.4921342730522156\n",
            "Loss:0.4918143153190613\n",
            "Loss:0.49149423837661743\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5870662331581116\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5548520684242249\n",
            "Loss:0.5545262098312378\n",
            "Loss:0.5542003512382507\n",
            "Loss:0.5538745522499084\n",
            "Loss:0.5535486340522766\n",
            "Loss:0.5532228350639343\n",
            "Loss:0.5528969764709473\n",
            "Loss:0.552571177482605\n",
            "Loss:0.5522452592849731\n",
            "Loss:0.5519194006919861\n",
            "Epoch: 10 | Loss: 0.5519194006919861 | Test loss: 0.5832561254501343\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8269]))])\n",
            "Loss:0.5515936017036438\n",
            "Loss:0.5512677431106567\n",
            "Loss:0.5509418249130249\n",
            "Loss:0.5506159663200378\n",
            "Loss:0.5502901673316956\n",
            "Loss:0.5499643087387085\n",
            "Loss:0.5496385097503662\n",
            "Loss:0.5493127107620239\n",
            "Loss:0.5489867329597473\n",
            "Loss:0.548660933971405\n",
            "Epoch: 20 | Loss: 0.548660933971405 | Test loss: 0.5794458985328674\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7622]])), ('linear_layer.bias', tensor([0.8241]))])\n",
            "Loss:0.5483350157737732\n",
            "Loss:0.5480092167854309\n",
            "Loss:0.5476833581924438\n",
            "Loss:0.5473574995994568\n",
            "Loss:0.547031581401825\n",
            "Loss:0.5467057228088379\n",
            "Loss:0.5463799238204956\n",
            "Loss:0.5460540652275085\n",
            "Loss:0.545728325843811\n",
            "Loss:0.5454024076461792\n",
            "Epoch: 30 | Loss: 0.5454024076461792 | Test loss: 0.5756356716156006\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7611]])), ('linear_layer.bias', tensor([0.8212]))])\n",
            "Loss:0.5450764894485474\n",
            "Loss:0.5447506904602051\n",
            "Loss:0.544424831867218\n",
            "Loss:0.5440989136695862\n",
            "Loss:0.5437731146812439\n",
            "Loss:0.5434472560882568\n",
            "Loss:0.5431213974952698\n",
            "Loss:0.5427955985069275\n",
            "Loss:0.5424696803092957\n",
            "Loss:0.5421438217163086\n",
            "Epoch: 40 | Loss: 0.5421438217163086 | Test loss: 0.5718255639076233\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7600]])), ('linear_layer.bias', tensor([0.8184]))])\n",
            "Loss:0.5418180227279663\n",
            "Loss:0.5414921641349792\n",
            "Loss:0.5411662459373474\n",
            "Loss:0.5408405065536499\n",
            "Loss:0.5405145883560181\n",
            "Loss:0.5401886701583862\n",
            "Loss:0.5398629307746887\n",
            "Loss:0.5395370721817017\n",
            "Loss:0.5392112135887146\n",
            "Loss:0.5388852953910828\n",
            "Epoch: 50 | Loss: 0.5388852953910828 | Test loss: 0.5680153369903564\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7589]])), ('linear_layer.bias', tensor([0.8156]))])\n",
            "Loss:0.5385594964027405\n",
            "Loss:0.5382336378097534\n",
            "Loss:0.5379077792167664\n",
            "Loss:0.5375819206237793\n",
            "Loss:0.5372560620307922\n",
            "Loss:0.5369302034378052\n",
            "Loss:0.5366043448448181\n",
            "Loss:0.5362785458564758\n",
            "Loss:0.5359526872634888\n",
            "Loss:0.5356268286705017\n",
            "Epoch: 60 | Loss: 0.5356268286705017 | Test loss: 0.5642052888870239\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7578]])), ('linear_layer.bias', tensor([0.8128]))])\n",
            "Loss:0.5353009104728699\n",
            "Loss:0.5349751710891724\n",
            "Loss:0.5346492528915405\n",
            "Loss:0.5343233942985535\n",
            "Loss:0.5339975357055664\n",
            "Loss:0.5336716771125793\n",
            "Loss:0.5333458781242371\n",
            "Loss:0.5330199599266052\n",
            "Loss:0.5326942205429077\n",
            "Loss:0.5323683023452759\n",
            "Epoch: 70 | Loss: 0.5323683023452759 | Test loss: 0.5603950619697571\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7567]])), ('linear_layer.bias', tensor([0.8099]))])\n",
            "Loss:0.5320425033569336\n",
            "Loss:0.531716525554657\n",
            "Loss:0.5313907861709595\n",
            "Loss:0.5310648679733276\n",
            "Loss:0.5307389497756958\n",
            "Loss:0.5304132103919983\n",
            "Loss:0.5300873517990112\n",
            "Loss:0.5297614932060242\n",
            "Loss:0.5294355750083923\n",
            "Loss:0.52910977602005\n",
            "Epoch: 80 | Loss: 0.52910977602005 | Test loss: 0.556584894657135\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7556]])), ('linear_layer.bias', tensor([0.8071]))])\n",
            "Loss:0.528783917427063\n",
            "Loss:0.5284579992294312\n",
            "Loss:0.5281322598457336\n",
            "Loss:0.5278064012527466\n",
            "Loss:0.5274804830551147\n",
            "Loss:0.5271546840667725\n",
            "Loss:0.5268288254737854\n",
            "Loss:0.5265029668807983\n",
            "Loss:0.526177167892456\n",
            "Loss:0.5258512496948242\n",
            "Epoch: 90 | Loss: 0.5258512496948242 | Test loss: 0.5527747869491577\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7545]])), ('linear_layer.bias', tensor([0.8043]))])\n",
            "Loss:0.5255253911018372\n",
            "Loss:0.5251995325088501\n",
            "Loss:0.524873673915863\n",
            "Loss:0.5245478749275208\n",
            "Loss:0.5242220163345337\n",
            "Loss:0.5238961577415466\n",
            "Loss:0.5235702991485596\n",
            "Loss:0.5232444405555725\n",
            "Loss:0.5229185223579407\n",
            "Loss:0.5225927233695984\n",
            "Epoch: 100 | Loss: 0.5225927233695984 | Test loss: 0.5489645600318909\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7534]])), ('linear_layer.bias', tensor([0.8014]))])\n",
            "Loss:0.5222669243812561\n",
            "Loss:0.521941065788269\n",
            "Loss:0.5216151475906372\n",
            "Loss:0.5212893486022949\n",
            "Loss:0.5209634900093079\n",
            "Loss:0.5206376314163208\n",
            "Loss:0.520311713218689\n",
            "Loss:0.5199859142303467\n",
            "Loss:0.5196600556373596\n",
            "Loss:0.5193341970443726\n",
            "Epoch: 110 | Loss: 0.5193341970443726 | Test loss: 0.5451544523239136\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7523]])), ('linear_layer.bias', tensor([0.7986]))])\n",
            "Loss:0.5190083384513855\n",
            "Loss:0.518682599067688\n",
            "Loss:0.5183566808700562\n",
            "Loss:0.5180307626724243\n",
            "Loss:0.5177049040794373\n",
            "Loss:0.517379105091095\n",
            "Loss:0.5170532464981079\n",
            "Loss:0.5167273879051208\n",
            "Loss:0.5164015889167786\n",
            "Loss:0.5160756707191467\n",
            "Epoch: 120 | Loss: 0.5160756707191467 | Test loss: 0.5413442850112915\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7512]])), ('linear_layer.bias', tensor([0.7958]))])\n",
            "Loss:0.5157498121261597\n",
            "Loss:0.5154239535331726\n",
            "Loss:0.5150981545448303\n",
            "Loss:0.5147722959518433\n",
            "Loss:0.5144463777542114\n",
            "Loss:0.5141205191612244\n",
            "Loss:0.5137947201728821\n",
            "Loss:0.513468861579895\n",
            "Loss:0.513143002986908\n",
            "Loss:0.5128172039985657\n",
            "Epoch: 130 | Loss: 0.5128172039985657 | Test loss: 0.5375341176986694\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7501]])), ('linear_layer.bias', tensor([0.7930]))])\n",
            "Loss:0.5124912858009338\n",
            "Loss:0.5121654272079468\n",
            "Loss:0.5118396282196045\n",
            "Loss:0.5115137696266174\n",
            "Loss:0.5111879110336304\n",
            "Loss:0.5108621120452881\n",
            "Loss:0.5105361938476562\n",
            "Loss:0.510210394859314\n",
            "Loss:0.5098844766616821\n",
            "Loss:0.5095586180686951\n",
            "Epoch: 140 | Loss: 0.5095586180686951 | Test loss: 0.5337239503860474\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7490]])), ('linear_layer.bias', tensor([0.7901]))])\n",
            "Loss:0.5092328190803528\n",
            "Loss:0.5089069604873657\n",
            "Loss:0.5085811018943787\n",
            "Loss:0.5082551836967468\n",
            "Loss:0.5079294443130493\n",
            "Loss:0.5076035261154175\n",
            "Loss:0.5072776675224304\n",
            "Loss:0.5069518089294434\n",
            "Loss:0.5066260099411011\n",
            "Loss:0.506300151348114\n",
            "Epoch: 150 | Loss: 0.506300151348114 | Test loss: 0.5299137830734253\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7479]])), ('linear_layer.bias', tensor([0.7873]))])\n",
            "Loss:0.5059742331504822\n",
            "Loss:0.5056484341621399\n",
            "Loss:0.5053225755691528\n",
            "Loss:0.5049967169761658\n",
            "Loss:0.5046708583831787\n",
            "Loss:0.5043449997901917\n",
            "Loss:0.5040191411972046\n",
            "Loss:0.5036933422088623\n",
            "Loss:0.5033674240112305\n",
            "Loss:0.5030416250228882\n",
            "Epoch: 160 | Loss: 0.5030416250228882 | Test loss: 0.5261036157608032\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7468]])), ('linear_layer.bias', tensor([0.7845]))])\n",
            "Loss:0.5027157664299011\n",
            "Loss:0.5023899078369141\n",
            "Loss:0.502064049243927\n",
            "Loss:0.5017381906509399\n",
            "Loss:0.5014123320579529\n",
            "Loss:0.5010864734649658\n",
            "Loss:0.5007606744766235\n",
            "Loss:0.5004348754882812\n",
            "Loss:0.5001088976860046\n",
            "Loss:0.4997830390930176\n",
            "Epoch: 170 | Loss: 0.4997830390930176 | Test loss: 0.5222934484481812\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7457]])), ('linear_layer.bias', tensor([0.7816]))])\n",
            "Loss:0.4994572103023529\n",
            "Loss:0.49913138151168823\n",
            "Loss:0.4988054633140564\n",
            "Loss:0.4984796941280365\n",
            "Loss:0.49815377593040466\n",
            "Loss:0.49782794713974\n",
            "Loss:0.49750208854675293\n",
            "Loss:0.49717631936073303\n",
            "Loss:0.4968504011631012\n",
            "Loss:0.4965245723724365\n",
            "Epoch: 180 | Loss: 0.4965245723724365 | Test loss: 0.5184832811355591\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7446]])), ('linear_layer.bias', tensor([0.7788]))])\n",
            "Loss:0.49619874358177185\n",
            "Loss:0.49587282538414\n",
            "Loss:0.49554699659347534\n",
            "Loss:0.4952211380004883\n",
            "Loss:0.4948953092098236\n",
            "Loss:0.49456945061683655\n",
            "Loss:0.4942436218261719\n",
            "Loss:0.4939177632331848\n",
            "Loss:0.49359193444252014\n",
            "Loss:0.4932660460472107\n",
            "Epoch: 190 | Loss: 0.4932660460472107 | Test loss: 0.514673113822937\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7435]])), ('linear_layer.bias', tensor([0.7760]))])\n",
            "Loss:0.49294018745422363\n",
            "Loss:0.49261435866355896\n",
            "Loss:0.4922885000705719\n",
            "Loss:0.49196261167526245\n",
            "Loss:0.49163684248924255\n",
            "Loss:0.4913109242916107\n",
            "Loss:0.49098509550094604\n",
            "Loss:0.4906591773033142\n",
            "Loss:0.4903333783149719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|    | 57/100 [00:17<00:13,  3.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5870593786239624\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5548462867736816\n",
            "Loss:0.5545145273208618\n",
            "Loss:0.5541828870773315\n",
            "Loss:0.5538511872291565\n",
            "Loss:0.5535195469856262\n",
            "Loss:0.5531878471374512\n",
            "Loss:0.5528560876846313\n",
            "Loss:0.5525244474411011\n",
            "Loss:0.5521928071975708\n",
            "Loss:0.5518611073493958\n",
            "Epoch: 10 | Loss: 0.5518611073493958 | Test loss: 0.5831810235977173\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8268]))])\n",
            "Loss:0.5515294075012207\n",
            "Loss:0.5511976480484009\n",
            "Loss:0.5508660078048706\n",
            "Loss:0.5505343675613403\n",
            "Loss:0.5502026677131653\n",
            "Loss:0.5498709082603455\n",
            "Loss:0.5495392680168152\n",
            "Loss:0.5492076277732849\n",
            "Loss:0.5488759279251099\n",
            "Loss:0.5485442876815796\n",
            "Epoch: 20 | Loss: 0.5485442876815796 | Test loss: 0.5793027281761169\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7622]])), ('linear_layer.bias', tensor([0.8240]))])\n",
            "Loss:0.5482125282287598\n",
            "Loss:0.5478808283805847\n",
            "Loss:0.5475491285324097\n",
            "Loss:0.5472174882888794\n",
            "Loss:0.5468857884407043\n",
            "Loss:0.5465540885925293\n",
            "Loss:0.546222448348999\n",
            "Loss:0.545890748500824\n",
            "Loss:0.5455591082572937\n",
            "Loss:0.5452274084091187\n",
            "Epoch: 30 | Loss: 0.5452274084091187 | Test loss: 0.5754244327545166\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7611]])), ('linear_layer.bias', tensor([0.8211]))])\n",
            "Loss:0.5448956489562988\n",
            "Loss:0.5445639491081238\n",
            "Loss:0.5442323088645935\n",
            "Loss:0.5439006090164185\n",
            "Loss:0.5435689091682434\n",
            "Loss:0.5432372093200684\n",
            "Loss:0.5429055690765381\n",
            "Loss:0.5425739288330078\n",
            "Loss:0.5422422289848328\n",
            "Loss:0.5419104695320129\n",
            "Epoch: 40 | Loss: 0.5419104695320129 | Test loss: 0.5715460181236267\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7599]])), ('linear_layer.bias', tensor([0.8182]))])\n",
            "Loss:0.5415787696838379\n",
            "Loss:0.5412471890449524\n",
            "Loss:0.5409154891967773\n",
            "Loss:0.5405837297439575\n",
            "Loss:0.5402520895004272\n",
            "Loss:0.539920449256897\n",
            "Loss:0.5395887494087219\n",
            "Loss:0.5392571091651917\n",
            "Loss:0.538925290107727\n",
            "Loss:0.5385936498641968\n",
            "Epoch: 50 | Loss: 0.5385936498641968 | Test loss: 0.5676676630973816\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7588]])), ('linear_layer.bias', tensor([0.8153]))])\n",
            "Loss:0.5382620096206665\n",
            "Loss:0.5379303693771362\n",
            "Loss:0.5375986099243164\n",
            "Loss:0.5372669100761414\n",
            "Loss:0.5369352102279663\n",
            "Loss:0.536603569984436\n",
            "Loss:0.536271870136261\n",
            "Loss:0.5359401702880859\n",
            "Loss:0.5356084704399109\n",
            "Loss:0.5352767705917358\n",
            "Epoch: 60 | Loss: 0.5352767705917358 | Test loss: 0.563789427280426\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7577]])), ('linear_layer.bias', tensor([0.8124]))])\n",
            "Loss:0.5349451303482056\n",
            "Loss:0.5346134305000305\n",
            "Loss:0.5342816710472107\n",
            "Loss:0.5339500308036804\n",
            "Loss:0.5336183309555054\n",
            "Loss:0.5332866907119751\n",
            "Loss:0.5329549908638\n",
            "Loss:0.5326233506202698\n",
            "Loss:0.5322916507720947\n",
            "Loss:0.5319600105285645\n",
            "Epoch: 70 | Loss: 0.5319600105285645 | Test loss: 0.5599110722541809\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7566]])), ('linear_layer.bias', tensor([0.8096]))])\n",
            "Loss:0.5316282510757446\n",
            "Loss:0.5312966108322144\n",
            "Loss:0.5309648513793945\n",
            "Loss:0.5306332111358643\n",
            "Loss:0.5303015112876892\n",
            "Loss:0.5299698114395142\n",
            "Loss:0.5296381711959839\n",
            "Loss:0.5293064713478088\n",
            "Loss:0.5289747714996338\n",
            "Loss:0.5286431312561035\n",
            "Epoch: 80 | Loss: 0.5286431312561035 | Test loss: 0.5560327768325806\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7554]])), ('linear_layer.bias', tensor([0.8067]))])\n",
            "Loss:0.5283114314079285\n",
            "Loss:0.5279797315597534\n",
            "Loss:0.5276479721069336\n",
            "Loss:0.5273163318634033\n",
            "Loss:0.5269846320152283\n",
            "Loss:0.526652991771698\n",
            "Loss:0.526321291923523\n",
            "Loss:0.5259896516799927\n",
            "Loss:0.5256579518318176\n",
            "Loss:0.5253262519836426\n",
            "Epoch: 90 | Loss: 0.5253262519836426 | Test loss: 0.5521543622016907\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7543]])), ('linear_layer.bias', tensor([0.8038]))])\n",
            "Loss:0.5249945521354675\n",
            "Loss:0.5246628522872925\n",
            "Loss:0.5243312120437622\n",
            "Loss:0.5239994525909424\n",
            "Loss:0.5236678123474121\n",
            "Loss:0.5233361124992371\n",
            "Loss:0.523004412651062\n",
            "Loss:0.5226727724075317\n",
            "Loss:0.5223411321640015\n",
            "Loss:0.5220094323158264\n",
            "Epoch: 100 | Loss: 0.5220094323158264 | Test loss: 0.5482760667800903\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7532]])), ('linear_layer.bias', tensor([0.8009]))])\n",
            "Loss:0.5216776728630066\n",
            "Loss:0.5213459730148315\n",
            "Loss:0.5210143327713013\n",
            "Loss:0.520682692527771\n",
            "Loss:0.5203509330749512\n",
            "Loss:0.5200192332267761\n",
            "Loss:0.5196875333786011\n",
            "Loss:0.5193558931350708\n",
            "Loss:0.5190242528915405\n",
            "Loss:0.5186924934387207\n",
            "Epoch: 110 | Loss: 0.5186924934387207 | Test loss: 0.5443977117538452\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7521]])), ('linear_layer.bias', tensor([0.7981]))])\n",
            "Loss:0.5183607935905457\n",
            "Loss:0.5180290937423706\n",
            "Loss:0.5176974534988403\n",
            "Loss:0.5173657536506653\n",
            "Loss:0.517034113407135\n",
            "Loss:0.51670241355896\n",
            "Loss:0.5163707137107849\n",
            "Loss:0.5160390734672546\n",
            "Loss:0.5157073736190796\n",
            "Loss:0.5153756141662598\n",
            "Epoch: 120 | Loss: 0.5153756141662598 | Test loss: 0.5405194163322449\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7510]])), ('linear_layer.bias', tensor([0.7952]))])\n",
            "Loss:0.5150439143180847\n",
            "Loss:0.5147122740745544\n",
            "Loss:0.5143805742263794\n",
            "Loss:0.5140489339828491\n",
            "Loss:0.5137172937393188\n",
            "Loss:0.513385534286499\n",
            "Loss:0.5130538940429688\n",
            "Loss:0.5127221941947937\n",
            "Loss:0.5123904943466187\n",
            "Loss:0.5120588541030884\n",
            "Epoch: 130 | Loss: 0.5120588541030884 | Test loss: 0.5366411209106445\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7498]])), ('linear_layer.bias', tensor([0.7923]))])\n",
            "Loss:0.5117271542549133\n",
            "Loss:0.5113953948020935\n",
            "Loss:0.5110636949539185\n",
            "Loss:0.5107320547103882\n",
            "Loss:0.5104004144668579\n",
            "Loss:0.5100687146186829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|    | 58/100 [00:17<00:12,  3.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5097370147705078\n",
            "Loss:0.5094053149223328\n",
            "Loss:0.5090736150741577\n",
            "Loss:0.5087419748306274\n",
            "Epoch: 140 | Loss: 0.5087419748306274 | Test loss: 0.5327626466751099\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7487]])), ('linear_layer.bias', tensor([0.7894]))])\n",
            "Loss:0.5084102749824524\n",
            "Loss:0.5080785751342773\n",
            "Loss:0.5077468752861023\n",
            "Loss:0.5074151754379272\n",
            "Loss:0.507083535194397\n",
            "Loss:0.5067518949508667\n",
            "Loss:0.5064201951026917\n",
            "Loss:0.5060885548591614\n",
            "Loss:0.5057567954063416\n",
            "Loss:0.5054251551628113\n",
            "Epoch: 150 | Loss: 0.5054251551628113 | Test loss: 0.5288844108581543\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7476]])), ('linear_layer.bias', tensor([0.7865]))])\n",
            "Loss:0.5050933957099915\n",
            "Loss:0.5047617554664612\n",
            "Loss:0.5044300556182861\n",
            "Loss:0.5040983557701111\n",
            "Loss:0.503766655921936\n",
            "Loss:0.5034350156784058\n",
            "Loss:0.5031033158302307\n",
            "Loss:0.5027716159820557\n",
            "Loss:0.5024399757385254\n",
            "Loss:0.5021082162857056\n",
            "Epoch: 160 | Loss: 0.5021082162857056 | Test loss: 0.5250060558319092\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7465]])), ('linear_layer.bias', tensor([0.7837]))])\n",
            "Loss:0.5017765760421753\n",
            "Loss:0.5014448761940002\n",
            "Loss:0.5011131763458252\n",
            "Loss:0.5007815361022949\n",
            "Loss:0.5004497766494751\n",
            "Loss:0.5001181364059448\n",
            "Loss:0.49978646636009216\n",
            "Loss:0.4994547963142395\n",
            "Loss:0.49912309646606445\n",
            "Loss:0.4987913966178894\n",
            "Epoch: 170 | Loss: 0.4987913966178894 | Test loss: 0.5211278200149536\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7453]])), ('linear_layer.bias', tensor([0.7808]))])\n",
            "Loss:0.49845972657203674\n",
            "Loss:0.4981279969215393\n",
            "Loss:0.49779635667800903\n",
            "Loss:0.497464656829834\n",
            "Loss:0.49713295698165894\n",
            "Loss:0.4968012869358063\n",
            "Loss:0.4964695870876312\n",
            "Loss:0.49613794684410095\n",
            "Loss:0.4958062171936035\n",
            "Loss:0.49547451734542847\n",
            "Epoch: 180 | Loss: 0.49547451734542847 | Test loss: 0.5172494649887085\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7442]])), ('linear_layer.bias', tensor([0.7779]))])\n",
            "Loss:0.4951428472995758\n",
            "Loss:0.49481114745140076\n",
            "Loss:0.4944794774055481\n",
            "Loss:0.4941478371620178\n",
            "Loss:0.493816077709198\n",
            "Loss:0.49348440766334534\n",
            "Loss:0.49315276741981506\n",
            "Loss:0.49282106757164\n",
            "Loss:0.49248939752578735\n",
            "Loss:0.4921577572822571\n",
            "Epoch: 190 | Loss: 0.4921577572822571 | Test loss: 0.5133710503578186\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7431]])), ('linear_layer.bias', tensor([0.7750]))])\n",
            "Loss:0.49182596802711487\n",
            "Loss:0.4914942681789398\n",
            "Loss:0.49116262793540955\n",
            "Loss:0.4908308982849121\n",
            "Loss:0.49049925804138184\n",
            "Loss:0.4901675581932068\n",
            "Loss:0.4898358881473541\n",
            "Loss:0.48950424790382385\n",
            "Loss:0.4891725182533264\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5870525240898132\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5548404455184937\n",
            "Loss:0.5545028448104858\n",
            "Loss:0.5541654229164124\n",
            "Loss:0.5538278818130493\n",
            "Loss:0.5534903407096863\n",
            "Loss:0.553152859210968\n",
            "Loss:0.552815318107605\n",
            "Loss:0.5524778366088867\n",
            "Loss:0.5521402359008789\n",
            "Loss:0.5518027544021606\n",
            "Epoch: 10 | Loss: 0.5518027544021606 | Test loss: 0.5831060409545898\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8268]))])\n",
            "Loss:0.5514651536941528\n",
            "Loss:0.5511277318000793\n",
            "Loss:0.5507901906967163\n",
            "Loss:0.5504526495933533\n",
            "Loss:0.5501151084899902\n",
            "Loss:0.549777626991272\n",
            "Loss:0.5494401454925537\n",
            "Loss:0.5491026043891907\n",
            "Loss:0.5487650632858276\n",
            "Loss:0.5484275221824646\n",
            "Epoch: 20 | Loss: 0.5484275221824646 | Test loss: 0.5791595578193665\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7621]])), ('linear_layer.bias', tensor([0.8239]))])\n",
            "Loss:0.5480901002883911\n",
            "Loss:0.5477524995803833\n",
            "Loss:0.5474149584770203\n",
            "Loss:0.547077476978302\n",
            "Loss:0.546739935874939\n",
            "Loss:0.5464024543762207\n",
            "Loss:0.5460649132728577\n",
            "Loss:0.5457274317741394\n",
            "Loss:0.5453899502754211\n",
            "Loss:0.5450523495674133\n",
            "Epoch: 30 | Loss: 0.5450523495674133 | Test loss: 0.5752130746841431\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7610]])), ('linear_layer.bias', tensor([0.8209]))])\n",
            "Loss:0.5447148084640503\n",
            "Loss:0.5443772077560425\n",
            "Loss:0.5440398454666138\n",
            "Loss:0.5437023043632507\n",
            "Loss:0.5433647036552429\n",
            "Loss:0.5430272221565247\n",
            "Loss:0.5426896810531616\n",
            "Loss:0.5423522591590881\n",
            "Loss:0.5420146584510803\n",
            "Loss:0.5416771173477173\n",
            "Epoch: 40 | Loss: 0.5416771173477173 | Test loss: 0.5712665319442749\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7599]])), ('linear_layer.bias', tensor([0.8180]))])\n",
            "Loss:0.541339635848999\n",
            "Loss:0.5410021543502808\n",
            "Loss:0.5406646132469177\n",
            "Loss:0.5403270721435547\n",
            "Loss:0.5399895310401917\n",
            "Loss:0.5396521091461182\n",
            "Loss:0.5393145084381104\n",
            "Loss:0.5389769673347473\n",
            "Loss:0.5386394262313843\n",
            "Loss:0.5383020639419556\n",
            "Epoch: 50 | Loss: 0.5383020639419556 | Test loss: 0.5673200488090515\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7587]])), ('linear_layer.bias', tensor([0.8151]))])\n",
            "Loss:0.5379644632339478\n",
            "Loss:0.5376269221305847\n",
            "Loss:0.5372894406318665\n",
            "Loss:0.5369518995285034\n",
            "Loss:0.5366143584251404\n",
            "Loss:0.5362768769264221\n",
            "Loss:0.5359393358230591\n",
            "Loss:0.5356019139289856\n",
            "Loss:0.5352643132209778\n",
            "Loss:0.5349267721176147\n",
            "Epoch: 60 | Loss: 0.5349267721176147 | Test loss: 0.5633735060691833\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7576]])), ('linear_layer.bias', tensor([0.8121]))])\n",
            "Loss:0.5345892310142517\n",
            "Loss:0.5342518091201782\n",
            "Loss:0.5339142084121704\n",
            "Loss:0.5335766673088074\n",
            "Loss:0.5332391858100891\n",
            "Loss:0.5329016447067261\n",
            "Loss:0.5325641632080078\n",
            "Loss:0.5322266221046448\n",
            "Loss:0.5318891406059265\n",
            "Loss:0.5315515398979187\n",
            "Epoch: 70 | Loss: 0.5315515398979187 | Test loss: 0.5594270825386047\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7564]])), ('linear_layer.bias', tensor([0.8092]))])\n",
            "Loss:0.5312141180038452\n",
            "Loss:0.5308765172958374\n",
            "Loss:0.5305389761924744\n",
            "Loss:0.5302015542984009\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|    | 59/100 [00:18<00:12,  3.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5298639535903931\n",
            "Loss:0.5295264720916748\n",
            "Loss:0.5291889905929565\n",
            "Loss:0.5288513898849487\n",
            "Loss:0.5285139083862305\n",
            "Loss:0.5281764268875122\n",
            "Epoch: 80 | Loss: 0.5281764268875122 | Test loss: 0.5554805994033813\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7553]])), ('linear_layer.bias', tensor([0.8063]))])\n",
            "Loss:0.5278388857841492\n",
            "Loss:0.5275013446807861\n",
            "Loss:0.5271638631820679\n",
            "Loss:0.5268263220787048\n",
            "Loss:0.5264887809753418\n",
            "Loss:0.5261512994766235\n",
            "Loss:0.5258137583732605\n",
            "Loss:0.5254762768745422\n",
            "Loss:0.525138795375824\n",
            "Loss:0.5248012542724609\n",
            "Epoch: 90 | Loss: 0.5248012542724609 | Test loss: 0.5515340566635132\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7541]])), ('linear_layer.bias', tensor([0.8033]))])\n",
            "Loss:0.5244637131690979\n",
            "Loss:0.5241261720657349\n",
            "Loss:0.5237886309623718\n",
            "Loss:0.5234511494636536\n",
            "Loss:0.5231136083602905\n",
            "Loss:0.5227761268615723\n",
            "Loss:0.522438645362854\n",
            "Loss:0.5221010446548462\n",
            "Loss:0.5217635035514832\n",
            "Loss:0.5214260220527649\n",
            "Epoch: 100 | Loss: 0.5214260220527649 | Test loss: 0.547587513923645\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7530]])), ('linear_layer.bias', tensor([0.8004]))])\n",
            "Loss:0.5210884809494019\n",
            "Loss:0.5207509994506836\n",
            "Loss:0.5204134583473206\n",
            "Loss:0.5200759768486023\n",
            "Loss:0.5197384357452393\n",
            "Loss:0.519400954246521\n",
            "Loss:0.519063413143158\n",
            "Loss:0.5187259316444397\n",
            "Loss:0.5183883905410767\n",
            "Loss:0.5180508494377136\n",
            "Epoch: 110 | Loss: 0.5180508494377136 | Test loss: 0.5436410307884216\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7519]])), ('linear_layer.bias', tensor([0.7975]))])\n",
            "Loss:0.5177133679389954\n",
            "Loss:0.5173757672309875\n",
            "Loss:0.5170383453369141\n",
            "Loss:0.5167007446289062\n",
            "Loss:0.516363263130188\n",
            "Loss:0.5160256624221802\n",
            "Loss:0.5156881809234619\n",
            "Loss:0.5153506994247437\n",
            "Loss:0.5150131583213806\n",
            "Loss:0.5146756768226624\n",
            "Epoch: 120 | Loss: 0.5146756768226624 | Test loss: 0.5396945476531982\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7507]])), ('linear_layer.bias', tensor([0.7946]))])\n",
            "Loss:0.5143381357192993\n",
            "Loss:0.5140005946159363\n",
            "Loss:0.5136630535125732\n",
            "Loss:0.513325572013855\n",
            "Loss:0.5129879713058472\n",
            "Loss:0.5126506090164185\n",
            "Loss:0.5123130083084106\n",
            "Loss:0.5119754672050476\n",
            "Loss:0.5116379857063293\n",
            "Loss:0.5113004446029663\n",
            "Epoch: 130 | Loss: 0.5113004446029663 | Test loss: 0.5357480645179749\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7496]])), ('linear_layer.bias', tensor([0.7916]))])\n",
            "Loss:0.510962963104248\n",
            "Loss:0.510625422000885\n",
            "Loss:0.510287880897522\n",
            "Loss:0.5099504590034485\n",
            "Loss:0.5096128582954407\n",
            "Loss:0.5092753171920776\n",
            "Loss:0.5089377760887146\n",
            "Loss:0.5086002945899963\n",
            "Loss:0.5082628130912781\n",
            "Loss:0.5079252123832703\n",
            "Epoch: 140 | Loss: 0.5079252123832703 | Test loss: 0.5318015813827515\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7484]])), ('linear_layer.bias', tensor([0.7887]))])\n",
            "Loss:0.507587730884552\n",
            "Loss:0.507250189781189\n",
            "Loss:0.5069127678871155\n",
            "Loss:0.5065752267837524\n",
            "Loss:0.5062376260757446\n",
            "Loss:0.5059002041816711\n",
            "Loss:0.5055626630783081\n",
            "Loss:0.5052251219749451\n",
            "Loss:0.504887580871582\n",
            "Loss:0.5045500993728638\n",
            "Epoch: 150 | Loss: 0.5045500993728638 | Test loss: 0.5278550386428833\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7473]])), ('linear_layer.bias', tensor([0.7858]))])\n",
            "Loss:0.5042125582695007\n",
            "Loss:0.5038750171661377\n",
            "Loss:0.5035375356674194\n",
            "Loss:0.5031999349594116\n",
            "Loss:0.5028624534606934\n",
            "Loss:0.5025249719619751\n",
            "Loss:0.5021874308586121\n",
            "Loss:0.5018499493598938\n",
            "Loss:0.5015124082565308\n",
            "Loss:0.5011748671531677\n",
            "Epoch: 160 | Loss: 0.5011748671531677 | Test loss: 0.5239085555076599\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7461]])), ('linear_layer.bias', tensor([0.7828]))])\n",
            "Loss:0.5008373856544495\n",
            "Loss:0.5004998445510864\n",
            "Loss:0.5001623630523682\n",
            "Loss:0.49982476234436035\n",
            "Loss:0.4994872510433197\n",
            "Loss:0.49914979934692383\n",
            "Loss:0.4988122880458832\n",
            "Loss:0.49847474694252014\n",
            "Loss:0.4981371760368347\n",
            "Loss:0.49779972434043884\n",
            "Epoch: 170 | Loss: 0.49779972434043884 | Test loss: 0.5199620127677917\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7450]])), ('linear_layer.bias', tensor([0.7799]))])\n",
            "Loss:0.4974621832370758\n",
            "Loss:0.49712467193603516\n",
            "Loss:0.4967871308326721\n",
            "Loss:0.4964495599269867\n",
            "Loss:0.49611204862594604\n",
            "Loss:0.49577459692955017\n",
            "Loss:0.49543705582618713\n",
            "Loss:0.4950995445251465\n",
            "Loss:0.49476203322410583\n",
            "Loss:0.4944245219230652\n",
            "Epoch: 180 | Loss: 0.4944245219230652 | Test loss: 0.5160155296325684\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7439]])), ('linear_layer.bias', tensor([0.7770]))])\n",
            "Loss:0.49408698081970215\n",
            "Loss:0.4937495291233063\n",
            "Loss:0.49341195821762085\n",
            "Loss:0.4930744171142578\n",
            "Loss:0.49273690581321716\n",
            "Loss:0.4923993945121765\n",
            "Loss:0.49206191301345825\n",
            "Loss:0.4917243421077728\n",
            "Loss:0.4913868010044098\n",
            "Loss:0.4910493791103363\n",
            "Epoch: 190 | Loss: 0.4910493791103363 | Test loss: 0.5120689868927002\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7427]])), ('linear_layer.bias', tensor([0.7741]))])\n",
            "Loss:0.49071183800697327\n",
            "Loss:0.49037426710128784\n",
            "Loss:0.4900367856025696\n",
            "Loss:0.48969921469688416\n",
            "Loss:0.4893617033958435\n",
            "Loss:0.48902422189712524\n",
            "Loss:0.4886866509914398\n",
            "Loss:0.48834913969039917\n",
            "Loss:0.4880116581916809\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5870457291603088\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5548346638679504\n",
            "Loss:0.5544913411140442\n",
            "Loss:0.5541480183601379\n",
            "Loss:0.5538047552108765\n",
            "Loss:0.5534614324569702\n",
            "Loss:0.5531181693077087\n",
            "Loss:0.5527749061584473\n",
            "Loss:0.5524317026138306\n",
            "Loss:0.55208820104599\n",
            "Loss:0.5517450571060181\n",
            "Epoch: 10 | Loss: 0.5517450571060181 | Test loss: 0.5830317735671997\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7633]])), ('linear_layer.bias', tensor([0.8267]))])\n",
            "Loss:0.551401674747467\n",
            "Loss:0.5510584115982056\n",
            "Loss:0.5507150888442993\n",
            "Loss:0.5503717660903931\n",
            "Loss:0.5500285029411316\n",
            "Loss:0.5496852397918701\n",
            "Loss:0.5493419766426086\n",
            "Loss:0.5489986538887024\n",
            "Loss:0.5486553907394409\n",
            "Loss:0.5483120679855347\n",
            "Epoch: 20 | Loss: 0.5483120679855347 | Test loss: 0.5790175795555115\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7621]])), ('linear_layer.bias', tensor([0.8238]))])\n",
            "Loss:0.5479687452316284\n",
            "Loss:0.5476254224777222\n",
            "Loss:0.5472822189331055\n",
            "Loss:0.546938955783844\n",
            "Loss:0.5465956330299377\n",
            "Loss:0.5462523698806763\n",
            "Loss:0.54590904712677\n",
            "Loss:0.5455657839775085\n",
            "Loss:0.5452224016189575\n",
            "Loss:0.5448790788650513\n",
            "Epoch: 30 | Loss: 0.5448790788650513 | Test loss: 0.5750035643577576\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7609]])), ('linear_layer.bias', tensor([0.8208]))])\n",
            "Loss:0.5445358753204346\n",
            "Loss:0.5441926121711731\n",
            "Loss:0.5438492894172668\n",
            "Loss:0.5435059666633606\n",
            "Loss:0.5431627035140991\n",
            "Loss:0.5428193807601929\n",
            "Loss:0.5424760580062866\n",
            "Loss:0.5421327948570251\n",
            "Loss:0.5417895317077637\n",
            "Loss:0.541446328163147\n",
            "Epoch: 40 | Loss: 0.541446328163147 | Test loss: 0.5709894895553589\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7598]])), ('linear_layer.bias', tensor([0.8178]))])\n",
            "Loss:0.5411028861999512\n",
            "Loss:0.5407596826553345\n",
            "Loss:0.5404163599014282\n",
            "Loss:0.5400730967521667\n",
            "Loss:0.5397297143936157\n",
            "Loss:0.5393863916397095\n",
            "Loss:0.539043128490448\n",
            "Loss:0.5386998653411865\n",
            "Loss:0.5383565425872803\n",
            "Loss:0.5380132794380188\n",
            "Epoch: 50 | Loss: 0.5380132794380188 | Test loss: 0.5669754147529602\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7586]])), ('linear_layer.bias', tensor([0.8148]))])\n",
            "Loss:0.5376700162887573\n",
            "Loss:0.5373266935348511\n",
            "Loss:0.5369833707809448\n",
            "Loss:0.5366401076316833\n",
            "Loss:0.5362968444824219\n",
            "Loss:0.5359535813331604\n",
            "Loss:0.5356101989746094\n",
            "Loss:0.5352669954299927\n",
            "Loss:0.5349236726760864\n",
            "Loss:0.534580409526825\n",
            "Epoch: 60 | Loss: 0.534580409526825 | Test loss: 0.5629612803459167\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7574]])), ('linear_layer.bias', tensor([0.8118]))])\n",
            "Loss:0.5342370271682739\n",
            "Loss:0.5338937640190125\n",
            "Loss:0.533550500869751\n",
            "Loss:0.5332072377204895\n",
            "Loss:0.5328639149665833\n",
            "Loss:0.532520592212677\n",
            "Loss:0.5321773290634155\n",
            "Loss:0.5318340063095093\n",
            "Loss:0.531490683555603\n",
            "Loss:0.5311474204063416\n",
            "Epoch: 70 | Loss: 0.5311474204063416 | Test loss: 0.5589472055435181\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7563]])), ('linear_layer.bias', tensor([0.8089]))])\n",
            "Loss:0.5308041572570801\n",
            "Loss:0.5304608941078186\n",
            "Loss:0.5301175117492676\n",
            "Loss:0.5297743082046509\n",
            "Loss:0.5294309854507446\n",
            "Loss:0.5290877223014832\n",
            "Loss:0.5287443399429321\n",
            "Loss:0.5284010767936707\n",
            "Loss:0.5280577540397644\n",
            "Loss:0.5277144908905029\n",
            "Epoch: 80 | Loss: 0.5277144908905029 | Test loss: 0.5549331307411194\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7551]])), ('linear_layer.bias', tensor([0.8059]))])\n",
            "Loss:0.5273712277412415\n",
            "Loss:0.5270279049873352\n",
            "Loss:0.5266846418380737\n",
            "Loss:0.5263413190841675\n",
            "Loss:0.5259979963302612\n",
            "Loss:0.5256547331809998\n",
            "Loss:0.5253114700317383\n",
            "Loss:0.5249682068824768\n",
            "Loss:0.5246248245239258\n",
            "Loss:0.5242815613746643\n",
            "Epoch: 90 | Loss: 0.5242815613746643 | Test loss: 0.5509191155433655\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7540]])), ('linear_layer.bias', tensor([0.8029]))])\n",
            "Loss:0.5239382982254028\n",
            "Loss:0.5235950350761414\n",
            "Loss:0.5232516527175903\n",
            "Loss:0.5229083895683289\n",
            "Loss:0.5225651264190674\n",
            "Loss:0.5222218632698059\n",
            "Loss:0.5218785405158997\n",
            "Loss:0.5215352177619934\n",
            "Loss:0.5211919546127319\n",
            "Loss:0.5208486318588257\n",
            "Epoch: 100 | Loss: 0.5208486318588257 | Test loss: 0.546904981136322\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7528]])), ('linear_layer.bias', tensor([0.7999]))])\n",
            "Loss:0.5205053091049194\n",
            "Loss:0.520162045955658\n",
            "Loss:0.5198187828063965\n",
            "Loss:0.519475519657135\n",
            "Loss:0.519132137298584\n",
            "Loss:0.5187889337539673\n",
            "Loss:0.518445611000061\n",
            "Loss:0.5181023478507996\n",
            "Loss:0.5177589654922485\n",
            "Loss:0.5174157023429871\n",
            "Epoch: 110 | Loss: 0.5174157023429871 | Test loss: 0.5428909659385681\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7516]])), ('linear_layer.bias', tensor([0.7969]))])\n",
            "Loss:0.5170723795890808\n",
            "Loss:0.5167291164398193\n",
            "Loss:0.5163858532905579\n",
            "Loss:0.5160425305366516\n",
            "Loss:0.5156992673873901\n",
            "Loss:0.5153559446334839\n",
            "Loss:0.5150126218795776\n",
            "Loss:0.5146693587303162\n",
            "Loss:0.5143260955810547\n",
            "Loss:0.5139828324317932\n",
            "Epoch: 120 | Loss: 0.5139828324317932 | Test loss: 0.5388768911361694\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7505]])), ('linear_layer.bias', tensor([0.7940]))])\n",
            "Loss:0.5136394500732422\n",
            "Loss:0.5132961869239807\n",
            "Loss:0.5129529237747192\n",
            "Loss:0.5126096606254578\n",
            "Loss:0.5122662782669067\n",
            "Loss:0.5119230151176453\n",
            "Loss:0.5115797519683838\n",
            "Loss:0.5112364888191223\n",
            "Loss:0.5108931660652161\n",
            "Loss:0.5105498433113098\n",
            "Epoch: 130 | Loss: 0.5105498433113098 | Test loss: 0.5348628163337708\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7493]])), ('linear_layer.bias', tensor([0.7910]))])\n",
            "Loss:0.5102065801620483\n",
            "Loss:0.5098632574081421\n",
            "Loss:0.5095199346542358\n",
            "Loss:0.5091766715049744\n",
            "Loss:0.5088334083557129\n",
            "Loss:0.5084901452064514\n",
            "Loss:0.5081467628479004\n",
            "Loss:0.5078035593032837\n",
            "Loss:0.5074602365493774\n",
            "Loss:0.507116973400116\n",
            "Epoch: 140 | Loss: 0.507116973400116 | Test loss: 0.5308486819267273\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7482]])), ('linear_layer.bias', tensor([0.7880]))])\n",
            "Loss:0.5067735910415649\n",
            "Loss:0.5064303278923035\n",
            "Loss:0.5060870051383972\n",
            "Loss:0.5057437419891357\n",
            "Loss:0.5054004788398743\n",
            "Loss:0.505057156085968\n",
            "Loss:0.5047138929367065\n",
            "Loss:0.5043705701828003\n",
            "Loss:0.504027247428894\n",
            "Loss:0.5036839842796326\n",
            "Epoch: 150 | Loss: 0.5036839842796326 | Test loss: 0.5268346071243286\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7470]])), ('linear_layer.bias', tensor([0.7850]))])\n",
            "Loss:0.5033407211303711\n",
            "Loss:0.5029974579811096\n",
            "Loss:0.5026541352272034\n",
            "Loss:0.5023108124732971\n",
            "Loss:0.5019675493240356\n",
            "Loss:0.5016242861747742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|    | 60/100 [00:18<00:12,  3.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5012809038162231\n",
            "Loss:0.5009376406669617\n",
            "Loss:0.5005943775177002\n",
            "Loss:0.5002511143684387\n",
            "Epoch: 160 | Loss: 0.5002511143684387 | Test loss: 0.5228205323219299\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7458]])), ('linear_layer.bias', tensor([0.7820]))])\n",
            "Loss:0.4999077320098877\n",
            "Loss:0.4995644688606262\n",
            "Loss:0.49922117590904236\n",
            "Loss:0.4988779127597809\n",
            "Loss:0.49853459000587463\n",
            "Loss:0.49819129705429077\n",
            "Loss:0.4978480339050293\n",
            "Loss:0.49750471115112305\n",
            "Loss:0.4971613883972168\n",
            "Loss:0.4968181550502777\n",
            "Epoch: 170 | Loss: 0.4968181550502777 | Test loss: 0.518806517124176\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7447]])), ('linear_layer.bias', tensor([0.7791]))])\n",
            "Loss:0.49647483229637146\n",
            "Loss:0.4961315095424652\n",
            "Loss:0.49578824639320374\n",
            "Loss:0.4954449534416199\n",
            "Loss:0.4951016306877136\n",
            "Loss:0.4947583079338074\n",
            "Loss:0.4944150447845459\n",
            "Loss:0.4940717816352844\n",
            "Loss:0.49372848868370056\n",
            "Loss:0.4933852255344391\n",
            "Epoch: 180 | Loss: 0.4933852255344391 | Test loss: 0.5147923827171326\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7435]])), ('linear_layer.bias', tensor([0.7761]))])\n",
            "Loss:0.49304190278053284\n",
            "Loss:0.492698609828949\n",
            "Loss:0.4923552870750427\n",
            "Loss:0.49201202392578125\n",
            "Loss:0.491668701171875\n",
            "Loss:0.4913254380226135\n",
            "Loss:0.49098214507102966\n",
            "Loss:0.4906388223171234\n",
            "Loss:0.49029555916786194\n",
            "Loss:0.4899522662162781\n",
            "Epoch: 190 | Loss: 0.4899522662162781 | Test loss: 0.5107783675193787\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7423]])), ('linear_layer.bias', tensor([0.7731]))])\n",
            "Loss:0.4896090030670166\n",
            "Loss:0.4892657399177551\n",
            "Loss:0.4889223575592041\n",
            "Loss:0.4885790944099426\n",
            "Loss:0.48823580145835876\n",
            "Loss:0.4878925383090973\n",
            "Loss:0.48754921555519104\n",
            "Loss:0.4872059226036072\n",
            "Loss:0.4868626594543457\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5870389342308044\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5548288226127625\n",
            "Loss:0.554479718208313\n",
            "Loss:0.5541306138038635\n",
            "Loss:0.5537813901901245\n",
            "Loss:0.5534323453903198\n",
            "Loss:0.5530831813812256\n",
            "Loss:0.5527340173721313\n",
            "Loss:0.5523849129676819\n",
            "Loss:0.5520358085632324\n",
            "Loss:0.5516866445541382\n",
            "Epoch: 10 | Loss: 0.5516866445541382 | Test loss: 0.5829567909240723\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7632]])), ('linear_layer.bias', tensor([0.8267]))])\n",
            "Loss:0.5513375997543335\n",
            "Loss:0.5509883761405945\n",
            "Loss:0.550639271736145\n",
            "Loss:0.5502901673316956\n",
            "Loss:0.5499410033226013\n",
            "Loss:0.5495918989181519\n",
            "Loss:0.5492427945137024\n",
            "Loss:0.5488936305046082\n",
            "Loss:0.5485445261001587\n",
            "Loss:0.548195481300354\n",
            "Epoch: 20 | Loss: 0.548195481300354 | Test loss: 0.5788744688034058\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7621]])), ('linear_layer.bias', tensor([0.8236]))])\n",
            "Loss:0.5478463172912598\n",
            "Loss:0.5474971532821655\n",
            "Loss:0.5471480488777161\n",
            "Loss:0.5467988848686218\n",
            "Loss:0.5464497804641724\n",
            "Loss:0.5461006760597229\n",
            "Loss:0.5457515716552734\n",
            "Loss:0.5454024076461792\n",
            "Loss:0.545053243637085\n",
            "Loss:0.5447040796279907\n",
            "Epoch: 30 | Loss: 0.5447040796279907 | Test loss: 0.574792206287384\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7609]])), ('linear_layer.bias', tensor([0.8206]))])\n",
            "Loss:0.544355034828186\n",
            "Loss:0.5440058708190918\n",
            "Loss:0.5436567664146423\n",
            "Loss:0.5433076620101929\n",
            "Loss:0.5429584980010986\n",
            "Loss:0.5426093935966492\n",
            "Loss:0.5422602891921997\n",
            "Loss:0.5419111251831055\n",
            "Loss:0.5415619611740112\n",
            "Loss:0.5412128567695618\n",
            "Epoch: 40 | Loss: 0.5412128567695618 | Test loss: 0.5707100033760071\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7597]])), ('linear_layer.bias', tensor([0.8176]))])\n",
            "Loss:0.5408637523651123\n",
            "Loss:0.5405145883560181\n",
            "Loss:0.5401654839515686\n",
            "Loss:0.5398163795471191\n",
            "Loss:0.5394672751426697\n",
            "Loss:0.5391181111335754\n",
            "Loss:0.538769006729126\n",
            "Loss:0.5384198427200317\n",
            "Loss:0.5380706787109375\n",
            "Loss:0.5377216339111328\n",
            "Epoch: 50 | Loss: 0.5377216339111328 | Test loss: 0.5666278004646301\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7585]])), ('linear_layer.bias', tensor([0.8146]))])\n",
            "Loss:0.5373724699020386\n",
            "Loss:0.5370233654975891\n",
            "Loss:0.5366742014884949\n",
            "Loss:0.5363251566886902\n",
            "Loss:0.535975992679596\n",
            "Loss:0.5356268286705017\n",
            "Loss:0.5352777242660522\n",
            "Loss:0.5349286198616028\n",
            "Loss:0.5345793962478638\n",
            "Loss:0.5342303514480591\n",
            "Epoch: 60 | Loss: 0.5342303514480591 | Test loss: 0.5625454783439636\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7573]])), ('linear_layer.bias', tensor([0.8115]))])\n",
            "Loss:0.5338811874389648\n",
            "Loss:0.5335320234298706\n",
            "Loss:0.5331829786300659\n",
            "Loss:0.5328338742256165\n",
            "Loss:0.5324847102165222\n",
            "Loss:0.5321356058120728\n",
            "Loss:0.5317865014076233\n",
            "Loss:0.5314372777938843\n",
            "Loss:0.5310882329940796\n",
            "Loss:0.5307390689849854\n",
            "Epoch: 70 | Loss: 0.5307390689849854 | Test loss: 0.5584632754325867\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7561]])), ('linear_layer.bias', tensor([0.8085]))])\n",
            "Loss:0.5303899049758911\n",
            "Loss:0.5300408601760864\n",
            "Loss:0.5296916961669922\n",
            "Loss:0.529342532157898\n",
            "Loss:0.5289934873580933\n",
            "Loss:0.5286443829536438\n",
            "Loss:0.5282951593399048\n",
            "Loss:0.5279460549354553\n",
            "Loss:0.5275969505310059\n",
            "Loss:0.5272477865219116\n",
            "Epoch: 80 | Loss: 0.5272477865219116 | Test loss: 0.5543810129165649\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7550]])), ('linear_layer.bias', tensor([0.8055]))])\n",
            "Loss:0.5268986821174622\n",
            "Loss:0.5265495181083679\n",
            "Loss:0.5262004137039185\n",
            "Loss:0.525851309299469\n",
            "Loss:0.5255022048950195\n",
            "Loss:0.5251530408859253\n",
            "Loss:0.5248039364814758\n",
            "Loss:0.5244547724723816\n",
            "Loss:0.5241056680679321\n",
            "Loss:0.5237565636634827\n",
            "Epoch: 90 | Loss: 0.5237565636634827 | Test loss: 0.550298810005188\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7538]])), ('linear_layer.bias', tensor([0.8024]))])\n",
            "Loss:0.5234073996543884\n",
            "Loss:0.523058295249939\n",
            "Loss:0.5227091908454895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|    | 61/100 [00:18<00:11,  3.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5223600268363953\n",
            "Loss:0.5220109224319458\n",
            "Loss:0.5216618180274963\n",
            "Loss:0.5213126540184021\n",
            "Loss:0.5209635496139526\n",
            "Loss:0.5206144452095032\n",
            "Loss:0.5202652215957642\n",
            "Epoch: 100 | Loss: 0.5202652215957642 | Test loss: 0.5462165474891663\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7526]])), ('linear_layer.bias', tensor([0.7994]))])\n",
            "Loss:0.5199161767959595\n",
            "Loss:0.5195670127868652\n",
            "Loss:0.519217848777771\n",
            "Loss:0.5188688039779663\n",
            "Loss:0.5185196995735168\n",
            "Loss:0.5181705355644226\n",
            "Loss:0.5178214311599731\n",
            "Loss:0.5174723267555237\n",
            "Loss:0.5171231031417847\n",
            "Loss:0.51677405834198\n",
            "Epoch: 110 | Loss: 0.51677405834198 | Test loss: 0.5421342849731445\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7514]])), ('linear_layer.bias', tensor([0.7964]))])\n",
            "Loss:0.5164248943328857\n",
            "Loss:0.5160757303237915\n",
            "Loss:0.5157265663146973\n",
            "Loss:0.5153775215148926\n",
            "Loss:0.5150284171104431\n",
            "Loss:0.5146793127059937\n",
            "Loss:0.5143301486968994\n",
            "Loss:0.5139809846878052\n",
            "Loss:0.5136319398880005\n",
            "Loss:0.5132827758789062\n",
            "Epoch: 120 | Loss: 0.5132827758789062 | Test loss: 0.5380521416664124\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7502]])), ('linear_layer.bias', tensor([0.7933]))])\n",
            "Loss:0.512933611869812\n",
            "Loss:0.5125845074653625\n",
            "Loss:0.5122353434562683\n",
            "Loss:0.5118862390518188\n",
            "Loss:0.5115371942520142\n",
            "Loss:0.5111879706382751\n",
            "Loss:0.5108388662338257\n",
            "Loss:0.5104897022247314\n",
            "Loss:0.510140597820282\n",
            "Loss:0.5097914934158325\n",
            "Epoch: 130 | Loss: 0.5097914934158325 | Test loss: 0.5339698195457458\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7491]])), ('linear_layer.bias', tensor([0.7903]))])\n",
            "Loss:0.5094423890113831\n",
            "Loss:0.5090932250022888\n",
            "Loss:0.5087441205978394\n",
            "Loss:0.5083950161933899\n",
            "Loss:0.5080458521842957\n",
            "Loss:0.5076967477798462\n",
            "Loss:0.5073476433753967\n",
            "Loss:0.5069984793663025\n",
            "Loss:0.506649374961853\n",
            "Loss:0.5063002109527588\n",
            "Epoch: 140 | Loss: 0.5063002109527588 | Test loss: 0.5298875570297241\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7479]])), ('linear_layer.bias', tensor([0.7873]))])\n",
            "Loss:0.5059510469436646\n",
            "Loss:0.5056020021438599\n",
            "Loss:0.5052528381347656\n",
            "Loss:0.5049036741256714\n",
            "Loss:0.5045546293258667\n",
            "Loss:0.5042055249214172\n",
            "Loss:0.503856360912323\n",
            "Loss:0.5035071969032288\n",
            "Loss:0.5031580924987793\n",
            "Loss:0.5028089284896851\n",
            "Epoch: 150 | Loss: 0.5028089284896851 | Test loss: 0.5258052349090576\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7467]])), ('linear_layer.bias', tensor([0.7843]))])\n",
            "Loss:0.5024598240852356\n",
            "Loss:0.5021107792854309\n",
            "Loss:0.5017615556716919\n",
            "Loss:0.5014125108718872\n",
            "Loss:0.501063346862793\n",
            "Loss:0.5007142424583435\n",
            "Loss:0.500365138053894\n",
            "Loss:0.500015914440155\n",
            "Loss:0.49966683983802795\n",
            "Loss:0.4993177056312561\n",
            "Epoch: 160 | Loss: 0.4993177056312561 | Test loss: 0.5217230319976807\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7455]])), ('linear_layer.bias', tensor([0.7812]))])\n",
            "Loss:0.49896854162216187\n",
            "Loss:0.49861940741539\n",
            "Loss:0.49827027320861816\n",
            "Loss:0.4979211688041687\n",
            "Loss:0.49757203459739685\n",
            "Loss:0.49722298979759216\n",
            "Loss:0.49687379598617554\n",
            "Loss:0.49652472138404846\n",
            "Loss:0.4961755871772766\n",
            "Loss:0.4958264231681824\n",
            "Epoch: 170 | Loss: 0.4958264231681824 | Test loss: 0.5176407694816589\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7443]])), ('linear_layer.bias', tensor([0.7782]))])\n",
            "Loss:0.4954772889614105\n",
            "Loss:0.49512821435928345\n",
            "Loss:0.4947790503501892\n",
            "Loss:0.49442997574806213\n",
            "Loss:0.4940808415412903\n",
            "Loss:0.49373167753219604\n",
            "Loss:0.4933825433254242\n",
            "Loss:0.4930334687232971\n",
            "Loss:0.4926842749118805\n",
            "Loss:0.49233517050743103\n",
            "Epoch: 180 | Loss: 0.49233517050743103 | Test loss: 0.513558566570282\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7431]])), ('linear_layer.bias', tensor([0.7752]))])\n",
            "Loss:0.4919860363006592\n",
            "Loss:0.49163690209388733\n",
            "Loss:0.49128779768943787\n",
            "Loss:0.490938663482666\n",
            "Loss:0.49058952927589417\n",
            "Loss:0.4902403950691223\n",
            "Loss:0.48989129066467285\n",
            "Loss:0.489542156457901\n",
            "Loss:0.48919305205345154\n",
            "Loss:0.4888439178466797\n",
            "Epoch: 190 | Loss: 0.4888439178466797 | Test loss: 0.5094763040542603\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7420]])), ('linear_layer.bias', tensor([0.7721]))])\n",
            "Loss:0.48849478363990784\n",
            "Loss:0.4881456792354584\n",
            "Loss:0.48779648542404175\n",
            "Loss:0.4874473512172699\n",
            "Loss:0.48709821701049805\n",
            "Loss:0.4867490828037262\n",
            "Loss:0.4864000678062439\n",
            "Loss:0.48605093359947205\n",
            "Loss:0.4857017397880554\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5870321989059448\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5548229217529297\n",
            "Loss:0.5544679760932922\n",
            "Loss:0.5541130304336548\n",
            "Loss:0.5537580847740173\n",
            "Loss:0.5534031987190247\n",
            "Loss:0.5530481338500977\n",
            "Loss:0.552693247795105\n",
            "Loss:0.5523382425308228\n",
            "Loss:0.5519832372665405\n",
            "Loss:0.5516283512115479\n",
            "Epoch: 10 | Loss: 0.5516283512115479 | Test loss: 0.5828816890716553\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7632]])), ('linear_layer.bias', tensor([0.8266]))])\n",
            "Loss:0.5512733459472656\n",
            "Loss:0.550918459892273\n",
            "Loss:0.5505634546279907\n",
            "Loss:0.5502085089683533\n",
            "Loss:0.549853503704071\n",
            "Loss:0.5494986176490784\n",
            "Loss:0.5491436719894409\n",
            "Loss:0.5487886667251587\n",
            "Loss:0.5484336614608765\n",
            "Loss:0.548078715801239\n",
            "Epoch: 20 | Loss: 0.548078715801239 | Test loss: 0.5787312984466553\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7620]])), ('linear_layer.bias', tensor([0.8235]))])\n",
            "Loss:0.5477237701416016\n",
            "Loss:0.5473688244819641\n",
            "Loss:0.5470138788223267\n",
            "Loss:0.5466588735580444\n",
            "Loss:0.546303927898407\n",
            "Loss:0.5459489226341248\n",
            "Loss:0.5455940365791321\n",
            "Loss:0.5452390909194946\n",
            "Loss:0.5448840856552124\n",
            "Loss:0.5445290803909302\n",
            "Epoch: 30 | Loss: 0.5445290803909302 | Test loss: 0.5745809674263\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7608]])), ('linear_layer.bias', tensor([0.8205]))])\n",
            "Loss:0.5441741943359375\n",
            "Loss:0.5438192486763\n",
            "Loss:0.5434643030166626\n",
            "Loss:0.5431092977523804\n",
            "Loss:0.5427543520927429\n",
            "Loss:0.5423992872238159\n",
            "Loss:0.5420444011688232\n",
            "Loss:0.541689395904541\n",
            "Loss:0.5413345098495483\n",
            "Loss:0.5409795045852661\n",
            "Epoch: 40 | Loss: 0.5409795045852661 | Test loss: 0.5704305171966553\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7596]])), ('linear_layer.bias', tensor([0.8174]))])\n",
            "Loss:0.5406244993209839\n",
            "Loss:0.5402696132659912\n",
            "Loss:0.5399146676063538\n",
            "Loss:0.5395596623420715\n",
            "Loss:0.5392047762870789\n",
            "Loss:0.5388497710227966\n",
            "Loss:0.5384947657585144\n",
            "Loss:0.538139820098877\n",
            "Loss:0.5377848744392395\n",
            "Loss:0.537429928779602\n",
            "Epoch: 50 | Loss: 0.537429928779602 | Test loss: 0.5662800073623657\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7584]])), ('linear_layer.bias', tensor([0.8143]))])\n",
            "Loss:0.5370749235153198\n",
            "Loss:0.5367200970649719\n",
            "Loss:0.5363650321960449\n",
            "Loss:0.5360100865364075\n",
            "Loss:0.53565514087677\n",
            "Loss:0.5353001356124878\n",
            "Loss:0.5349451899528503\n",
            "Loss:0.5345902442932129\n",
            "Loss:0.5342353582382202\n",
            "Loss:0.533880352973938\n",
            "Epoch: 60 | Loss: 0.533880352973938 | Test loss: 0.5621296763420105\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7572]])), ('linear_layer.bias', tensor([0.8112]))])\n",
            "Loss:0.5335253477096558\n",
            "Loss:0.5331704020500183\n",
            "Loss:0.5328154563903809\n",
            "Loss:0.5324605107307434\n",
            "Loss:0.532105565071106\n",
            "Loss:0.5317505598068237\n",
            "Loss:0.5313955545425415\n",
            "Loss:0.531040608882904\n",
            "Loss:0.5306856632232666\n",
            "Loss:0.5303307175636292\n",
            "Epoch: 70 | Loss: 0.5303307175636292 | Test loss: 0.5579792261123657\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7560]])), ('linear_layer.bias', tensor([0.8081]))])\n",
            "Loss:0.5299757719039917\n",
            "Loss:0.5296207666397095\n",
            "Loss:0.5292658805847168\n",
            "Loss:0.5289108753204346\n",
            "Loss:0.5285559296607971\n",
            "Loss:0.5282009840011597\n",
            "Loss:0.5278460383415222\n",
            "Loss:0.5274909734725952\n",
            "Loss:0.5271360874176025\n",
            "Loss:0.5267811417579651\n",
            "Epoch: 80 | Loss: 0.5267811417579651 | Test loss: 0.5538288950920105\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7548]])), ('linear_layer.bias', tensor([0.8051]))])\n",
            "Loss:0.5264261960983276\n",
            "Loss:0.5260712504386902\n",
            "Loss:0.525716245174408\n",
            "Loss:0.5253612995147705\n",
            "Loss:0.5250063538551331\n",
            "Loss:0.5246514081954956\n",
            "Loss:0.5242964029312134\n",
            "Loss:0.5239413976669312\n",
            "Loss:0.5235865116119385\n",
            "Loss:0.523231565952301\n",
            "Epoch: 90 | Loss: 0.523231565952301 | Test loss: 0.5496784448623657\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7536]])), ('linear_layer.bias', tensor([0.8020]))])\n",
            "Loss:0.5228765606880188\n",
            "Loss:0.5225216150283813\n",
            "Loss:0.5221666693687439\n",
            "Loss:0.5218117237091064\n",
            "Loss:0.521456778049469\n",
            "Loss:0.5211017727851868\n",
            "Loss:0.5207468271255493\n",
            "Loss:0.5203918218612671\n",
            "Loss:0.5200368762016296\n",
            "Loss:0.5196819305419922\n",
            "Epoch: 100 | Loss: 0.5196819305419922 | Test loss: 0.5455280542373657\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7524]])), ('linear_layer.bias', tensor([0.7989]))])\n",
            "Loss:0.5193269848823547\n",
            "Loss:0.5189720392227173\n",
            "Loss:0.5186170339584351\n",
            "Loss:0.5182620882987976\n",
            "Loss:0.5179071426391602\n",
            "Loss:0.5175521969795227\n",
            "Loss:0.5171971917152405\n",
            "Loss:0.516842246055603\n",
            "Loss:0.5164873003959656\n",
            "Loss:0.5161322951316833\n",
            "Epoch: 110 | Loss: 0.5161322951316833 | Test loss: 0.5413776636123657\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7512]])), ('linear_layer.bias', tensor([0.7958]))])\n",
            "Loss:0.5157774090766907\n",
            "Loss:0.5154224634170532\n",
            "Loss:0.515067458152771\n",
            "Loss:0.5147125124931335\n",
            "Loss:0.5143574476242065\n",
            "Loss:0.5140025615692139\n",
            "Loss:0.5136476755142212\n",
            "Loss:0.513292670249939\n",
            "Loss:0.5129376649856567\n",
            "Loss:0.5125827789306641\n",
            "Epoch: 120 | Loss: 0.5125827789306641 | Test loss: 0.5372272729873657\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7500]])), ('linear_layer.bias', tensor([0.7927]))])\n",
            "Loss:0.5122277736663818\n",
            "Loss:0.5118728876113892\n",
            "Loss:0.5115178823471069\n",
            "Loss:0.5111628770828247\n",
            "Loss:0.5108079314231873\n",
            "Loss:0.5104530453681946\n",
            "Loss:0.5100980401039124\n",
            "Loss:0.5097430944442749\n",
            "Loss:0.5093880891799927\n",
            "Loss:0.5090330839157104\n",
            "Epoch: 130 | Loss: 0.5090330839157104 | Test loss: 0.5330767631530762\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7488]])), ('linear_layer.bias', tensor([0.7896]))])\n",
            "Loss:0.5086781978607178\n",
            "Loss:0.5083232522010803\n",
            "Loss:0.5079683065414429\n",
            "Loss:0.5076133012771606\n",
            "Loss:0.5072582960128784\n",
            "Loss:0.506903350353241\n",
            "Loss:0.5065484046936035\n",
            "Loss:0.5061934590339661\n",
            "Loss:0.5058384537696838\n",
            "Loss:0.5054835081100464\n",
            "Epoch: 140 | Loss: 0.5054835081100464 | Test loss: 0.5289263725280762\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7476]])), ('linear_layer.bias', tensor([0.7866]))])\n",
            "Loss:0.5051285624504089\n",
            "Loss:0.5047736167907715\n",
            "Loss:0.504418671131134\n",
            "Loss:0.5040637254714966\n",
            "Loss:0.5037087202072144\n",
            "Loss:0.5033537745475769\n",
            "Loss:0.5029988288879395\n",
            "Loss:0.5026438236236572\n",
            "Loss:0.5022889375686646\n",
            "Loss:0.5019339323043823\n",
            "Epoch: 150 | Loss: 0.5019339323043823 | Test loss: 0.5247759222984314\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7464]])), ('linear_layer.bias', tensor([0.7835]))])\n",
            "Loss:0.5015789866447449\n",
            "Loss:0.5012240409851074\n",
            "Loss:0.5008690357208252\n",
            "Loss:0.5005141496658325\n",
            "Loss:0.5001591444015503\n",
            "Loss:0.49980416893959045\n",
            "Loss:0.4994491934776306\n",
            "Loss:0.49909424781799316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|   | 62/100 [00:19<00:11,  3.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.4987393021583557\n",
            "Loss:0.4983842968940735\n",
            "Epoch: 160 | Loss: 0.4983842968940735 | Test loss: 0.5206255912780762\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7452]])), ('linear_layer.bias', tensor([0.7804]))])\n",
            "Loss:0.4980293810367584\n",
            "Loss:0.4976743757724762\n",
            "Loss:0.49731945991516113\n",
            "Loss:0.4969645142555237\n",
            "Loss:0.49660953879356384\n",
            "Loss:0.4962545931339264\n",
            "Loss:0.49589958786964417\n",
            "Loss:0.4955446124076843\n",
            "Loss:0.4951896667480469\n",
            "Loss:0.4948347508907318\n",
            "Epoch: 170 | Loss: 0.4948347508907318 | Test loss: 0.5164750814437866\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7440]])), ('linear_layer.bias', tensor([0.7773]))])\n",
            "Loss:0.49447980523109436\n",
            "Loss:0.4941248297691345\n",
            "Loss:0.4937698245048523\n",
            "Loss:0.4934149384498596\n",
            "Loss:0.4930599331855774\n",
            "Loss:0.49270501732826233\n",
            "Loss:0.4923500120639801\n",
            "Loss:0.49199503660202026\n",
            "Loss:0.4916401505470276\n",
            "Loss:0.49128514528274536\n",
            "Epoch: 180 | Loss: 0.49128514528274536 | Test loss: 0.5123246908187866\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7428]])), ('linear_layer.bias', tensor([0.7742]))])\n",
            "Loss:0.4909301698207855\n",
            "Loss:0.49057522416114807\n",
            "Loss:0.49022024869918823\n",
            "Loss:0.4898653030395508\n",
            "Loss:0.48951035737991333\n",
            "Loss:0.4891553819179535\n",
            "Loss:0.48880043625831604\n",
            "Loss:0.4884454607963562\n",
            "Loss:0.48809051513671875\n",
            "Loss:0.4877355694770813\n",
            "Epoch: 190 | Loss: 0.4877355694770813 | Test loss: 0.5081743001937866\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7416]])), ('linear_layer.bias', tensor([0.7712]))])\n",
            "Loss:0.4873805642127991\n",
            "Loss:0.487025648355484\n",
            "Loss:0.4866706430912018\n",
            "Loss:0.4863157272338867\n",
            "Loss:0.4859607219696045\n",
            "Loss:0.48560580611228943\n",
            "Loss:0.4852508008480072\n",
            "Loss:0.48489588499069214\n",
            "Loss:0.4845409393310547\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5870254039764404\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5548171997070312\n",
            "Loss:0.5544564127922058\n",
            "Loss:0.5540957450866699\n",
            "Loss:0.5537349581718445\n",
            "Loss:0.5533742904663086\n",
            "Loss:0.5530135035514832\n",
            "Loss:0.5526527762413025\n",
            "Loss:0.5522920489311218\n",
            "Loss:0.5519313216209412\n",
            "Loss:0.5515705347061157\n",
            "Epoch: 10 | Loss: 0.5515705347061157 | Test loss: 0.5828073620796204\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7632]])), ('linear_layer.bias', tensor([0.8266]))])\n",
            "Loss:0.5512098073959351\n",
            "Loss:0.5508490800857544\n",
            "Loss:0.5504883527755737\n",
            "Loss:0.5501276850700378\n",
            "Loss:0.5497668981552124\n",
            "Loss:0.5494061708450317\n",
            "Loss:0.5490454435348511\n",
            "Loss:0.5486847162246704\n",
            "Loss:0.5483239889144897\n",
            "Loss:0.5479632616043091\n",
            "Epoch: 20 | Loss: 0.5479632616043091 | Test loss: 0.5785894393920898\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7620]])), ('linear_layer.bias', tensor([0.8234]))])\n",
            "Loss:0.5476024746894836\n",
            "Loss:0.5472418069839478\n",
            "Loss:0.5468810796737671\n",
            "Loss:0.5465202927589417\n",
            "Loss:0.5461596250534058\n",
            "Loss:0.5457988381385803\n",
            "Loss:0.5454381704330444\n",
            "Loss:0.545077383518219\n",
            "Loss:0.5447166562080383\n",
            "Loss:0.5443559288978577\n",
            "Epoch: 30 | Loss: 0.5443559288978577 | Test loss: 0.5743714570999146\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7608]])), ('linear_layer.bias', tensor([0.8203]))])\n",
            "Loss:0.5439952611923218\n",
            "Loss:0.5436344742774963\n",
            "Loss:0.5432736873626709\n",
            "Loss:0.542913019657135\n",
            "Loss:0.5425522923469543\n",
            "Loss:0.5421915054321289\n",
            "Loss:0.541830837726593\n",
            "Loss:0.5414701104164124\n",
            "Loss:0.5411092638969421\n",
            "Loss:0.5407485365867615\n",
            "Epoch: 40 | Loss: 0.5407485365867615 | Test loss: 0.5701534748077393\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7595]])), ('linear_layer.bias', tensor([0.8172]))])\n",
            "Loss:0.5403878092765808\n",
            "Loss:0.5400270223617554\n",
            "Loss:0.5396663546562195\n",
            "Loss:0.539305567741394\n",
            "Loss:0.5389449000358582\n",
            "Loss:0.5385841727256775\n",
            "Loss:0.5382234454154968\n",
            "Loss:0.5378627181053162\n",
            "Loss:0.5375019907951355\n",
            "Loss:0.5371412038803101\n",
            "Epoch: 50 | Loss: 0.5371412038803101 | Test loss: 0.565935492515564\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7583]])), ('linear_layer.bias', tensor([0.8140]))])\n",
            "Loss:0.5367805361747742\n",
            "Loss:0.5364197492599487\n",
            "Loss:0.5360590219497681\n",
            "Loss:0.5356982946395874\n",
            "Loss:0.5353375673294067\n",
            "Loss:0.5349768400192261\n",
            "Loss:0.5346161127090454\n",
            "Loss:0.53425532579422\n",
            "Loss:0.5338945984840393\n",
            "Loss:0.5335338711738586\n",
            "Epoch: 60 | Loss: 0.5335338711738586 | Test loss: 0.5617174506187439\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7571]])), ('linear_layer.bias', tensor([0.8109]))])\n",
            "Loss:0.5331732034683228\n",
            "Loss:0.5328124761581421\n",
            "Loss:0.5324516892433167\n",
            "Loss:0.532090961933136\n",
            "Loss:0.5317302346229553\n",
            "Loss:0.5313695073127747\n",
            "Loss:0.531008780002594\n",
            "Loss:0.5306480526924133\n",
            "Loss:0.5302872657775879\n",
            "Loss:0.529926598072052\n",
            "Epoch: 70 | Loss: 0.529926598072052 | Test loss: 0.5574994683265686\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7559]])), ('linear_layer.bias', tensor([0.8078]))])\n",
            "Loss:0.5295658111572266\n",
            "Loss:0.5292050838470459\n",
            "Loss:0.5288443565368652\n",
            "Loss:0.5284835696220398\n",
            "Loss:0.5281227827072144\n",
            "Loss:0.5277621150016785\n",
            "Loss:0.5274014472961426\n",
            "Loss:0.5270406603813171\n",
            "Loss:0.5266799330711365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|   | 63/100 [00:19<00:11,  3.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5263192057609558\n",
            "Epoch: 80 | Loss: 0.5263192057609558 | Test loss: 0.5532815456390381\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7546]])), ('linear_layer.bias', tensor([0.8046]))])\n",
            "Loss:0.5259584188461304\n",
            "Loss:0.5255977511405945\n",
            "Loss:0.5252370238304138\n",
            "Loss:0.5248762965202332\n",
            "Loss:0.5245155096054077\n",
            "Loss:0.524154782295227\n",
            "Loss:0.5237940549850464\n",
            "Loss:0.5234333276748657\n",
            "Loss:0.5230726003646851\n",
            "Loss:0.5227118730545044\n",
            "Epoch: 90 | Loss: 0.5227118730545044 | Test loss: 0.549063503742218\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7534]])), ('linear_layer.bias', tensor([0.8015]))])\n",
            "Loss:0.5223511457443237\n",
            "Loss:0.5219904184341431\n",
            "Loss:0.5216296911239624\n",
            "Loss:0.5212689638137817\n",
            "Loss:0.5209082365036011\n",
            "Loss:0.5205475091934204\n",
            "Loss:0.520186722278595\n",
            "Loss:0.5198259949684143\n",
            "Loss:0.5194652676582336\n",
            "Loss:0.519104540348053\n",
            "Epoch: 100 | Loss: 0.519104540348053 | Test loss: 0.5448455214500427\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7522]])), ('linear_layer.bias', tensor([0.7984]))])\n",
            "Loss:0.5187438130378723\n",
            "Loss:0.5183830857276917\n",
            "Loss:0.518022358417511\n",
            "Loss:0.5176616311073303\n",
            "Loss:0.5173008441925049\n",
            "Loss:0.516940176486969\n",
            "Loss:0.5165793895721436\n",
            "Loss:0.5162187218666077\n",
            "Loss:0.5158579349517822\n",
            "Loss:0.5154972076416016\n",
            "Epoch: 110 | Loss: 0.5154972076416016 | Test loss: 0.5406274795532227\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7510]])), ('linear_layer.bias', tensor([0.7953]))])\n",
            "Loss:0.5151365399360657\n",
            "Loss:0.5147757530212402\n",
            "Loss:0.5144149661064148\n",
            "Loss:0.5140542984008789\n",
            "Loss:0.5136935114860535\n",
            "Loss:0.5133327841758728\n",
            "Loss:0.5129720568656921\n",
            "Loss:0.5126113295555115\n",
            "Loss:0.512250542640686\n",
            "Loss:0.5118898153305054\n",
            "Epoch: 120 | Loss: 0.5118898153305054 | Test loss: 0.5364094972610474\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7498]])), ('linear_layer.bias', tensor([0.7921]))])\n",
            "Loss:0.5115290880203247\n",
            "Loss:0.511168360710144\n",
            "Loss:0.5108076930046082\n",
            "Loss:0.5104469060897827\n",
            "Loss:0.510086178779602\n",
            "Loss:0.5097254514694214\n",
            "Loss:0.5093647241592407\n",
            "Loss:0.5090039968490601\n",
            "Loss:0.5086432695388794\n",
            "Loss:0.5082825422286987\n",
            "Epoch: 130 | Loss: 0.5082825422286987 | Test loss: 0.5321915745735168\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7485]])), ('linear_layer.bias', tensor([0.7890]))])\n",
            "Loss:0.5079218149185181\n",
            "Loss:0.5075610280036926\n",
            "Loss:0.5072003602981567\n",
            "Loss:0.5068396329879761\n",
            "Loss:0.5064788460731506\n",
            "Loss:0.50611811876297\n",
            "Loss:0.5057573914527893\n",
            "Loss:0.5053966641426086\n",
            "Loss:0.505035936832428\n",
            "Loss:0.5046752095222473\n",
            "Epoch: 140 | Loss: 0.5046752095222473 | Test loss: 0.5279735326766968\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7473]])), ('linear_layer.bias', tensor([0.7859]))])\n",
            "Loss:0.5043144822120667\n",
            "Loss:0.5039536952972412\n",
            "Loss:0.5035930275917053\n",
            "Loss:0.5032322406768799\n",
            "Loss:0.502871572971344\n",
            "Loss:0.5025107860565186\n",
            "Loss:0.5021500587463379\n",
            "Loss:0.5017893314361572\n",
            "Loss:0.5014286041259766\n",
            "Loss:0.5010678768157959\n",
            "Epoch: 150 | Loss: 0.5010678768157959 | Test loss: 0.5237556099891663\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7461]])), ('linear_layer.bias', tensor([0.7827]))])\n",
            "Loss:0.5007071495056152\n",
            "Loss:0.5003463625907898\n",
            "Loss:0.4999856948852539\n",
            "Loss:0.49962490797042847\n",
            "Loss:0.4992641806602478\n",
            "Loss:0.49890342354774475\n",
            "Loss:0.4985427260398865\n",
            "Loss:0.4981819689273834\n",
            "Loss:0.49782124161720276\n",
            "Loss:0.4974605143070221\n",
            "Epoch: 160 | Loss: 0.4974605143070221 | Test loss: 0.5195375680923462\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7449]])), ('linear_layer.bias', tensor([0.7796]))])\n",
            "Loss:0.49709978699684143\n",
            "Loss:0.496739000082016\n",
            "Loss:0.4963783323764801\n",
            "Loss:0.49601760506629944\n",
            "Loss:0.495656818151474\n",
            "Loss:0.4952961504459381\n",
            "Loss:0.49493536353111267\n",
            "Loss:0.4945746958255768\n",
            "Loss:0.4942139685153961\n",
            "Loss:0.4938531816005707\n",
            "Epoch: 170 | Loss: 0.4938531816005707 | Test loss: 0.5153195858001709\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7437]])), ('linear_layer.bias', tensor([0.7765]))])\n",
            "Loss:0.4934924244880676\n",
            "Loss:0.49313172698020935\n",
            "Loss:0.4927709698677063\n",
            "Loss:0.49241024255752563\n",
            "Loss:0.49204951524734497\n",
            "Loss:0.49168872833251953\n",
            "Loss:0.49132800102233887\n",
            "Loss:0.4909672737121582\n",
            "Loss:0.4906066060066223\n",
            "Loss:0.4902458190917969\n",
            "Epoch: 180 | Loss: 0.4902458190917969 | Test loss: 0.5111016035079956\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7424]])), ('linear_layer.bias', tensor([0.7733]))])\n",
            "Loss:0.489885151386261\n",
            "Loss:0.4895244240760803\n",
            "Loss:0.4891636371612549\n",
            "Loss:0.4888029098510742\n",
            "Loss:0.48844218254089355\n",
            "Loss:0.4880814552307129\n",
            "Loss:0.48772066831588745\n",
            "Loss:0.48736000061035156\n",
            "Loss:0.4869992136955261\n",
            "Loss:0.48663845658302307\n",
            "Epoch: 190 | Loss: 0.48663845658302307 | Test loss: 0.5068836212158203\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7412]])), ('linear_layer.bias', tensor([0.7702]))])\n",
            "Loss:0.4862777590751648\n",
            "Loss:0.48591700196266174\n",
            "Loss:0.4855562746524811\n",
            "Loss:0.4851955473423004\n",
            "Loss:0.48483482003211975\n",
            "Loss:0.4844740927219391\n",
            "Loss:0.4841133654117584\n",
            "Loss:0.48375263810157776\n",
            "Loss:0.4833918511867523\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.587018609046936\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.554811418056488\n",
            "Loss:0.5544447898864746\n",
            "Loss:0.554078221321106\n",
            "Loss:0.5537117123603821\n",
            "Loss:0.5533450841903687\n",
            "Loss:0.552978515625\n",
            "Loss:0.5526119470596313\n",
            "Loss:0.5522454380989075\n",
            "Loss:0.551878809928894\n",
            "Loss:0.5515123009681702\n",
            "Epoch: 10 | Loss: 0.5515123009681702 | Test loss: 0.5827324390411377\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7632]])), ('linear_layer.bias', tensor([0.8265]))])\n",
            "Loss:0.5511457324028015\n",
            "Loss:0.5507790446281433\n",
            "Loss:0.5504125356674194\n",
            "Loss:0.5500460267066956\n",
            "Loss:0.5496794581413269\n",
            "Loss:0.5493128299713135\n",
            "Loss:0.5489462614059448\n",
            "Loss:0.548579752445221\n",
            "Loss:0.5482131242752075\n",
            "Loss:0.5478465557098389\n",
            "Epoch: 20 | Loss: 0.5478465557098389 | Test loss: 0.5784462690353394\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7619]])), ('linear_layer.bias', tensor([0.8233]))])\n",
            "Loss:0.547480046749115\n",
            "Loss:0.5471134781837463\n",
            "Loss:0.5467468500137329\n",
            "Loss:0.5463804006576538\n",
            "Loss:0.5460137724876404\n",
            "Loss:0.5456472039222717\n",
            "Loss:0.5452805757522583\n",
            "Loss:0.5449140667915344\n",
            "Loss:0.544547438621521\n",
            "Loss:0.5441808700561523\n",
            "Epoch: 30 | Loss: 0.5441808700561523 | Test loss: 0.5741600394248962\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7607]])), ('linear_layer.bias', tensor([0.8201]))])\n",
            "Loss:0.5438143610954285\n",
            "Loss:0.5434477925300598\n",
            "Loss:0.5430811643600464\n",
            "Loss:0.5427145957946777\n",
            "Loss:0.5423480868339539\n",
            "Loss:0.5419815182685852\n",
            "Loss:0.5416148900985718\n",
            "Loss:0.5412483811378479\n",
            "Loss:0.5408817529678345\n",
            "Loss:0.5405152440071106\n",
            "Epoch: 40 | Loss: 0.5405152440071106 | Test loss: 0.5698739290237427\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7595]])), ('linear_layer.bias', tensor([0.8170]))])\n",
            "Loss:0.5401487350463867\n",
            "Loss:0.5397821068763733\n",
            "Loss:0.5394154787063599\n",
            "Loss:0.539048969745636\n",
            "Loss:0.5386824011802673\n",
            "Loss:0.5383157730102539\n",
            "Loss:0.5379492044448853\n",
            "Loss:0.5375826954841614\n",
            "Loss:0.5372161269187927\n",
            "Loss:0.5368496179580688\n",
            "Epoch: 50 | Loss: 0.5368496179580688 | Test loss: 0.5655877590179443\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7582]])), ('linear_layer.bias', tensor([0.8138]))])\n",
            "Loss:0.5364829897880554\n",
            "Loss:0.5361164212226868\n",
            "Loss:0.5357498526573181\n",
            "Loss:0.5353833436965942\n",
            "Loss:0.5350167155265808\n",
            "Loss:0.5346502065658569\n",
            "Loss:0.5342835783958435\n",
            "Loss:0.5339170694351196\n",
            "Loss:0.5335504412651062\n",
            "Loss:0.5331838726997375\n",
            "Epoch: 60 | Loss: 0.5331838726997375 | Test loss: 0.561301589012146\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7570]])), ('linear_layer.bias', tensor([0.8106]))])\n",
            "Loss:0.5328173637390137\n",
            "Loss:0.532450795173645\n",
            "Loss:0.5320842266082764\n",
            "Loss:0.5317175984382629\n",
            "Loss:0.5313510894775391\n",
            "Loss:0.5309845209121704\n",
            "Loss:0.530617892742157\n",
            "Loss:0.5302513241767883\n",
            "Loss:0.5298847556114197\n",
            "Loss:0.5295182466506958\n",
            "Epoch: 70 | Loss: 0.5295182466506958 | Test loss: 0.5570154786109924\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7557]])), ('linear_layer.bias', tensor([0.8074]))])\n",
            "Loss:0.5291515588760376\n",
            "Loss:0.5287851095199585\n",
            "Loss:0.5284185409545898\n",
            "Loss:0.5280519723892212\n",
            "Loss:0.5276854038238525\n",
            "Loss:0.5273188352584839\n",
            "Loss:0.5269522070884705\n",
            "Loss:0.5265856981277466\n",
            "Loss:0.5262190699577332\n",
            "Loss:0.5258525609970093\n",
            "Epoch: 80 | Loss: 0.5258525609970093 | Test loss: 0.5527293682098389\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7545]])), ('linear_layer.bias', tensor([0.8042]))])\n",
            "Loss:0.5254858732223511\n",
            "Loss:0.525119423866272\n",
            "Loss:0.5247528553009033\n",
            "Loss:0.5243862867355347\n",
            "Loss:0.524019718170166\n",
            "Loss:0.5236531496047974\n",
            "Loss:0.5232865214347839\n",
            "Loss:0.5229200124740601\n",
            "Loss:0.5225535035133362\n",
            "Loss:0.5221868753433228\n",
            "Epoch: 90 | Loss: 0.5221868753433228 | Test loss: 0.5484431982040405\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7532]])), ('linear_layer.bias', tensor([0.8011]))])\n",
            "Loss:0.5218203067779541\n",
            "Loss:0.5214537382125854\n",
            "Loss:0.5210871696472168\n",
            "Loss:0.5207206010818481\n",
            "Loss:0.5203539729118347\n",
            "Loss:0.5199874639511108\n",
            "Loss:0.5196208357810974\n",
            "Loss:0.5192543268203735\n",
            "Loss:0.5188878178596497\n",
            "Loss:0.5185211896896362\n",
            "Epoch: 100 | Loss: 0.5185211896896362 | Test loss: 0.5441570281982422\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7520]])), ('linear_layer.bias', tensor([0.7979]))])\n",
            "Loss:0.5181546211242676\n",
            "Loss:0.5177880525588989\n",
            "Loss:0.5174214839935303\n",
            "Loss:0.5170549154281616\n",
            "Loss:0.516688346862793\n",
            "Loss:0.5163217782974243\n",
            "Loss:0.5159552693367004\n",
            "Loss:0.515588641166687\n",
            "Loss:0.5152221322059631\n",
            "Loss:0.5148555040359497\n",
            "Epoch: 110 | Loss: 0.5148555040359497 | Test loss: 0.5398708581924438\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7508]])), ('linear_layer.bias', tensor([0.7947]))])\n",
            "Loss:0.5144889950752258\n",
            "Loss:0.5141223669052124\n",
            "Loss:0.5137557983398438\n",
            "Loss:0.5133892297744751\n",
            "Loss:0.5130227208137512\n",
            "Loss:0.5126560926437378\n",
            "Loss:0.5122895836830139\n",
            "Loss:0.5119229555130005\n",
            "Loss:0.5115564465522766\n",
            "Loss:0.5111898183822632\n",
            "Epoch: 120 | Loss: 0.5111898183822632 | Test loss: 0.5355846285820007\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7495]])), ('linear_layer.bias', tensor([0.7915]))])\n",
            "Loss:0.5108232498168945\n",
            "Loss:0.5104566812515259\n",
            "Loss:0.510090172290802\n",
            "Loss:0.5097235441207886\n",
            "Loss:0.5093569755554199\n",
            "Loss:0.508990466594696\n",
            "Loss:0.5086238980293274\n",
            "Loss:0.508257269859314\n",
            "Loss:0.5078907012939453\n",
            "Loss:0.5075241923332214\n",
            "Epoch: 130 | Loss: 0.5075241923332214 | Test loss: 0.5312984585762024\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7483]])), ('linear_layer.bias', tensor([0.7883]))])\n",
            "Loss:0.507157564163208\n",
            "Loss:0.5067909955978394\n",
            "Loss:0.5064245462417603\n",
            "Loss:0.506057858467102\n",
            "Loss:0.5056913495063782\n",
            "Loss:0.5053247213363647\n",
            "Loss:0.5049582123756409\n",
            "Loss:0.5045916438102722\n",
            "Loss:0.5042250752449036\n",
            "Loss:0.5038585066795349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|   | 64/100 [00:19<00:11,  3.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 140 | Loss: 0.5038585066795349 | Test loss: 0.5270123481750488\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7470]])), ('linear_layer.bias', tensor([0.7851]))])\n",
            "Loss:0.5034919381141663\n",
            "Loss:0.5031253695487976\n",
            "Loss:0.502758800983429\n",
            "Loss:0.5023922324180603\n",
            "Loss:0.5020256042480469\n",
            "Loss:0.5016590356826782\n",
            "Loss:0.5012925267219543\n",
            "Loss:0.5009259581565857\n",
            "Loss:0.500559389591217\n",
            "Loss:0.5001928210258484\n",
            "Epoch: 150 | Loss: 0.5001928210258484 | Test loss: 0.5227262377738953\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7458]])), ('linear_layer.bias', tensor([0.7820]))])\n",
            "Loss:0.49982625246047974\n",
            "Loss:0.4994596838951111\n",
            "Loss:0.4990931451320648\n",
            "Loss:0.4987265467643738\n",
            "Loss:0.4983600080013275\n",
            "Loss:0.4979934096336365\n",
            "Loss:0.4976268410682678\n",
            "Loss:0.49726027250289917\n",
            "Loss:0.4968937039375305\n",
            "Loss:0.49652719497680664\n",
            "Epoch: 160 | Loss: 0.49652719497680664 | Test loss: 0.5184400677680969\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7446]])), ('linear_layer.bias', tensor([0.7788]))])\n",
            "Loss:0.4961605966091156\n",
            "Loss:0.49579399824142456\n",
            "Loss:0.4954274296760559\n",
            "Loss:0.49506086111068726\n",
            "Loss:0.4946942925453186\n",
            "Loss:0.49432772397994995\n",
            "Loss:0.49396124482154846\n",
            "Loss:0.49359458684921265\n",
            "Loss:0.4932280480861664\n",
            "Loss:0.49286144971847534\n",
            "Epoch: 170 | Loss: 0.49286144971847534 | Test loss: 0.5141538381576538\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7433]])), ('linear_layer.bias', tensor([0.7756]))])\n",
            "Loss:0.4924949109554291\n",
            "Loss:0.49212831258773804\n",
            "Loss:0.4917617440223694\n",
            "Loss:0.49139517545700073\n",
            "Loss:0.49102863669395447\n",
            "Loss:0.4906620383262634\n",
            "Loss:0.49029549956321716\n",
            "Loss:0.4899289608001709\n",
            "Loss:0.48956236243247986\n",
            "Loss:0.4891958236694336\n",
            "Epoch: 180 | Loss: 0.4891958236694336 | Test loss: 0.509867787361145\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7421]])), ('linear_layer.bias', tensor([0.7724]))])\n",
            "Loss:0.48882928490638733\n",
            "Loss:0.4884626269340515\n",
            "Loss:0.48809605836868286\n",
            "Loss:0.487729549407959\n",
            "Loss:0.4873630106449127\n",
            "Loss:0.4869963526725769\n",
            "Loss:0.4866298735141754\n",
            "Loss:0.4862632751464844\n",
            "Loss:0.48589667677879333\n",
            "Loss:0.4855300784111023\n",
            "Epoch: 190 | Loss: 0.4855300784111023 | Test loss: 0.5055816173553467\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7408]])), ('linear_layer.bias', tensor([0.7692]))])\n",
            "Loss:0.4851635992527008\n",
            "Loss:0.48479700088500977\n",
            "Loss:0.48443037271499634\n",
            "Loss:0.48406392335891724\n",
            "Loss:0.4836973249912262\n",
            "Loss:0.48333078622817993\n",
            "Loss:0.4829641282558441\n",
            "Loss:0.48259758949279785\n",
            "Loss:0.4822310507297516\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5870117545127869\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5548055171966553\n",
            "Loss:0.5544331669807434\n",
            "Loss:0.5540607571601868\n",
            "Loss:0.5536883473396301\n",
            "Loss:0.5533159375190735\n",
            "Loss:0.5529435276985168\n",
            "Loss:0.552571177482605\n",
            "Loss:0.5521987676620483\n",
            "Loss:0.5518262982368469\n",
            "Loss:0.5514539480209351\n",
            "Epoch: 10 | Loss: 0.5514539480209351 | Test loss: 0.5826574563980103\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7632]])), ('linear_layer.bias', tensor([0.8265]))])\n",
            "Loss:0.5510815382003784\n",
            "Loss:0.5507091283798218\n",
            "Loss:0.5503367185592651\n",
            "Loss:0.5499643087387085\n",
            "Loss:0.5495918989181519\n",
            "Loss:0.5492194890975952\n",
            "Loss:0.5488470792770386\n",
            "Loss:0.5484747290611267\n",
            "Loss:0.5481023192405701\n",
            "Loss:0.5477299094200134\n",
            "Epoch: 20 | Loss: 0.5477299094200134 | Test loss: 0.5783030986785889\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7619]])), ('linear_layer.bias', tensor([0.8232]))])\n",
            "Loss:0.5473574995994568\n",
            "Loss:0.5469850897789001\n",
            "Loss:0.5466126799583435\n",
            "Loss:0.5462403297424316\n",
            "Loss:0.5458678007125854\n",
            "Loss:0.5454954504966736\n",
            "Loss:0.5451231598854065\n",
            "Loss:0.5447507500648499\n",
            "Loss:0.5443782806396484\n",
            "Loss:0.5440058708190918\n",
            "Epoch: 30 | Loss: 0.5440058708190918 | Test loss: 0.5739488005638123\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7606]])), ('linear_layer.bias', tensor([0.8200]))])\n",
            "Loss:0.5436334609985352\n",
            "Loss:0.5432611107826233\n",
            "Loss:0.5428887605667114\n",
            "Loss:0.54251629114151\n",
            "Loss:0.5421438813209534\n",
            "Loss:0.5417715311050415\n",
            "Loss:0.5413990616798401\n",
            "Loss:0.5410267114639282\n",
            "Loss:0.5406543612480164\n",
            "Loss:0.5402818918228149\n",
            "Epoch: 40 | Loss: 0.5402818918228149 | Test loss: 0.5695944428443909\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7594]])), ('linear_layer.bias', tensor([0.8168]))])\n",
            "Loss:0.5399094820022583\n",
            "Loss:0.5395370721817017\n",
            "Loss:0.5391647219657898\n",
            "Loss:0.5387923121452332\n",
            "Loss:0.5384198427200317\n",
            "Loss:0.5380474328994751\n",
            "Loss:0.537675142288208\n",
            "Loss:0.5373026728630066\n",
            "Loss:0.53693026304245\n",
            "Loss:0.5365579128265381\n",
            "Epoch: 50 | Loss: 0.5365579128265381 | Test loss: 0.5652400851249695\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7581]])), ('linear_layer.bias', tensor([0.8135]))])\n",
            "Loss:0.5361855030059814\n",
            "Loss:0.5358130931854248\n",
            "Loss:0.5354407429695129\n",
            "Loss:0.5350682735443115\n",
            "Loss:0.5346959233283997\n",
            "Loss:0.5343234539031982\n",
            "Loss:0.5339511036872864\n",
            "Loss:0.5335786938667297\n",
            "Loss:0.5332062840461731\n",
            "Loss:0.5328338742256165\n",
            "Epoch: 60 | Loss: 0.5328338742256165 | Test loss: 0.5608857870101929\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7568]])), ('linear_layer.bias', tensor([0.8103]))])\n",
            "Loss:0.5324615240097046\n",
            "Loss:0.5320890545845032\n",
            "Loss:0.5317167043685913\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|   | 65/100 [00:20<00:10,  3.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5313442945480347\n",
            "Loss:0.530971884727478\n",
            "Loss:0.5305994749069214\n",
            "Loss:0.5302270650863647\n",
            "Loss:0.5298546552658081\n",
            "Loss:0.5294822454452515\n",
            "Loss:0.5291098356246948\n",
            "Epoch: 70 | Loss: 0.5291098356246948 | Test loss: 0.556531548500061\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7556]])), ('linear_layer.bias', tensor([0.8071]))])\n",
            "Loss:0.5287374258041382\n",
            "Loss:0.5283650755882263\n",
            "Loss:0.5279926657676697\n",
            "Loss:0.527620255947113\n",
            "Loss:0.5272478461265564\n",
            "Loss:0.5268754363059998\n",
            "Loss:0.5265030860900879\n",
            "Loss:0.5261306762695312\n",
            "Loss:0.5257582068443298\n",
            "Loss:0.525385856628418\n",
            "Epoch: 80 | Loss: 0.525385856628418 | Test loss: 0.5521771311759949\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7543]])), ('linear_layer.bias', tensor([0.8038]))])\n",
            "Loss:0.5250134468078613\n",
            "Loss:0.5246410965919495\n",
            "Loss:0.5242686867713928\n",
            "Loss:0.5238962173461914\n",
            "Loss:0.5235238671302795\n",
            "Loss:0.5231514573097229\n",
            "Loss:0.5227790474891663\n",
            "Loss:0.5224066972732544\n",
            "Loss:0.5220342874526978\n",
            "Loss:0.5216618776321411\n",
            "Epoch: 90 | Loss: 0.5216618776321411 | Test loss: 0.5478228330612183\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7531]])), ('linear_layer.bias', tensor([0.8006]))])\n",
            "Loss:0.5212894678115845\n",
            "Loss:0.5209170579910278\n",
            "Loss:0.5205446481704712\n",
            "Loss:0.5201722383499146\n",
            "Loss:0.5197998285293579\n",
            "Loss:0.5194274187088013\n",
            "Loss:0.5190550684928894\n",
            "Loss:0.518682599067688\n",
            "Loss:0.5183102488517761\n",
            "Loss:0.5179378390312195\n",
            "Epoch: 100 | Loss: 0.5179378390312195 | Test loss: 0.5434684753417969\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7518]])), ('linear_layer.bias', tensor([0.7974]))])\n",
            "Loss:0.5175654292106628\n",
            "Loss:0.5171930193901062\n",
            "Loss:0.5168206095695496\n",
            "Loss:0.5164481997489929\n",
            "Loss:0.516075849533081\n",
            "Loss:0.5157033801078796\n",
            "Loss:0.5153310894966125\n",
            "Loss:0.5149586200714111\n",
            "Loss:0.5145862102508545\n",
            "Loss:0.5142138004302979\n",
            "Epoch: 110 | Loss: 0.5142138004302979 | Test loss: 0.5391141772270203\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7505]])), ('linear_layer.bias', tensor([0.7941]))])\n",
            "Loss:0.513841450214386\n",
            "Loss:0.5134690403938293\n",
            "Loss:0.5130966305732727\n",
            "Loss:0.5127242803573608\n",
            "Loss:0.5123518109321594\n",
            "Loss:0.5119794607162476\n",
            "Loss:0.5116070508956909\n",
            "Loss:0.5112346410751343\n",
            "Loss:0.5108622312545776\n",
            "Loss:0.510489821434021\n",
            "Epoch: 120 | Loss: 0.510489821434021 | Test loss: 0.5347598195075989\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7493]])), ('linear_layer.bias', tensor([0.7909]))])\n",
            "Loss:0.5101174116134644\n",
            "Loss:0.5097450613975525\n",
            "Loss:0.5093726515769958\n",
            "Loss:0.5090002417564392\n",
            "Loss:0.5086278319358826\n",
            "Loss:0.5082553625106812\n",
            "Loss:0.5078830122947693\n",
            "Loss:0.5075106620788574\n",
            "Loss:0.507138192653656\n",
            "Loss:0.5067658424377441\n",
            "Epoch: 130 | Loss: 0.5067658424377441 | Test loss: 0.5304054617881775\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7480]])), ('linear_layer.bias', tensor([0.7877]))])\n",
            "Loss:0.5063934326171875\n",
            "Loss:0.5060209631919861\n",
            "Loss:0.5056486129760742\n",
            "Loss:0.5052762031555176\n",
            "Loss:0.5049038529396057\n",
            "Loss:0.5045313835144043\n",
            "Loss:0.5041590332984924\n",
            "Loss:0.5037866234779358\n",
            "Loss:0.5034142732620239\n",
            "Loss:0.5030418038368225\n",
            "Epoch: 140 | Loss: 0.5030418038368225 | Test loss: 0.5260511636734009\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7468]])), ('linear_layer.bias', tensor([0.7844]))])\n",
            "Loss:0.5026694536209106\n",
            "Loss:0.502297043800354\n",
            "Loss:0.5019246339797974\n",
            "Loss:0.5015522241592407\n",
            "Loss:0.5011798143386841\n",
            "Loss:0.5008074045181274\n",
            "Loss:0.5004349946975708\n",
            "Loss:0.5000626444816589\n",
            "Loss:0.4996902048587799\n",
            "Loss:0.49931779503822327\n",
            "Epoch: 150 | Loss: 0.49931779503822327 | Test loss: 0.521696925163269\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7455]])), ('linear_layer.bias', tensor([0.7812]))])\n",
            "Loss:0.4989453852176666\n",
            "Loss:0.4985730051994324\n",
            "Loss:0.49820059537887573\n",
            "Loss:0.4978281855583191\n",
            "Loss:0.49745577573776245\n",
            "Loss:0.4970833659172058\n",
            "Loss:0.49671095609664917\n",
            "Loss:0.4963386058807373\n",
            "Loss:0.49596619606018066\n",
            "Loss:0.495593786239624\n",
            "Epoch: 160 | Loss: 0.495593786239624 | Test loss: 0.5173425078392029\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7442]])), ('linear_layer.bias', tensor([0.7780]))])\n",
            "Loss:0.49522143602371216\n",
            "Loss:0.4948490262031555\n",
            "Loss:0.4944765567779541\n",
            "Loss:0.49410420656204224\n",
            "Loss:0.4937317967414856\n",
            "Loss:0.49335938692092896\n",
            "Loss:0.4929870069026947\n",
            "Loss:0.4926145672798157\n",
            "Loss:0.4922422468662262\n",
            "Loss:0.4918697476387024\n",
            "Epoch: 170 | Loss: 0.4918697476387024 | Test loss: 0.5129882097244263\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7430]])), ('linear_layer.bias', tensor([0.7747]))])\n",
            "Loss:0.4914974272251129\n",
            "Loss:0.4911250174045563\n",
            "Loss:0.49075260758399963\n",
            "Loss:0.4903801381587982\n",
            "Loss:0.49000778794288635\n",
            "Loss:0.4896353781223297\n",
            "Loss:0.48926296830177307\n",
            "Loss:0.48889055848121643\n",
            "Loss:0.4885181784629822\n",
            "Loss:0.48814576864242554\n",
            "Epoch: 180 | Loss: 0.48814576864242554 | Test loss: 0.5086338520050049\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7417]])), ('linear_layer.bias', tensor([0.7715]))])\n",
            "Loss:0.48777341842651367\n",
            "Loss:0.48740094900131226\n",
            "Loss:0.4870285987854004\n",
            "Loss:0.48665618896484375\n",
            "Loss:0.48628371953964233\n",
            "Loss:0.48591136932373047\n",
            "Loss:0.48553895950317383\n",
            "Loss:0.4851665496826172\n",
            "Loss:0.4847941994667053\n",
            "Loss:0.4844217300415039\n",
            "Epoch: 190 | Loss: 0.4844217300415039 | Test loss: 0.5042795538902283\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7405]])), ('linear_layer.bias', tensor([0.7683]))])\n",
            "Loss:0.48404937982559204\n",
            "Loss:0.4836769998073578\n",
            "Loss:0.48330456018447876\n",
            "Loss:0.4829321801662445\n",
            "Loss:0.48255977034568787\n",
            "Loss:0.48218733072280884\n",
            "Loss:0.48181501030921936\n",
            "Loss:0.48144254088401794\n",
            "Loss:0.4810701906681061\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5870048999786377\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5547996759414673\n",
            "Loss:0.5544214248657227\n",
            "Loss:0.5540432333946228\n",
            "Loss:0.5536649823188782\n",
            "Loss:0.5532866716384888\n",
            "Loss:0.5529085397720337\n",
            "Loss:0.5525302886962891\n",
            "Loss:0.5521520376205444\n",
            "Loss:0.5517738461494446\n",
            "Loss:0.5513955950737\n",
            "Epoch: 10 | Loss: 0.5513955950737 | Test loss: 0.5825824737548828\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7631]])), ('linear_layer.bias', tensor([0.8264]))])\n",
            "Loss:0.5510174036026001\n",
            "Loss:0.5506391525268555\n",
            "Loss:0.5502609014511108\n",
            "Loss:0.5498825907707214\n",
            "Loss:0.5495043992996216\n",
            "Loss:0.549126148223877\n",
            "Loss:0.5487478971481323\n",
            "Loss:0.5483696460723877\n",
            "Loss:0.5479914546012878\n",
            "Loss:0.547613263130188\n",
            "Epoch: 20 | Loss: 0.547613263130188 | Test loss: 0.5781599283218384\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7618]])), ('linear_layer.bias', tensor([0.8231]))])\n",
            "Loss:0.5472349524497986\n",
            "Loss:0.5468567609786987\n",
            "Loss:0.5464785099029541\n",
            "Loss:0.5461003184318542\n",
            "Loss:0.5457220673561096\n",
            "Loss:0.545343816280365\n",
            "Loss:0.5449656248092651\n",
            "Loss:0.5445873141288757\n",
            "Loss:0.5442091226577759\n",
            "Loss:0.5438308715820312\n",
            "Epoch: 30 | Loss: 0.5438308715820312 | Test loss: 0.5737374424934387\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7606]])), ('linear_layer.bias', tensor([0.8198]))])\n",
            "Loss:0.5434526205062866\n",
            "Loss:0.5430744290351868\n",
            "Loss:0.5426961779594421\n",
            "Loss:0.5423179864883423\n",
            "Loss:0.5419397354125977\n",
            "Loss:0.541561484336853\n",
            "Loss:0.5411832332611084\n",
            "Loss:0.5408049821853638\n",
            "Loss:0.5404267907142639\n",
            "Loss:0.5400485396385193\n",
            "Epoch: 40 | Loss: 0.5400485396385193 | Test loss: 0.5693149566650391\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7593]])), ('linear_layer.bias', tensor([0.8165]))])\n",
            "Loss:0.5396703481674194\n",
            "Loss:0.53929203748703\n",
            "Loss:0.5389138460159302\n",
            "Loss:0.5385356545448303\n",
            "Loss:0.5381573438644409\n",
            "Loss:0.5377791523933411\n",
            "Loss:0.5374009013175964\n",
            "Loss:0.5370227098464966\n",
            "Loss:0.536644458770752\n",
            "Loss:0.5362662076950073\n",
            "Epoch: 50 | Loss: 0.5362662076950073 | Test loss: 0.5648924708366394\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7580]])), ('linear_layer.bias', tensor([0.8133]))])\n",
            "Loss:0.5358879566192627\n",
            "Loss:0.5355097055435181\n",
            "Loss:0.535131573677063\n",
            "Loss:0.5347532033920288\n",
            "Loss:0.5343750715255737\n",
            "Loss:0.5339968204498291\n",
            "Loss:0.5336185693740845\n",
            "Loss:0.5332403182983398\n",
            "Loss:0.53286212682724\n",
            "Loss:0.5324838757514954\n",
            "Epoch: 60 | Loss: 0.5324838757514954 | Test loss: 0.5604699850082397\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7567]])), ('linear_layer.bias', tensor([0.8100]))])\n",
            "Loss:0.5321056246757507\n",
            "Loss:0.5317274332046509\n",
            "Loss:0.5313491821289062\n",
            "Loss:0.5309709310531616\n",
            "Loss:0.530592679977417\n",
            "Loss:0.5302144885063171\n",
            "Loss:0.5298362970352173\n",
            "Loss:0.5294579863548279\n",
            "Loss:0.529079794883728\n",
            "Loss:0.5287015438079834\n",
            "Epoch: 70 | Loss: 0.5287015438079834 | Test loss: 0.5560474395751953\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7554]])), ('linear_layer.bias', tensor([0.8067]))])\n",
            "Loss:0.5283232927322388\n",
            "Loss:0.5279450416564941\n",
            "Loss:0.5275667905807495\n",
            "Loss:0.5271885991096497\n",
            "Loss:0.526810348033905\n",
            "Loss:0.5264321565628052\n",
            "Loss:0.5260539054870605\n",
            "Loss:0.5256756544113159\n",
            "Loss:0.5252974629402161\n",
            "Loss:0.5249192118644714\n",
            "Epoch: 80 | Loss: 0.5249192118644714 | Test loss: 0.5516248941421509\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7542]])), ('linear_layer.bias', tensor([0.8034]))])\n",
            "Loss:0.524540901184082\n",
            "Loss:0.5241626501083374\n",
            "Loss:0.5237844586372375\n",
            "Loss:0.5234063267707825\n",
            "Loss:0.5230280160903931\n",
            "Loss:0.5226497650146484\n",
            "Loss:0.5222715139389038\n",
            "Loss:0.521893322467804\n",
            "Loss:0.5215150117874146\n",
            "Loss:0.5211368799209595\n",
            "Epoch: 90 | Loss: 0.5211368799209595 | Test loss: 0.547202467918396\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7529]])), ('linear_layer.bias', tensor([0.8001]))])\n",
            "Loss:0.5207586288452148\n",
            "Loss:0.5203803777694702\n",
            "Loss:0.5200021862983704\n",
            "Loss:0.519623875617981\n",
            "Loss:0.5192456841468811\n",
            "Loss:0.5188673734664917\n",
            "Loss:0.5184891819953918\n",
            "Loss:0.5181109309196472\n",
            "Loss:0.5177326798439026\n",
            "Loss:0.5173544883728027\n",
            "Epoch: 100 | Loss: 0.5173544883728027 | Test loss: 0.5427799224853516\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7516]])), ('linear_layer.bias', tensor([0.7968]))])\n",
            "Loss:0.5169762372970581\n",
            "Loss:0.5165979862213135\n",
            "Loss:0.5162197947502136\n",
            "Loss:0.515841543674469\n",
            "Loss:0.5154632925987244\n",
            "Loss:0.5150851011276245\n",
            "Loss:0.5147068500518799\n",
            "Loss:0.5143285989761353\n",
            "Loss:0.5139503479003906\n",
            "Loss:0.513572096824646\n",
            "Epoch: 110 | Loss: 0.513572096824646 | Test loss: 0.5383574962615967\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7503]])), ('linear_layer.bias', tensor([0.7936]))])\n",
            "Loss:0.5131939053535461\n",
            "Loss:0.5128156542778015\n",
            "Loss:0.5124374628067017\n",
            "Loss:0.5120591521263123\n",
            "Loss:0.5116809606552124\n",
            "Loss:0.5113027691841125\n",
            "Loss:0.5109244585037231\n",
            "Loss:0.5105462670326233\n",
            "Loss:0.5101680159568787\n",
            "Loss:0.5097898244857788\n",
            "Epoch: 120 | Loss: 0.5097898244857788 | Test loss: 0.5339349508285522\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7490]])), ('linear_layer.bias', tensor([0.7903]))])\n",
            "Loss:0.509411633014679\n",
            "Loss:0.5090333223342896\n",
            "Loss:0.5086551308631897\n",
            "Loss:0.5082768797874451\n",
            "Loss:0.5078986287117004\n",
            "Loss:0.5075203776359558\n",
            "Loss:0.507142186164856\n",
            "Loss:0.5067638754844666\n",
            "Loss:0.5063856840133667\n",
            "Loss:0.5060074925422668\n",
            "Epoch: 130 | Loss: 0.5060074925422668 | Test loss: 0.5295124650001526\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7478]])), ('linear_layer.bias', tensor([0.7870]))])\n",
            "Loss:0.5056292414665222\n",
            "Loss:0.5052510499954224\n",
            "Loss:0.504872739315033\n",
            "Loss:0.5044945478439331\n",
            "Loss:0.5041162371635437\n",
            "Loss:0.5037380456924438\n",
            "Loss:0.5033597946166992\n",
            "Loss:0.5029815435409546\n",
            "Loss:0.5026033520698547\n",
            "Loss:0.5022251009941101\n",
            "Epoch: 140 | Loss: 0.5022251009941101 | Test loss: 0.5250899791717529\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7465]])), ('linear_layer.bias', tensor([0.7837]))])\n",
            "Loss:0.5018469095230103\n",
            "Loss:0.5014686584472656\n",
            "Loss:0.501090407371521\n",
            "Loss:0.5007122159004211\n",
            "Loss:0.5003339648246765\n",
            "Loss:0.4999557137489319\n",
            "Loss:0.49957752227783203\n",
            "Loss:0.499199241399765\n",
            "Loss:0.4988210201263428\n",
            "Loss:0.49844279885292053\n",
            "Epoch: 150 | Loss: 0.49844279885292053 | Test loss: 0.5206674933433533\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7452]])), ('linear_layer.bias', tensor([0.7804]))])\n",
            "Loss:0.4980645179748535\n",
            "Loss:0.49768632650375366\n",
            "Loss:0.49730807542800903\n",
            "Loss:0.4969298243522644\n",
            "Loss:0.49655160307884216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|   | 66/100 [00:20<00:10,  3.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.4961733818054199\n",
            "Loss:0.4957951605319977\n",
            "Loss:0.49541693925857544\n",
            "Loss:0.4950386881828308\n",
            "Loss:0.49466046690940857\n",
            "Epoch: 160 | Loss: 0.49466046690940857 | Test loss: 0.5162450075149536\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7439]])), ('linear_layer.bias', tensor([0.7772]))])\n",
            "Loss:0.49428224563598633\n",
            "Loss:0.4939039349555969\n",
            "Loss:0.4935256838798523\n",
            "Loss:0.4931475520133972\n",
            "Loss:0.4927692413330078\n",
            "Loss:0.49239102005958557\n",
            "Loss:0.49201279878616333\n",
            "Loss:0.4916345477104187\n",
            "Loss:0.4912562966346741\n",
            "Loss:0.4908781051635742\n",
            "Epoch: 170 | Loss: 0.4908781051635742 | Test loss: 0.5118224620819092\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7426]])), ('linear_layer.bias', tensor([0.7739]))])\n",
            "Loss:0.4904998242855072\n",
            "Loss:0.49012160301208496\n",
            "Loss:0.48974332213401794\n",
            "Loss:0.4893651604652405\n",
            "Loss:0.48898690938949585\n",
            "Loss:0.4886086583137512\n",
            "Loss:0.48823046684265137\n",
            "Loss:0.48785218596458435\n",
            "Loss:0.4874739646911621\n",
            "Loss:0.48709574341773987\n",
            "Epoch: 180 | Loss: 0.48709574341773987 | Test loss: 0.5073999166488647\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7414]])), ('linear_layer.bias', tensor([0.7706]))])\n",
            "Loss:0.48671746253967285\n",
            "Loss:0.4863392412662506\n",
            "Loss:0.48596101999282837\n",
            "Loss:0.48558276891708374\n",
            "Loss:0.4852045476436615\n",
            "Loss:0.48482632637023926\n",
            "Loss:0.484448105096817\n",
            "Loss:0.48406982421875\n",
            "Loss:0.48369160294532776\n",
            "Loss:0.4833133816719055\n",
            "Epoch: 190 | Loss: 0.4833133816719055 | Test loss: 0.5029774904251099\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7401]])), ('linear_layer.bias', tensor([0.7673]))])\n",
            "Loss:0.4829351007938385\n",
            "Loss:0.48255690932273865\n",
            "Loss:0.4821786880493164\n",
            "Loss:0.48180046677589417\n",
            "Loss:0.4814222455024719\n",
            "Loss:0.4810439944267273\n",
            "Loss:0.48066574335098267\n",
            "Loss:0.48028749227523804\n",
            "Loss:0.4799092710018158\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5869981646537781\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5547939538955688\n",
            "Loss:0.554409921169281\n",
            "Loss:0.5540259480476379\n",
            "Loss:0.5536419153213501\n",
            "Loss:0.5532578825950623\n",
            "Loss:0.5528739094734192\n",
            "Loss:0.5524898767471313\n",
            "Loss:0.5521057844161987\n",
            "Loss:0.5517218708992004\n",
            "Loss:0.5513378977775574\n",
            "Epoch: 10 | Loss: 0.5513378977775574 | Test loss: 0.5825081467628479\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7631]])), ('linear_layer.bias', tensor([0.8263]))])\n",
            "Loss:0.5509538054466248\n",
            "Loss:0.5505697727203369\n",
            "Loss:0.5501857995986938\n",
            "Loss:0.5498018264770508\n",
            "Loss:0.5494178533554077\n",
            "Loss:0.5490338206291199\n",
            "Loss:0.548649787902832\n",
            "Loss:0.5482657551765442\n",
            "Loss:0.5478817820549011\n",
            "Loss:0.5474977493286133\n",
            "Epoch: 20 | Loss: 0.5474977493286133 | Test loss: 0.578018069267273\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7618]])), ('linear_layer.bias', tensor([0.8230]))])\n",
            "Loss:0.5471137762069702\n",
            "Loss:0.5467297434806824\n",
            "Loss:0.5463457703590393\n",
            "Loss:0.5459617376327515\n",
            "Loss:0.5455777049064636\n",
            "Loss:0.5451937317848206\n",
            "Loss:0.5448096990585327\n",
            "Loss:0.5444256067276001\n",
            "Loss:0.5440417528152466\n",
            "Loss:0.543657660484314\n",
            "Epoch: 30 | Loss: 0.543657660484314 | Test loss: 0.5735279321670532\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7605]])), ('linear_layer.bias', tensor([0.8197]))])\n",
            "Loss:0.5432736873626709\n",
            "Loss:0.5428897142410278\n",
            "Loss:0.5425056219100952\n",
            "Loss:0.5421216487884521\n",
            "Loss:0.5417376756668091\n",
            "Loss:0.5413535833358765\n",
            "Loss:0.5409696698188782\n",
            "Loss:0.5405855774879456\n",
            "Loss:0.5402016043663025\n",
            "Loss:0.5398175716400146\n",
            "Epoch: 40 | Loss: 0.5398175716400146 | Test loss: 0.569037914276123\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7592]])), ('linear_layer.bias', tensor([0.8163]))])\n",
            "Loss:0.5394335985183716\n",
            "Loss:0.5390495657920837\n",
            "Loss:0.5386655926704407\n",
            "Loss:0.5382815599441528\n",
            "Loss:0.5378975868225098\n",
            "Loss:0.5375136137008667\n",
            "Loss:0.5371295809745789\n",
            "Loss:0.536745548248291\n",
            "Loss:0.536361575126648\n",
            "Loss:0.5359774827957153\n",
            "Epoch: 50 | Loss: 0.5359774827957153 | Test loss: 0.5645478963851929\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7579]])), ('linear_layer.bias', tensor([0.8130]))])\n",
            "Loss:0.5355933904647827\n",
            "Loss:0.5352095365524292\n",
            "Loss:0.5348255038261414\n",
            "Loss:0.5344414710998535\n",
            "Loss:0.5340574979782104\n",
            "Loss:0.5336734652519226\n",
            "Loss:0.5332894325256348\n",
            "Loss:0.5329054594039917\n",
            "Loss:0.5325214266777039\n",
            "Loss:0.5321374535560608\n",
            "Epoch: 60 | Loss: 0.5321374535560608 | Test loss: 0.5600577592849731\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7566]])), ('linear_layer.bias', tensor([0.8097]))])\n",
            "Loss:0.531753420829773\n",
            "Loss:0.5313693881034851\n",
            "Loss:0.5309854745864868\n",
            "Loss:0.5306013822555542\n",
            "Loss:0.5302174091339111\n",
            "Loss:0.5298333764076233\n",
            "Loss:0.5294493436813354\n",
            "Loss:0.5290653705596924\n",
            "Loss:0.5286813378334045\n",
            "Loss:0.5282973647117615\n",
            "Epoch: 70 | Loss: 0.5282973647117615 | Test loss: 0.5555676817893982\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7553]])), ('linear_layer.bias', tensor([0.8063]))])\n",
            "Loss:0.5279132723808289\n",
            "Loss:0.5275293588638306\n",
            "Loss:0.527145266532898\n",
            "Loss:0.5267612934112549\n",
            "Loss:0.5263773202896118\n",
            "Loss:0.525993287563324\n",
            "Loss:0.5256093144416809\n",
            "Loss:0.5252252817153931\n",
            "Loss:0.5248412489891052\n",
            "Loss:0.5244572758674622\n",
            "Epoch: 80 | Loss: 0.5244572758674622 | Test loss: 0.5510776042938232\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7540]])), ('linear_layer.bias', tensor([0.8030]))])\n",
            "Loss:0.5240732431411743\n",
            "Loss:0.5236892700195312\n",
            "Loss:0.5233051776885986\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|   | 67/100 [00:20<00:10,  3.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5229212045669556\n",
            "Loss:0.5225371718406677\n",
            "Loss:0.5221532583236694\n",
            "Loss:0.5217691659927368\n",
            "Loss:0.5213852524757385\n",
            "Loss:0.5210012197494507\n",
            "Loss:0.5206171274185181\n",
            "Epoch: 90 | Loss: 0.5206171274185181 | Test loss: 0.5465875864028931\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7527]])), ('linear_layer.bias', tensor([0.7997]))])\n",
            "Loss:0.5202332139015198\n",
            "Loss:0.5198491811752319\n",
            "Loss:0.5194651484489441\n",
            "Loss:0.519081175327301\n",
            "Loss:0.5186971426010132\n",
            "Loss:0.5183131098747253\n",
            "Loss:0.5179291367530823\n",
            "Loss:0.5175451040267944\n",
            "Loss:0.5171610713005066\n",
            "Loss:0.5167771577835083\n",
            "Epoch: 100 | Loss: 0.5167771577835083 | Test loss: 0.5420974493026733\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7514]])), ('linear_layer.bias', tensor([0.7963]))])\n",
            "Loss:0.5163930654525757\n",
            "Loss:0.5160090923309326\n",
            "Loss:0.5156251192092896\n",
            "Loss:0.5152410864830017\n",
            "Loss:0.5148570537567139\n",
            "Loss:0.5144730806350708\n",
            "Loss:0.514089047908783\n",
            "Loss:0.5137050747871399\n",
            "Loss:0.513321042060852\n",
            "Loss:0.5129370093345642\n",
            "Epoch: 110 | Loss: 0.5129370093345642 | Test loss: 0.5376074314117432\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7501]])), ('linear_layer.bias', tensor([0.7930]))])\n",
            "Loss:0.5125530362129211\n",
            "Loss:0.5121690034866333\n",
            "Loss:0.5117849707603455\n",
            "Loss:0.5114009976387024\n",
            "Loss:0.5110169649124146\n",
            "Loss:0.5106328725814819\n",
            "Loss:0.5102489590644836\n",
            "Loss:0.5098649263381958\n",
            "Loss:0.5094809532165527\n",
            "Loss:0.5090969204902649\n",
            "Epoch: 120 | Loss: 0.5090969204902649 | Test loss: 0.5331173539161682\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7488]])), ('linear_layer.bias', tensor([0.7897]))])\n",
            "Loss:0.5087129473686218\n",
            "Loss:0.508328914642334\n",
            "Loss:0.5079448819160461\n",
            "Loss:0.5075608491897583\n",
            "Loss:0.5071768760681152\n",
            "Loss:0.5067928433418274\n",
            "Loss:0.5064088702201843\n",
            "Loss:0.5060248970985413\n",
            "Loss:0.5056408643722534\n",
            "Loss:0.5052568316459656\n",
            "Epoch: 130 | Loss: 0.5052568316459656 | Test loss: 0.5286272764205933\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7475]])), ('linear_layer.bias', tensor([0.7863]))])\n",
            "Loss:0.5048728585243225\n",
            "Loss:0.5044888257980347\n",
            "Loss:0.5041048526763916\n",
            "Loss:0.5037208199501038\n",
            "Loss:0.5033367872238159\n",
            "Loss:0.5029528737068176\n",
            "Loss:0.5025688409805298\n",
            "Loss:0.5021847486495972\n",
            "Loss:0.5018007755279541\n",
            "Loss:0.501416802406311\n",
            "Epoch: 140 | Loss: 0.501416802406311 | Test loss: 0.5241372585296631\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7462]])), ('linear_layer.bias', tensor([0.7830]))])\n",
            "Loss:0.5010327696800232\n",
            "Loss:0.5006487369537354\n",
            "Loss:0.5002647638320923\n",
            "Loss:0.49988070130348206\n",
            "Loss:0.4994967579841614\n",
            "Loss:0.49911269545555115\n",
            "Loss:0.49872875213623047\n",
            "Loss:0.49834465980529785\n",
            "Loss:0.4979606568813324\n",
            "Loss:0.49757665395736694\n",
            "Epoch: 150 | Loss: 0.49757665395736694 | Test loss: 0.5196471214294434\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7449]])), ('linear_layer.bias', tensor([0.7797]))])\n",
            "Loss:0.4971926808357239\n",
            "Loss:0.4968086779117584\n",
            "Loss:0.49642467498779297\n",
            "Loss:0.4960406720638275\n",
            "Loss:0.49565666913986206\n",
            "Loss:0.4952726364135742\n",
            "Loss:0.4948886036872864\n",
            "Loss:0.4945046305656433\n",
            "Loss:0.49412059783935547\n",
            "Loss:0.49373659491539\n",
            "Epoch: 160 | Loss: 0.49373659491539 | Test loss: 0.5151570439338684\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7436]])), ('linear_layer.bias', tensor([0.7763]))])\n",
            "Loss:0.49335259199142456\n",
            "Loss:0.4929685592651367\n",
            "Loss:0.49258461594581604\n",
            "Loss:0.4922005534172058\n",
            "Loss:0.49181652069091797\n",
            "Loss:0.4914325773715973\n",
            "Loss:0.49104851484298706\n",
            "Loss:0.490664541721344\n",
            "Loss:0.49028053879737854\n",
            "Loss:0.4898965358734131\n",
            "Epoch: 170 | Loss: 0.4898965358734131 | Test loss: 0.5106669664382935\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7423]])), ('linear_layer.bias', tensor([0.7730]))])\n",
            "Loss:0.48951253294944763\n",
            "Loss:0.4891285300254822\n",
            "Loss:0.4887445569038391\n",
            "Loss:0.4883604943752289\n",
            "Loss:0.48797646164894104\n",
            "Loss:0.4875924587249756\n",
            "Loss:0.48720845580101013\n",
            "Loss:0.4868244528770447\n",
            "Loss:0.48644042015075684\n",
            "Loss:0.48605647683143616\n",
            "Epoch: 180 | Loss: 0.48605647683143616 | Test loss: 0.5061768889427185\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7410]])), ('linear_layer.bias', tensor([0.7697]))])\n",
            "Loss:0.48567238450050354\n",
            "Loss:0.48528844118118286\n",
            "Loss:0.48490437865257263\n",
            "Loss:0.48452043533325195\n",
            "Loss:0.4841364026069641\n",
            "Loss:0.48375242948532104\n",
            "Loss:0.4833683967590332\n",
            "Loss:0.48298436403274536\n",
            "Loss:0.4826003611087799\n",
            "Loss:0.48221635818481445\n",
            "Epoch: 190 | Loss: 0.48221635818481445 | Test loss: 0.5016868114471436\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7397]])), ('linear_layer.bias', tensor([0.7663]))])\n",
            "Loss:0.481832355260849\n",
            "Loss:0.48144835233688354\n",
            "Loss:0.4810643196105957\n",
            "Loss:0.48068031668663025\n",
            "Loss:0.4802963137626648\n",
            "Loss:0.47991234064102173\n",
            "Loss:0.4795282781124115\n",
            "Loss:0.47914427518844604\n",
            "Loss:0.478760302066803\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5869913697242737\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5547881126403809\n",
            "Loss:0.554398238658905\n",
            "Loss:0.5540083646774292\n",
            "Loss:0.5536185503005981\n",
            "Loss:0.5532287359237671\n",
            "Loss:0.552838921546936\n",
            "Loss:0.5524489879608154\n",
            "Loss:0.5520591735839844\n",
            "Loss:0.5516693592071533\n",
            "Loss:0.5512794852256775\n",
            "Epoch: 10 | Loss: 0.5512794852256775 | Test loss: 0.5824331641197205\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7631]])), ('linear_layer.bias', tensor([0.8263]))])\n",
            "Loss:0.5508896708488464\n",
            "Loss:0.5504998564720154\n",
            "Loss:0.5501100420951843\n",
            "Loss:0.5497201681137085\n",
            "Loss:0.5493302941322327\n",
            "Loss:0.5489404797554016\n",
            "Loss:0.5485506057739258\n",
            "Loss:0.54816073179245\n",
            "Loss:0.5477708578109741\n",
            "Loss:0.5473810434341431\n",
            "Epoch: 20 | Loss: 0.5473810434341431 | Test loss: 0.5778749585151672\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7618]])), ('linear_layer.bias', tensor([0.8229]))])\n",
            "Loss:0.546991229057312\n",
            "Loss:0.546601414680481\n",
            "Loss:0.5462116003036499\n",
            "Loss:0.5458217859268188\n",
            "Loss:0.545431911945343\n",
            "Loss:0.5450420379638672\n",
            "Loss:0.5446521639823914\n",
            "Loss:0.5442623496055603\n",
            "Loss:0.5438725352287292\n",
            "Loss:0.5434826612472534\n",
            "Epoch: 30 | Loss: 0.5434826612472534 | Test loss: 0.5733166337013245\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7604]])), ('linear_layer.bias', tensor([0.8195]))])\n",
            "Loss:0.5430928468704224\n",
            "Loss:0.5427029728889465\n",
            "Loss:0.5423131585121155\n",
            "Loss:0.5419233441352844\n",
            "Loss:0.5415334701538086\n",
            "Loss:0.5411436557769775\n",
            "Loss:0.5407538414001465\n",
            "Loss:0.5403639078140259\n",
            "Loss:0.5399740934371948\n",
            "Loss:0.5395842790603638\n",
            "Epoch: 40 | Loss: 0.5395842790603638 | Test loss: 0.5687584280967712\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7591]])), ('linear_layer.bias', tensor([0.8161]))])\n",
            "Loss:0.5391944646835327\n",
            "Loss:0.5388045310974121\n",
            "Loss:0.538414716720581\n",
            "Loss:0.53802490234375\n",
            "Loss:0.5376350283622742\n",
            "Loss:0.5372452139854431\n",
            "Loss:0.5368553400039673\n",
            "Loss:0.5364655256271362\n",
            "Loss:0.5360757112503052\n",
            "Loss:0.5356858372688293\n",
            "Epoch: 50 | Loss: 0.5356858372688293 | Test loss: 0.5642001628875732\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7578]])), ('linear_layer.bias', tensor([0.8128]))])\n",
            "Loss:0.5352960228919983\n",
            "Loss:0.5349061489105225\n",
            "Loss:0.5345163345336914\n",
            "Loss:0.5341265201568604\n",
            "Loss:0.5337365865707397\n",
            "Loss:0.5333467721939087\n",
            "Loss:0.5329569578170776\n",
            "Loss:0.5325671434402466\n",
            "Loss:0.5321772694587708\n",
            "Loss:0.5317874550819397\n",
            "Epoch: 60 | Loss: 0.5317874550819397 | Test loss: 0.55964195728302\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7565]])), ('linear_layer.bias', tensor([0.8094]))])\n",
            "Loss:0.5313975214958191\n",
            "Loss:0.5310077667236328\n",
            "Loss:0.530617892742157\n",
            "Loss:0.5302280187606812\n",
            "Loss:0.5298382043838501\n",
            "Loss:0.529448390007019\n",
            "Loss:0.529058575630188\n",
            "Loss:0.5286686420440674\n",
            "Loss:0.5282788276672363\n",
            "Loss:0.5278890132904053\n",
            "Epoch: 70 | Loss: 0.5278890132904053 | Test loss: 0.555083692073822\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7552]])), ('linear_layer.bias', tensor([0.8060]))])\n",
            "Loss:0.5274991393089294\n",
            "Loss:0.5271093249320984\n",
            "Loss:0.5267195105552673\n",
            "Loss:0.5263296365737915\n",
            "Loss:0.5259397625923157\n",
            "Loss:0.5255499482154846\n",
            "Loss:0.5251600742340088\n",
            "Loss:0.5247702598571777\n",
            "Loss:0.5243804454803467\n",
            "Loss:0.5239905714988708\n",
            "Epoch: 80 | Loss: 0.5239905714988708 | Test loss: 0.5505254864692688\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7538]])), ('linear_layer.bias', tensor([0.8026]))])\n",
            "Loss:0.523600697517395\n",
            "Loss:0.523210883140564\n",
            "Loss:0.5228210687637329\n",
            "Loss:0.5224312543869019\n",
            "Loss:0.522041380405426\n",
            "Loss:0.521651566028595\n",
            "Loss:0.5212616920471191\n",
            "Loss:0.5208718776702881\n",
            "Loss:0.5204820036888123\n",
            "Loss:0.5200921893119812\n",
            "Epoch: 90 | Loss: 0.5200921893119812 | Test loss: 0.545967161655426\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7525]])), ('linear_layer.bias', tensor([0.7992]))])\n",
            "Loss:0.5197023153305054\n",
            "Loss:0.5193125009536743\n",
            "Loss:0.5189226269721985\n",
            "Loss:0.5185327529907227\n",
            "Loss:0.5181429386138916\n",
            "Loss:0.5177530646324158\n",
            "Loss:0.5173633098602295\n",
            "Loss:0.5169734358787537\n",
            "Loss:0.5165835618972778\n",
            "Loss:0.5161937475204468\n",
            "Epoch: 100 | Loss: 0.5161937475204468 | Test loss: 0.5414089560508728\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7512]])), ('linear_layer.bias', tensor([0.7958]))])\n",
            "Loss:0.5158039331436157\n",
            "Loss:0.5154140591621399\n",
            "Loss:0.5150242447853088\n",
            "Loss:0.5146344304084778\n",
            "Loss:0.514244556427002\n",
            "Loss:0.5138546824455261\n",
            "Loss:0.5134648680686951\n",
            "Loss:0.5130749940872192\n",
            "Loss:0.5126851797103882\n",
            "Loss:0.5122953653335571\n",
            "Epoch: 110 | Loss: 0.5122953653335571 | Test loss: 0.5368506908416748\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7499]])), ('linear_layer.bias', tensor([0.7924]))])\n",
            "Loss:0.5119054913520813\n",
            "Loss:0.5115156173706055\n",
            "Loss:0.5111258029937744\n",
            "Loss:0.5107359290122986\n",
            "Loss:0.5103461742401123\n",
            "Loss:0.5099562406539917\n",
            "Loss:0.5095664262771606\n",
            "Loss:0.5091766119003296\n",
            "Loss:0.5087867379188538\n",
            "Loss:0.5083969235420227\n",
            "Epoch: 120 | Loss: 0.5083969235420227 | Test loss: 0.5322924852371216\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7486]])), ('linear_layer.bias', tensor([0.7891]))])\n",
            "Loss:0.5080070495605469\n",
            "Loss:0.5076172947883606\n",
            "Loss:0.5072274208068848\n",
            "Loss:0.5068375468254089\n",
            "Loss:0.5064476728439331\n",
            "Loss:0.506057858467102\n",
            "Loss:0.505668044090271\n",
            "Loss:0.5052782297134399\n",
            "Loss:0.5048883557319641\n",
            "Loss:0.5044984817504883\n",
            "Epoch: 130 | Loss: 0.5044984817504883 | Test loss: 0.5277342200279236\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7473]])), ('linear_layer.bias', tensor([0.7857]))])\n",
            "Loss:0.5041086077690125\n",
            "Loss:0.5037188529968262\n",
            "Loss:0.5033289790153503\n",
            "Loss:0.5029391050338745\n",
            "Loss:0.5025492906570435\n",
            "Loss:0.5021594762802124\n",
            "Loss:0.5017696619033813\n",
            "Loss:0.5013797283172607\n",
            "Loss:0.5009899139404297\n",
            "Loss:0.5006000995635986\n",
            "Epoch: 140 | Loss: 0.5006000995635986 | Test loss: 0.5231760144233704\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7459]])), ('linear_layer.bias', tensor([0.7823]))])\n",
            "Loss:0.5002102255821228\n",
            "Loss:0.49982041120529175\n",
            "Loss:0.4994305670261383\n",
            "Loss:0.4990406930446625\n",
            "Loss:0.4986508786678314\n",
            "Loss:0.498261034488678\n",
            "Loss:0.4978712499141693\n",
            "Loss:0.4974813461303711\n",
            "Loss:0.49709147214889526\n",
            "Loss:0.4967016577720642\n",
            "Epoch: 150 | Loss: 0.4967016577720642 | Test loss: 0.5186177492141724\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7446]])), ('linear_layer.bias', tensor([0.7789]))])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|   | 68/100 [00:21<00:09,  3.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.49631181359291077\n",
            "Loss:0.4959220290184021\n",
            "Loss:0.4955321252346039\n",
            "Loss:0.49514228105545044\n",
            "Loss:0.4947524070739746\n",
            "Loss:0.49436259269714355\n",
            "Loss:0.4939727187156677\n",
            "Loss:0.49358290433883667\n",
            "Loss:0.4931930899620056\n",
            "Loss:0.4928031861782074\n",
            "Epoch: 160 | Loss: 0.4928031861782074 | Test loss: 0.5140595436096191\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7433]])), ('linear_layer.bias', tensor([0.7755]))])\n",
            "Loss:0.4924134314060211\n",
            "Loss:0.4920235574245453\n",
            "Loss:0.49163371324539185\n",
            "Loss:0.4912438988685608\n",
            "Loss:0.49085408449172974\n",
            "Loss:0.4904642105102539\n",
            "Loss:0.4900743365287781\n",
            "Loss:0.48968449234962463\n",
            "Loss:0.4892946779727936\n",
            "Loss:0.4889048635959625\n",
            "Epoch: 170 | Loss: 0.4889048635959625 | Test loss: 0.5095012784004211\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7420]])), ('linear_layer.bias', tensor([0.7721]))])\n",
            "Loss:0.4885149896144867\n",
            "Loss:0.48812514543533325\n",
            "Loss:0.4877352714538574\n",
            "Loss:0.48734545707702637\n",
            "Loss:0.4869556427001953\n",
            "Loss:0.4865657687187195\n",
            "Loss:0.4861759543418884\n",
            "Loss:0.4857860505580902\n",
            "Loss:0.48539629578590393\n",
            "Loss:0.4850063920021057\n",
            "Epoch: 180 | Loss: 0.4850063920021057 | Test loss: 0.5049430131912231\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7407]])), ('linear_layer.bias', tensor([0.7688]))])\n",
            "Loss:0.48461657762527466\n",
            "Loss:0.4842267632484436\n",
            "Loss:0.4838368892669678\n",
            "Loss:0.48344701528549194\n",
            "Loss:0.4830572009086609\n",
            "Loss:0.48266735672950745\n",
            "Loss:0.4822775423526764\n",
            "Loss:0.48188766837120056\n",
            "Loss:0.4814978539943695\n",
            "Loss:0.48110800981521606\n",
            "Epoch: 190 | Loss: 0.48110800981521606 | Test loss: 0.5003847479820251\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7393]])), ('linear_layer.bias', tensor([0.7654]))])\n",
            "Loss:0.48071813583374023\n",
            "Loss:0.4803282618522644\n",
            "Loss:0.47993844747543335\n",
            "Loss:0.4795486032962799\n",
            "Loss:0.47915878891944885\n",
            "Loss:0.4787689745426178\n",
            "Loss:0.4783790707588196\n",
            "Loss:0.47798919677734375\n",
            "Loss:0.4775993824005127\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5869845747947693\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5547822713851929\n",
            "Loss:0.5543864965438843\n",
            "Loss:0.55399090051651\n",
            "Loss:0.5535951852798462\n",
            "Loss:0.5531995296478271\n",
            "Loss:0.5528038740158081\n",
            "Loss:0.5524082183837891\n",
            "Loss:0.55201256275177\n",
            "Loss:0.5516168475151062\n",
            "Loss:0.5512211918830872\n",
            "Epoch: 10 | Loss: 0.5512211918830872 | Test loss: 0.5823581218719482\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7631]])), ('linear_layer.bias', tensor([0.8262]))])\n",
            "Loss:0.5508254766464233\n",
            "Loss:0.5504298210144043\n",
            "Loss:0.5500341653823853\n",
            "Loss:0.5496385097503662\n",
            "Loss:0.5492428541183472\n",
            "Loss:0.5488470792770386\n",
            "Loss:0.5484514832496643\n",
            "Loss:0.5480557680130005\n",
            "Loss:0.5476601719856262\n",
            "Loss:0.5472643971443176\n",
            "Epoch: 20 | Loss: 0.5472643971443176 | Test loss: 0.5777317881584167\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7617]])), ('linear_layer.bias', tensor([0.8228]))])\n",
            "Loss:0.5468686819076538\n",
            "Loss:0.5464730262756348\n",
            "Loss:0.5460774302482605\n",
            "Loss:0.5456817746162415\n",
            "Loss:0.5452860593795776\n",
            "Loss:0.5448903441429138\n",
            "Loss:0.54449462890625\n",
            "Loss:0.5440990924835205\n",
            "Loss:0.5437034368515015\n",
            "Loss:0.5433076620101929\n",
            "Epoch: 30 | Loss: 0.5433076620101929 | Test loss: 0.5731053352355957\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7604]])), ('linear_layer.bias', tensor([0.8194]))])\n",
            "Loss:0.542911946773529\n",
            "Loss:0.5425163507461548\n",
            "Loss:0.5421206951141357\n",
            "Loss:0.5417249798774719\n",
            "Loss:0.5413292646408081\n",
            "Loss:0.5409336090087891\n",
            "Loss:0.5405378937721252\n",
            "Loss:0.5401422381401062\n",
            "Loss:0.5397466421127319\n",
            "Loss:0.5393509268760681\n",
            "Epoch: 40 | Loss: 0.5393509268760681 | Test loss: 0.5684788823127747\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7590]])), ('linear_layer.bias', tensor([0.8159]))])\n",
            "Loss:0.5389552116394043\n",
            "Loss:0.5385595560073853\n",
            "Loss:0.5381639003753662\n",
            "Loss:0.5377682447433472\n",
            "Loss:0.5373725891113281\n",
            "Loss:0.5369768738746643\n",
            "Loss:0.5365811586380005\n",
            "Loss:0.5361855626106262\n",
            "Loss:0.5357898473739624\n",
            "Loss:0.5353941321372986\n",
            "Epoch: 50 | Loss: 0.5353941321372986 | Test loss: 0.5638524889945984\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7577]])), ('linear_layer.bias', tensor([0.8125]))])\n",
            "Loss:0.5349984765052795\n",
            "Loss:0.5346028208732605\n",
            "Loss:0.5342071056365967\n",
            "Loss:0.5338114500045776\n",
            "Loss:0.5334157943725586\n",
            "Loss:0.5330201387405396\n",
            "Loss:0.5326244831085205\n",
            "Loss:0.5322287678718567\n",
            "Loss:0.5318330526351929\n",
            "Loss:0.5314373970031738\n",
            "Epoch: 60 | Loss: 0.5314373970031738 | Test loss: 0.5592260956764221\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7564]])), ('linear_layer.bias', tensor([0.8091]))])\n",
            "Loss:0.5310417413711548\n",
            "Loss:0.5306460857391357\n",
            "Loss:0.5302504301071167\n",
            "Loss:0.5298546552658081\n",
            "Loss:0.5294590592384338\n",
            "Loss:0.52906334400177\n",
            "Loss:0.528667688369751\n",
            "Loss:0.5282720327377319\n",
            "Loss:0.5278763175010681\n",
            "Loss:0.5274806022644043\n",
            "Epoch: 70 | Loss: 0.5274806022644043 | Test loss: 0.5545996427536011\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7550]])), ('linear_layer.bias', tensor([0.8056]))])\n",
            "Loss:0.52708500623703\n",
            "Loss:0.5266892910003662\n",
            "Loss:0.5262936353683472\n",
            "Loss:0.5258979201316833\n",
            "Loss:0.5255022644996643\n",
            "Loss:0.5251066088676453\n",
            "Loss:0.524711012840271\n",
            "Loss:0.5243152379989624\n",
            "Loss:0.5239195823669434\n",
            "Loss:0.5235239267349243\n",
            "Epoch: 80 | Loss: 0.5235239267349243 | Test loss: 0.5499732494354248\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7537]])), ('linear_layer.bias', tensor([0.8022]))])\n",
            "Loss:0.5231282114982605\n",
            "Loss:0.5227325558662415\n",
            "Loss:0.5223369002342224\n",
            "Loss:0.5219411849975586\n",
            "Loss:0.5215455293655396\n",
            "Loss:0.5211498141288757\n",
            "Loss:0.5207541584968567\n",
            "Loss:0.5203585028648376\n",
            "Loss:0.5199629068374634\n",
            "Loss:0.5195671319961548\n",
            "Epoch: 90 | Loss: 0.5195671319961548 | Test loss: 0.5453468561172485\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7524]])), ('linear_layer.bias', tensor([0.7988]))])\n",
            "Loss:0.5191714763641357\n",
            "Loss:0.5187758207321167\n",
            "Loss:0.5183801651000977\n",
            "Loss:0.5179845094680786\n",
            "Loss:0.5175887942314148\n",
            "Loss:0.517193078994751\n",
            "Loss:0.5167974233627319\n",
            "Loss:0.5164017677307129\n",
            "Loss:0.5160061120986938\n",
            "Loss:0.51561039686203\n",
            "Epoch: 100 | Loss: 0.51561039686203 | Test loss: 0.5407204627990723\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7510]])), ('linear_layer.bias', tensor([0.7953]))])\n",
            "Loss:0.515214741230011\n",
            "Loss:0.5148190259933472\n",
            "Loss:0.5144233703613281\n",
            "Loss:0.5140277147293091\n",
            "Loss:0.5136319994926453\n",
            "Loss:0.5132363438606262\n",
            "Loss:0.5128406882286072\n",
            "Loss:0.5124449729919434\n",
            "Loss:0.5120493173599243\n",
            "Loss:0.5116536617279053\n",
            "Epoch: 110 | Loss: 0.5116536617279053 | Test loss: 0.536094069480896\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7497]])), ('linear_layer.bias', tensor([0.7919]))])\n",
            "Loss:0.5112580060958862\n",
            "Loss:0.5108622908592224\n",
            "Loss:0.5104666948318481\n",
            "Loss:0.5100709199905396\n",
            "Loss:0.5096753239631653\n",
            "Loss:0.5092796087265015\n",
            "Loss:0.5088838934898376\n",
            "Loss:0.5084882378578186\n",
            "Loss:0.5080925226211548\n",
            "Loss:0.5076969265937805\n",
            "Epoch: 120 | Loss: 0.5076969265937805 | Test loss: 0.5314675569534302\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7483]])), ('linear_layer.bias', tensor([0.7885]))])\n",
            "Loss:0.5073012113571167\n",
            "Loss:0.5069055557250977\n",
            "Loss:0.5065098404884338\n",
            "Loss:0.5061141848564148\n",
            "Loss:0.5057185888290405\n",
            "Loss:0.5053228139877319\n",
            "Loss:0.5049271583557129\n",
            "Loss:0.5045315027236938\n",
            "Loss:0.50413578748703\n",
            "Loss:0.5037401914596558\n",
            "Epoch: 130 | Loss: 0.5037401914596558 | Test loss: 0.5268412232398987\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7470]])), ('linear_layer.bias', tensor([0.7850]))])\n",
            "Loss:0.5033444762229919\n",
            "Loss:0.5029488205909729\n",
            "Loss:0.5025531053543091\n",
            "Loss:0.50215744972229\n",
            "Loss:0.501761794090271\n",
            "Loss:0.5013660192489624\n",
            "Loss:0.5009704828262329\n",
            "Loss:0.5005747079849243\n",
            "Loss:0.5001790523529053\n",
            "Loss:0.49978336691856384\n",
            "Epoch: 140 | Loss: 0.49978336691856384 | Test loss: 0.5222147703170776\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7457]])), ('linear_layer.bias', tensor([0.7816]))])\n",
            "Loss:0.4993877410888672\n",
            "Loss:0.49899205565452576\n",
            "Loss:0.49859634041786194\n",
            "Loss:0.4982006549835205\n",
            "Loss:0.49780502915382385\n",
            "Loss:0.4974093437194824\n",
            "Loss:0.497013658285141\n",
            "Loss:0.49661797285079956\n",
            "Loss:0.4962223172187805\n",
            "Loss:0.4958266317844391\n",
            "Epoch: 150 | Loss: 0.4958266317844391 | Test loss: 0.5175884366035461\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7443]])), ('linear_layer.bias', tensor([0.7781]))])\n",
            "Loss:0.49543094635009766\n",
            "Loss:0.495035320520401\n",
            "Loss:0.4946395754814148\n",
            "Loss:0.49424394965171814\n",
            "Loss:0.4938482344150543\n",
            "Loss:0.4934525489807129\n",
            "Loss:0.49305686354637146\n",
            "Loss:0.4926612973213196\n",
            "Loss:0.4922655522823334\n",
            "Loss:0.49186986684799194\n",
            "Epoch: 160 | Loss: 0.49186986684799194 | Test loss: 0.5129619836807251\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|   | 69/100 [00:21<00:10,  2.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('linear_layer.weight', tensor([[0.7430]])), ('linear_layer.bias', tensor([0.7747]))])\n",
            "Loss:0.4914742112159729\n",
            "Loss:0.49107852578163147\n",
            "Loss:0.49068284034729004\n",
            "Loss:0.4902872145175934\n",
            "Loss:0.48989152908325195\n",
            "Loss:0.48949581384658813\n",
            "Loss:0.4891001582145691\n",
            "Loss:0.48870450258255005\n",
            "Loss:0.488308846950531\n",
            "Loss:0.4879131317138672\n",
            "Epoch: 170 | Loss: 0.4879131317138672 | Test loss: 0.508335530757904\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7416]])), ('linear_layer.bias', tensor([0.7713]))])\n",
            "Loss:0.48751744627952576\n",
            "Loss:0.4871217608451843\n",
            "Loss:0.4867261052131653\n",
            "Loss:0.48633041977882385\n",
            "Loss:0.4859347939491272\n",
            "Loss:0.48553910851478577\n",
            "Loss:0.48514342308044434\n",
            "Loss:0.4847477376461029\n",
            "Loss:0.48435211181640625\n",
            "Loss:0.48395639657974243\n",
            "Epoch: 180 | Loss: 0.48395639657974243 | Test loss: 0.5037091970443726\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7403]])), ('linear_layer.bias', tensor([0.7678]))])\n",
            "Loss:0.483560711145401\n",
            "Loss:0.48316502571105957\n",
            "Loss:0.4827693998813629\n",
            "Loss:0.4823737144470215\n",
            "Loss:0.48197799921035767\n",
            "Loss:0.4815823435783386\n",
            "Loss:0.4811866283416748\n",
            "Loss:0.4807909429073334\n",
            "Loss:0.4803953170776367\n",
            "Loss:0.4799996316432953\n",
            "Epoch: 190 | Loss: 0.4799996316432953 | Test loss: 0.4990827143192291\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7390]])), ('linear_layer.bias', tensor([0.7644]))])\n",
            "Loss:0.47960394620895386\n",
            "Loss:0.4792082905769348\n",
            "Loss:0.4788126051425934\n",
            "Loss:0.47841691970825195\n",
            "Loss:0.4780212342739105\n",
            "Loss:0.47762560844421387\n",
            "Loss:0.47722989320755005\n",
            "Loss:0.476834237575531\n",
            "Loss:0.4764385223388672\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5869777202606201\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5547764301300049\n",
            "Loss:0.5543748736381531\n",
            "Loss:0.553973376750946\n",
            "Loss:0.5535719394683838\n",
            "Loss:0.553170382976532\n",
            "Loss:0.552768886089325\n",
            "Loss:0.5523673892021179\n",
            "Loss:0.5519658327102661\n",
            "Loss:0.5515643358230591\n",
            "Loss:0.551162838935852\n",
            "Epoch: 10 | Loss: 0.551162838935852 | Test loss: 0.5822831392288208\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7630]])), ('linear_layer.bias', tensor([0.8262]))])\n",
            "Loss:0.550761342048645\n",
            "Loss:0.550359845161438\n",
            "Loss:0.5499582886695862\n",
            "Loss:0.5495567917823792\n",
            "Loss:0.5491553544998169\n",
            "Loss:0.5487537980079651\n",
            "Loss:0.5483523011207581\n",
            "Loss:0.547950804233551\n",
            "Loss:0.547549307346344\n",
            "Loss:0.5471477508544922\n",
            "Epoch: 20 | Loss: 0.5471477508544922 | Test loss: 0.5775885581970215\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7617]])), ('linear_layer.bias', tensor([0.8227]))])\n",
            "Loss:0.5467462539672852\n",
            "Loss:0.5463446974754333\n",
            "Loss:0.5459432005882263\n",
            "Loss:0.5455417037010193\n",
            "Loss:0.5451401472091675\n",
            "Loss:0.5447386503219604\n",
            "Loss:0.5443372130393982\n",
            "Loss:0.5439356565475464\n",
            "Loss:0.5435342192649841\n",
            "Loss:0.5431326627731323\n",
            "Epoch: 30 | Loss: 0.5431326627731323 | Test loss: 0.5728939771652222\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7603]])), ('linear_layer.bias', tensor([0.8192]))])\n",
            "Loss:0.5427311658859253\n",
            "Loss:0.5423296689987183\n",
            "Loss:0.5419281125068665\n",
            "Loss:0.5415266752243042\n",
            "Loss:0.5411251187324524\n",
            "Loss:0.5407236218452454\n",
            "Loss:0.5403221249580383\n",
            "Loss:0.5399206280708313\n",
            "Loss:0.5395190715789795\n",
            "Loss:0.5391175746917725\n",
            "Epoch: 40 | Loss: 0.5391175746917725 | Test loss: 0.5681994557380676\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7590]])), ('linear_layer.bias', tensor([0.8157]))])\n",
            "Loss:0.5387161374092102\n",
            "Loss:0.5383145809173584\n",
            "Loss:0.5379130244255066\n",
            "Loss:0.5375115275382996\n",
            "Loss:0.5371099710464478\n",
            "Loss:0.5367084741592407\n",
            "Loss:0.5363070368766785\n",
            "Loss:0.5359054803848267\n",
            "Loss:0.5355039834976196\n",
            "Loss:0.5351024866104126\n",
            "Epoch: 50 | Loss: 0.5351024866104126 | Test loss: 0.5635048747062683\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7576]])), ('linear_layer.bias', tensor([0.8122]))])\n",
            "Loss:0.5347009897232056\n",
            "Loss:0.5342994928359985\n",
            "Loss:0.5338979959487915\n",
            "Loss:0.5334964394569397\n",
            "Loss:0.5330950021743774\n",
            "Loss:0.5326934456825256\n",
            "Loss:0.5322919487953186\n",
            "Loss:0.5318903923034668\n",
            "Loss:0.5314889550209045\n",
            "Loss:0.5310873985290527\n",
            "Epoch: 60 | Loss: 0.5310873985290527 | Test loss: 0.5588102340698242\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7562]])), ('linear_layer.bias', tensor([0.8087]))])\n",
            "Loss:0.5306859016418457\n",
            "Loss:0.5302844047546387\n",
            "Loss:0.5298828482627869\n",
            "Loss:0.5294814109802246\n",
            "Loss:0.5290798544883728\n",
            "Loss:0.5286783576011658\n",
            "Loss:0.528276801109314\n",
            "Loss:0.5278753042221069\n",
            "Loss:0.5274738073348999\n",
            "Loss:0.5270723104476929\n",
            "Epoch: 70 | Loss: 0.5270723104476929 | Test loss: 0.5541156530380249\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7549]])), ('linear_layer.bias', tensor([0.8053]))])\n",
            "Loss:0.5266708135604858\n",
            "Loss:0.5262693166732788\n",
            "Loss:0.5258678197860718\n",
            "Loss:0.5254663228988647\n",
            "Loss:0.5250647664070129\n",
            "Loss:0.5246632695198059\n",
            "Loss:0.5242617726325989\n",
            "Loss:0.5238602161407471\n",
            "Loss:0.5234587788581848\n",
            "Loss:0.523057222366333\n",
            "Epoch: 80 | Loss: 0.523057222366333 | Test loss: 0.5494210720062256\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7535]])), ('linear_layer.bias', tensor([0.8018]))])\n",
            "Loss:0.522655725479126\n",
            "Loss:0.522254228591919\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|   | 70/100 [00:21<00:10,  2.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5218526721000671\n",
            "Loss:0.5214511752128601\n",
            "Loss:0.5210496783256531\n",
            "Loss:0.520648181438446\n",
            "Loss:0.5202466249465942\n",
            "Loss:0.5198451280593872\n",
            "Loss:0.5194436311721802\n",
            "Loss:0.5190421342849731\n",
            "Epoch: 90 | Loss: 0.5190421342849731 | Test loss: 0.5447264909744263\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7522]])), ('linear_layer.bias', tensor([0.7983]))])\n",
            "Loss:0.5186406373977661\n",
            "Loss:0.5182391405105591\n",
            "Loss:0.517837643623352\n",
            "Loss:0.517436146736145\n",
            "Loss:0.5170345902442932\n",
            "Loss:0.516633152961731\n",
            "Loss:0.5162315368652344\n",
            "Loss:0.5158300399780273\n",
            "Loss:0.5154285430908203\n",
            "Loss:0.5150270462036133\n",
            "Epoch: 100 | Loss: 0.5150270462036133 | Test loss: 0.540031909942627\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7508]])), ('linear_layer.bias', tensor([0.7948]))])\n",
            "Loss:0.5146255493164062\n",
            "Loss:0.5142240524291992\n",
            "Loss:0.5138224959373474\n",
            "Loss:0.5134210586547852\n",
            "Loss:0.5130195021629333\n",
            "Loss:0.5126180052757263\n",
            "Loss:0.5122164487838745\n",
            "Loss:0.5118149518966675\n",
            "Loss:0.5114134550094604\n",
            "Loss:0.5110119581222534\n",
            "Epoch: 110 | Loss: 0.5110119581222534 | Test loss: 0.5353373289108276\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7495]])), ('linear_layer.bias', tensor([0.7913]))])\n",
            "Loss:0.5106104612350464\n",
            "Loss:0.5102089643478394\n",
            "Loss:0.5098074078559875\n",
            "Loss:0.5094059705734253\n",
            "Loss:0.5090044736862183\n",
            "Loss:0.5086029171943665\n",
            "Loss:0.5082014203071594\n",
            "Loss:0.5077998638153076\n",
            "Loss:0.5073984265327454\n",
            "Loss:0.5069968700408936\n",
            "Epoch: 120 | Loss: 0.5069968700408936 | Test loss: 0.5306428074836731\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7481]])), ('linear_layer.bias', tensor([0.7878]))])\n",
            "Loss:0.5065953731536865\n",
            "Loss:0.5061938166618347\n",
            "Loss:0.5057923793792725\n",
            "Loss:0.5053908228874207\n",
            "Loss:0.5049893260002136\n",
            "Loss:0.5045878291130066\n",
            "Loss:0.5041862726211548\n",
            "Loss:0.5037848353385925\n",
            "Loss:0.5033832788467407\n",
            "Loss:0.5029817819595337\n",
            "Epoch: 130 | Loss: 0.5029817819595337 | Test loss: 0.5259482264518738\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7467]])), ('linear_layer.bias', tensor([0.7844]))])\n",
            "Loss:0.5025802850723267\n",
            "Loss:0.5021787881851196\n",
            "Loss:0.5017772316932678\n",
            "Loss:0.5013757944107056\n",
            "Loss:0.5009742379188538\n",
            "Loss:0.5005728006362915\n",
            "Loss:0.5001711845397949\n",
            "Loss:0.49976974725723267\n",
            "Loss:0.49936819076538086\n",
            "Loss:0.49896669387817383\n",
            "Epoch: 140 | Loss: 0.49896669387817383 | Test loss: 0.5212535858154297\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7454]])), ('linear_layer.bias', tensor([0.7809]))])\n",
            "Loss:0.49856510758399963\n",
            "Loss:0.49816370010375977\n",
            "Loss:0.49776220321655273\n",
            "Loss:0.4973606467247009\n",
            "Loss:0.49695920944213867\n",
            "Loss:0.49655765295028687\n",
            "Loss:0.49615615606307983\n",
            "Loss:0.4957546293735504\n",
            "Loss:0.4953531324863434\n",
            "Loss:0.49495163559913635\n",
            "Epoch: 150 | Loss: 0.49495163559913635 | Test loss: 0.5165590047836304\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7440]])), ('linear_layer.bias', tensor([0.7774]))])\n",
            "Loss:0.49455007910728455\n",
            "Loss:0.4941485822200775\n",
            "Loss:0.4937470853328705\n",
            "Loss:0.49334555864334106\n",
            "Loss:0.4929440915584564\n",
            "Loss:0.4925425052642822\n",
            "Loss:0.49214106798171997\n",
            "Loss:0.49173957109451294\n",
            "Loss:0.49133801460266113\n",
            "Loss:0.4909365773200989\n",
            "Epoch: 160 | Loss: 0.4909365773200989 | Test loss: 0.511864423751831\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7427]])), ('linear_layer.bias', tensor([0.7739]))])\n",
            "Loss:0.4905349612236023\n",
            "Loss:0.49013352394104004\n",
            "Loss:0.48973196744918823\n",
            "Loss:0.4893304705619812\n",
            "Loss:0.4889289438724518\n",
            "Loss:0.48852747678756714\n",
            "Loss:0.4881259500980377\n",
            "Loss:0.4877244830131531\n",
            "Loss:0.48732295632362366\n",
            "Loss:0.4869214594364166\n",
            "Epoch: 170 | Loss: 0.4869214594364166 | Test loss: 0.5071698427200317\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7413]])), ('linear_layer.bias', tensor([0.7704]))])\n",
            "Loss:0.4865199029445648\n",
            "Loss:0.48611846566200256\n",
            "Loss:0.4857168197631836\n",
            "Loss:0.48531538248062134\n",
            "Loss:0.4849139153957367\n",
            "Loss:0.4845123887062073\n",
            "Loss:0.48411083221435547\n",
            "Loss:0.4837093949317932\n",
            "Loss:0.4833078384399414\n",
            "Loss:0.4829063415527344\n",
            "Epoch: 180 | Loss: 0.4829063415527344 | Test loss: 0.5024752616882324\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7399]])), ('linear_layer.bias', tensor([0.7669]))])\n",
            "Loss:0.48250484466552734\n",
            "Loss:0.4821033477783203\n",
            "Loss:0.4817017912864685\n",
            "Loss:0.4813002645969391\n",
            "Loss:0.48089879751205444\n",
            "Loss:0.480497270822525\n",
            "Loss:0.4800958037376404\n",
            "Loss:0.47969427704811096\n",
            "Loss:0.47929278016090393\n",
            "Loss:0.4788912832736969\n",
            "Epoch: 190 | Loss: 0.4788912832736969 | Test loss: 0.4977806508541107\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7386]])), ('linear_layer.bias', tensor([0.7634]))])\n",
            "Loss:0.4784897267818451\n",
            "Loss:0.4780882000923157\n",
            "Loss:0.47768673300743103\n",
            "Loss:0.477285236120224\n",
            "Loss:0.4768837094306946\n",
            "Loss:0.47648224234580994\n",
            "Loss:0.47608065605163574\n",
            "Loss:0.4756792187690735\n",
            "Loss:0.4752776622772217\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5869709253311157\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8297]))])\n",
            "Loss:0.5547707080841064\n",
            "Loss:0.5543633699417114\n",
            "Loss:0.553956151008606\n",
            "Loss:0.5535488128662109\n",
            "Loss:0.5531415343284607\n",
            "Loss:0.5527342557907104\n",
            "Loss:0.552327036857605\n",
            "Loss:0.5519196391105652\n",
            "Loss:0.5515123605728149\n",
            "Loss:0.5511051416397095\n",
            "Epoch: 10 | Loss: 0.5511051416397095 | Test loss: 0.5822088718414307\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7630]])), ('linear_layer.bias', tensor([0.8261]))])\n",
            "Loss:0.5506978034973145\n",
            "Loss:0.5502905249595642\n",
            "Loss:0.549883246421814\n",
            "Loss:0.5494760274887085\n",
            "Loss:0.5490686893463135\n",
            "Loss:0.5486614108085632\n",
            "Loss:0.548254132270813\n",
            "Loss:0.5478468537330627\n",
            "Loss:0.5474395751953125\n",
            "Loss:0.5470322370529175\n",
            "Epoch: 20 | Loss: 0.5470322370529175 | Test loss: 0.577446699142456\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7616]])), ('linear_layer.bias', tensor([0.8226]))])\n",
            "Loss:0.5466249585151672\n",
            "Loss:0.5462177395820618\n",
            "Loss:0.5458104014396667\n",
            "Loss:0.5454031229019165\n",
            "Loss:0.5449958443641663\n",
            "Loss:0.5445886850357056\n",
            "Loss:0.5441812872886658\n",
            "Loss:0.5437740087509155\n",
            "Loss:0.5433666110038757\n",
            "Loss:0.5429593920707703\n",
            "Epoch: 30 | Loss: 0.5429593920707703 | Test loss: 0.5726845264434814\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7603]])), ('linear_layer.bias', tensor([0.8190]))])\n",
            "Loss:0.5425521731376648\n",
            "Loss:0.5421448945999146\n",
            "Loss:0.5417375564575195\n",
            "Loss:0.5413303375244141\n",
            "Loss:0.5409230589866638\n",
            "Loss:0.5405157804489136\n",
            "Loss:0.5401085019111633\n",
            "Loss:0.5397012233734131\n",
            "Loss:0.5392939448356628\n",
            "Loss:0.5388866066932678\n",
            "Epoch: 40 | Loss: 0.5388866066932678 | Test loss: 0.5679224133491516\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7589]])), ('linear_layer.bias', tensor([0.8155]))])\n",
            "Loss:0.5384793877601624\n",
            "Loss:0.5380720496177673\n",
            "Loss:0.5376647710800171\n",
            "Loss:0.5372574925422668\n",
            "Loss:0.5368502140045166\n",
            "Loss:0.5364429354667664\n",
            "Loss:0.5360356569290161\n",
            "Loss:0.5356283187866211\n",
            "Loss:0.5352210402488708\n",
            "Loss:0.5348137617111206\n",
            "Epoch: 50 | Loss: 0.5348137617111206 | Test loss: 0.5631601810455322\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7575]])), ('linear_layer.bias', tensor([0.8120]))])\n",
            "Loss:0.5344064831733704\n",
            "Loss:0.5339992046356201\n",
            "Loss:0.5335919260978699\n",
            "Loss:0.5331846475601196\n",
            "Loss:0.5327773690223694\n",
            "Loss:0.5323700904846191\n",
            "Loss:0.5319628119468689\n",
            "Loss:0.5315554738044739\n",
            "Loss:0.5311482548713684\n",
            "Loss:0.5307409763336182\n",
            "Epoch: 60 | Loss: 0.5307409763336182 | Test loss: 0.5583980679512024\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7561]])), ('linear_layer.bias', tensor([0.8084]))])\n",
            "Loss:0.5303336977958679\n",
            "Loss:0.5299264192581177\n",
            "Loss:0.5295191407203674\n",
            "Loss:0.5291118621826172\n",
            "Loss:0.5287045240402222\n",
            "Loss:0.5282973051071167\n",
            "Loss:0.5278899669647217\n",
            "Loss:0.5274826884269714\n",
            "Loss:0.5270754098892212\n",
            "Loss:0.5266681909561157\n",
            "Epoch: 70 | Loss: 0.5266681909561157 | Test loss: 0.5536358952522278\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7548]])), ('linear_layer.bias', tensor([0.8049]))])\n",
            "Loss:0.5262608528137207\n",
            "Loss:0.5258535742759705\n",
            "Loss:0.5254462957382202\n",
            "Loss:0.52503901720047\n",
            "Loss:0.524631679058075\n",
            "Loss:0.5242244005203247\n",
            "Loss:0.5238171815872192\n",
            "Loss:0.523409903049469\n",
            "Loss:0.5230026245117188\n",
            "Loss:0.5225952863693237\n",
            "Epoch: 80 | Loss: 0.5225952863693237 | Test loss: 0.5488737225532532\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7534]])), ('linear_layer.bias', tensor([0.8014]))])\n",
            "Loss:0.5221880078315735\n",
            "Loss:0.5217807292938232\n",
            "Loss:0.521373450756073\n",
            "Loss:0.5209661722183228\n",
            "Loss:0.5205589532852173\n",
            "Loss:0.5201516151428223\n",
            "Loss:0.5197443962097168\n",
            "Loss:0.5193370580673218\n",
            "Loss:0.5189297795295715\n",
            "Loss:0.5185225009918213\n",
            "Epoch: 90 | Loss: 0.5185225009918213 | Test loss: 0.5441116094589233\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7520]])), ('linear_layer.bias', tensor([0.7978]))])\n",
            "Loss:0.518115222454071\n",
            "Loss:0.5177079439163208\n",
            "Loss:0.5173006653785706\n",
            "Loss:0.5168933272361755\n",
            "Loss:0.5164861083030701\n",
            "Loss:0.5160788297653198\n",
            "Loss:0.5156714916229248\n",
            "Loss:0.5152642130851746\n",
            "Loss:0.5148569345474243\n",
            "Loss:0.5144496560096741\n",
            "Epoch: 100 | Loss: 0.5144496560096741 | Test loss: 0.5393494367599487\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7506]])), ('linear_layer.bias', tensor([0.7943]))])\n",
            "Loss:0.5140423774719238\n",
            "Loss:0.5136350393295288\n",
            "Loss:0.5132278203964233\n",
            "Loss:0.5128205418586731\n",
            "Loss:0.5124132037162781\n",
            "Loss:0.5120059251785278\n",
            "Loss:0.5115987062454224\n",
            "Loss:0.5111913681030273\n",
            "Loss:0.5107840895652771\n",
            "Loss:0.5103768110275269\n",
            "Epoch: 110 | Loss: 0.5103768110275269 | Test loss: 0.5345872640609741\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7492]])), ('linear_layer.bias', tensor([0.7908]))])\n",
            "Loss:0.5099695324897766\n",
            "Loss:0.5095622539520264\n",
            "Loss:0.5091549754142761\n",
            "Loss:0.5087476968765259\n",
            "Loss:0.5083404779434204\n",
            "Loss:0.5079331398010254\n",
            "Loss:0.5075259208679199\n",
            "Loss:0.5071185827255249\n",
            "Loss:0.5067113041877747\n",
            "Loss:0.5063040256500244\n",
            "Epoch: 120 | Loss: 0.5063040256500244 | Test loss: 0.5298251509666443\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7479]])), ('linear_layer.bias', tensor([0.7872]))])\n",
            "Loss:0.5058967471122742\n",
            "Loss:0.5054894685745239\n",
            "Loss:0.5050821900367737\n",
            "Loss:0.5046748518943787\n",
            "Loss:0.5042675733566284\n",
            "Loss:0.5038602948188782\n",
            "Loss:0.5034530758857727\n",
            "Loss:0.5030457377433777\n",
            "Loss:0.5026384592056274\n",
            "Loss:0.5022311806678772\n",
            "Epoch: 130 | Loss: 0.5022311806678772 | Test loss: 0.5250629186630249\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7465]])), ('linear_layer.bias', tensor([0.7837]))])\n",
            "Loss:0.501823902130127\n",
            "Loss:0.5014166235923767\n",
            "Loss:0.5010093450546265\n",
            "Loss:0.5006020665168762\n",
            "Loss:0.5001947283744812\n",
            "Loss:0.49978747963905334\n",
            "Loss:0.4993802011013031\n",
            "Loss:0.49897295236587524\n",
            "Loss:0.4985656142234802\n",
            "Loss:0.49815836548805237\n",
            "Epoch: 140 | Loss: 0.49815836548805237 | Test loss: 0.5203008055686951\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7451]])), ('linear_layer.bias', tensor([0.7802]))])\n",
            "Loss:0.49775105714797974\n",
            "Loss:0.49734383821487427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|   | 71/100 [00:22<00:09,  2.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.4969364106655121\n",
            "Loss:0.4965292811393738\n",
            "Loss:0.49612197279930115\n",
            "Loss:0.4957146644592285\n",
            "Loss:0.4953073561191559\n",
            "Loss:0.4949001371860504\n",
            "Loss:0.4944928288459778\n",
            "Loss:0.49408555030822754\n",
            "Epoch: 150 | Loss: 0.49408555030822754 | Test loss: 0.5155386328697205\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7437]])), ('linear_layer.bias', tensor([0.7766]))])\n",
            "Loss:0.4936782419681549\n",
            "Loss:0.49327102303504944\n",
            "Loss:0.4928637146949768\n",
            "Loss:0.4924563765525818\n",
            "Loss:0.49204906821250916\n",
            "Loss:0.4916418492794037\n",
            "Loss:0.49123454093933105\n",
            "Loss:0.4908272624015808\n",
            "Loss:0.49042001366615295\n",
            "Loss:0.4900127053260803\n",
            "Epoch: 160 | Loss: 0.4900127053260803 | Test loss: 0.5107765197753906\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7423]])), ('linear_layer.bias', tensor([0.7731]))])\n",
            "Loss:0.4896053671836853\n",
            "Loss:0.48919811844825745\n",
            "Loss:0.4887908399105072\n",
            "Loss:0.48838353157043457\n",
            "Loss:0.4879762530326843\n",
            "Loss:0.48756900429725647\n",
            "Loss:0.48716169595718384\n",
            "Loss:0.4867544174194336\n",
            "Loss:0.48634713888168335\n",
            "Loss:0.4859398901462555\n",
            "Epoch: 170 | Loss: 0.4859398901462555 | Test loss: 0.506014347076416\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7410]])), ('linear_layer.bias', tensor([0.7696]))])\n",
            "Loss:0.48553258180618286\n",
            "Loss:0.48512524366378784\n",
            "Loss:0.4847180247306824\n",
            "Loss:0.48431071639060974\n",
            "Loss:0.4839034080505371\n",
            "Loss:0.48349618911743164\n",
            "Loss:0.483088880777359\n",
            "Loss:0.48268166184425354\n",
            "Loss:0.4822743535041809\n",
            "Loss:0.48186707496643066\n",
            "Epoch: 180 | Loss: 0.48186707496643066 | Test loss: 0.5012522339820862\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7396]])), ('linear_layer.bias', tensor([0.7660]))])\n",
            "Loss:0.48145976662635803\n",
            "Loss:0.4810524880886078\n",
            "Loss:0.48064517974853516\n",
            "Loss:0.4802379608154297\n",
            "Loss:0.47983065247535706\n",
            "Loss:0.4794233739376068\n",
            "Loss:0.4790160655975342\n",
            "Loss:0.47860878705978394\n",
            "Loss:0.4782015383243561\n",
            "Loss:0.47779422998428345\n",
            "Epoch: 190 | Loss: 0.47779422998428345 | Test loss: 0.4964900612831116\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7382]])), ('linear_layer.bias', tensor([0.7625]))])\n",
            "Loss:0.4773869514465332\n",
            "Loss:0.47697967290878296\n",
            "Loss:0.47657233476638794\n",
            "Loss:0.47616511583328247\n",
            "Loss:0.47575777769088745\n",
            "Loss:0.4753505289554596\n",
            "Loss:0.47494325041770935\n",
            "Loss:0.4745359420776367\n",
            "Loss:0.4741286337375641\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5869642496109009\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5547648072242737\n",
            "Loss:0.5543516874313354\n",
            "Loss:0.5539385676383972\n",
            "Loss:0.5535255074501038\n",
            "Loss:0.5531123876571655\n",
            "Loss:0.5526992678642273\n",
            "Loss:0.5522861480712891\n",
            "Loss:0.5518730282783508\n",
            "Loss:0.5514599084854126\n",
            "Loss:0.5510467886924744\n",
            "Epoch: 10 | Loss: 0.5510467886924744 | Test loss: 0.5821338295936584\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7630]])), ('linear_layer.bias', tensor([0.8261]))])\n",
            "Loss:0.5506336688995361\n",
            "Loss:0.5502205491065979\n",
            "Loss:0.5498074293136597\n",
            "Loss:0.5493943095207214\n",
            "Loss:0.5489811301231384\n",
            "Loss:0.548568069934845\n",
            "Loss:0.5481549501419067\n",
            "Loss:0.5477418899536133\n",
            "Loss:0.5473287105560303\n",
            "Loss:0.546915590763092\n",
            "Epoch: 20 | Loss: 0.546915590763092 | Test loss: 0.5773035287857056\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7616]])), ('linear_layer.bias', tensor([0.8225]))])\n",
            "Loss:0.5465024709701538\n",
            "Loss:0.5460894107818604\n",
            "Loss:0.5456762313842773\n",
            "Loss:0.5452631711959839\n",
            "Loss:0.5448499917984009\n",
            "Loss:0.5444368124008179\n",
            "Loss:0.5440238118171692\n",
            "Loss:0.543610692024231\n",
            "Loss:0.543197512626648\n",
            "Loss:0.5427843928337097\n",
            "Epoch: 30 | Loss: 0.5427843928337097 | Test loss: 0.5724731683731079\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7602]])), ('linear_layer.bias', tensor([0.8189]))])\n",
            "Loss:0.5423712730407715\n",
            "Loss:0.541958212852478\n",
            "Loss:0.5415450930595398\n",
            "Loss:0.5411319732666016\n",
            "Loss:0.5407189130783081\n",
            "Loss:0.5403057336807251\n",
            "Loss:0.5398926138877869\n",
            "Loss:0.5394794940948486\n",
            "Loss:0.5390663743019104\n",
            "Loss:0.5386532545089722\n",
            "Epoch: 40 | Loss: 0.5386532545089722 | Test loss: 0.567642867565155\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7588]])), ('linear_layer.bias', tensor([0.8153]))])\n",
            "Loss:0.5382401347160339\n",
            "Loss:0.5378271341323853\n",
            "Loss:0.5374139547348022\n",
            "Loss:0.5370007753372192\n",
            "Loss:0.5365877747535706\n",
            "Loss:0.5361745953559875\n",
            "Loss:0.5357614755630493\n",
            "Loss:0.5353483557701111\n",
            "Loss:0.5349352359771729\n",
            "Loss:0.5345221757888794\n",
            "Epoch: 50 | Loss: 0.5345221757888794 | Test loss: 0.5628125667572021\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7574]])), ('linear_layer.bias', tensor([0.8117]))])\n",
            "Loss:0.5341089963912964\n",
            "Loss:0.5336958765983582\n",
            "Loss:0.5332827568054199\n",
            "Loss:0.5328696370124817\n",
            "Loss:0.5324565172195435\n",
            "Loss:0.53204345703125\n",
            "Loss:0.531630277633667\n",
            "Loss:0.5312172174453735\n",
            "Loss:0.5308040380477905\n",
            "Loss:0.5303909778594971\n",
            "Epoch: 60 | Loss: 0.5303909778594971 | Test loss: 0.5579821467399597\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7560]])), ('linear_layer.bias', tensor([0.8081]))])\n",
            "Loss:0.5299778580665588\n",
            "Loss:0.5295647382736206\n",
            "Loss:0.5291516184806824\n",
            "Loss:0.5287384390830994\n",
            "Loss:0.5283253192901611\n",
            "Loss:0.5279122591018677\n",
            "Loss:0.5274991393089294\n",
            "Loss:0.527086079120636\n",
            "Loss:0.526672899723053\n",
            "Loss:0.5262597799301147\n",
            "Epoch: 70 | Loss: 0.5262597799301147 | Test loss: 0.5531519055366516\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7546]])), ('linear_layer.bias', tensor([0.8045]))])\n",
            "Loss:0.5258467197418213\n",
            "Loss:0.5254335999488831\n",
            "Loss:0.5250204205513\n",
            "Loss:0.5246073007583618\n",
            "Loss:0.5241941809654236\n",
            "Loss:0.5237811207771301\n",
            "Loss:0.5233680009841919\n",
            "Loss:0.5229548215866089\n",
            "Loss:0.5225417613983154\n",
            "Loss:0.5221286416053772\n",
            "Epoch: 80 | Loss: 0.5221286416053772 | Test loss: 0.5483216047286987\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7532]])), ('linear_layer.bias', tensor([0.8010]))])\n",
            "Loss:0.521715521812439\n",
            "Loss:0.521302342414856\n",
            "Loss:0.5208892822265625\n",
            "Loss:0.520476222038269\n",
            "Loss:0.520063042640686\n",
            "Loss:0.5196499228477478\n",
            "Loss:0.5192368626594543\n",
            "Loss:0.5188237428665161\n",
            "Loss:0.5184105634689331\n",
            "Loss:0.5179975032806396\n",
            "Epoch: 90 | Loss: 0.5179975032806396 | Test loss: 0.5434912443161011\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7518]])), ('linear_layer.bias', tensor([0.7974]))])\n",
            "Loss:0.5175843834877014\n",
            "Loss:0.5171712636947632\n",
            "Loss:0.5167580842971802\n",
            "Loss:0.5163450241088867\n",
            "Loss:0.5159319043159485\n",
            "Loss:0.5155187845230103\n",
            "Loss:0.515105664730072\n",
            "Loss:0.5146925449371338\n",
            "Loss:0.5142794251441956\n",
            "Loss:0.5138663053512573\n",
            "Epoch: 100 | Loss: 0.5138663053512573 | Test loss: 0.5386609435081482\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7504]])), ('linear_layer.bias', tensor([0.7938]))])\n",
            "Loss:0.5134531259536743\n",
            "Loss:0.5130400657653809\n",
            "Loss:0.5126270055770874\n",
            "Loss:0.5122138261795044\n",
            "Loss:0.5118007659912109\n",
            "Loss:0.5113875865936279\n",
            "Loss:0.5109745264053345\n",
            "Loss:0.5105613470077515\n",
            "Loss:0.510148286819458\n",
            "Loss:0.509735107421875\n",
            "Epoch: 110 | Loss: 0.509735107421875 | Test loss: 0.5338306427001953\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7490]])), ('linear_layer.bias', tensor([0.7902]))])\n",
            "Loss:0.5093220472335815\n",
            "Loss:0.5089088678359985\n",
            "Loss:0.5084958076477051\n",
            "Loss:0.5080826878547668\n",
            "Loss:0.5076696276664734\n",
            "Loss:0.5072564482688904\n",
            "Loss:0.5068433880805969\n",
            "Loss:0.5064302682876587\n",
            "Loss:0.5060170888900757\n",
            "Loss:0.5056039690971375\n",
            "Epoch: 120 | Loss: 0.5056039690971375 | Test loss: 0.5290002822875977\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7476]])), ('linear_layer.bias', tensor([0.7866]))])\n",
            "Loss:0.505190908908844\n",
            "Loss:0.504777729511261\n",
            "Loss:0.5043646097183228\n",
            "Loss:0.5039515495300293\n",
            "Loss:0.5035384297370911\n",
            "Loss:0.5031253099441528\n",
            "Loss:0.5027121305465698\n",
            "Loss:0.5022990107536316\n",
            "Loss:0.5018860101699829\n",
            "Loss:0.5014728307723999\n",
            "Epoch: 130 | Loss: 0.5014728307723999 | Test loss: 0.524169921875\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7462]])), ('linear_layer.bias', tensor([0.7830]))])\n",
            "Loss:0.5010597109794617\n",
            "Loss:0.5006465911865234\n",
            "Loss:0.5002334713935852\n",
            "Loss:0.49982038140296936\n",
            "Loss:0.49940723180770874\n",
            "Loss:0.4989941120147705\n",
            "Loss:0.4985809922218323\n",
            "Loss:0.49816784262657166\n",
            "Loss:0.4977547526359558\n",
            "Loss:0.4973416328430176\n",
            "Epoch: 140 | Loss: 0.4973416328430176 | Test loss: 0.5193396210670471\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7448]])), ('linear_layer.bias', tensor([0.7794]))])\n",
            "Loss:0.49692854285240173\n",
            "Loss:0.4965154230594635\n",
            "Loss:0.49610233306884766\n",
            "Loss:0.4956892132759094\n",
            "Loss:0.4952761232852936\n",
            "Loss:0.49486294388771057\n",
            "Loss:0.49444979429244995\n",
            "Loss:0.4940367341041565\n",
            "Loss:0.4936235845088959\n",
            "Loss:0.4932105541229248\n",
            "Epoch: 150 | Loss: 0.4932105541229248 | Test loss: 0.5145093202590942\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7434]])), ('linear_layer.bias', tensor([0.7759]))])\n",
            "Loss:0.4927974343299866\n",
            "Loss:0.49238425493240356\n",
            "Loss:0.4919711649417877\n",
            "Loss:0.4915580153465271\n",
            "Loss:0.49114495515823364\n",
            "Loss:0.490731805562973\n",
            "Loss:0.4903186857700348\n",
            "Loss:0.48990553617477417\n",
            "Loss:0.48949241638183594\n",
            "Loss:0.4890792965888977\n",
            "Epoch: 160 | Loss: 0.4890792965888977 | Test loss: 0.5096789598464966\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7420]])), ('linear_layer.bias', tensor([0.7723]))])\n",
            "Loss:0.48866623640060425\n",
            "Loss:0.48825305700302124\n",
            "Loss:0.4878399968147278\n",
            "Loss:0.48742690682411194\n",
            "Loss:0.48701372742652893\n",
            "Loss:0.48660069704055786\n",
            "Loss:0.48618751764297485\n",
            "Loss:0.4857744574546814\n",
            "Loss:0.4853612780570984\n",
            "Loss:0.48494815826416016\n",
            "Epoch: 170 | Loss: 0.48494815826416016 | Test loss: 0.5048486590385437\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7406]])), ('linear_layer.bias', tensor([0.7687]))])\n",
            "Loss:0.4845350682735443\n",
            "Loss:0.4841219484806061\n",
            "Loss:0.48370885848999023\n",
            "Loss:0.483295738697052\n",
            "Loss:0.482882559299469\n",
            "Loss:0.48246949911117554\n",
            "Loss:0.4820563793182373\n",
            "Loss:0.48164328932762146\n",
            "Loss:0.48123010993003845\n",
            "Loss:0.4808170199394226\n",
            "Epoch: 180 | Loss: 0.4808170199394226 | Test loss: 0.500018298625946\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7392]])), ('linear_layer.bias', tensor([0.7651]))])\n",
            "Loss:0.4804039001464844\n",
            "Loss:0.47999078035354614\n",
            "Loss:0.4795776307582855\n",
            "Loss:0.4791645407676697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|  | 72/100 [00:22<00:09,  2.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.4787514805793762\n",
            "Loss:0.47833824157714844\n",
            "Loss:0.47792521119117737\n",
            "Loss:0.47751206159591675\n",
            "Loss:0.4770990014076233\n",
            "Loss:0.47668585181236267\n",
            "Epoch: 190 | Loss: 0.47668585181236267 | Test loss: 0.49518799781799316\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7378]])), ('linear_layer.bias', tensor([0.7615]))])\n",
            "Loss:0.47627273201942444\n",
            "Loss:0.4758596420288086\n",
            "Loss:0.47544652223587036\n",
            "Loss:0.47503337264060974\n",
            "Loss:0.4746202826499939\n",
            "Loss:0.47420716285705566\n",
            "Loss:0.47379404306411743\n",
            "Loss:0.4733809530735016\n",
            "Loss:0.4729677736759186\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5869573354721069\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5547589659690857\n",
            "Loss:0.5543400049209595\n",
            "Loss:0.5539210438728333\n",
            "Loss:0.5535021424293518\n",
            "Loss:0.5530831813812256\n",
            "Loss:0.5526642203330994\n",
            "Loss:0.5522452592849731\n",
            "Loss:0.5518263578414917\n",
            "Loss:0.5514073967933655\n",
            "Loss:0.5509883761405945\n",
            "Epoch: 10 | Loss: 0.5509883761405945 | Test loss: 0.582058846950531\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7630]])), ('linear_layer.bias', tensor([0.8260]))])\n",
            "Loss:0.5505695343017578\n",
            "Loss:0.5501505136489868\n",
            "Loss:0.5497316122055054\n",
            "Loss:0.5493125915527344\n",
            "Loss:0.5488936901092529\n",
            "Loss:0.5484747290611267\n",
            "Loss:0.5480557680130005\n",
            "Loss:0.547636866569519\n",
            "Loss:0.547217845916748\n",
            "Loss:0.5467988848686218\n",
            "Epoch: 20 | Loss: 0.5467988848686218 | Test loss: 0.5771603584289551\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7616]])), ('linear_layer.bias', tensor([0.8224]))])\n",
            "Loss:0.5463799834251404\n",
            "Loss:0.5459610223770142\n",
            "Loss:0.5455420613288879\n",
            "Loss:0.5451231598854065\n",
            "Loss:0.5447041988372803\n",
            "Loss:0.5442851781845093\n",
            "Loss:0.5438662767410278\n",
            "Loss:0.5434473156929016\n",
            "Loss:0.5430284142494202\n",
            "Loss:0.542609453201294\n",
            "Epoch: 30 | Loss: 0.542609453201294 | Test loss: 0.5722618699073792\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7601]])), ('linear_layer.bias', tensor([0.8187]))])\n",
            "Loss:0.5421904921531677\n",
            "Loss:0.5417715311050415\n",
            "Loss:0.5413526296615601\n",
            "Loss:0.5409336090087891\n",
            "Loss:0.5405146479606628\n",
            "Loss:0.5400957465171814\n",
            "Loss:0.5396767854690552\n",
            "Loss:0.539257824420929\n",
            "Loss:0.5388388633728027\n",
            "Loss:0.5384199619293213\n",
            "Epoch: 40 | Loss: 0.5384199619293213 | Test loss: 0.5673633813858032\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7587]])), ('linear_layer.bias', tensor([0.8151]))])\n",
            "Loss:0.5380009412765503\n",
            "Loss:0.5375820398330688\n",
            "Loss:0.5371631383895874\n",
            "Loss:0.5367441773414612\n",
            "Loss:0.5363251566886902\n",
            "Loss:0.535906195640564\n",
            "Loss:0.5354872941970825\n",
            "Loss:0.5350682735443115\n",
            "Loss:0.5346494317054749\n",
            "Loss:0.5342304706573486\n",
            "Epoch: 50 | Loss: 0.5342304706573486 | Test loss: 0.5624648332595825\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7573]])), ('linear_layer.bias', tensor([0.8115]))])\n",
            "Loss:0.5338115096092224\n",
            "Loss:0.5333925485610962\n",
            "Loss:0.53297358751297\n",
            "Loss:0.5325546860694885\n",
            "Loss:0.5321357250213623\n",
            "Loss:0.5317167043685913\n",
            "Loss:0.5312978029251099\n",
            "Loss:0.5308789014816284\n",
            "Loss:0.5304598808288574\n",
            "Loss:0.5300409197807312\n",
            "Epoch: 60 | Loss: 0.5300409197807312 | Test loss: 0.5575663447380066\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7559]])), ('linear_layer.bias', tensor([0.8078]))])\n",
            "Loss:0.5296220183372498\n",
            "Loss:0.5292030572891235\n",
            "Loss:0.5287840962409973\n",
            "Loss:0.5283651351928711\n",
            "Loss:0.5279461741447449\n",
            "Loss:0.5275272727012634\n",
            "Loss:0.5271083116531372\n",
            "Loss:0.526689350605011\n",
            "Loss:0.5262704491615295\n",
            "Loss:0.5258514285087585\n",
            "Epoch: 70 | Loss: 0.5258514285087585 | Test loss: 0.5526679158210754\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7545]])), ('linear_layer.bias', tensor([0.8042]))])\n",
            "Loss:0.5254324674606323\n",
            "Loss:0.5250135660171509\n",
            "Loss:0.5245946645736694\n",
            "Loss:0.5241756439208984\n",
            "Loss:0.5237566828727722\n",
            "Loss:0.5233377814292908\n",
            "Loss:0.5229188203811646\n",
            "Loss:0.5224997997283936\n",
            "Loss:0.5220808982849121\n",
            "Loss:0.5216619372367859\n",
            "Epoch: 80 | Loss: 0.5216619372367859 | Test loss: 0.5477694272994995\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7531]])), ('linear_layer.bias', tensor([0.8006]))])\n",
            "Loss:0.5212429761886597\n",
            "Loss:0.5208240747451782\n",
            "Loss:0.520405113697052\n",
            "Loss:0.5199861526489258\n",
            "Loss:0.5195671319961548\n",
            "Loss:0.5191482305526733\n",
            "Loss:0.5187293291091919\n",
            "Loss:0.5183103680610657\n",
            "Loss:0.5178913474082947\n",
            "Loss:0.517472505569458\n",
            "Epoch: 90 | Loss: 0.517472505569458 | Test loss: 0.5428709387779236\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7516]])), ('linear_layer.bias', tensor([0.7969]))])\n",
            "Loss:0.517053484916687\n",
            "Loss:0.5166345834732056\n",
            "Loss:0.5162156224250793\n",
            "Loss:0.5157966017723083\n",
            "Loss:0.5153777003288269\n",
            "Loss:0.5149587392807007\n",
            "Loss:0.5145398378372192\n",
            "Loss:0.514120876789093\n",
            "Loss:0.5137019753456116\n",
            "Loss:0.5132828950881958\n",
            "Epoch: 100 | Loss: 0.5132828950881958 | Test loss: 0.5379723906517029\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7502]])), ('linear_layer.bias', tensor([0.7933]))])\n",
            "Loss:0.5128639936447144\n",
            "Loss:0.5124450922012329\n",
            "Loss:0.5120260119438171\n",
            "Loss:0.5116071701049805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|  | 73/100 [00:22<00:09,  2.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5111882090568542\n",
            "Loss:0.510769248008728\n",
            "Loss:0.5103503465652466\n",
            "Loss:0.5099313259124756\n",
            "Loss:0.5095124840736389\n",
            "Loss:0.5090934634208679\n",
            "Epoch: 110 | Loss: 0.5090934634208679 | Test loss: 0.5330739617347717\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7488]])), ('linear_layer.bias', tensor([0.7896]))])\n",
            "Loss:0.5086745023727417\n",
            "Loss:0.5082556009292603\n",
            "Loss:0.507836639881134\n",
            "Loss:0.5074176788330078\n",
            "Loss:0.5069986581802368\n",
            "Loss:0.5065797567367554\n",
            "Loss:0.5061608552932739\n",
            "Loss:0.5057418942451477\n",
            "Loss:0.5053228735923767\n",
            "Loss:0.5049039125442505\n",
            "Epoch: 120 | Loss: 0.5049039125442505 | Test loss: 0.5281754732131958\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7474]])), ('linear_layer.bias', tensor([0.7860]))])\n",
            "Loss:0.504485011100769\n",
            "Loss:0.5040661096572876\n",
            "Loss:0.5036471486091614\n",
            "Loss:0.5032281279563904\n",
            "Loss:0.5028092265129089\n",
            "Loss:0.5023902654647827\n",
            "Loss:0.5019713640213013\n",
            "Loss:0.501552402973175\n",
            "Loss:0.5011333227157593\n",
            "Loss:0.5007144212722778\n",
            "Epoch: 130 | Loss: 0.5007144212722778 | Test loss: 0.5232769250869751\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7460]])), ('linear_layer.bias', tensor([0.7824]))])\n",
            "Loss:0.5002955198287964\n",
            "Loss:0.49987658858299255\n",
            "Loss:0.4994576573371887\n",
            "Loss:0.4990386962890625\n",
            "Loss:0.4986197352409363\n",
            "Loss:0.49820080399513245\n",
            "Loss:0.49778181314468384\n",
            "Loss:0.4973629117012024\n",
            "Loss:0.4969438910484314\n",
            "Loss:0.49652498960494995\n",
            "Epoch: 140 | Loss: 0.49652498960494995 | Test loss: 0.5183784365653992\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7445]])), ('linear_layer.bias', tensor([0.7787]))])\n",
            "Loss:0.4961060583591461\n",
            "Loss:0.4956870973110199\n",
            "Loss:0.49526816606521606\n",
            "Loss:0.49484914541244507\n",
            "Loss:0.49443021416664124\n",
            "Loss:0.4940113127231598\n",
            "Loss:0.49359235167503357\n",
            "Loss:0.49317336082458496\n",
            "Loss:0.49275439977645874\n",
            "Loss:0.4923354685306549\n",
            "Epoch: 150 | Loss: 0.4923354685306549 | Test loss: 0.513480007648468\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7431]])), ('linear_layer.bias', tensor([0.7751]))])\n",
            "Loss:0.4919164776802063\n",
            "Loss:0.49149757623672485\n",
            "Loss:0.49107861518859863\n",
            "Loss:0.4906596541404724\n",
            "Loss:0.49024075269699097\n",
            "Loss:0.48982176184654236\n",
            "Loss:0.4894028306007385\n",
            "Loss:0.4889839291572571\n",
            "Loss:0.4885649085044861\n",
            "Loss:0.48814597725868225\n",
            "Epoch: 160 | Loss: 0.48814597725868225 | Test loss: 0.5085813403129578\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7417]])), ('linear_layer.bias', tensor([0.7715]))])\n",
            "Loss:0.48772701621055603\n",
            "Loss:0.4873080253601074\n",
            "Loss:0.486889123916626\n",
            "Loss:0.48647016286849976\n",
            "Loss:0.4860512316226959\n",
            "Loss:0.4856322705745697\n",
            "Loss:0.4852132797241211\n",
            "Loss:0.4847944378852844\n",
            "Loss:0.4843754172325134\n",
            "Loss:0.483956515789032\n",
            "Epoch: 170 | Loss: 0.483956515789032 | Test loss: 0.5036829113960266\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7403]])), ('linear_layer.bias', tensor([0.7678]))])\n",
            "Loss:0.4835375249385834\n",
            "Loss:0.48311859369277954\n",
            "Loss:0.4826996922492981\n",
            "Loss:0.4822806715965271\n",
            "Loss:0.48186174035072327\n",
            "Loss:0.48144277930259705\n",
            "Loss:0.4810238778591156\n",
            "Loss:0.480604887008667\n",
            "Loss:0.48018592596054077\n",
            "Loss:0.47976699471473694\n",
            "Epoch: 180 | Loss: 0.47976699471473694 | Test loss: 0.49878445267677307\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7389]])), ('linear_layer.bias', tensor([0.7642]))])\n",
            "Loss:0.47934800386428833\n",
            "Loss:0.4789290428161621\n",
            "Loss:0.47851014137268066\n",
            "Loss:0.4780912399291992\n",
            "Loss:0.47767218947410583\n",
            "Loss:0.4772532880306244\n",
            "Loss:0.47683435678482056\n",
            "Loss:0.47641533613204956\n",
            "Loss:0.4759964346885681\n",
            "Loss:0.4755775034427643\n",
            "Epoch: 190 | Loss: 0.4755775034427643 | Test loss: 0.49388593435287476\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7375]])), ('linear_layer.bias', tensor([0.7606]))])\n",
            "Loss:0.47515860199928284\n",
            "Loss:0.47473955154418945\n",
            "Loss:0.474320650100708\n",
            "Loss:0.4739016592502594\n",
            "Loss:0.47348275780677795\n",
            "Loss:0.47306376695632935\n",
            "Loss:0.4726448655128479\n",
            "Loss:0.4722259044647217\n",
            "Loss:0.47180691361427307\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5869505405426025\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5547531247138977\n",
            "Loss:0.5543283820152283\n",
            "Loss:0.5539036393165588\n",
            "Loss:0.5534788370132446\n",
            "Loss:0.5530540347099304\n",
            "Loss:0.5526292324066162\n",
            "Loss:0.552204430103302\n",
            "Loss:0.5517796277999878\n",
            "Loss:0.5513548851013184\n",
            "Loss:0.5509300827980042\n",
            "Epoch: 10 | Loss: 0.5509300827980042 | Test loss: 0.5819838643074036\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7630]])), ('linear_layer.bias', tensor([0.8260]))])\n",
            "Loss:0.5505052804946899\n",
            "Loss:0.5500804781913757\n",
            "Loss:0.5496557354927063\n",
            "Loss:0.5492309927940369\n",
            "Loss:0.5488062500953674\n",
            "Loss:0.5483814477920532\n",
            "Loss:0.5479565858840942\n",
            "Loss:0.5475318431854248\n",
            "Loss:0.5471070408821106\n",
            "Loss:0.5466822385787964\n",
            "Epoch: 20 | Loss: 0.5466822385787964 | Test loss: 0.5770171880722046\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7615]])), ('linear_layer.bias', tensor([0.8223]))])\n",
            "Loss:0.546257495880127\n",
            "Loss:0.5458326935768127\n",
            "Loss:0.5454078912734985\n",
            "Loss:0.5449831485748291\n",
            "Loss:0.5445583462715149\n",
            "Loss:0.5441335439682007\n",
            "Loss:0.5437088012695312\n",
            "Loss:0.5432840585708618\n",
            "Loss:0.5428592562675476\n",
            "Loss:0.5424344539642334\n",
            "Epoch: 30 | Loss: 0.5424344539642334 | Test loss: 0.5720505118370056\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7601]])), ('linear_layer.bias', tensor([0.8186]))])\n",
            "Loss:0.542009711265564\n",
            "Loss:0.541584849357605\n",
            "Loss:0.5411600470542908\n",
            "Loss:0.5407353043556213\n",
            "Loss:0.5403105020523071\n",
            "Loss:0.5398856997489929\n",
            "Loss:0.5394609570503235\n",
            "Loss:0.5390361547470093\n",
            "Loss:0.5386114120483398\n",
            "Loss:0.5381865501403809\n",
            "Epoch: 40 | Loss: 0.5381865501403809 | Test loss: 0.5670838356018066\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7586]])), ('linear_layer.bias', tensor([0.8149]))])\n",
            "Loss:0.5377618074417114\n",
            "Loss:0.5373370051383972\n",
            "Loss:0.5369122624397278\n",
            "Loss:0.5364875197410583\n",
            "Loss:0.5360626578330994\n",
            "Loss:0.5356379151344299\n",
            "Loss:0.5352131128311157\n",
            "Loss:0.5347883105278015\n",
            "Loss:0.5343635678291321\n",
            "Loss:0.5339387655258179\n",
            "Epoch: 50 | Loss: 0.5339387655258179 | Test loss: 0.5621172785758972\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7572]])), ('linear_layer.bias', tensor([0.8112]))])\n",
            "Loss:0.5335139632225037\n",
            "Loss:0.533089280128479\n",
            "Loss:0.53266441822052\n",
            "Loss:0.5322396159172058\n",
            "Loss:0.5318149328231812\n",
            "Loss:0.5313900709152222\n",
            "Loss:0.5309653282165527\n",
            "Loss:0.5305405259132385\n",
            "Loss:0.5301157236099243\n",
            "Loss:0.5296909213066101\n",
            "Epoch: 60 | Loss: 0.5296909213066101 | Test loss: 0.5571505427360535\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7558]])), ('linear_layer.bias', tensor([0.8075]))])\n",
            "Loss:0.5292661190032959\n",
            "Loss:0.5288413763046265\n",
            "Loss:0.5284165740013123\n",
            "Loss:0.5279918313026428\n",
            "Loss:0.5275670886039734\n",
            "Loss:0.5271422266960144\n",
            "Loss:0.526717483997345\n",
            "Loss:0.5262926816940308\n",
            "Loss:0.5258679389953613\n",
            "Loss:0.5254431366920471\n",
            "Epoch: 70 | Loss: 0.5254431366920471 | Test loss: 0.5521838665008545\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7543]])), ('linear_layer.bias', tensor([0.8038]))])\n",
            "Loss:0.5250183343887329\n",
            "Loss:0.5245935320854187\n",
            "Loss:0.5241687893867493\n",
            "Loss:0.5237439870834351\n",
            "Loss:0.5233191847801208\n",
            "Loss:0.5228944420814514\n",
            "Loss:0.5224696397781372\n",
            "Loss:0.522044837474823\n",
            "Loss:0.5216200947761536\n",
            "Loss:0.5211952924728394\n",
            "Epoch: 80 | Loss: 0.5211952924728394 | Test loss: 0.5472171902656555\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7529]])), ('linear_layer.bias', tensor([0.8001]))])\n",
            "Loss:0.5207704901695251\n",
            "Loss:0.5203457474708557\n",
            "Loss:0.5199209451675415\n",
            "Loss:0.5194961428642273\n",
            "Loss:0.5190713405609131\n",
            "Loss:0.5186465978622437\n",
            "Loss:0.5182217359542847\n",
            "Loss:0.5177969932556152\n",
            "Loss:0.517372190952301\n",
            "Loss:0.5169473886489868\n",
            "Epoch: 90 | Loss: 0.5169473886489868 | Test loss: 0.5422505140304565\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7515]])), ('linear_layer.bias', tensor([0.7965]))])\n",
            "Loss:0.5165226459503174\n",
            "Loss:0.5160978436470032\n",
            "Loss:0.5156731009483337\n",
            "Loss:0.5152482986450195\n",
            "Loss:0.5148235559463501\n",
            "Loss:0.5143987536430359\n",
            "Loss:0.5139739513397217\n",
            "Loss:0.5135492086410522\n",
            "Loss:0.5131243467330933\n",
            "Loss:0.5126996040344238\n",
            "Epoch: 100 | Loss: 0.5126996040344238 | Test loss: 0.5372838973999023\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7500]])), ('linear_layer.bias', tensor([0.7928]))])\n",
            "Loss:0.5122748613357544\n",
            "Loss:0.5118499994277954\n",
            "Loss:0.5114251971244812\n",
            "Loss:0.5110004544258118\n",
            "Loss:0.5105756521224976\n",
            "Loss:0.5101509094238281\n",
            "Loss:0.5097260475158691\n",
            "Loss:0.5093013048171997\n",
            "Loss:0.508876621723175\n",
            "Loss:0.5084518194198608\n",
            "Epoch: 110 | Loss: 0.5084518194198608 | Test loss: 0.5323172807693481\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7486]])), ('linear_layer.bias', tensor([0.7891]))])\n",
            "Loss:0.5080270171165466\n",
            "Loss:0.5076021552085876\n",
            "Loss:0.507177472114563\n",
            "Loss:0.506752610206604\n",
            "Loss:0.5063278675079346\n",
            "Loss:0.5059030652046204\n",
            "Loss:0.5054782629013062\n",
            "Loss:0.5050535202026367\n",
            "Loss:0.5046287775039673\n",
            "Loss:0.5042039752006531\n",
            "Epoch: 120 | Loss: 0.5042039752006531 | Test loss: 0.5273505449295044\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7471]])), ('linear_layer.bias', tensor([0.7854]))])\n",
            "Loss:0.5037791132926941\n",
            "Loss:0.5033543705940247\n",
            "Loss:0.5029295682907104\n",
            "Loss:0.502504825592041\n",
            "Loss:0.5020800828933716\n",
            "Loss:0.5016552209854126\n",
            "Loss:0.5012304782867432\n",
            "Loss:0.500805675983429\n",
            "Loss:0.5003808736801147\n",
            "Loss:0.49995607137680054\n",
            "Epoch: 130 | Loss: 0.49995607137680054 | Test loss: 0.5223838686943054\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7457]])), ('linear_layer.bias', tensor([0.7817]))])\n",
            "Loss:0.49953126907348633\n",
            "Loss:0.49910658597946167\n",
            "Loss:0.4986817240715027\n",
            "Loss:0.49825698137283325\n",
            "Loss:0.49783220887184143\n",
            "Loss:0.4974074363708496\n",
            "Loss:0.4969826638698578\n",
            "Loss:0.4965578615665436\n",
            "Loss:0.496133029460907\n",
            "Loss:0.49570831656455994\n",
            "Epoch: 140 | Loss: 0.49570831656455994 | Test loss: 0.5174172520637512\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7443]])), ('linear_layer.bias', tensor([0.7780]))])\n",
            "Loss:0.49528345465660095\n",
            "Loss:0.49485868215560913\n",
            "Loss:0.4944339394569397\n",
            "Loss:0.4940091073513031\n",
            "Loss:0.4935843348503113\n",
            "Loss:0.49315953254699707\n",
            "Loss:0.49273481965065\n",
            "Loss:0.4923100471496582\n",
            "Loss:0.4918852746486664\n",
            "Loss:0.4914604723453522\n",
            "Epoch: 150 | Loss: 0.4914604723453522 | Test loss: 0.5124505758285522\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7428]])), ('linear_layer.bias', tensor([0.7743]))])\n",
            "Loss:0.4910356402397156\n",
            "Loss:0.49061089754104614\n",
            "Loss:0.49018606543540955\n",
            "Loss:0.4897612929344177\n",
            "Loss:0.4893365502357483\n",
            "Loss:0.48891177773475647\n",
            "Loss:0.4884869456291199\n",
            "Loss:0.48806220293045044\n",
            "Loss:0.4876374304294586\n",
            "Loss:0.4872126579284668\n",
            "Epoch: 160 | Loss: 0.4872126579284668 | Test loss: 0.5074838995933533\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7414]])), ('linear_layer.bias', tensor([0.7706]))])\n",
            "Loss:0.4867878556251526\n",
            "Loss:0.48636308312416077\n",
            "Loss:0.48593825101852417\n",
            "Loss:0.48551344871520996\n",
            "Loss:0.4850887358188629\n",
            "Loss:0.4846639037132263\n",
            "Loss:0.4842391014099121\n",
            "Loss:0.4838143289089203\n",
            "Loss:0.48338955640792847\n",
            "Loss:0.4829646944999695\n",
            "Epoch: 170 | Loss: 0.4829646944999695 | Test loss: 0.5025172233581543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|  | 74/100 [00:23<00:08,  3.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('linear_layer.weight', tensor([[0.7400]])), ('linear_layer.bias', tensor([0.7670]))])\n",
            "Loss:0.48253998160362244\n",
            "Loss:0.4821151793003082\n",
            "Loss:0.4816904067993164\n",
            "Loss:0.4812656342983246\n",
            "Loss:0.48084086179733276\n",
            "Loss:0.48041611909866333\n",
            "Loss:0.47999128699302673\n",
            "Loss:0.4795665144920349\n",
            "Loss:0.4791417121887207\n",
            "Loss:0.4787169396877289\n",
            "Epoch: 180 | Loss: 0.4787169396877289 | Test loss: 0.4975505769252777\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7385]])), ('linear_layer.bias', tensor([0.7633]))])\n",
            "Loss:0.47829216718673706\n",
            "Loss:0.47786736488342285\n",
            "Loss:0.47744256258010864\n",
            "Loss:0.4770177900791168\n",
            "Loss:0.476593017578125\n",
            "Loss:0.4761682450771332\n",
            "Loss:0.47574347257614136\n",
            "Loss:0.47531867027282715\n",
            "Loss:0.4748938977718353\n",
            "Loss:0.4744691252708435\n",
            "Epoch: 190 | Loss: 0.4744691252708435 | Test loss: 0.49258390069007874\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7371]])), ('linear_layer.bias', tensor([0.7596]))])\n",
            "Loss:0.4740443825721741\n",
            "Loss:0.4736195504665375\n",
            "Loss:0.47319474816322327\n",
            "Loss:0.4727700352668762\n",
            "Loss:0.4723452031612396\n",
            "Loss:0.4719204008579254\n",
            "Loss:0.4714955687522888\n",
            "Loss:0.4710708260536194\n",
            "Loss:0.47064608335494995\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5869438052177429\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5547474026679993\n",
            "Loss:0.5543168187141418\n",
            "Loss:0.5538862347602844\n",
            "Loss:0.5534557104110718\n",
            "Loss:0.5530251264572144\n",
            "Loss:0.5525946021080017\n",
            "Loss:0.5521640181541443\n",
            "Loss:0.5517334342002869\n",
            "Loss:0.551302969455719\n",
            "Loss:0.5508723258972168\n",
            "Epoch: 10 | Loss: 0.5508723258972168 | Test loss: 0.5819095373153687\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7629]])), ('linear_layer.bias', tensor([0.8259]))])\n",
            "Loss:0.5504417419433594\n",
            "Loss:0.5500112175941467\n",
            "Loss:0.5495806932449341\n",
            "Loss:0.5491501092910767\n",
            "Loss:0.5487195253372192\n",
            "Loss:0.5482890009880066\n",
            "Loss:0.547858476638794\n",
            "Loss:0.5474279522895813\n",
            "Loss:0.5469974279403687\n",
            "Loss:0.5465667843818665\n",
            "Epoch: 20 | Loss: 0.5465667843818665 | Test loss: 0.5768753290176392\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7615]])), ('linear_layer.bias', tensor([0.8222]))])\n",
            "Loss:0.5461362600326538\n",
            "Loss:0.5457056760787964\n",
            "Loss:0.545275092124939\n",
            "Loss:0.5448445081710815\n",
            "Loss:0.5444139838218689\n",
            "Loss:0.5439834594726562\n",
            "Loss:0.5435528755187988\n",
            "Loss:0.543122410774231\n",
            "Loss:0.5426917672157288\n",
            "Loss:0.5422611832618713\n",
            "Epoch: 30 | Loss: 0.5422611832618713 | Test loss: 0.5718410611152649\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7600]])), ('linear_layer.bias', tensor([0.8184]))])\n",
            "Loss:0.5418307185173035\n",
            "Loss:0.5414000749588013\n",
            "Loss:0.5409695506095886\n",
            "Loss:0.5405389666557312\n",
            "Loss:0.5401084423065186\n",
            "Loss:0.5396779179573059\n",
            "Loss:0.5392473340034485\n",
            "Loss:0.5388167500495911\n",
            "Loss:0.5383862257003784\n",
            "Loss:0.5379557013511658\n",
            "Epoch: 40 | Loss: 0.5379557013511658 | Test loss: 0.5668068528175354\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7586]])), ('linear_layer.bias', tensor([0.8147]))])\n",
            "Loss:0.5375250577926636\n",
            "Loss:0.5370944738388062\n",
            "Loss:0.5366639494895935\n",
            "Loss:0.5362334251403809\n",
            "Loss:0.5358028411865234\n",
            "Loss:0.5353723168373108\n",
            "Loss:0.5349417924880981\n",
            "Loss:0.534511148929596\n",
            "Loss:0.5340806245803833\n",
            "Loss:0.5336501002311707\n",
            "Epoch: 50 | Loss: 0.5336501002311707 | Test loss: 0.5617726445198059\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7571]])), ('linear_layer.bias', tensor([0.8109]))])\n",
            "Loss:0.5332195162773132\n",
            "Loss:0.5327889323234558\n",
            "Loss:0.5323584079742432\n",
            "Loss:0.5319278836250305\n",
            "Loss:0.5314972996711731\n",
            "Loss:0.5310667157173157\n",
            "Loss:0.530636191368103\n",
            "Loss:0.5302056074142456\n",
            "Loss:0.529775083065033\n",
            "Loss:0.5293444991111755\n",
            "Epoch: 60 | Loss: 0.5293444991111755 | Test loss: 0.5567383766174316\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7556]])), ('linear_layer.bias', tensor([0.8072]))])\n",
            "Loss:0.5289139151573181\n",
            "Loss:0.5284833908081055\n",
            "Loss:0.5280528664588928\n",
            "Loss:0.5276223421096802\n",
            "Loss:0.5271917581558228\n",
            "Loss:0.5267611742019653\n",
            "Loss:0.5263305902481079\n",
            "Loss:0.5259000658988953\n",
            "Loss:0.5254694819450378\n",
            "Loss:0.5250388979911804\n",
            "Epoch: 70 | Loss: 0.5250388979911804 | Test loss: 0.5517041683197021\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7542]])), ('linear_layer.bias', tensor([0.8035]))])\n",
            "Loss:0.5246083736419678\n",
            "Loss:0.5241778492927551\n",
            "Loss:0.5237473249435425\n",
            "Loss:0.5233167409896851\n",
            "Loss:0.5228861570358276\n",
            "Loss:0.522455632686615\n",
            "Loss:0.5220250487327576\n",
            "Loss:0.5215944647789001\n",
            "Loss:0.5211638808250427\n",
            "Loss:0.5207333564758301\n",
            "Epoch: 80 | Loss: 0.5207333564758301 | Test loss: 0.5466699004173279\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7527]])), ('linear_layer.bias', tensor([0.7997]))])\n",
            "Loss:0.5203028321266174\n",
            "Loss:0.51987224817276\n",
            "Loss:0.5194417238235474\n",
            "Loss:0.5190111398696899\n",
            "Loss:0.5185806155204773\n",
            "Loss:0.5181500315666199\n",
            "Loss:0.5177194476127625\n",
            "Loss:0.517288863658905\n",
            "Loss:0.5168583393096924\n",
            "Loss:0.5164278149604797\n",
            "Epoch: 90 | Loss: 0.5164278149604797 | Test loss: 0.5416356325149536\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7513]])), ('linear_layer.bias', tensor([0.7960]))])\n",
            "Loss:0.5159972310066223\n",
            "Loss:0.5155667066574097\n",
            "Loss:0.5151361227035522\n",
            "Loss:0.5147055387496948\n",
            "Loss:0.514275074005127\n",
            "Loss:0.5138444304466248\n",
            "Loss:0.5134139060974121\n",
            "Loss:0.5129833221435547\n",
            "Loss:0.5125528573989868\n",
            "Loss:0.5121222138404846\n",
            "Epoch: 100 | Loss: 0.5121222138404846 | Test loss: 0.5366014242172241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|  | 75/100 [00:23<00:08,  3.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('linear_layer.weight', tensor([[0.7498]])), ('linear_layer.bias', tensor([0.7923]))])\n",
            "Loss:0.511691689491272\n",
            "Loss:0.5112611055374146\n",
            "Loss:0.5108305215835571\n",
            "Loss:0.5103999972343445\n",
            "Loss:0.5099694132804871\n",
            "Loss:0.5095388889312744\n",
            "Loss:0.5091082453727722\n",
            "Loss:0.5086777806282043\n",
            "Loss:0.5082471966743469\n",
            "Loss:0.5078166723251343\n",
            "Epoch: 110 | Loss: 0.5078166723251343 | Test loss: 0.5315671563148499\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7484]])), ('linear_layer.bias', tensor([0.7885]))])\n",
            "Loss:0.5073860883712769\n",
            "Loss:0.5069555044174194\n",
            "Loss:0.5065249800682068\n",
            "Loss:0.5060944557189941\n",
            "Loss:0.5056638717651367\n",
            "Loss:0.5052332878112793\n",
            "Loss:0.5048028230667114\n",
            "Loss:0.504372239112854\n",
            "Loss:0.5039416551589966\n",
            "Loss:0.5035110712051392\n",
            "Epoch: 120 | Loss: 0.5035110712051392 | Test loss: 0.5265329480171204\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7469]])), ('linear_layer.bias', tensor([0.7848]))])\n",
            "Loss:0.5030804872512817\n",
            "Loss:0.5026499032974243\n",
            "Loss:0.5022193789482117\n",
            "Loss:0.501788854598999\n",
            "Loss:0.5013583302497864\n",
            "Loss:0.5009276866912842\n",
            "Loss:0.5004972219467163\n",
            "Loss:0.5000665783882141\n",
            "Loss:0.49963608384132385\n",
            "Loss:0.49920549988746643\n",
            "Epoch: 130 | Loss: 0.49920549988746643 | Test loss: 0.5214987397193909\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7454]])), ('linear_layer.bias', tensor([0.7811]))])\n",
            "Loss:0.498774915933609\n",
            "Loss:0.49834442138671875\n",
            "Loss:0.49791377782821655\n",
            "Loss:0.4974832534790039\n",
            "Loss:0.49705272912979126\n",
            "Loss:0.49662214517593384\n",
            "Loss:0.4961915910243988\n",
            "Loss:0.4957610070705414\n",
            "Loss:0.49533048272132874\n",
            "Loss:0.4948999285697937\n",
            "Epoch: 140 | Loss: 0.4948999285697937 | Test loss: 0.5164644718170166\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7440]])), ('linear_layer.bias', tensor([0.7773]))])\n",
            "Loss:0.49446940422058105\n",
            "Loss:0.4940388798713684\n",
            "Loss:0.493608295917511\n",
            "Loss:0.49317774176597595\n",
            "Loss:0.49274712800979614\n",
            "Loss:0.4923165738582611\n",
            "Loss:0.49188604950904846\n",
            "Loss:0.4914554953575134\n",
            "Loss:0.491024911403656\n",
            "Loss:0.4905943274497986\n",
            "Epoch: 150 | Loss: 0.4905943274497986 | Test loss: 0.5114302635192871\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7425]])), ('linear_layer.bias', tensor([0.7736]))])\n",
            "Loss:0.49016380310058594\n",
            "Loss:0.4897332191467285\n",
            "Loss:0.48930269479751587\n",
            "Loss:0.48887214064598083\n",
            "Loss:0.4884415566921234\n",
            "Loss:0.48801103234291077\n",
            "Loss:0.48758044838905334\n",
            "Loss:0.4871498942375183\n",
            "Loss:0.48671942949295044\n",
            "Loss:0.48628878593444824\n",
            "Epoch: 160 | Loss: 0.48628878593444824 | Test loss: 0.5063959956169128\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7411]])), ('linear_layer.bias', tensor([0.7698]))])\n",
            "Loss:0.4858582615852356\n",
            "Loss:0.4854276776313782\n",
            "Loss:0.48499712347984314\n",
            "Loss:0.4845665395259857\n",
            "Loss:0.48413601517677307\n",
            "Loss:0.48370543122291565\n",
            "Loss:0.4832748770713806\n",
            "Loss:0.48284435272216797\n",
            "Loss:0.48241376876831055\n",
            "Loss:0.4819832444190979\n",
            "Epoch: 170 | Loss: 0.4819832444190979 | Test loss: 0.5013617277145386\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7396]])), ('linear_layer.bias', tensor([0.7661]))])\n",
            "Loss:0.48155269026756287\n",
            "Loss:0.48112210631370544\n",
            "Loss:0.480691522359848\n",
            "Loss:0.4802609980106354\n",
            "Loss:0.47983044385910034\n",
            "Loss:0.4793998599052429\n",
            "Loss:0.4789693355560303\n",
            "Loss:0.4785388112068176\n",
            "Loss:0.4781082272529602\n",
            "Loss:0.4776776432991028\n",
            "Epoch: 180 | Loss: 0.4776776432991028 | Test loss: 0.4963274896144867\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7382]])), ('linear_layer.bias', tensor([0.7624]))])\n",
            "Loss:0.47724708914756775\n",
            "Loss:0.4768165647983551\n",
            "Loss:0.4763859808444977\n",
            "Loss:0.47595542669296265\n",
            "Loss:0.47552481293678284\n",
            "Loss:0.4750943183898926\n",
            "Loss:0.47466373443603516\n",
            "Loss:0.4742332100868225\n",
            "Loss:0.4738026559352875\n",
            "Loss:0.47337204217910767\n",
            "Epoch: 190 | Loss: 0.47337204217910767 | Test loss: 0.4912932813167572\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7367]])), ('linear_layer.bias', tensor([0.7586]))])\n",
            "Loss:0.4729415476322174\n",
            "Loss:0.4725109040737152\n",
            "Loss:0.47208037972450256\n",
            "Loss:0.47164982557296753\n",
            "Loss:0.4712193012237549\n",
            "Loss:0.47078877687454224\n",
            "Loss:0.4703581929206848\n",
            "Loss:0.4699276089668274\n",
            "Loss:0.46949705481529236\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5869369506835938\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5547415614128113\n",
            "Loss:0.5543051362037659\n",
            "Loss:0.5538687705993652\n",
            "Loss:0.5534323453903198\n",
            "Loss:0.5529959797859192\n",
            "Loss:0.5525595545768738\n",
            "Loss:0.5521231889724731\n",
            "Loss:0.5516867637634277\n",
            "Loss:0.5512504577636719\n",
            "Loss:0.5508140325546265\n",
            "Epoch: 10 | Loss: 0.5508140325546265 | Test loss: 0.5818345546722412\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7629]])), ('linear_layer.bias', tensor([0.8258]))])\n",
            "Loss:0.5503776669502258\n",
            "Loss:0.5499412417411804\n",
            "Loss:0.5495048761367798\n",
            "Loss:0.5490683913230896\n",
            "Loss:0.548632025718689\n",
            "Loss:0.5481957197189331\n",
            "Loss:0.5477592349052429\n",
            "Loss:0.5473229289054871\n",
            "Loss:0.5468865633010864\n",
            "Loss:0.5464500784873962\n",
            "Epoch: 20 | Loss: 0.5464500784873962 | Test loss: 0.5767321586608887\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7614]])), ('linear_layer.bias', tensor([0.8221]))])\n",
            "Loss:0.5460137724876404\n",
            "Loss:0.5455772876739502\n",
            "Loss:0.5451409220695496\n",
            "Loss:0.5447045564651489\n",
            "Loss:0.5442682504653931\n",
            "Loss:0.5438317656517029\n",
            "Loss:0.5433953404426575\n",
            "Loss:0.5429590344429016\n",
            "Loss:0.5425225496292114\n",
            "Loss:0.5420861840248108\n",
            "Epoch: 30 | Loss: 0.5420861840248108 | Test loss: 0.5716297626495361\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7600]])), ('linear_layer.bias', tensor([0.8183]))])\n",
            "Loss:0.5416498184204102\n",
            "Loss:0.5412133932113647\n",
            "Loss:0.5407770276069641\n",
            "Loss:0.5403406620025635\n",
            "Loss:0.5399042367935181\n",
            "Loss:0.5394678711891174\n",
            "Loss:0.539031445980072\n",
            "Loss:0.5385950803756714\n",
            "Loss:0.5381587147712708\n",
            "Loss:0.5377224087715149\n",
            "Epoch: 40 | Loss: 0.5377224087715149 | Test loss: 0.566527247428894\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7585]])), ('linear_layer.bias', tensor([0.8145]))])\n",
            "Loss:0.5372859239578247\n",
            "Loss:0.5368494987487793\n",
            "Loss:0.5364130735397339\n",
            "Loss:0.535976767539978\n",
            "Loss:0.5355403423309326\n",
            "Loss:0.5351039171218872\n",
            "Loss:0.5346676111221313\n",
            "Loss:0.5342311859130859\n",
            "Loss:0.5337947607040405\n",
            "Loss:0.5333583950996399\n",
            "Epoch: 50 | Loss: 0.5333583950996399 | Test loss: 0.5614249110221863\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7570]])), ('linear_layer.bias', tensor([0.8107]))])\n",
            "Loss:0.5329220294952393\n",
            "Loss:0.5324856042861938\n",
            "Loss:0.5320491790771484\n",
            "Loss:0.5316128730773926\n",
            "Loss:0.5311764478683472\n",
            "Loss:0.5307400822639465\n",
            "Loss:0.5303036570549011\n",
            "Loss:0.5298672914505005\n",
            "Loss:0.5294309258460999\n",
            "Loss:0.5289945006370544\n",
            "Epoch: 60 | Loss: 0.5289945006370544 | Test loss: 0.5563225150108337\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7555]])), ('linear_layer.bias', tensor([0.8069]))])\n",
            "Loss:0.5285581350326538\n",
            "Loss:0.5281217098236084\n",
            "Loss:0.527685284614563\n",
            "Loss:0.5272489786148071\n",
            "Loss:0.5268125534057617\n",
            "Loss:0.5263761281967163\n",
            "Loss:0.5259397625923157\n",
            "Loss:0.5255033373832703\n",
            "Loss:0.5250669717788696\n",
            "Loss:0.5246305465698242\n",
            "Epoch: 70 | Loss: 0.5246305465698242 | Test loss: 0.5512201189994812\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7541]])), ('linear_layer.bias', tensor([0.8031]))])\n",
            "Loss:0.5241941213607788\n",
            "Loss:0.523757815361023\n",
            "Loss:0.5233214497566223\n",
            "Loss:0.5228849649429321\n",
            "Loss:0.5224486589431763\n",
            "Loss:0.5220122933387756\n",
            "Loss:0.5215758681297302\n",
            "Loss:0.5211395025253296\n",
            "Loss:0.520703136920929\n",
            "Loss:0.5202667117118835\n",
            "Epoch: 80 | Loss: 0.5202667117118835 | Test loss: 0.5461177229881287\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7526]])), ('linear_layer.bias', tensor([0.7993]))])\n",
            "Loss:0.5198303461074829\n",
            "Loss:0.519393801689148\n",
            "Loss:0.5189574956893921\n",
            "Loss:0.5185211300849915\n",
            "Loss:0.518084704875946\n",
            "Loss:0.5176483392715454\n",
            "Loss:0.5172119736671448\n",
            "Loss:0.5167755484580994\n",
            "Loss:0.5163391828536987\n",
            "Loss:0.5159028172492981\n",
            "Epoch: 90 | Loss: 0.5159028172492981 | Test loss: 0.5410152673721313\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7511]])), ('linear_layer.bias', tensor([0.7955]))])\n",
            "Loss:0.5154663920402527\n",
            "Loss:0.515030026435852\n",
            "Loss:0.5145936608314514\n",
            "Loss:0.5141571760177612\n",
            "Loss:0.5137208104133606\n",
            "Loss:0.5132843852043152\n",
            "Loss:0.5128480195999146\n",
            "Loss:0.5124116539955139\n",
            "Loss:0.5119752287864685\n",
            "Loss:0.5115388631820679\n",
            "Epoch: 100 | Loss: 0.5115388631820679 | Test loss: 0.5359128713607788\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7496]])), ('linear_layer.bias', tensor([0.7918]))])\n",
            "Loss:0.5111024379730225\n",
            "Loss:0.5106660723686218\n",
            "Loss:0.5102297067642212\n",
            "Loss:0.5097933411598206\n",
            "Loss:0.5093568563461304\n",
            "Loss:0.5089205503463745\n",
            "Loss:0.5084840655326843\n",
            "Loss:0.5080476999282837\n",
            "Loss:0.5076113939285278\n",
            "Loss:0.5071749687194824\n",
            "Epoch: 110 | Loss: 0.5071749687194824 | Test loss: 0.5308104753494263\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7481]])), ('linear_layer.bias', tensor([0.7880]))])\n",
            "Loss:0.506738543510437\n",
            "Loss:0.5063022375106812\n",
            "Loss:0.505865752696991\n",
            "Loss:0.5054293870925903\n",
            "Loss:0.5049930214881897\n",
            "Loss:0.5045565962791443\n",
            "Loss:0.5041202902793884\n",
            "Loss:0.503683865070343\n",
            "Loss:0.5032474398612976\n",
            "Loss:0.502811074256897\n",
            "Epoch: 120 | Loss: 0.502811074256897 | Test loss: 0.5257080793380737\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7467]])), ('linear_layer.bias', tensor([0.7842]))])\n",
            "Loss:0.5023746490478516\n",
            "Loss:0.5019382238388062\n",
            "Loss:0.5015019178390503\n",
            "Loss:0.5010654926300049\n",
            "Loss:0.5006291270256042\n",
            "Loss:0.5001927018165588\n",
            "Loss:0.4997562766075134\n",
            "Loss:0.4993199408054352\n",
            "Loss:0.49888354539871216\n",
            "Loss:0.4984471797943115\n",
            "Epoch: 130 | Loss: 0.4984471797943115 | Test loss: 0.5206056237220764\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7452]])), ('linear_layer.bias', tensor([0.7804]))])\n",
            "Loss:0.4980107843875885\n",
            "Loss:0.4975743889808655\n",
            "Loss:0.49713802337646484\n",
            "Loss:0.49670156836509705\n",
            "Loss:0.496265172958374\n",
            "Loss:0.4958288073539734\n",
            "Loss:0.495392382144928\n",
            "Loss:0.49495601654052734\n",
            "Loss:0.4945196211338043\n",
            "Loss:0.4940832555294037\n",
            "Epoch: 140 | Loss: 0.4940832555294037 | Test loss: 0.5155032277107239\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7437]])), ('linear_layer.bias', tensor([0.7766]))])\n",
            "Loss:0.49364686012268066\n",
            "Loss:0.49321046471595764\n",
            "Loss:0.4927740693092346\n",
            "Loss:0.492337703704834\n",
            "Loss:0.49190130829811096\n",
            "Loss:0.49146491289138794\n",
            "Loss:0.4910285472869873\n",
            "Loss:0.4905920922756195\n",
            "Loss:0.4901556968688965\n",
            "Loss:0.48971933126449585\n",
            "Epoch: 150 | Loss: 0.48971933126449585 | Test loss: 0.5104008316993713\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7422]])), ('linear_layer.bias', tensor([0.7728]))])\n",
            "Loss:0.4892829358577728\n",
            "Loss:0.4888465404510498\n",
            "Loss:0.4884101450443268\n",
            "Loss:0.48797377943992615\n",
            "Loss:0.4875373840332031\n",
            "Loss:0.4871010184288025\n",
            "Loss:0.48666462302207947\n",
            "Loss:0.48622822761535645\n",
            "Loss:0.48579177260398865\n",
            "Loss:0.4853554666042328\n",
            "Epoch: 160 | Loss: 0.4853554666042328 | Test loss: 0.505298376083374\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7408]])), ('linear_layer.bias', tensor([0.7690]))])\n",
            "Loss:0.48491907119750977\n",
            "Loss:0.48448261618614197\n",
            "Loss:0.4840462803840637\n",
            "Loss:0.4836098551750183\n",
            "Loss:0.4831734597682953\n",
            "Loss:0.48273712396621704\n",
            "Loss:0.48230069875717163\n",
            "Loss:0.4818643033504486\n",
            "Loss:0.4814279079437256\n",
            "Loss:0.48099154233932495\n",
            "Epoch: 170 | Loss: 0.48099154233932495 | Test loss: 0.500196099281311\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7393]])), ('linear_layer.bias', tensor([0.7652]))])\n",
            "Loss:0.48055514693260193\n",
            "Loss:0.4801187515258789\n",
            "Loss:0.4796823561191559\n",
            "Loss:0.47924596071243286\n",
            "Loss:0.47880953550338745\n",
            "Loss:0.4783731997013092\n",
            "Loss:0.4779367446899414\n",
            "Loss:0.4775003492832184\n",
            "Loss:0.4770640432834625\n",
            "Loss:0.4766275882720947\n",
            "Epoch: 180 | Loss: 0.4766275882720947 | Test loss: 0.49509358406066895\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7378]])), ('linear_layer.bias', tensor([0.7614]))])\n",
            "Loss:0.4761912226676941\n",
            "Loss:0.47575488686561584\n",
            "Loss:0.47531843185424805\n",
            "Loss:0.474882036447525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|  | 76/100 [00:23<00:07,  3.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.4744456708431244\n",
            "Loss:0.4740092158317566\n",
            "Loss:0.47357290983200073\n",
            "Loss:0.4731365144252777\n",
            "Loss:0.4727000594139099\n",
            "Loss:0.4722636640071869\n",
            "Epoch: 190 | Loss: 0.4722636640071869 | Test loss: 0.4899912476539612\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7363]])), ('linear_layer.bias', tensor([0.7577]))])\n",
            "Loss:0.47182726860046387\n",
            "Loss:0.47139090299606323\n",
            "Loss:0.4709545075893402\n",
            "Loss:0.4705181121826172\n",
            "Loss:0.47008174657821655\n",
            "Loss:0.46964535117149353\n",
            "Loss:0.4692089557647705\n",
            "Loss:0.4687725901603699\n",
            "Loss:0.46833619475364685\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5869301557540894\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5547357201576233\n",
            "Loss:0.5542934536933899\n",
            "Loss:0.5538512468338013\n",
            "Loss:0.5534089803695679\n",
            "Loss:0.552966833114624\n",
            "Loss:0.5525245666503906\n",
            "Loss:0.5520823001861572\n",
            "Loss:0.5516401529312134\n",
            "Loss:0.55119788646698\n",
            "Loss:0.5507556796073914\n",
            "Epoch: 10 | Loss: 0.5507556796073914 | Test loss: 0.5817595720291138\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7629]])), ('linear_layer.bias', tensor([0.8258]))])\n",
            "Loss:0.5503134727478027\n",
            "Loss:0.5498712658882141\n",
            "Loss:0.5494289994239807\n",
            "Loss:0.5489867329597473\n",
            "Loss:0.5485446453094482\n",
            "Loss:0.5481023192405701\n",
            "Loss:0.5476601719856262\n",
            "Loss:0.547217845916748\n",
            "Loss:0.5467756986618042\n",
            "Loss:0.5463334321975708\n",
            "Epoch: 20 | Loss: 0.5463334321975708 | Test loss: 0.5765889286994934\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7614]])), ('linear_layer.bias', tensor([0.8219]))])\n",
            "Loss:0.5458912253379822\n",
            "Loss:0.5454489588737488\n",
            "Loss:0.5450068116188049\n",
            "Loss:0.5445646047592163\n",
            "Loss:0.5441223382949829\n",
            "Loss:0.5436801314353943\n",
            "Loss:0.5432378649711609\n",
            "Loss:0.5427955985069275\n",
            "Loss:0.5423534512519836\n",
            "Loss:0.541911244392395\n",
            "Epoch: 30 | Loss: 0.541911244392395 | Test loss: 0.5714184045791626\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7599]])), ('linear_layer.bias', tensor([0.8181]))])\n",
            "Loss:0.5414689779281616\n",
            "Loss:0.541026771068573\n",
            "Loss:0.5405845642089844\n",
            "Loss:0.540142297744751\n",
            "Loss:0.5397000908851624\n",
            "Loss:0.539257824420929\n",
            "Loss:0.5388156771659851\n",
            "Loss:0.5383734107017517\n",
            "Loss:0.5379311442375183\n",
            "Loss:0.5374889969825745\n",
            "Epoch: 40 | Loss: 0.5374889969825745 | Test loss: 0.566247820854187\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7584]])), ('linear_layer.bias', tensor([0.8143]))])\n",
            "Loss:0.5370467901229858\n",
            "Loss:0.5366045236587524\n",
            "Loss:0.536162257194519\n",
            "Loss:0.5357200503349304\n",
            "Loss:0.5352778434753418\n",
            "Loss:0.5348355770111084\n",
            "Loss:0.5343934297561646\n",
            "Loss:0.5339511632919312\n",
            "Loss:0.5335089564323425\n",
            "Loss:0.5330666899681091\n",
            "Epoch: 50 | Loss: 0.5330666899681091 | Test loss: 0.5610772371292114\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7569]])), ('linear_layer.bias', tensor([0.8104]))])\n",
            "Loss:0.5326245427131653\n",
            "Loss:0.5321822762489319\n",
            "Loss:0.5317400693893433\n",
            "Loss:0.5312978029251099\n",
            "Loss:0.5308555364608765\n",
            "Loss:0.5304133296012878\n",
            "Loss:0.529971182346344\n",
            "Loss:0.5295289754867554\n",
            "Loss:0.5290867686271667\n",
            "Loss:0.5286445021629333\n",
            "Epoch: 60 | Loss: 0.5286445021629333 | Test loss: 0.5559067130088806\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7554]])), ('linear_layer.bias', tensor([0.8066]))])\n",
            "Loss:0.5282022356987\n",
            "Loss:0.5277600288391113\n",
            "Loss:0.5273178219795227\n",
            "Loss:0.5268756151199341\n",
            "Loss:0.5264333486557007\n",
            "Loss:0.5259911417961121\n",
            "Loss:0.5255489349365234\n",
            "Loss:0.5251067280769348\n",
            "Loss:0.5246644616127014\n",
            "Loss:0.5242222547531128\n",
            "Epoch: 70 | Loss: 0.5242222547531128 | Test loss: 0.5507360696792603\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7539]])), ('linear_layer.bias', tensor([0.8028]))])\n",
            "Loss:0.5237799882888794\n",
            "Loss:0.5233377814292908\n",
            "Loss:0.5228955149650574\n",
            "Loss:0.5224533677101135\n",
            "Loss:0.5220111608505249\n",
            "Loss:0.5215688943862915\n",
            "Loss:0.5211266279220581\n",
            "Loss:0.5206844806671143\n",
            "Loss:0.5202422738075256\n",
            "Loss:0.5198000073432922\n",
            "Epoch: 80 | Loss: 0.5198000073432922 | Test loss: 0.5455654859542847\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7524]])), ('linear_layer.bias', tensor([0.7989]))])\n",
            "Loss:0.5193577408790588\n",
            "Loss:0.5189155340194702\n",
            "Loss:0.5184733271598816\n",
            "Loss:0.518031120300293\n",
            "Loss:0.5175889134407043\n",
            "Loss:0.517146646976471\n",
            "Loss:0.5167044401168823\n",
            "Loss:0.5162621736526489\n",
            "Loss:0.5158199667930603\n",
            "Loss:0.5153777599334717\n",
            "Epoch: 90 | Loss: 0.5153777599334717 | Test loss: 0.5403949022293091\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7509]])), ('linear_layer.bias', tensor([0.7951]))])\n",
            "Loss:0.5149355530738831\n",
            "Loss:0.5144932866096497\n",
            "Loss:0.514051079750061\n",
            "Loss:0.5136088728904724\n",
            "Loss:0.513166606426239\n",
            "Loss:0.5127243995666504\n",
            "Loss:0.5122821927070618\n",
            "Loss:0.5118399262428284\n",
            "Loss:0.5113977193832397\n",
            "Loss:0.5109555721282959\n",
            "Epoch: 100 | Loss: 0.5109555721282959 | Test loss: 0.5352243185043335\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7494]])), ('linear_layer.bias', tensor([0.7912]))])\n",
            "Loss:0.5105133056640625\n",
            "Loss:0.5100710391998291\n",
            "Loss:0.5096288919448853\n",
            "Loss:0.5091866254806519\n",
            "Loss:0.5087443590164185\n",
            "Loss:0.5083021521568298\n",
            "Loss:0.5078599452972412\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|  | 77/100 [00:24<00:07,  3.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5074177384376526\n",
            "Loss:0.506975531578064\n",
            "Loss:0.5065332651138306\n",
            "Epoch: 110 | Loss: 0.5065332651138306 | Test loss: 0.5300538539886475\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7479]])), ('linear_layer.bias', tensor([0.7874]))])\n",
            "Loss:0.5060910582542419\n",
            "Loss:0.5056488513946533\n",
            "Loss:0.5052065849304199\n",
            "Loss:0.5047643780708313\n",
            "Loss:0.5043221712112427\n",
            "Loss:0.5038799047470093\n",
            "Loss:0.5034376978874207\n",
            "Loss:0.502995491027832\n",
            "Loss:0.5025532841682434\n",
            "Loss:0.50211101770401\n",
            "Epoch: 120 | Loss: 0.50211101770401 | Test loss: 0.5248832702636719\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7464]])), ('linear_layer.bias', tensor([0.7836]))])\n",
            "Loss:0.5016688108444214\n",
            "Loss:0.5012266039848328\n",
            "Loss:0.5007843375205994\n",
            "Loss:0.500342071056366\n",
            "Loss:0.4998999536037445\n",
            "Loss:0.4994577467441559\n",
            "Loss:0.4990154802799225\n",
            "Loss:0.4985732138156891\n",
            "Loss:0.49813103675842285\n",
            "Loss:0.49768877029418945\n",
            "Epoch: 130 | Loss: 0.49768877029418945 | Test loss: 0.5197126269340515\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7449]])), ('linear_layer.bias', tensor([0.7797]))])\n",
            "Loss:0.49724656343460083\n",
            "Loss:0.4968043267726898\n",
            "Loss:0.4963621199131012\n",
            "Loss:0.4959198832511902\n",
            "Loss:0.4954776167869568\n",
            "Loss:0.49503546953201294\n",
            "Loss:0.49459323287010193\n",
            "Loss:0.4941510260105133\n",
            "Loss:0.4937087595462799\n",
            "Loss:0.49326658248901367\n",
            "Epoch: 140 | Loss: 0.49326658248901367 | Test loss: 0.5145420432090759\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7434]])), ('linear_layer.bias', tensor([0.7759]))])\n",
            "Loss:0.49282437562942505\n",
            "Loss:0.49238210916519165\n",
            "Loss:0.4919399321079254\n",
            "Loss:0.491497665643692\n",
            "Loss:0.491055428981781\n",
            "Loss:0.4906131625175476\n",
            "Loss:0.490170955657959\n",
            "Loss:0.48972874879837036\n",
            "Loss:0.48928651213645935\n",
            "Loss:0.4888443052768707\n",
            "Epoch: 150 | Loss: 0.4888443052768707 | Test loss: 0.5093714594841003\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7419]])), ('linear_layer.bias', tensor([0.7720]))])\n",
            "Loss:0.4884021282196045\n",
            "Loss:0.4879598617553711\n",
            "Loss:0.48751765489578247\n",
            "Loss:0.4870753884315491\n",
            "Loss:0.48663321137428284\n",
            "Loss:0.48619094491004944\n",
            "Loss:0.4857487678527832\n",
            "Loss:0.4853065609931946\n",
            "Loss:0.48486432433128357\n",
            "Loss:0.48442205786705017\n",
            "Epoch: 160 | Loss: 0.48442205786705017 | Test loss: 0.5042008757591248\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7404]])), ('linear_layer.bias', tensor([0.7682]))])\n",
            "Loss:0.4839797914028168\n",
            "Loss:0.48353761434555054\n",
            "Loss:0.4830954074859619\n",
            "Loss:0.4826532006263733\n",
            "Loss:0.4822109341621399\n",
            "Loss:0.48176875710487366\n",
            "Loss:0.48132649064064026\n",
            "Loss:0.48088425397872925\n",
            "Loss:0.4804420471191406\n",
            "Loss:0.4799998700618744\n",
            "Epoch: 170 | Loss: 0.4799998700618744 | Test loss: 0.49903029203414917\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7389]])), ('linear_layer.bias', tensor([0.7644]))])\n",
            "Loss:0.479557603597641\n",
            "Loss:0.4791153371334076\n",
            "Loss:0.47867316007614136\n",
            "Loss:0.47823095321655273\n",
            "Loss:0.4777887463569641\n",
            "Loss:0.4773464798927307\n",
            "Loss:0.4769043028354645\n",
            "Loss:0.4764620363712311\n",
            "Loss:0.47601979970932007\n",
            "Loss:0.47557753324508667\n",
            "Epoch: 180 | Loss: 0.47557753324508667 | Test loss: 0.49385976791381836\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7374]])), ('linear_layer.bias', tensor([0.7605]))])\n",
            "Loss:0.4751353859901428\n",
            "Loss:0.4746931195259094\n",
            "Loss:0.4742508828639984\n",
            "Loss:0.4738086760044098\n",
            "Loss:0.47336649894714355\n",
            "Loss:0.47292423248291016\n",
            "Loss:0.47248202562332153\n",
            "Loss:0.4720397889614105\n",
            "Loss:0.4715975821018219\n",
            "Loss:0.4711553156375885\n",
            "Epoch: 190 | Loss: 0.4711553156375885 | Test loss: 0.488689124584198\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7360]])), ('linear_layer.bias', tensor([0.7567]))])\n",
            "Loss:0.47071313858032227\n",
            "Loss:0.47027093172073364\n",
            "Loss:0.46982866525650024\n",
            "Loss:0.46938642859458923\n",
            "Loss:0.468944251537323\n",
            "Loss:0.4685020446777344\n",
            "Loss:0.468059778213501\n",
            "Loss:0.46761757135391235\n",
            "Loss:0.46717530488967896\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.586923360824585\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5547299385070801\n",
            "Loss:0.5542818903923035\n",
            "Loss:0.5538338422775269\n",
            "Loss:0.553385853767395\n",
            "Loss:0.5529378056526184\n",
            "Loss:0.5524898767471313\n",
            "Loss:0.5520417094230652\n",
            "Loss:0.5515937805175781\n",
            "Loss:0.5511457324028015\n",
            "Loss:0.5506976842880249\n",
            "Epoch: 10 | Loss: 0.5506976842880249 | Test loss: 0.5816846489906311\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7629]])), ('linear_layer.bias', tensor([0.8257]))])\n",
            "Loss:0.5502496957778931\n",
            "Loss:0.5498017072677612\n",
            "Loss:0.5493536591529846\n",
            "Loss:0.5489055514335632\n",
            "Loss:0.5484576225280762\n",
            "Loss:0.5480095744132996\n",
            "Loss:0.547561526298523\n",
            "Loss:0.5471135377883911\n",
            "Loss:0.5466655492782593\n",
            "Loss:0.5462175607681274\n",
            "Epoch: 20 | Loss: 0.5462175607681274 | Test loss: 0.576445996761322\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7614]])), ('linear_layer.bias', tensor([0.8218]))])\n",
            "Loss:0.5457695126533508\n",
            "Loss:0.5453214049339294\n",
            "Loss:0.5448734760284424\n",
            "Loss:0.5444254875183105\n",
            "Loss:0.5439773797988892\n",
            "Loss:0.5435293912887573\n",
            "Loss:0.5430814027786255\n",
            "Loss:0.5426333546638489\n",
            "Loss:0.542185366153717\n",
            "Loss:0.5417372584342957\n",
            "Epoch: 30 | Loss: 0.5417372584342957 | Test loss: 0.5712072849273682\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7598]])), ('linear_layer.bias', tensor([0.8180]))])\n",
            "Loss:0.541289210319519\n",
            "Loss:0.5408412218093872\n",
            "Loss:0.5403932332992554\n",
            "Loss:0.5399452447891235\n",
            "Loss:0.5394972562789917\n",
            "Loss:0.5390491485595703\n",
            "Loss:0.5386011004447937\n",
            "Loss:0.5381531119346619\n",
            "Loss:0.5377050638198853\n",
            "Loss:0.5372570753097534\n",
            "Epoch: 40 | Loss: 0.5372570753097534 | Test loss: 0.5659685730934143\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7583]])), ('linear_layer.bias', tensor([0.8141]))])\n",
            "Loss:0.5368090867996216\n",
            "Loss:0.5363609790802002\n",
            "Loss:0.5359130501747131\n",
            "Loss:0.5354650616645813\n",
            "Loss:0.5350168943405151\n",
            "Loss:0.5345689654350281\n",
            "Loss:0.5341209173202515\n",
            "Loss:0.5336729288101196\n",
            "Loss:0.533224880695343\n",
            "Loss:0.5327768325805664\n",
            "Epoch: 50 | Loss: 0.5327768325805664 | Test loss: 0.5607298612594604\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7568]])), ('linear_layer.bias', tensor([0.8102]))])\n",
            "Loss:0.5323287844657898\n",
            "Loss:0.531880795955658\n",
            "Loss:0.5314328074455261\n",
            "Loss:0.5309847593307495\n",
            "Loss:0.5305367708206177\n",
            "Loss:0.5300887823104858\n",
            "Loss:0.5296407341957092\n",
            "Loss:0.5291926860809326\n",
            "Loss:0.5287446975708008\n",
            "Loss:0.5282966494560242\n",
            "Epoch: 60 | Loss: 0.5282966494560242 | Test loss: 0.5554912686347961\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7553]])), ('linear_layer.bias', tensor([0.8063]))])\n",
            "Loss:0.5278486013412476\n",
            "Loss:0.5274006128311157\n",
            "Loss:0.5269526243209839\n",
            "Loss:0.526504635810852\n",
            "Loss:0.5260565280914307\n",
            "Loss:0.5256085395812988\n",
            "Loss:0.5251604914665222\n",
            "Loss:0.5247124433517456\n",
            "Loss:0.5242644548416138\n",
            "Loss:0.5238164663314819\n",
            "Epoch: 70 | Loss: 0.5238164663314819 | Test loss: 0.5502525568008423\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7538]])), ('linear_layer.bias', tensor([0.8024]))])\n",
            "Loss:0.5233684778213501\n",
            "Loss:0.5229203701019287\n",
            "Loss:0.5224723815917969\n",
            "Loss:0.522024393081665\n",
            "Loss:0.5215763449668884\n",
            "Loss:0.5211282968521118\n",
            "Loss:0.52068030834198\n",
            "Loss:0.5202323198318481\n",
            "Loss:0.5197842717170715\n",
            "Loss:0.5193362236022949\n",
            "Epoch: 80 | Loss: 0.5193362236022949 | Test loss: 0.5450139045715332\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7523]])), ('linear_layer.bias', tensor([0.7985]))])\n",
            "Loss:0.5188881754875183\n",
            "Loss:0.5184401273727417\n",
            "Loss:0.5179921388626099\n",
            "Loss:0.517544150352478\n",
            "Loss:0.5170961618423462\n",
            "Loss:0.5166481137275696\n",
            "Loss:0.5162001252174377\n",
            "Loss:0.5157520174980164\n",
            "Loss:0.5153039693832397\n",
            "Loss:0.5148559808731079\n",
            "Epoch: 90 | Loss: 0.5148559808731079 | Test loss: 0.5397751927375793\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7507]])), ('linear_layer.bias', tensor([0.7946]))])\n",
            "Loss:0.5144079923629761\n",
            "Loss:0.5139599442481995\n",
            "Loss:0.5135120153427124\n",
            "Loss:0.5130639672279358\n",
            "Loss:0.5126158595085144\n",
            "Loss:0.5121678709983826\n",
            "Loss:0.5117198824882507\n",
            "Loss:0.5112718343734741\n",
            "Loss:0.5108237862586975\n",
            "Loss:0.5103758573532104\n",
            "Epoch: 100 | Loss: 0.5103758573532104 | Test loss: 0.5345365405082703\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7492]])), ('linear_layer.bias', tensor([0.7907]))])\n",
            "Loss:0.5099277496337891\n",
            "Loss:0.5094797611236572\n",
            "Loss:0.5090317726135254\n",
            "Loss:0.5085837244987488\n",
            "Loss:0.5081356763839722\n",
            "Loss:0.5076876878738403\n",
            "Loss:0.5072396993637085\n",
            "Loss:0.5067917108535767\n",
            "Loss:0.5063436031341553\n",
            "Loss:0.5058956146240234\n",
            "Epoch: 110 | Loss: 0.5058956146240234 | Test loss: 0.5292978286743164\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7477]])), ('linear_layer.bias', tensor([0.7868]))])\n",
            "Loss:0.5054475665092468\n",
            "Loss:0.5049995183944702\n",
            "Loss:0.5045515298843384\n",
            "Loss:0.5041035413742065\n",
            "Loss:0.5036554336547852\n",
            "Loss:0.5032075047492981\n",
            "Loss:0.5027594566345215\n",
            "Loss:0.5023114085197449\n",
            "Loss:0.5018633604049683\n",
            "Loss:0.5014153718948364\n",
            "Epoch: 120 | Loss: 0.5014153718948364 | Test loss: 0.5240591168403625\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7462]])), ('linear_layer.bias', tensor([0.7830]))])\n",
            "Loss:0.5009673833847046\n",
            "Loss:0.500519335269928\n",
            "Loss:0.5000713467597961\n",
            "Loss:0.49962329864501953\n",
            "Loss:0.4991752505302429\n",
            "Loss:0.4987272322177887\n",
            "Loss:0.49827924370765686\n",
            "Loss:0.49783116579055786\n",
            "Loss:0.4973832070827484\n",
            "Loss:0.4969351887702942\n",
            "Epoch: 130 | Loss: 0.4969351887702942 | Test loss: 0.5188204050064087\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7447]])), ('linear_layer.bias', tensor([0.7791]))])\n",
            "Loss:0.4964871406555176\n",
            "Loss:0.49603909254074097\n",
            "Loss:0.49559107422828674\n",
            "Loss:0.4951431155204773\n",
            "Loss:0.4946950078010559\n",
            "Loss:0.4942470192909241\n",
            "Loss:0.49379903078079224\n",
            "Loss:0.4933509826660156\n",
            "Loss:0.4929029941558838\n",
            "Loss:0.4924549460411072\n",
            "Epoch: 140 | Loss: 0.4924549460411072 | Test loss: 0.5135818123817444\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7431]])), ('linear_layer.bias', tensor([0.7752]))])\n",
            "Loss:0.49200692772865295\n",
            "Loss:0.4915589392185211\n",
            "Loss:0.4911108911037445\n",
            "Loss:0.49066290259361267\n",
            "Loss:0.49021482467651367\n",
            "Loss:0.48976677656173706\n",
            "Loss:0.4893187880516052\n",
            "Loss:0.48887085914611816\n",
            "Loss:0.48842278122901917\n",
            "Loss:0.48797473311424255\n",
            "Epoch: 150 | Loss: 0.48797473311424255 | Test loss: 0.5083431005477905\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7416]])), ('linear_layer.bias', tensor([0.7713]))])\n",
            "Loss:0.4875267446041107\n",
            "Loss:0.4870787262916565\n",
            "Loss:0.4866306781768799\n",
            "Loss:0.48618263006210327\n",
            "Loss:0.48573464155197144\n",
            "Loss:0.48528656363487244\n",
            "Loss:0.4848385751247406\n",
            "Loss:0.4843905568122864\n",
            "Loss:0.48394256830215454\n",
            "Loss:0.48349452018737793\n",
            "Epoch: 160 | Loss: 0.48349452018737793 | Test loss: 0.5031044483184814\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7401]])), ('linear_layer.bias', tensor([0.7674]))])\n",
            "Loss:0.4830464720726013\n",
            "Loss:0.4825984537601471\n",
            "Loss:0.48215046525001526\n",
            "Loss:0.48170241713523865\n",
            "Loss:0.4812543988227844\n",
            "Loss:0.4808064103126526\n",
            "Loss:0.480358362197876\n",
            "Loss:0.47991037368774414\n",
            "Loss:0.47946229577064514\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|  | 78/100 [00:24<00:07,  3.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.4790143072605133\n",
            "Epoch: 170 | Loss: 0.4790143072605133 | Test loss: 0.4978657364845276\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7386]])), ('linear_layer.bias', tensor([0.7635]))])\n",
            "Loss:0.47856631875038147\n",
            "Loss:0.47811833024024963\n",
            "Loss:0.47767025232315063\n",
            "Loss:0.477222204208374\n",
            "Loss:0.4767742156982422\n",
            "Loss:0.4763261675834656\n",
            "Loss:0.47587814927101135\n",
            "Loss:0.4754301607608795\n",
            "Loss:0.4749820828437805\n",
            "Loss:0.4745340943336487\n",
            "Epoch: 180 | Loss: 0.4745340943336487 | Test loss: 0.4926270544528961\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7371]])), ('linear_layer.bias', tensor([0.7596]))])\n",
            "Loss:0.47408610582351685\n",
            "Loss:0.47363805770874023\n",
            "Loss:0.4731900095939636\n",
            "Loss:0.4727420210838318\n",
            "Loss:0.47229403257369995\n",
            "Loss:0.47184595465660095\n",
            "Loss:0.4713979661464691\n",
            "Loss:0.4709499478340149\n",
            "Loss:0.4705018997192383\n",
            "Loss:0.47005385160446167\n",
            "Epoch: 190 | Loss: 0.47005385160446167 | Test loss: 0.48738837242126465\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7356]])), ('linear_layer.bias', tensor([0.7557]))])\n",
            "Loss:0.46960586309432983\n",
            "Loss:0.46915778517723083\n",
            "Loss:0.468709796667099\n",
            "Loss:0.46826180815696716\n",
            "Loss:0.4678138196468353\n",
            "Loss:0.46736574172973633\n",
            "Loss:0.4669176936149597\n",
            "Loss:0.46646976470947266\n",
            "Loss:0.46602171659469604\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.586916446685791\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5547240972518921\n",
            "Loss:0.5542702078819275\n",
            "Loss:0.5538163781166077\n",
            "Loss:0.5533624887466431\n",
            "Loss:0.5529085993766785\n",
            "Loss:0.5524548292160034\n",
            "Loss:0.5520009398460388\n",
            "Loss:0.551547110080719\n",
            "Loss:0.5510932803153992\n",
            "Loss:0.5506393909454346\n",
            "Epoch: 10 | Loss: 0.5506393909454346 | Test loss: 0.5816096663475037\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7628]])), ('linear_layer.bias', tensor([0.8257]))])\n",
            "Loss:0.5501855611801147\n",
            "Loss:0.5497316718101501\n",
            "Loss:0.5492777824401855\n",
            "Loss:0.5488239526748657\n",
            "Loss:0.5483700037002563\n",
            "Loss:0.5479162931442261\n",
            "Loss:0.5474623441696167\n",
            "Loss:0.5470085144042969\n",
            "Loss:0.546554684638977\n",
            "Loss:0.5461007952690125\n",
            "Epoch: 20 | Loss: 0.5461007952690125 | Test loss: 0.5763028264045715\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7613]])), ('linear_layer.bias', tensor([0.8217]))])\n",
            "Loss:0.5456470251083374\n",
            "Loss:0.5451931357383728\n",
            "Loss:0.544739305973053\n",
            "Loss:0.5442854166030884\n",
            "Loss:0.5438315272331238\n",
            "Loss:0.543377697467804\n",
            "Loss:0.5429238677024841\n",
            "Loss:0.5424700379371643\n",
            "Loss:0.5420161485671997\n",
            "Loss:0.5415622591972351\n",
            "Epoch: 30 | Loss: 0.5415622591972351 | Test loss: 0.5709959268569946\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7598]])), ('linear_layer.bias', tensor([0.8178]))])\n",
            "Loss:0.5411084294319153\n",
            "Loss:0.5406545400619507\n",
            "Loss:0.5402007699012756\n",
            "Loss:0.539746880531311\n",
            "Loss:0.5392929911613464\n",
            "Loss:0.5388391613960266\n",
            "Loss:0.538385272026062\n",
            "Loss:0.5379314422607422\n",
            "Loss:0.5374775528907776\n",
            "Loss:0.5370237827301025\n",
            "Epoch: 40 | Loss: 0.5370237827301025 | Test loss: 0.5656890869140625\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7582]])), ('linear_layer.bias', tensor([0.8139]))])\n",
            "Loss:0.5365698933601379\n",
            "Loss:0.5361160039901733\n",
            "Loss:0.5356621146202087\n",
            "Loss:0.5352083444595337\n",
            "Loss:0.5347545146942139\n",
            "Loss:0.5343006253242493\n",
            "Loss:0.5338467955589294\n",
            "Loss:0.5333929061889648\n",
            "Loss:0.532939076423645\n",
            "Loss:0.5324851870536804\n",
            "Epoch: 50 | Loss: 0.5324851870536804 | Test loss: 0.5603822469711304\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7567]])), ('linear_layer.bias', tensor([0.8099]))])\n",
            "Loss:0.5320313572883606\n",
            "Loss:0.531577467918396\n",
            "Loss:0.5311235785484314\n",
            "Loss:0.5306697487831116\n",
            "Loss:0.5302159190177917\n",
            "Loss:0.5297620892524719\n",
            "Loss:0.5293081998825073\n",
            "Loss:0.5288543701171875\n",
            "Loss:0.5284004807472229\n",
            "Loss:0.5279466509819031\n",
            "Epoch: 60 | Loss: 0.5279466509819031 | Test loss: 0.5550754070281982\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7552]])), ('linear_layer.bias', tensor([0.8060]))])\n",
            "Loss:0.5274928212165833\n",
            "Loss:0.5270389318466187\n",
            "Loss:0.5265851020812988\n",
            "Loss:0.526131272315979\n",
            "Loss:0.5256773233413696\n",
            "Loss:0.5252235531806946\n",
            "Loss:0.52476966381073\n",
            "Loss:0.5243157744407654\n",
            "Loss:0.5238620042800903\n",
            "Loss:0.523408055305481\n",
            "Epoch: 70 | Loss: 0.523408055305481 | Test loss: 0.5497685670852661\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7536]])), ('linear_layer.bias', tensor([0.8020]))])\n",
            "Loss:0.5229542255401611\n",
            "Loss:0.5225003957748413\n",
            "Loss:0.5220465064048767\n",
            "Loss:0.5215926766395569\n",
            "Loss:0.5211387872695923\n",
            "Loss:0.5206849575042725\n",
            "Loss:0.5202311277389526\n",
            "Loss:0.5197771787643433\n",
            "Loss:0.5193233489990234\n",
            "Loss:0.5188695788383484\n",
            "Epoch: 80 | Loss: 0.5188695788383484 | Test loss: 0.5444616079330444\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7521]])), ('linear_layer.bias', tensor([0.7981]))])\n",
            "Loss:0.5184156894683838\n",
            "Loss:0.517961859703064\n",
            "Loss:0.5175079703330994\n",
            "Loss:0.5170542001724243\n",
            "Loss:0.5166003108024597\n",
            "Loss:0.5161464214324951\n",
            "Loss:0.5156925916671753\n",
            "Loss:0.5152387619018555\n",
            "Loss:0.5147848725318909\n",
            "Loss:0.5143309831619263\n",
            "Epoch: 90 | Loss: 0.5143309831619263 | Test loss: 0.5391548871994019\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7506]])), ('linear_layer.bias', tensor([0.7942]))])\n",
            "Loss:0.5138771533966064\n",
            "Loss:0.5134232640266418\n",
            "Loss:0.512969434261322\n",
            "Loss:0.5125155448913574\n",
            "Loss:0.5120617151260376\n",
            "Loss:0.511607825756073\n",
            "Loss:0.511154055595398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|  | 79/100 [00:24<00:06,  3.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5107001066207886\n",
            "Loss:0.5102463364601135\n",
            "Loss:0.5097925066947937\n",
            "Epoch: 100 | Loss: 0.5097925066947937 | Test loss: 0.5338479280471802\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7490]])), ('linear_layer.bias', tensor([0.7902]))])\n",
            "Loss:0.5093386173248291\n",
            "Loss:0.5088847875595093\n",
            "Loss:0.5084308981895447\n",
            "Loss:0.5079770684242249\n",
            "Loss:0.5075231790542603\n",
            "Loss:0.5070692896842957\n",
            "Loss:0.5066155195236206\n",
            "Loss:0.5061615705490112\n",
            "Loss:0.5057077407836914\n",
            "Loss:0.5052539110183716\n",
            "Epoch: 110 | Loss: 0.5052539110183716 | Test loss: 0.5285412073135376\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7475]])), ('linear_layer.bias', tensor([0.7863]))])\n",
            "Loss:0.5048000812530518\n",
            "Loss:0.5043462514877319\n",
            "Loss:0.5038923025131226\n",
            "Loss:0.5034384727478027\n",
            "Loss:0.5029846429824829\n",
            "Loss:0.5025307536125183\n",
            "Loss:0.5020769238471985\n",
            "Loss:0.5016230344772339\n",
            "Loss:0.5011692047119141\n",
            "Loss:0.500715434551239\n",
            "Epoch: 120 | Loss: 0.500715434551239 | Test loss: 0.5232342481613159\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7459]])), ('linear_layer.bias', tensor([0.7823]))])\n",
            "Loss:0.5002615451812744\n",
            "Loss:0.4998076558113098\n",
            "Loss:0.4993537962436676\n",
            "Loss:0.49889999628067017\n",
            "Loss:0.4984460771083832\n",
            "Loss:0.49799221754074097\n",
            "Loss:0.49753838777542114\n",
            "Loss:0.49708452820777893\n",
            "Loss:0.4966307282447815\n",
            "Loss:0.4961768090724945\n",
            "Epoch: 130 | Loss: 0.4961768090724945 | Test loss: 0.5179274082183838\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7444]])), ('linear_layer.bias', tensor([0.7784]))])\n",
            "Loss:0.4957229197025299\n",
            "Loss:0.49526911973953247\n",
            "Loss:0.49481526017189026\n",
            "Loss:0.49436140060424805\n",
            "Loss:0.49390751123428345\n",
            "Loss:0.49345365166664124\n",
            "Loss:0.492999792098999\n",
            "Loss:0.4925459921360016\n",
            "Loss:0.4920921325683594\n",
            "Loss:0.49163827300071716\n",
            "Epoch: 140 | Loss: 0.49163827300071716 | Test loss: 0.5126205682754517\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7429]])), ('linear_layer.bias', tensor([0.7745]))])\n",
            "Loss:0.49118441343307495\n",
            "Loss:0.4907305836677551\n",
            "Loss:0.4902767241001129\n",
            "Loss:0.4898228645324707\n",
            "Loss:0.4893690049648285\n",
            "Loss:0.4889151453971863\n",
            "Loss:0.4884612560272217\n",
            "Loss:0.48800745606422424\n",
            "Loss:0.48755353689193726\n",
            "Loss:0.48709970712661743\n",
            "Epoch: 150 | Loss: 0.48709970712661743 | Test loss: 0.5073137283325195\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7413]])), ('linear_layer.bias', tensor([0.7705]))])\n",
            "Loss:0.4866458475589752\n",
            "Loss:0.486191987991333\n",
            "Loss:0.4857381284236908\n",
            "Loss:0.4852842688560486\n",
            "Loss:0.48483043909072876\n",
            "Loss:0.4843765199184418\n",
            "Loss:0.4839227795600891\n",
            "Loss:0.4834689199924469\n",
            "Loss:0.4830150008201599\n",
            "Loss:0.4825612008571625\n",
            "Epoch: 160 | Loss: 0.4825612008571625 | Test loss: 0.5020068883895874\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7398]])), ('linear_layer.bias', tensor([0.7666]))])\n",
            "Loss:0.4821072518825531\n",
            "Loss:0.48165345191955566\n",
            "Loss:0.48119959235191345\n",
            "Loss:0.48074573278427124\n",
            "Loss:0.4802919030189514\n",
            "Loss:0.4798380434513092\n",
            "Loss:0.479384183883667\n",
            "Loss:0.4789303243160248\n",
            "Loss:0.47847646474838257\n",
            "Loss:0.47802263498306274\n",
            "Epoch: 170 | Loss: 0.47802263498306274 | Test loss: 0.4967000484466553\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7383]])), ('linear_layer.bias', tensor([0.7626]))])\n",
            "Loss:0.47756877541542053\n",
            "Loss:0.47711485624313354\n",
            "Loss:0.4766610264778137\n",
            "Loss:0.4762071669101715\n",
            "Loss:0.4757533073425293\n",
            "Loss:0.47529950737953186\n",
            "Loss:0.47484564781188965\n",
            "Loss:0.47439175844192505\n",
            "Loss:0.47393789887428284\n",
            "Loss:0.4734840393066406\n",
            "Epoch: 180 | Loss: 0.4734840393066406 | Test loss: 0.49139317870140076\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7367]])), ('linear_layer.bias', tensor([0.7587]))])\n",
            "Loss:0.4730301797389984\n",
            "Loss:0.472576379776001\n",
            "Loss:0.47212252020835876\n",
            "Loss:0.47166863083839417\n",
            "Loss:0.47121477127075195\n",
            "Loss:0.4707609713077545\n",
            "Loss:0.47030705213546753\n",
            "Loss:0.4698532521724701\n",
            "Loss:0.4693993926048279\n",
            "Loss:0.4689455032348633\n",
            "Epoch: 190 | Loss: 0.4689455032348633 | Test loss: 0.48608630895614624\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7352]])), ('linear_layer.bias', tensor([0.7548]))])\n",
            "Loss:0.46849164366722107\n",
            "Loss:0.46803778409957886\n",
            "Loss:0.46758389472961426\n",
            "Loss:0.4671300947666168\n",
            "Loss:0.4666762351989746\n",
            "Loss:0.4662223756313324\n",
            "Loss:0.4657685160636902\n",
            "Loss:0.46531468629837036\n",
            "Loss:0.46486082673072815\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5869097709655762\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5547182559967041\n",
            "Loss:0.5542585253715515\n",
            "Loss:0.5537988543510437\n",
            "Loss:0.5533391833305359\n",
            "Loss:0.5528795719146729\n",
            "Loss:0.5524197816848755\n",
            "Loss:0.5519601106643677\n",
            "Loss:0.5515004396438599\n",
            "Loss:0.551040768623352\n",
            "Loss:0.5505810379981995\n",
            "Epoch: 10 | Loss: 0.5505810379981995 | Test loss: 0.5815346837043762\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7628]])), ('linear_layer.bias', tensor([0.8256]))])\n",
            "Loss:0.5501213669776917\n",
            "Loss:0.5496616959571838\n",
            "Loss:0.5492019653320312\n",
            "Loss:0.5487422943115234\n",
            "Loss:0.5482826232910156\n",
            "Loss:0.547822892665863\n",
            "Loss:0.5473631620407104\n",
            "Loss:0.5469035506248474\n",
            "Loss:0.5464438199996948\n",
            "Loss:0.545984148979187\n",
            "Epoch: 20 | Loss: 0.545984148979187 | Test loss: 0.5761595964431763\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7613]])), ('linear_layer.bias', tensor([0.8216]))])\n",
            "Loss:0.545524537563324\n",
            "Loss:0.5450648069381714\n",
            "Loss:0.5446051359176636\n",
            "Loss:0.5441454648971558\n",
            "Loss:0.543685793876648\n",
            "Loss:0.5432260036468506\n",
            "Loss:0.5427663326263428\n",
            "Loss:0.542306661605835\n",
            "Loss:0.5418469905853271\n",
            "Loss:0.5413873195648193\n",
            "Epoch: 30 | Loss: 0.5413873195648193 | Test loss: 0.5707846879959106\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7597]])), ('linear_layer.bias', tensor([0.8176]))])\n",
            "Loss:0.5409275889396667\n",
            "Loss:0.5404679179191589\n",
            "Loss:0.5400082468986511\n",
            "Loss:0.5395485758781433\n",
            "Loss:0.5390888452529907\n",
            "Loss:0.5386291742324829\n",
            "Loss:0.5381694436073303\n",
            "Loss:0.5377098321914673\n",
            "Loss:0.5372501611709595\n",
            "Loss:0.5367903709411621\n",
            "Epoch: 40 | Loss: 0.5367903709411621 | Test loss: 0.5654096007347107\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7582]])), ('linear_layer.bias', tensor([0.8136]))])\n",
            "Loss:0.5363307595252991\n",
            "Loss:0.5358709692955017\n",
            "Loss:0.5354113578796387\n",
            "Loss:0.5349516272544861\n",
            "Loss:0.5344918966293335\n",
            "Loss:0.5340322852134705\n",
            "Loss:0.5335725545883179\n",
            "Loss:0.5331128835678101\n",
            "Loss:0.5326532125473022\n",
            "Loss:0.5321934819221497\n",
            "Epoch: 50 | Loss: 0.5321934819221497 | Test loss: 0.5600346326828003\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7566]])), ('linear_layer.bias', tensor([0.8097]))])\n",
            "Loss:0.5317338705062866\n",
            "Loss:0.531274139881134\n",
            "Loss:0.5308144688606262\n",
            "Loss:0.5303547382354736\n",
            "Loss:0.5298950672149658\n",
            "Loss:0.529435396194458\n",
            "Loss:0.5289756059646606\n",
            "Loss:0.5285160541534424\n",
            "Loss:0.5280563235282898\n",
            "Loss:0.5275965929031372\n",
            "Epoch: 60 | Loss: 0.5275965929031372 | Test loss: 0.5546594858169556\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7550]])), ('linear_layer.bias', tensor([0.8057]))])\n",
            "Loss:0.5271369814872742\n",
            "Loss:0.5266772508621216\n",
            "Loss:0.5262175798416138\n",
            "Loss:0.525757908821106\n",
            "Loss:0.5252982378005981\n",
            "Loss:0.5248385071754456\n",
            "Loss:0.5243788361549377\n",
            "Loss:0.5239191055297852\n",
            "Loss:0.5234594345092773\n",
            "Loss:0.5229997634887695\n",
            "Epoch: 70 | Loss: 0.5229997634887695 | Test loss: 0.5492845773696899\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7535]])), ('linear_layer.bias', tensor([0.8017]))])\n",
            "Loss:0.5225400924682617\n",
            "Loss:0.5220803618431091\n",
            "Loss:0.5216207504272461\n",
            "Loss:0.5211609601974487\n",
            "Loss:0.5207012891769409\n",
            "Loss:0.5202416181564331\n",
            "Loss:0.5197819471359253\n",
            "Loss:0.5193222165107727\n",
            "Loss:0.5188626050949097\n",
            "Loss:0.5184028744697571\n",
            "Epoch: 80 | Loss: 0.5184028744697571 | Test loss: 0.54390949010849\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7519]])), ('linear_layer.bias', tensor([0.7977]))])\n",
            "Loss:0.5179432034492493\n",
            "Loss:0.5174834728240967\n",
            "Loss:0.5170237421989441\n",
            "Loss:0.516564130783081\n",
            "Loss:0.5161044001579285\n",
            "Loss:0.5156447291374207\n",
            "Loss:0.5151849985122681\n",
            "Loss:0.514725387096405\n",
            "Loss:0.5142656564712524\n",
            "Loss:0.5138059258460999\n",
            "Epoch: 90 | Loss: 0.5138059258460999 | Test loss: 0.5385345220565796\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7504]])), ('linear_layer.bias', tensor([0.7937]))])\n",
            "Loss:0.5133463144302368\n",
            "Loss:0.512886643409729\n",
            "Loss:0.5124269723892212\n",
            "Loss:0.5119672417640686\n",
            "Loss:0.511507511138916\n",
            "Loss:0.5110478401184082\n",
            "Loss:0.5105881690979004\n",
            "Loss:0.510128378868103\n",
            "Loss:0.50966876745224\n",
            "Loss:0.509209156036377\n",
            "Epoch: 100 | Loss: 0.509209156036377 | Test loss: 0.5331594944000244\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7488]])), ('linear_layer.bias', tensor([0.7897]))])\n",
            "Loss:0.5087494254112244\n",
            "Loss:0.5082896947860718\n",
            "Loss:0.507830023765564\n",
            "Loss:0.5073703527450562\n",
            "Loss:0.5069106221199036\n",
            "Loss:0.5064510107040405\n",
            "Loss:0.5059913396835327\n",
            "Loss:0.5055315494537354\n",
            "Loss:0.5050718784332275\n",
            "Loss:0.5046122074127197\n",
            "Epoch: 110 | Loss: 0.5046122074127197 | Test loss: 0.5277844667434692\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7473]])), ('linear_layer.bias', tensor([0.7857]))])\n",
            "Loss:0.5041524767875671\n",
            "Loss:0.5036928653717041\n",
            "Loss:0.5032331347465515\n",
            "Loss:0.5027734637260437\n",
            "Loss:0.5023137331008911\n",
            "Loss:0.5018540620803833\n",
            "Loss:0.5013943910598755\n",
            "Loss:0.5009347200393677\n",
            "Loss:0.5004750490188599\n",
            "Loss:0.5000153183937073\n",
            "Epoch: 120 | Loss: 0.5000153183937073 | Test loss: 0.5224094986915588\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7457]])), ('linear_layer.bias', tensor([0.7817]))])\n",
            "Loss:0.49955567717552185\n",
            "Loss:0.49909597635269165\n",
            "Loss:0.49863624572753906\n",
            "Loss:0.49817657470703125\n",
            "Loss:0.49771690368652344\n",
            "Loss:0.4972572326660156\n",
            "Loss:0.49679750204086304\n",
            "Loss:0.49633780121803284\n",
            "Loss:0.495878130197525\n",
            "Loss:0.49541839957237244\n",
            "Epoch: 130 | Loss: 0.49541839957237244 | Test loss: 0.5170344114303589\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7442]])), ('linear_layer.bias', tensor([0.7777]))])\n",
            "Loss:0.4949587881565094\n",
            "Loss:0.4944990575313568\n",
            "Loss:0.494039386510849\n",
            "Loss:0.4935796856880188\n",
            "Loss:0.493120014667511\n",
            "Loss:0.4926603436470032\n",
            "Loss:0.4922006130218506\n",
            "Loss:0.4917409420013428\n",
            "Loss:0.49128127098083496\n",
            "Loss:0.49082159996032715\n",
            "Epoch: 140 | Loss: 0.49082159996032715 | Test loss: 0.5116594433784485\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7426]])), ('linear_layer.bias', tensor([0.7737]))])\n",
            "Loss:0.49036186933517456\n",
            "Loss:0.48990219831466675\n",
            "Loss:0.48944249749183655\n",
            "Loss:0.48898282647132874\n",
            "Loss:0.4885231554508209\n",
            "Loss:0.48806342482566833\n",
            "Loss:0.48760372400283813\n",
            "Loss:0.4871440529823303\n",
            "Loss:0.4866844117641449\n",
            "Loss:0.4862247109413147\n",
            "Epoch: 150 | Loss: 0.4862247109413147 | Test loss: 0.5062843561172485\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7410]])), ('linear_layer.bias', tensor([0.7698]))])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|  | 80/100 [00:25<00:06,  3.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.4857649803161621\n",
            "Loss:0.4853053092956543\n",
            "Loss:0.4848455488681793\n",
            "Loss:0.48438596725463867\n",
            "Loss:0.4839262068271637\n",
            "Loss:0.48346662521362305\n",
            "Loss:0.48300689458847046\n",
            "Loss:0.48254719376564026\n",
            "Loss:0.48208752274513245\n",
            "Loss:0.48162779211997986\n",
            "Epoch: 160 | Loss: 0.48162779211997986 | Test loss: 0.5009093284606934\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7395]])), ('linear_layer.bias', tensor([0.7658]))])\n",
            "Loss:0.48116809129714966\n",
            "Loss:0.48070845007896423\n",
            "Loss:0.48024868965148926\n",
            "Loss:0.4797890782356262\n",
            "Loss:0.47932934761047363\n",
            "Loss:0.4788697361946106\n",
            "Loss:0.478410005569458\n",
            "Loss:0.4779502749443054\n",
            "Loss:0.4774906039237976\n",
            "Loss:0.4770309031009674\n",
            "Epoch: 170 | Loss: 0.4770309031009674 | Test loss: 0.49553433060646057\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7379]])), ('linear_layer.bias', tensor([0.7618]))])\n",
            "Loss:0.4765711724758148\n",
            "Loss:0.4761115610599518\n",
            "Loss:0.47565189003944397\n",
            "Loss:0.47519224882125854\n",
            "Loss:0.47473248839378357\n",
            "Loss:0.47427278757095337\n",
            "Loss:0.47381311655044556\n",
            "Loss:0.47335338592529297\n",
            "Loss:0.47289371490478516\n",
            "Loss:0.47243404388427734\n",
            "Epoch: 180 | Loss: 0.47243404388427734 | Test loss: 0.4901593327522278\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7364]])), ('linear_layer.bias', tensor([0.7578]))])\n",
            "Loss:0.47197437286376953\n",
            "Loss:0.47151464223861694\n",
            "Loss:0.47105497121810913\n",
            "Loss:0.47059527039527893\n",
            "Loss:0.4701355993747711\n",
            "Loss:0.46967583894729614\n",
            "Loss:0.4692162573337555\n",
            "Loss:0.4687565267086029\n",
            "Loss:0.4682968258857727\n",
            "Loss:0.4678371548652649\n",
            "Epoch: 190 | Loss: 0.4678371548652649 | Test loss: 0.4847842752933502\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7348]])), ('linear_layer.bias', tensor([0.7538]))])\n",
            "Loss:0.4673774838447571\n",
            "Loss:0.46691781282424927\n",
            "Loss:0.4664580821990967\n",
            "Loss:0.46599847078323364\n",
            "Loss:0.4655386805534363\n",
            "Loss:0.46507900953292847\n",
            "Loss:0.46461933851242065\n",
            "Loss:0.46415966749191284\n",
            "Loss:0.46369999647140503\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5869028568267822\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5547124147415161\n",
            "Loss:0.5542468428611755\n",
            "Loss:0.5537813901901245\n",
            "Loss:0.5533158183097839\n",
            "Loss:0.5528503656387329\n",
            "Loss:0.5523847937583923\n",
            "Loss:0.5519192814826965\n",
            "Loss:0.551453709602356\n",
            "Loss:0.5509882569313049\n",
            "Loss:0.5505227446556091\n",
            "Epoch: 10 | Loss: 0.5505227446556091 | Test loss: 0.5814597010612488\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7628]])), ('linear_layer.bias', tensor([0.8256]))])\n",
            "Loss:0.5500572323799133\n",
            "Loss:0.5495917201042175\n",
            "Loss:0.549126148223877\n",
            "Loss:0.5486606359481812\n",
            "Loss:0.5481951236724854\n",
            "Loss:0.5477296113967896\n",
            "Loss:0.547264039516449\n",
            "Loss:0.546798586845398\n",
            "Loss:0.5463330149650574\n",
            "Loss:0.5458674430847168\n",
            "Epoch: 20 | Loss: 0.5458674430847168 | Test loss: 0.5760164260864258\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7612]])), ('linear_layer.bias', tensor([0.8215]))])\n",
            "Loss:0.545401930809021\n",
            "Loss:0.54493647813797\n",
            "Loss:0.5444709062576294\n",
            "Loss:0.5440053343772888\n",
            "Loss:0.5435398817062378\n",
            "Loss:0.543074369430542\n",
            "Loss:0.5426088571548462\n",
            "Loss:0.5421432852745056\n",
            "Loss:0.5416778326034546\n",
            "Loss:0.541212260723114\n",
            "Epoch: 30 | Loss: 0.541212260723114 | Test loss: 0.5705732703208923\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7597]])), ('linear_layer.bias', tensor([0.8175]))])\n",
            "Loss:0.540746808052063\n",
            "Loss:0.5402811765670776\n",
            "Loss:0.5398157238960266\n",
            "Loss:0.5393502116203308\n",
            "Loss:0.5388846397399902\n",
            "Loss:0.5384191274642944\n",
            "Loss:0.5379536151885986\n",
            "Loss:0.5374881029129028\n",
            "Loss:0.537022590637207\n",
            "Loss:0.5365570783615112\n",
            "Epoch: 40 | Loss: 0.5365570783615112 | Test loss: 0.5651301145553589\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7581]])), ('linear_layer.bias', tensor([0.8134]))])\n",
            "Loss:0.5360915064811707\n",
            "Loss:0.5356259942054749\n",
            "Loss:0.5351605415344238\n",
            "Loss:0.5346949696540833\n",
            "Loss:0.5342294573783875\n",
            "Loss:0.5337640047073364\n",
            "Loss:0.5332983732223511\n",
            "Loss:0.5328328609466553\n",
            "Loss:0.5323673486709595\n",
            "Loss:0.5319018363952637\n",
            "Epoch: 50 | Loss: 0.5319018363952637 | Test loss: 0.5596869587898254\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7565]])), ('linear_layer.bias', tensor([0.8094]))])\n",
            "Loss:0.5314363241195679\n",
            "Loss:0.5309707522392273\n",
            "Loss:0.5305052995681763\n",
            "Loss:0.5300397872924805\n",
            "Loss:0.5295742154121399\n",
            "Loss:0.5291086435317993\n",
            "Loss:0.5286432504653931\n",
            "Loss:0.5281776785850525\n",
            "Loss:0.5277121067047119\n",
            "Loss:0.5272465944290161\n",
            "Epoch: 60 | Loss: 0.5272465944290161 | Test loss: 0.5542437434196472\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7549]])), ('linear_layer.bias', tensor([0.8054]))])\n",
            "Loss:0.5267810821533203\n",
            "Loss:0.5263155698776245\n",
            "Loss:0.5258499979972839\n",
            "Loss:0.5253845453262329\n",
            "Loss:0.5249190330505371\n",
            "Loss:0.5244535207748413\n",
            "Loss:0.523987889289856\n",
            "Loss:0.5235224366188049\n",
            "Loss:0.5230569243431091\n",
            "Loss:0.5225914120674133\n",
            "Epoch: 70 | Loss: 0.5225914120674133 | Test loss: 0.5488005876541138\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7533]])), ('linear_layer.bias', tensor([0.8013]))])\n",
            "Loss:0.5221258401870728\n",
            "Loss:0.5216603875160217\n",
            "Loss:0.5211948156356812\n",
            "Loss:0.5207293629646301\n",
            "Loss:0.5202637314796448\n",
            "Loss:0.5197982788085938\n",
            "Loss:0.519332766532898\n",
            "Loss:0.5188671946525574\n",
            "Loss:0.5184016823768616\n",
            "Loss:0.5179361701011658\n",
            "Epoch: 80 | Loss: 0.5179361701011658 | Test loss: 0.5433573126792908\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7518]])), ('linear_layer.bias', tensor([0.7973]))])\n",
            "Loss:0.5174707174301147\n",
            "Loss:0.5170051455497742\n",
            "Loss:0.5165395736694336\n",
            "Loss:0.5160740613937378\n",
            "Loss:0.5156086087226868\n",
            "Loss:0.5151430368423462\n",
            "Loss:0.5146775245666504\n",
            "Loss:0.5142120122909546\n",
            "Loss:0.5137465000152588\n",
            "Loss:0.513280987739563\n",
            "Epoch: 90 | Loss: 0.513280987739563 | Test loss: 0.5379141569137573\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7502]])), ('linear_layer.bias', tensor([0.7932]))])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|  | 81/100 [00:25<00:06,  3.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5128154158592224\n",
            "Loss:0.5123499631881714\n",
            "Loss:0.5118843913078308\n",
            "Loss:0.511418879032135\n",
            "Loss:0.5109533071517944\n",
            "Loss:0.5104877948760986\n",
            "Loss:0.5100222826004028\n",
            "Loss:0.509556770324707\n",
            "Loss:0.5090912580490112\n",
            "Loss:0.5086257457733154\n",
            "Epoch: 100 | Loss: 0.5086257457733154 | Test loss: 0.5324709415435791\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7486]])), ('linear_layer.bias', tensor([0.7892]))])\n",
            "Loss:0.5081602334976196\n",
            "Loss:0.507694661617279\n",
            "Loss:0.507229208946228\n",
            "Loss:0.5067636370658875\n",
            "Loss:0.5062981843948364\n",
            "Loss:0.5058326721191406\n",
            "Loss:0.5053671002388\n",
            "Loss:0.5049015283584595\n",
            "Loss:0.5044361352920532\n",
            "Loss:0.5039705038070679\n",
            "Epoch: 110 | Loss: 0.5039705038070679 | Test loss: 0.5270277261734009\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7470]])), ('linear_layer.bias', tensor([0.7852]))])\n",
            "Loss:0.5035049915313721\n",
            "Loss:0.5030394792556763\n",
            "Loss:0.5025739669799805\n",
            "Loss:0.5021084547042847\n",
            "Loss:0.5016428828239441\n",
            "Loss:0.5011774301528931\n",
            "Loss:0.5007119178771973\n",
            "Loss:0.5002463459968567\n",
            "Loss:0.4997808039188385\n",
            "Loss:0.4993153214454651\n",
            "Epoch: 120 | Loss: 0.4993153214454651 | Test loss: 0.5215846300125122\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7455]])), ('linear_layer.bias', tensor([0.7811]))])\n",
            "Loss:0.4988497793674469\n",
            "Loss:0.4983842372894287\n",
            "Loss:0.4979187548160553\n",
            "Loss:0.4974532127380371\n",
            "Loss:0.4969877302646637\n",
            "Loss:0.4965221881866455\n",
            "Loss:0.4960566461086273\n",
            "Loss:0.4955911636352539\n",
            "Loss:0.4951256811618805\n",
            "Loss:0.49466007947921753\n",
            "Epoch: 130 | Loss: 0.49466007947921753 | Test loss: 0.5161413550376892\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7439]])), ('linear_layer.bias', tensor([0.7771]))])\n",
            "Loss:0.4941945970058441\n",
            "Loss:0.4937290549278259\n",
            "Loss:0.4932635426521301\n",
            "Loss:0.4927980303764343\n",
            "Loss:0.49233245849609375\n",
            "Loss:0.4918670058250427\n",
            "Loss:0.4914014935493469\n",
            "Loss:0.49093589186668396\n",
            "Loss:0.49047034978866577\n",
            "Loss:0.49000492691993713\n",
            "Epoch: 140 | Loss: 0.49000492691993713 | Test loss: 0.5106981992721558\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7423]])), ('linear_layer.bias', tensor([0.7730]))])\n",
            "Loss:0.48953932523727417\n",
            "Loss:0.48907381296157837\n",
            "Loss:0.48860830068588257\n",
            "Loss:0.48814281821250916\n",
            "Loss:0.48767727613449097\n",
            "Loss:0.48721176385879517\n",
            "Loss:0.48674625158309937\n",
            "Loss:0.48628073930740356\n",
            "Loss:0.4858151376247406\n",
            "Loss:0.4853496551513672\n",
            "Epoch: 150 | Loss: 0.4853496551513672 | Test loss: 0.5052550435066223\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7407]])), ('linear_layer.bias', tensor([0.7690]))])\n",
            "Loss:0.484884113073349\n",
            "Loss:0.4844186305999756\n",
            "Loss:0.4839530885219574\n",
            "Loss:0.4834875464439392\n",
            "Loss:0.4830220639705658\n",
            "Loss:0.4825565218925476\n",
            "Loss:0.4820910096168518\n",
            "Loss:0.481625497341156\n",
            "Loss:0.4811599850654602\n",
            "Loss:0.48069438338279724\n",
            "Epoch: 160 | Loss: 0.48069438338279724 | Test loss: 0.4998117983341217\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7392]])), ('linear_layer.bias', tensor([0.7650]))])\n",
            "Loss:0.48022890090942383\n",
            "Loss:0.4797634184360504\n",
            "Loss:0.4792978763580322\n",
            "Loss:0.4788323938846588\n",
            "Loss:0.47836679220199585\n",
            "Loss:0.47790130972862244\n",
            "Loss:0.47743576765060425\n",
            "Loss:0.47697028517723083\n",
            "Loss:0.47650471329689026\n",
            "Loss:0.47603923082351685\n",
            "Epoch: 170 | Loss: 0.47603923082351685 | Test loss: 0.49436864256858826\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7376]])), ('linear_layer.bias', tensor([0.7609]))])\n",
            "Loss:0.47557368874549866\n",
            "Loss:0.47510814666748047\n",
            "Loss:0.47464266419410706\n",
            "Loss:0.47417718172073364\n",
            "Loss:0.47371163964271545\n",
            "Loss:0.47324609756469727\n",
            "Loss:0.4727805554866791\n",
            "Loss:0.4723150134086609\n",
            "Loss:0.4718495309352875\n",
            "Loss:0.4713839590549469\n",
            "Epoch: 180 | Loss: 0.4713839590549469 | Test loss: 0.48892539739608765\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7360]])), ('linear_layer.bias', tensor([0.7569]))])\n",
            "Loss:0.4709184765815735\n",
            "Loss:0.4704529643058777\n",
            "Loss:0.4699874520301819\n",
            "Loss:0.4695219099521637\n",
            "Loss:0.4690564274787903\n",
            "Loss:0.4685908854007721\n",
            "Loss:0.4681253433227539\n",
            "Loss:0.4676598608493805\n",
            "Loss:0.4671943187713623\n",
            "Loss:0.4667288362979889\n",
            "Epoch: 190 | Loss: 0.4667288362979889 | Test loss: 0.4834822118282318\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7344]])), ('linear_layer.bias', tensor([0.7528]))])\n",
            "Loss:0.4662632942199707\n",
            "Loss:0.4657977223396301\n",
            "Loss:0.4653322100639343\n",
            "Loss:0.4648666977882385\n",
            "Loss:0.46440115571022034\n",
            "Loss:0.46393561363220215\n",
            "Loss:0.46347013115882874\n",
            "Loss:0.46300458908081055\n",
            "Loss:0.46253910660743713\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5868961811065674\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5547066330909729\n",
            "Loss:0.5542353391647339\n",
            "Loss:0.5537640452384949\n",
            "Loss:0.5532927513122559\n",
            "Loss:0.5528215169906616\n",
            "Loss:0.5523501634597778\n",
            "Loss:0.5518788695335388\n",
            "Loss:0.5514076352119446\n",
            "Loss:0.5509362816810608\n",
            "Loss:0.5504649877548218\n",
            "Epoch: 10 | Loss: 0.5504649877548218 | Test loss: 0.5813853740692139\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7628]])), ('linear_layer.bias', tensor([0.8255]))])\n",
            "Loss:0.549993634223938\n",
            "Loss:0.5495223999023438\n",
            "Loss:0.5490511059761047\n",
            "Loss:0.5485798120498657\n",
            "Loss:0.5481084585189819\n",
            "Loss:0.5476372838020325\n",
            "Loss:0.5471659302711487\n",
            "Loss:0.5466946363449097\n",
            "Loss:0.5462232828140259\n",
            "Loss:0.5457519888877869\n",
            "Epoch: 20 | Loss: 0.5457519888877869 | Test loss: 0.5758745670318604\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7612]])), ('linear_layer.bias', tensor([0.8214]))])\n",
            "Loss:0.5452808141708374\n",
            "Loss:0.5448094606399536\n",
            "Loss:0.5443381071090698\n",
            "Loss:0.5438668131828308\n",
            "Loss:0.5433955192565918\n",
            "Loss:0.5429242849349976\n",
            "Loss:0.5424529314041138\n",
            "Loss:0.54198157787323\n",
            "Loss:0.5415104031562805\n",
            "Loss:0.5410390496253967\n",
            "Epoch: 30 | Loss: 0.5410390496253967 | Test loss: 0.5703638195991516\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7596]])), ('linear_layer.bias', tensor([0.8173]))])\n",
            "Loss:0.5405677556991577\n",
            "Loss:0.5400964617729187\n",
            "Loss:0.5396251678466797\n",
            "Loss:0.5391539335250854\n",
            "Loss:0.5386825799942017\n",
            "Loss:0.5382112264633179\n",
            "Loss:0.5377399921417236\n",
            "Loss:0.5372686386108398\n",
            "Loss:0.5367974042892456\n",
            "Loss:0.5363260507583618\n",
            "Epoch: 40 | Loss: 0.5363260507583618 | Test loss: 0.5648530721664429\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7580]])), ('linear_layer.bias', tensor([0.8132]))])\n",
            "Loss:0.5358548164367676\n",
            "Loss:0.5353835821151733\n",
            "Loss:0.5349122285842896\n",
            "Loss:0.5344408750534058\n",
            "Loss:0.5339696407318115\n",
            "Loss:0.5334983468055725\n",
            "Loss:0.5330270528793335\n",
            "Loss:0.5325556993484497\n",
            "Loss:0.5320844650268555\n",
            "Loss:0.5316131114959717\n",
            "Epoch: 50 | Loss: 0.5316131114959717 | Test loss: 0.5593422651290894\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7564]])), ('linear_layer.bias', tensor([0.8091]))])\n",
            "Loss:0.5311418771743774\n",
            "Loss:0.5306705236434937\n",
            "Loss:0.5301992297172546\n",
            "Loss:0.5297279953956604\n",
            "Loss:0.5292566418647766\n",
            "Loss:0.5287853479385376\n",
            "Loss:0.5283141136169434\n",
            "Loss:0.5278428196907043\n",
            "Loss:0.5273715257644653\n",
            "Loss:0.5269001722335815\n",
            "Epoch: 60 | Loss: 0.5269001722335815 | Test loss: 0.5538315176963806\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7548]])), ('linear_layer.bias', tensor([0.8051]))])\n",
            "Loss:0.5264288783073425\n",
            "Loss:0.5259576439857483\n",
            "Loss:0.5254863500595093\n",
            "Loss:0.5250149965286255\n",
            "Loss:0.5245437622070312\n",
            "Loss:0.5240724086761475\n",
            "Loss:0.5236011147499084\n",
            "Loss:0.5231298208236694\n",
            "Loss:0.5226585268974304\n",
            "Loss:0.5221872329711914\n",
            "Epoch: 70 | Loss: 0.5221872329711914 | Test loss: 0.5483207106590271\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7532]])), ('linear_layer.bias', tensor([0.8010]))])\n",
            "Loss:0.5217159986495972\n",
            "Loss:0.5212446451187134\n",
            "Loss:0.5207734107971191\n",
            "Loss:0.5203020572662354\n",
            "Loss:0.5198307037353516\n",
            "Loss:0.5193594694137573\n",
            "Loss:0.5188881158828735\n",
            "Loss:0.5184168815612793\n",
            "Loss:0.5179455876350403\n",
            "Loss:0.5174742937088013\n",
            "Epoch: 80 | Loss: 0.5174742937088013 | Test loss: 0.5428100228309631\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7516]])), ('linear_layer.bias', tensor([0.7969]))])\n",
            "Loss:0.5170029401779175\n",
            "Loss:0.5165317058563232\n",
            "Loss:0.5160604119300842\n",
            "Loss:0.5155890583992004\n",
            "Loss:0.5151178240776062\n",
            "Loss:0.5146464705467224\n",
            "Loss:0.5141752362251282\n",
            "Loss:0.5137039422988892\n",
            "Loss:0.5132325887680054\n",
            "Loss:0.5127613544464111\n",
            "Epoch: 90 | Loss: 0.5127613544464111 | Test loss: 0.5372992753982544\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7500]])), ('linear_layer.bias', tensor([0.7928]))])\n",
            "Loss:0.5122900009155273\n",
            "Loss:0.5118187069892883\n",
            "Loss:0.5113474130630493\n",
            "Loss:0.5108761191368103\n",
            "Loss:0.5104048252105713\n",
            "Loss:0.509933590888977\n",
            "Loss:0.5094622373580933\n",
            "Loss:0.5089909434318542\n",
            "Loss:0.5085196495056152\n",
            "Loss:0.5080483555793762\n",
            "Epoch: 100 | Loss: 0.5080483555793762 | Test loss: 0.5317885279655457\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7484]])), ('linear_layer.bias', tensor([0.7887]))])\n",
            "Loss:0.507577121257782\n",
            "Loss:0.5071057677268982\n",
            "Loss:0.5066344738006592\n",
            "Loss:0.5061631202697754\n",
            "Loss:0.5056918859481812\n",
            "Loss:0.5052205920219421\n",
            "Loss:0.5047492980957031\n",
            "Loss:0.5042780041694641\n",
            "Loss:0.5038067102432251\n",
            "Loss:0.5033354163169861\n",
            "Epoch: 110 | Loss: 0.5033354163169861 | Test loss: 0.5262776613235474\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7468]])), ('linear_layer.bias', tensor([0.7846]))])\n",
            "Loss:0.5028641223907471\n",
            "Loss:0.5023927688598633\n",
            "Loss:0.501921534538269\n",
            "Loss:0.50145024061203\n",
            "Loss:0.500978946685791\n",
            "Loss:0.5005075931549072\n",
            "Loss:0.500036358833313\n",
            "Loss:0.499565064907074\n",
            "Loss:0.49909377098083496\n",
            "Loss:0.49862247705459595\n",
            "Epoch: 120 | Loss: 0.49862247705459595 | Test loss: 0.5207669138908386\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7452]])), ('linear_layer.bias', tensor([0.7805]))])\n",
            "Loss:0.49815112352371216\n",
            "Loss:0.4976798892021179\n",
            "Loss:0.4972085952758789\n",
            "Loss:0.4967372417449951\n",
            "Loss:0.4962659478187561\n",
            "Loss:0.4957946836948395\n",
            "Loss:0.4953233599662781\n",
            "Loss:0.49485206604003906\n",
            "Loss:0.49438077211380005\n",
            "Loss:0.4939095079898834\n",
            "Epoch: 130 | Loss: 0.4939095079898834 | Test loss: 0.5152561664581299\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7436]])), ('linear_layer.bias', tensor([0.7764]))])\n",
            "Loss:0.493438184261322\n",
            "Loss:0.492966890335083\n",
            "Loss:0.4924955368041992\n",
            "Loss:0.49202433228492737\n",
            "Loss:0.49155306816101074\n",
            "Loss:0.49108171463012695\n",
            "Loss:0.49061042070388794\n",
            "Loss:0.49013909697532654\n",
            "Loss:0.4896678328514099\n",
            "Loss:0.4891965389251709\n",
            "Epoch: 140 | Loss: 0.4891965389251709 | Test loss: 0.5097454190254211\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7420]])), ('linear_layer.bias', tensor([0.7723]))])\n",
            "Loss:0.4887252449989319\n",
            "Loss:0.48825398087501526\n",
            "Loss:0.48778262734413147\n",
            "Loss:0.48731136322021484\n",
            "Loss:0.48684006929397583\n",
            "Loss:0.4863688051700592\n",
            "Loss:0.4858974814414978\n",
            "Loss:0.4854261875152588\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%| | 82/100 [00:25<00:05,  3.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.4849548935890198\n",
            "Loss:0.48448362946510315\n",
            "Epoch: 150 | Loss: 0.48448362946510315 | Test loss: 0.5042346715927124\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7404]])), ('linear_layer.bias', tensor([0.7682]))])\n",
            "Loss:0.48401230573654175\n",
            "Loss:0.48354101181030273\n",
            "Loss:0.4830697178840637\n",
            "Loss:0.4825983941555023\n",
            "Loss:0.4821271300315857\n",
            "Loss:0.4816557765007019\n",
            "Loss:0.4811844825744629\n",
            "Loss:0.48071327805519104\n",
            "Loss:0.48024192452430725\n",
            "Loss:0.47977060079574585\n",
            "Epoch: 160 | Loss: 0.47977060079574585 | Test loss: 0.4987238347530365\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7388]])), ('linear_layer.bias', tensor([0.7641]))])\n",
            "Loss:0.47929930686950684\n",
            "Loss:0.47882795333862305\n",
            "Loss:0.4783567488193512\n",
            "Loss:0.4778854250907898\n",
            "Loss:0.477414071559906\n",
            "Loss:0.47694283723831177\n",
            "Loss:0.47647157311439514\n",
            "Loss:0.47600024938583374\n",
            "Loss:0.4755289554595947\n",
            "Loss:0.4750576913356781\n",
            "Epoch: 170 | Loss: 0.4750576913356781 | Test loss: 0.49321311712265015\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7373]])), ('linear_layer.bias', tensor([0.7601]))])\n",
            "Loss:0.4745863974094391\n",
            "Loss:0.4741150736808777\n",
            "Loss:0.47364377975463867\n",
            "Loss:0.47317248582839966\n",
            "Loss:0.47270116209983826\n",
            "Loss:0.47222989797592163\n",
            "Loss:0.47175854444503784\n",
            "Loss:0.47128725051879883\n",
            "Loss:0.470816045999527\n",
            "Loss:0.4703446924686432\n",
            "Epoch: 180 | Loss: 0.4703446924686432 | Test loss: 0.4877023696899414\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7357]])), ('linear_layer.bias', tensor([0.7560]))])\n",
            "Loss:0.46987342834472656\n",
            "Loss:0.46940213441848755\n",
            "Loss:0.46893081068992615\n",
            "Loss:0.46845951676368713\n",
            "Loss:0.46798819303512573\n",
            "Loss:0.4675169885158539\n",
            "Loss:0.4670456349849701\n",
            "Loss:0.4665743410587311\n",
            "Loss:0.4661030173301697\n",
            "Loss:0.46563178300857544\n",
            "Epoch: 190 | Loss: 0.46563178300857544 | Test loss: 0.48219162225723267\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7341]])), ('linear_layer.bias', tensor([0.7519]))])\n",
            "Loss:0.46516045928001404\n",
            "Loss:0.464689165353775\n",
            "Loss:0.4642178416252136\n",
            "Loss:0.4637465476989746\n",
            "Loss:0.463275283575058\n",
            "Loss:0.46280398964881897\n",
            "Loss:0.4623326361179352\n",
            "Loss:0.46186143159866333\n",
            "Loss:0.46139010787010193\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5868892669677734\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5547007918357849\n",
            "Loss:0.5542237162590027\n",
            "Loss:0.5537465214729309\n",
            "Loss:0.5532694458961487\n",
            "Loss:0.5527922511100769\n",
            "Loss:0.5523151755332947\n",
            "Loss:0.5518380403518677\n",
            "Loss:0.5513609051704407\n",
            "Loss:0.5508837699890137\n",
            "Loss:0.5504066348075867\n",
            "Epoch: 10 | Loss: 0.5504066348075867 | Test loss: 0.5813103914260864\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7628]])), ('linear_layer.bias', tensor([0.8255]))])\n",
            "Loss:0.5499294996261597\n",
            "Loss:0.5494524240493774\n",
            "Loss:0.5489752292633057\n",
            "Loss:0.5484981536865234\n",
            "Loss:0.5480210185050964\n",
            "Loss:0.5475438833236694\n",
            "Loss:0.5470668077468872\n",
            "Loss:0.5465895533561707\n",
            "Loss:0.5461124181747437\n",
            "Loss:0.5456353425979614\n",
            "Epoch: 20 | Loss: 0.5456353425979614 | Test loss: 0.5757314562797546\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7611]])), ('linear_layer.bias', tensor([0.8213]))])\n",
            "Loss:0.5451582074165344\n",
            "Loss:0.5446810722351074\n",
            "Loss:0.5442039370536804\n",
            "Loss:0.5437268018722534\n",
            "Loss:0.5432497262954712\n",
            "Loss:0.5427725911140442\n",
            "Loss:0.5422954559326172\n",
            "Loss:0.5418183207511902\n",
            "Loss:0.5413411855697632\n",
            "Loss:0.5408640503883362\n",
            "Epoch: 30 | Loss: 0.5408640503883362 | Test loss: 0.5701525211334229\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7595]])), ('linear_layer.bias', tensor([0.8172]))])\n",
            "Loss:0.540386974811554\n",
            "Loss:0.539909839630127\n",
            "Loss:0.5394326448440552\n",
            "Loss:0.538955569267273\n",
            "Loss:0.5384783744812012\n",
            "Loss:0.538001298904419\n",
            "Loss:0.5375241041183472\n",
            "Loss:0.5370470285415649\n",
            "Loss:0.5365698933601379\n",
            "Loss:0.5360926985740662\n",
            "Epoch: 40 | Loss: 0.5360926985740662 | Test loss: 0.5645735263824463\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7579]])), ('linear_layer.bias', tensor([0.8130]))])\n",
            "Loss:0.5356155633926392\n",
            "Loss:0.5351384878158569\n",
            "Loss:0.5346613526344299\n",
            "Loss:0.5341842770576477\n",
            "Loss:0.5337070822715759\n",
            "Loss:0.5332300066947937\n",
            "Loss:0.5327528715133667\n",
            "Loss:0.5322757363319397\n",
            "Loss:0.5317986607551575\n",
            "Loss:0.5313214659690857\n",
            "Epoch: 50 | Loss: 0.5313214659690857 | Test loss: 0.5589946508407593\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7563]])), ('linear_layer.bias', tensor([0.8089]))])\n",
            "Loss:0.5308443307876587\n",
            "Loss:0.5303671956062317\n",
            "Loss:0.5298900604248047\n",
            "Loss:0.5294129252433777\n",
            "Loss:0.5289357900619507\n",
            "Loss:0.5284587144851685\n",
            "Loss:0.5279815793037415\n",
            "Loss:0.5275044441223145\n",
            "Loss:0.5270273089408875\n",
            "Loss:0.5265501737594604\n",
            "Epoch: 60 | Loss: 0.5265501737594604 | Test loss: 0.5534157156944275\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7547]])), ('linear_layer.bias', tensor([0.8047]))])\n",
            "Loss:0.5260730981826782\n",
            "Loss:0.5255959630012512\n",
            "Loss:0.5251188278198242\n",
            "Loss:0.5246416926383972\n",
            "Loss:0.5241645574569702\n",
            "Loss:0.5236874222755432\n",
            "Loss:0.5232102274894714\n",
            "Loss:0.5227331519126892\n",
            "Loss:0.5222560167312622\n",
            "Loss:0.5217788815498352\n",
            "Epoch: 70 | Loss: 0.5217788815498352 | Test loss: 0.5478367805480957\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7531]])), ('linear_layer.bias', tensor([0.8006]))])\n",
            "Loss:0.521301805973053\n",
            "Loss:0.5208246111869812\n",
            "Loss:0.5203474760055542\n",
            "Loss:0.5198703408241272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%| | 83/100 [00:25<00:05,  3.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.519393265247345\n",
            "Loss:0.518916130065918\n",
            "Loss:0.518438994884491\n",
            "Loss:0.517961859703064\n",
            "Loss:0.5174846649169922\n",
            "Loss:0.51700758934021\n",
            "Epoch: 80 | Loss: 0.51700758934021 | Test loss: 0.5422577857971191\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7515]])), ('linear_layer.bias', tensor([0.7965]))])\n",
            "Loss:0.516530454158783\n",
            "Loss:0.516053318977356\n",
            "Loss:0.5155762434005737\n",
            "Loss:0.515099048614502\n",
            "Loss:0.514621913433075\n",
            "Loss:0.514144778251648\n",
            "Loss:0.5136677026748657\n",
            "Loss:0.5131905674934387\n",
            "Loss:0.5127134323120117\n",
            "Loss:0.5122362971305847\n",
            "Epoch: 90 | Loss: 0.5122362971305847 | Test loss: 0.5366789102554321\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7498]])), ('linear_layer.bias', tensor([0.7923]))])\n",
            "Loss:0.5117591619491577\n",
            "Loss:0.5112820267677307\n",
            "Loss:0.5108049511909485\n",
            "Loss:0.5103277564048767\n",
            "Loss:0.5098506212234497\n",
            "Loss:0.5093735456466675\n",
            "Loss:0.5088964104652405\n",
            "Loss:0.5084192752838135\n",
            "Loss:0.5079420804977417\n",
            "Loss:0.5074650049209595\n",
            "Epoch: 100 | Loss: 0.5074650049209595 | Test loss: 0.5310999751091003\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7482]])), ('linear_layer.bias', tensor([0.7882]))])\n",
            "Loss:0.5069879293441772\n",
            "Loss:0.5065107345581055\n",
            "Loss:0.5060336589813232\n",
            "Loss:0.5055564641952515\n",
            "Loss:0.5050793886184692\n",
            "Loss:0.5046022534370422\n",
            "Loss:0.5041251182556152\n",
            "Loss:0.5036479830741882\n",
            "Loss:0.5031708478927612\n",
            "Loss:0.502693772315979\n",
            "Epoch: 110 | Loss: 0.502693772315979 | Test loss: 0.5255210399627686\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7466]])), ('linear_layer.bias', tensor([0.7840]))])\n",
            "Loss:0.502216637134552\n",
            "Loss:0.5017394423484802\n",
            "Loss:0.5012623071670532\n",
            "Loss:0.500785231590271\n",
            "Loss:0.500308096408844\n",
            "Loss:0.4998309016227722\n",
            "Loss:0.4993537962436676\n",
            "Loss:0.4988767206668854\n",
            "Loss:0.498399555683136\n",
            "Loss:0.497922420501709\n",
            "Epoch: 120 | Loss: 0.497922420501709 | Test loss: 0.519942045211792\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7450]])), ('linear_layer.bias', tensor([0.7799]))])\n",
            "Loss:0.497445285320282\n",
            "Loss:0.49696817994117737\n",
            "Loss:0.49649104475975037\n",
            "Loss:0.49601393938064575\n",
            "Loss:0.49553680419921875\n",
            "Loss:0.49505963921546936\n",
            "Loss:0.49458250403404236\n",
            "Loss:0.49410542845726013\n",
            "Loss:0.49362826347351074\n",
            "Loss:0.49315112829208374\n",
            "Epoch: 130 | Loss: 0.49315112829208374 | Test loss: 0.514363169670105\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7434]])), ('linear_layer.bias', tensor([0.7758]))])\n",
            "Loss:0.49267396330833435\n",
            "Loss:0.4921968877315521\n",
            "Loss:0.49171972274780273\n",
            "Loss:0.4912426471710205\n",
            "Loss:0.4907655119895935\n",
            "Loss:0.4902883470058441\n",
            "Loss:0.4898112416267395\n",
            "Loss:0.4893341064453125\n",
            "Loss:0.4888569712638855\n",
            "Loss:0.4883798658847809\n",
            "Epoch: 140 | Loss: 0.4883798658847809 | Test loss: 0.5087842345237732\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7418]])), ('linear_layer.bias', tensor([0.7716]))])\n",
            "Loss:0.4879027009010315\n",
            "Loss:0.48742562532424927\n",
            "Loss:0.48694849014282227\n",
            "Loss:0.4864713251590729\n",
            "Loss:0.4859941899776459\n",
            "Loss:0.48551708459854126\n",
            "Loss:0.48503994941711426\n",
            "Loss:0.48456278443336487\n",
            "Loss:0.48408564925193787\n",
            "Loss:0.48360854387283325\n",
            "Epoch: 150 | Loss: 0.48360854387283325 | Test loss: 0.5032052993774414\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7401]])), ('linear_layer.bias', tensor([0.7675]))])\n",
            "Loss:0.48313140869140625\n",
            "Loss:0.48265427350997925\n",
            "Loss:0.48217710852622986\n",
            "Loss:0.48170003294944763\n",
            "Loss:0.481222927570343\n",
            "Loss:0.480745792388916\n",
            "Loss:0.480268657207489\n",
            "Loss:0.4797914922237396\n",
            "Loss:0.479314386844635\n",
            "Loss:0.4788373112678528\n",
            "Epoch: 160 | Loss: 0.4788373112678528 | Test loss: 0.49762630462646484\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7385]])), ('linear_layer.bias', tensor([0.7633]))])\n",
            "Loss:0.478360116481781\n",
            "Loss:0.4778830111026764\n",
            "Loss:0.477405846118927\n",
            "Loss:0.4769287705421448\n",
            "Loss:0.476451575756073\n",
            "Loss:0.47597450017929077\n",
            "Loss:0.4754973351955414\n",
            "Loss:0.47502022981643677\n",
            "Loss:0.47454309463500977\n",
            "Loss:0.47406595945358276\n",
            "Epoch: 170 | Loss: 0.47406595945358276 | Test loss: 0.49204739928245544\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7369]])), ('linear_layer.bias', tensor([0.7592]))])\n",
            "Loss:0.47358885407447815\n",
            "Loss:0.47311168909072876\n",
            "Loss:0.47263455390930176\n",
            "Loss:0.47215747833251953\n",
            "Loss:0.47168034315109253\n",
            "Loss:0.47120317816734314\n",
            "Loss:0.4707261025905609\n",
            "Loss:0.4702489376068115\n",
            "Loss:0.4697718024253845\n",
            "Loss:0.4692947268486023\n",
            "Epoch: 180 | Loss: 0.4692947268486023 | Test loss: 0.48646849393844604\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7353]])), ('linear_layer.bias', tensor([0.7550]))])\n",
            "Loss:0.4688175320625305\n",
            "Loss:0.4683404564857483\n",
            "Loss:0.4678632616996765\n",
            "Loss:0.4673861563205719\n",
            "Loss:0.4669089913368225\n",
            "Loss:0.4664319157600403\n",
            "Loss:0.4659547805786133\n",
            "Loss:0.4654776155948639\n",
            "Loss:0.46500054001808167\n",
            "Loss:0.4645233750343323\n",
            "Epoch: 190 | Loss: 0.4645233750343323 | Test loss: 0.48088955879211426\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7337]])), ('linear_layer.bias', tensor([0.7509]))])\n",
            "Loss:0.46404629945755005\n",
            "Loss:0.46356916427612305\n",
            "Loss:0.4630919396877289\n",
            "Loss:0.46261486411094666\n",
            "Loss:0.46213769912719727\n",
            "Loss:0.46166062355041504\n",
            "Loss:0.46118345856666565\n",
            "Loss:0.4607063829898834\n",
            "Loss:0.4602292478084564\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.586882472038269\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5546949505805969\n",
            "Loss:0.5542119741439819\n",
            "Loss:0.5537289977073669\n",
            "Loss:0.5532460808753967\n",
            "Loss:0.5527631044387817\n",
            "Loss:0.5522801280021667\n",
            "Loss:0.5517972111701965\n",
            "Loss:0.5513142347335815\n",
            "Loss:0.5508311986923218\n",
            "Loss:0.5503483414649963\n",
            "Epoch: 10 | Loss: 0.5503483414649963 | Test loss: 0.581235408782959\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7627]])), ('linear_layer.bias', tensor([0.8254]))])\n",
            "Loss:0.5498653650283813\n",
            "Loss:0.5493823885917664\n",
            "Loss:0.5488994717597961\n",
            "Loss:0.5484164953231812\n",
            "Loss:0.5479334592819214\n",
            "Loss:0.5474505424499512\n",
            "Loss:0.546967625617981\n",
            "Loss:0.546484649181366\n",
            "Loss:0.5460015535354614\n",
            "Loss:0.545518696308136\n",
            "Epoch: 20 | Loss: 0.545518696308136 | Test loss: 0.5755882859230042\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7611]])), ('linear_layer.bias', tensor([0.8212]))])\n",
            "Loss:0.545035719871521\n",
            "Loss:0.544552743434906\n",
            "Loss:0.5440698266029358\n",
            "Loss:0.5435868501663208\n",
            "Loss:0.543103814125061\n",
            "Loss:0.5426208972930908\n",
            "Loss:0.5421379208564758\n",
            "Loss:0.5416549444198608\n",
            "Loss:0.5411720275878906\n",
            "Loss:0.5406890511512756\n",
            "Epoch: 30 | Loss: 0.5406890511512756 | Test loss: 0.5699412226676941\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7595]])), ('linear_layer.bias', tensor([0.8170]))])\n",
            "Loss:0.5402061343193054\n",
            "Loss:0.5397230982780457\n",
            "Loss:0.5392402410507202\n",
            "Loss:0.5387572050094604\n",
            "Loss:0.5382742881774902\n",
            "Loss:0.5377912521362305\n",
            "Loss:0.5373083353042603\n",
            "Loss:0.5368252992630005\n",
            "Loss:0.5363423824310303\n",
            "Loss:0.5358593463897705\n",
            "Epoch: 40 | Loss: 0.5358593463897705 | Test loss: 0.5642940998077393\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7578]])), ('linear_layer.bias', tensor([0.8128]))])\n",
            "Loss:0.5353764295578003\n",
            "Loss:0.5348934531211853\n",
            "Loss:0.5344105958938599\n",
            "Loss:0.5339275598526001\n",
            "Loss:0.5334445834159851\n",
            "Loss:0.5329616665840149\n",
            "Loss:0.5324786901473999\n",
            "Loss:0.5319957137107849\n",
            "Loss:0.5315127968788147\n",
            "Loss:0.5310298204421997\n",
            "Epoch: 50 | Loss: 0.5310298204421997 | Test loss: 0.5586470365524292\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7562]])), ('linear_layer.bias', tensor([0.8086]))])\n",
            "Loss:0.5305468440055847\n",
            "Loss:0.5300638675689697\n",
            "Loss:0.5295808911323547\n",
            "Loss:0.5290979146957397\n",
            "Loss:0.5286149382591248\n",
            "Loss:0.5281320214271545\n",
            "Loss:0.5276490449905396\n",
            "Loss:0.5271660685539246\n",
            "Loss:0.5266830921173096\n",
            "Loss:0.5262001752853394\n",
            "Epoch: 60 | Loss: 0.5262001752853394 | Test loss: 0.5529998540878296\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7546]])), ('linear_layer.bias', tensor([0.8044]))])\n",
            "Loss:0.5257171988487244\n",
            "Loss:0.5252342820167542\n",
            "Loss:0.5247513055801392\n",
            "Loss:0.5242683291435242\n",
            "Loss:0.523785412311554\n",
            "Loss:0.523302435874939\n",
            "Loss:0.5228193998336792\n",
            "Loss:0.522336483001709\n",
            "Loss:0.521853506565094\n",
            "Loss:0.521370530128479\n",
            "Epoch: 70 | Loss: 0.521370530128479 | Test loss: 0.5473527908325195\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7529]])), ('linear_layer.bias', tensor([0.8002]))])\n",
            "Loss:0.520887553691864\n",
            "Loss:0.5204046368598938\n",
            "Loss:0.5199216604232788\n",
            "Loss:0.5194386839866638\n",
            "Loss:0.5189557075500488\n",
            "Loss:0.5184727311134338\n",
            "Loss:0.5179898142814636\n",
            "Loss:0.5175068378448486\n",
            "Loss:0.5170238614082336\n",
            "Loss:0.5165408849716187\n",
            "Epoch: 80 | Loss: 0.5165408849716187 | Test loss: 0.5417057275772095\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7513]])), ('linear_layer.bias', tensor([0.7961]))])\n",
            "Loss:0.5160579681396484\n",
            "Loss:0.5155749917030334\n",
            "Loss:0.5150920152664185\n",
            "Loss:0.5146090388298035\n",
            "Loss:0.5141261219978333\n",
            "Loss:0.5136430859565735\n",
            "Loss:0.5131601095199585\n",
            "Loss:0.5126771330833435\n",
            "Loss:0.5121942758560181\n",
            "Loss:0.5117112398147583\n",
            "Epoch: 90 | Loss: 0.5117112398147583 | Test loss: 0.5360585451126099\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7497]])), ('linear_layer.bias', tensor([0.7919]))])\n",
            "Loss:0.5112283229827881\n",
            "Loss:0.5107453465461731\n",
            "Loss:0.5102623701095581\n",
            "Loss:0.5097794532775879\n",
            "Loss:0.5092964768409729\n",
            "Loss:0.5088135004043579\n",
            "Loss:0.5083305835723877\n",
            "Loss:0.5078476667404175\n",
            "Loss:0.5073646306991577\n",
            "Loss:0.506881594657898\n",
            "Epoch: 100 | Loss: 0.506881594657898 | Test loss: 0.530411422252655\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7480]])), ('linear_layer.bias', tensor([0.7877]))])\n",
            "Loss:0.5063986778259277\n",
            "Loss:0.5059157609939575\n",
            "Loss:0.5054327249526978\n",
            "Loss:0.5049497485160828\n",
            "Loss:0.5044668912887573\n",
            "Loss:0.5039838552474976\n",
            "Loss:0.5035009384155273\n",
            "Loss:0.5030179619789124\n",
            "Loss:0.5025349855422974\n",
            "Loss:0.5020520091056824\n",
            "Epoch: 110 | Loss: 0.5020520091056824 | Test loss: 0.5247644186019897\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7464]])), ('linear_layer.bias', tensor([0.7835]))])\n",
            "Loss:0.5015690922737122\n",
            "Loss:0.5010861158370972\n",
            "Loss:0.5006031394004822\n",
            "Loss:0.5001201629638672\n",
            "Loss:0.4996372163295746\n",
            "Loss:0.499154269695282\n",
            "Loss:0.49867135286331177\n",
            "Loss:0.498188316822052\n",
            "Loss:0.4977053701877594\n",
            "Loss:0.49722233414649963\n",
            "Epoch: 120 | Loss: 0.49722233414649963 | Test loss: 0.5191172361373901\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7448]])), ('linear_layer.bias', tensor([0.7793]))])\n",
            "Loss:0.4967394471168518\n",
            "Loss:0.49625644087791443\n",
            "Loss:0.4957734942436218\n",
            "Loss:0.49529051780700684\n",
            "Loss:0.49480757117271423\n",
            "Loss:0.49432462453842163\n",
            "Loss:0.4938417077064514\n",
            "Loss:0.49335870146751404\n",
            "Loss:0.49287575483322144\n",
            "Loss:0.49239271879196167\n",
            "Epoch: 130 | Loss: 0.49239271879196167 | Test loss: 0.5134701132774353\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7431]])), ('linear_layer.bias', tensor([0.7751]))])\n",
            "Loss:0.49190983176231384\n",
            "Loss:0.49142685532569885\n",
            "Loss:0.490943968296051\n",
            "Loss:0.4904608726501465\n",
            "Loss:0.48997798562049866\n",
            "Loss:0.4894949793815613\n",
            "Loss:0.48901206254959106\n",
            "Loss:0.48852911591529846\n",
            "Loss:0.4880461096763611\n",
            "Loss:0.4875631332397461\n",
            "Epoch: 140 | Loss: 0.4875631332397461 | Test loss: 0.5078229904174805\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7415]])), ('linear_layer.bias', tensor([0.7709]))])\n",
            "Loss:0.4870801866054535\n",
            "Loss:0.4865972399711609\n",
            "Loss:0.4861142635345459\n",
            "Loss:0.4856313169002533\n",
            "Loss:0.4851483404636383\n",
            "Loss:0.4846653342247009\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 84%| | 84/100 [00:26<00:05,  3.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.4841824173927307\n",
            "Loss:0.4836994707584381\n",
            "Loss:0.4832165241241455\n",
            "Loss:0.4827335476875305\n",
            "Epoch: 150 | Loss: 0.4827335476875305 | Test loss: 0.5021759271621704\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7399]])), ('linear_layer.bias', tensor([0.7667]))])\n",
            "Loss:0.4822506010532379\n",
            "Loss:0.4817676544189453\n",
            "Loss:0.48128461837768555\n",
            "Loss:0.48080167174339294\n",
            "Loss:0.4803186357021332\n",
            "Loss:0.47983574867248535\n",
            "Loss:0.47935277223587036\n",
            "Loss:0.47886982560157776\n",
            "Loss:0.47838687896728516\n",
            "Loss:0.47790390253067017\n",
            "Epoch: 160 | Loss: 0.47790390253067017 | Test loss: 0.4965288043022156\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7382]])), ('linear_layer.bias', tensor([0.7625]))])\n",
            "Loss:0.4774208962917328\n",
            "Loss:0.47693800926208496\n",
            "Loss:0.47645503282546997\n",
            "Loss:0.4759720265865326\n",
            "Loss:0.47548907995224\n",
            "Loss:0.4750061631202698\n",
            "Loss:0.4745232164859772\n",
            "Loss:0.4740402102470398\n",
            "Loss:0.4735572934150696\n",
            "Loss:0.4730742573738098\n",
            "Epoch: 170 | Loss: 0.4730742573738098 | Test loss: 0.49088168144226074\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7366]])), ('linear_layer.bias', tensor([0.7583]))])\n",
            "Loss:0.4725913107395172\n",
            "Loss:0.47210830450057983\n",
            "Loss:0.471625417470932\n",
            "Loss:0.47114238142967224\n",
            "Loss:0.47065940499305725\n",
            "Loss:0.4701765179634094\n",
            "Loss:0.46969351172447205\n",
            "Loss:0.46921056509017944\n",
            "Loss:0.46872758865356445\n",
            "Loss:0.46824464201927185\n",
            "Epoch: 180 | Loss: 0.46824464201927185 | Test loss: 0.4852345883846283\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7349]])), ('linear_layer.bias', tensor([0.7541]))])\n",
            "Loss:0.46776166558265686\n",
            "Loss:0.4672786593437195\n",
            "Loss:0.46679577231407166\n",
            "Loss:0.46631282567977905\n",
            "Loss:0.46582984924316406\n",
            "Loss:0.4653468132019043\n",
            "Loss:0.46486395597457886\n",
            "Loss:0.4643809199333191\n",
            "Loss:0.4638979434967041\n",
            "Loss:0.4634149670600891\n",
            "Epoch: 190 | Loss: 0.4634149670600891 | Test loss: 0.47958746552467346\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7333]])), ('linear_layer.bias', tensor([0.7499]))])\n",
            "Loss:0.4629320502281189\n",
            "Loss:0.4624490737915039\n",
            "Loss:0.4619661271572113\n",
            "Loss:0.4614831805229187\n",
            "Loss:0.4610002040863037\n",
            "Loss:0.4605172276496887\n",
            "Loss:0.4600343108177185\n",
            "Loss:0.4595513343811035\n",
            "Loss:0.4590683579444885\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5868756771087646\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5546891689300537\n",
            "Loss:0.5542003512382507\n",
            "Loss:0.5537115335464478\n",
            "Loss:0.5532227754592896\n",
            "Loss:0.5527339577674866\n",
            "Loss:0.5522451400756836\n",
            "Loss:0.5517562627792358\n",
            "Loss:0.5512675642967224\n",
            "Loss:0.5507787466049194\n",
            "Loss:0.5502899289131165\n",
            "Epoch: 10 | Loss: 0.5502899289131165 | Test loss: 0.5811603665351868\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7627]])), ('linear_layer.bias', tensor([0.8253]))])\n",
            "Loss:0.5498011708259583\n",
            "Loss:0.5493123531341553\n",
            "Loss:0.5488235354423523\n",
            "Loss:0.5483347773551941\n",
            "Loss:0.5478459596633911\n",
            "Loss:0.5473572015762329\n",
            "Loss:0.5468683242797852\n",
            "Loss:0.5463796257972717\n",
            "Loss:0.5458908081054688\n",
            "Loss:0.5454019904136658\n",
            "Epoch: 20 | Loss: 0.5454019904136658 | Test loss: 0.5754451751708984\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7611]])), ('linear_layer.bias', tensor([0.8211]))])\n",
            "Loss:0.5449131727218628\n",
            "Loss:0.5444244146347046\n",
            "Loss:0.5439356565475464\n",
            "Loss:0.5434468388557434\n",
            "Loss:0.5429580807685852\n",
            "Loss:0.5424692630767822\n",
            "Loss:0.5419803857803345\n",
            "Loss:0.541491687297821\n",
            "Loss:0.5410028696060181\n",
            "Loss:0.5405140519142151\n",
            "Epoch: 30 | Loss: 0.5405140519142151 | Test loss: 0.5697298645973206\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7594]])), ('linear_layer.bias', tensor([0.8169]))])\n",
            "Loss:0.5400252342224121\n",
            "Loss:0.5395364761352539\n",
            "Loss:0.5390476584434509\n",
            "Loss:0.538558840751648\n",
            "Loss:0.538070023059845\n",
            "Loss:0.5375813245773315\n",
            "Loss:0.5370924472808838\n",
            "Loss:0.5366037487983704\n",
            "Loss:0.5361148715019226\n",
            "Loss:0.5356260538101196\n",
            "Epoch: 40 | Loss: 0.5356260538101196 | Test loss: 0.5640146136283875\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7578]])), ('linear_layer.bias', tensor([0.8126]))])\n",
            "Loss:0.5351372361183167\n",
            "Loss:0.5346484184265137\n",
            "Loss:0.5341597199440002\n",
            "Loss:0.5336708426475525\n",
            "Loss:0.5331820845603943\n",
            "Loss:0.5326932668685913\n",
            "Loss:0.5322045087814331\n",
            "Loss:0.5317156910896301\n",
            "Loss:0.5312269926071167\n",
            "Loss:0.530738115310669\n",
            "Epoch: 50 | Loss: 0.530738115310669 | Test loss: 0.5582993030548096\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7561]])), ('linear_layer.bias', tensor([0.8084]))])\n",
            "Loss:0.530249297618866\n",
            "Loss:0.529760479927063\n",
            "Loss:0.5292717218399048\n",
            "Loss:0.5287829637527466\n",
            "Loss:0.5282941460609436\n",
            "Loss:0.5278053879737854\n",
            "Loss:0.5273165106773376\n",
            "Loss:0.5268277525901794\n",
            "Loss:0.5263389348983765\n",
            "Loss:0.5258501768112183\n",
            "Epoch: 60 | Loss: 0.5258501768112183 | Test loss: 0.5525840520858765\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7544]])), ('linear_layer.bias', tensor([0.8041]))])\n",
            "Loss:0.5253613591194153\n",
            "Loss:0.5248726010322571\n",
            "Loss:0.5243837237358093\n",
            "Loss:0.5238949656486511\n",
            "Loss:0.5234061479568481\n",
            "Loss:0.5229173898696899\n",
            "Loss:0.5224286317825317\n",
            "Loss:0.5219398140907288\n",
            "Loss:0.521450936794281\n",
            "Loss:0.5209621787071228\n",
            "Epoch: 70 | Loss: 0.5209621787071228 | Test loss: 0.5468686819076538\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7528]])), ('linear_layer.bias', tensor([0.7999]))])\n",
            "Loss:0.5204733610153198\n",
            "Loss:0.5199846029281616\n",
            "Loss:0.5194957852363586\n",
            "Loss:0.5190070271492004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 85%| | 85/100 [00:26<00:04,  3.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5185182094573975\n",
            "Loss:0.5180293917655945\n",
            "Loss:0.5175406336784363\n",
            "Loss:0.5170518159866333\n",
            "Loss:0.5165630578994751\n",
            "Loss:0.5160742998123169\n",
            "Epoch: 80 | Loss: 0.5160742998123169 | Test loss: 0.5411534905433655\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7511]])), ('linear_layer.bias', tensor([0.7956]))])\n",
            "Loss:0.5155854821205139\n",
            "Loss:0.5150966048240662\n",
            "Loss:0.514607846736908\n",
            "Loss:0.514119029045105\n",
            "Loss:0.5136302709579468\n",
            "Loss:0.5131414532661438\n",
            "Loss:0.5126526951789856\n",
            "Loss:0.5121638774871826\n",
            "Loss:0.5116750597953796\n",
            "Loss:0.5111862421035767\n",
            "Epoch: 90 | Loss: 0.5111862421035767 | Test loss: 0.5354382395744324\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7495]])), ('linear_layer.bias', tensor([0.7914]))])\n",
            "Loss:0.5106974840164185\n",
            "Loss:0.5102086663246155\n",
            "Loss:0.5097199082374573\n",
            "Loss:0.5092310905456543\n",
            "Loss:0.5087422728538513\n",
            "Loss:0.5082534551620483\n",
            "Loss:0.5077646970748901\n",
            "Loss:0.5072759389877319\n",
            "Loss:0.5067871809005737\n",
            "Loss:0.506298303604126\n",
            "Epoch: 100 | Loss: 0.506298303604126 | Test loss: 0.5297228693962097\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7478]])), ('linear_layer.bias', tensor([0.7872]))])\n",
            "Loss:0.5058095455169678\n",
            "Loss:0.5053207278251648\n",
            "Loss:0.5048319101333618\n",
            "Loss:0.5043431520462036\n",
            "Loss:0.5038543343544006\n",
            "Loss:0.5033655166625977\n",
            "Loss:0.5028766989707947\n",
            "Loss:0.5023878812789917\n",
            "Loss:0.5018991231918335\n",
            "Loss:0.5014103651046753\n",
            "Epoch: 110 | Loss: 0.5014103651046753 | Test loss: 0.5240076780319214\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7462]])), ('linear_layer.bias', tensor([0.7829]))])\n",
            "Loss:0.5009215474128723\n",
            "Loss:0.5004327893257141\n",
            "Loss:0.49994397163391113\n",
            "Loss:0.49945515394210815\n",
            "Loss:0.49896639585494995\n",
            "Loss:0.4984775483608246\n",
            "Loss:0.497988760471344\n",
            "Loss:0.497499942779541\n",
            "Loss:0.4970111846923828\n",
            "Loss:0.49652236700057983\n",
            "Epoch: 120 | Loss: 0.49652236700057983 | Test loss: 0.5182924270629883\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7445]])), ('linear_layer.bias', tensor([0.7787]))])\n",
            "Loss:0.49603351950645447\n",
            "Loss:0.49554482102394104\n",
            "Loss:0.49505600333213806\n",
            "Loss:0.4945671558380127\n",
            "Loss:0.4940783381462097\n",
            "Loss:0.4935896396636963\n",
            "Loss:0.4931007921695709\n",
            "Loss:0.49261197447776794\n",
            "Loss:0.49212321639060974\n",
            "Loss:0.49163442850112915\n",
            "Epoch: 130 | Loss: 0.49163442850112915 | Test loss: 0.5125771164894104\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7429]])), ('linear_layer.bias', tensor([0.7744]))])\n",
            "Loss:0.49114561080932617\n",
            "Loss:0.49065685272216797\n",
            "Loss:0.490168035030365\n",
            "Loss:0.4896791875362396\n",
            "Loss:0.4891904294490814\n",
            "Loss:0.4887016713619232\n",
            "Loss:0.48821282386779785\n",
            "Loss:0.4877240061759949\n",
            "Loss:0.48723524808883667\n",
            "Loss:0.4867464601993561\n",
            "Epoch: 140 | Loss: 0.4867464601993561 | Test loss: 0.5068618655204773\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7412]])), ('linear_layer.bias', tensor([0.7702]))])\n",
            "Loss:0.4862576425075531\n",
            "Loss:0.4857688546180725\n",
            "Loss:0.48528003692626953\n",
            "Loss:0.48479127883911133\n",
            "Loss:0.48430246114730835\n",
            "Loss:0.48381367325782776\n",
            "Loss:0.48332491517066956\n",
            "Loss:0.4828360974788666\n",
            "Loss:0.482347309589386\n",
            "Loss:0.4818585515022278\n",
            "Epoch: 150 | Loss: 0.4818585515022278 | Test loss: 0.5011465549468994\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7396]])), ('linear_layer.bias', tensor([0.7659]))])\n",
            "Loss:0.48136967420578003\n",
            "Loss:0.48088088631629944\n",
            "Loss:0.4803921580314636\n",
            "Loss:0.47990331053733826\n",
            "Loss:0.47941452264785767\n",
            "Loss:0.47892576456069946\n",
            "Loss:0.4784369468688965\n",
            "Loss:0.4779481291770935\n",
            "Loss:0.4774593412876129\n",
            "Loss:0.47697049379348755\n",
            "Epoch: 160 | Loss: 0.47697049379348755 | Test loss: 0.4954312741756439\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7379]])), ('linear_layer.bias', tensor([0.7617]))])\n",
            "Loss:0.47648176550865173\n",
            "Loss:0.47599291801452637\n",
            "Loss:0.4755041003227234\n",
            "Loss:0.47501540184020996\n",
            "Loss:0.4745265543460846\n",
            "Loss:0.4740377366542816\n",
            "Loss:0.47354888916015625\n",
            "Loss:0.4730601906776428\n",
            "Loss:0.47257131338119507\n",
            "Loss:0.4720825254917145\n",
            "Epoch: 170 | Loss: 0.4720825254917145 | Test loss: 0.48971596360206604\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7362]])), ('linear_layer.bias', tensor([0.7575]))])\n",
            "Loss:0.4715937674045563\n",
            "Loss:0.4711049497127533\n",
            "Loss:0.4706161618232727\n",
            "Loss:0.4701274037361145\n",
            "Loss:0.4696385860443115\n",
            "Loss:0.46914976835250854\n",
            "Loss:0.46866101026535034\n",
            "Loss:0.46817222237586975\n",
            "Loss:0.4676834046840668\n",
            "Loss:0.4671946167945862\n",
            "Epoch: 180 | Loss: 0.4671946167945862 | Test loss: 0.4840007424354553\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7346]])), ('linear_layer.bias', tensor([0.7532]))])\n",
            "Loss:0.466705858707428\n",
            "Loss:0.466217041015625\n",
            "Loss:0.465728223323822\n",
            "Loss:0.46523943543434143\n",
            "Loss:0.46475061774253845\n",
            "Loss:0.46426182985305786\n",
            "Loss:0.4637730121612549\n",
            "Loss:0.4632842540740967\n",
            "Loss:0.4627954363822937\n",
            "Loss:0.4623066484928131\n",
            "Epoch: 190 | Loss: 0.4623066484928131 | Test loss: 0.47828546166419983\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7329]])), ('linear_layer.bias', tensor([0.7490]))])\n",
            "Loss:0.46181783080101013\n",
            "Loss:0.46132907271385193\n",
            "Loss:0.46084022521972656\n",
            "Loss:0.46035146713256836\n",
            "Loss:0.4598626494407654\n",
            "Loss:0.4593738615512848\n",
            "Loss:0.4588850438594818\n",
            "Loss:0.4583962559700012\n",
            "Loss:0.457907497882843\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5868688821792603\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5546833276748657\n",
            "Loss:0.5541888475418091\n",
            "Loss:0.5536941289901733\n",
            "Loss:0.5531996488571167\n",
            "Loss:0.5527051091194153\n",
            "Loss:0.5522104501724243\n",
            "Loss:0.5517159700393677\n",
            "Loss:0.5512213706970215\n",
            "Loss:0.5507268309593201\n",
            "Loss:0.5502322316169739\n",
            "Epoch: 10 | Loss: 0.5502322316169739 | Test loss: 0.5810860395431519\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7627]])), ('linear_layer.bias', tensor([0.8253]))])\n",
            "Loss:0.5497376322746277\n",
            "Loss:0.5492430925369263\n",
            "Loss:0.5487484931945801\n",
            "Loss:0.5482538938522339\n",
            "Loss:0.5477593541145325\n",
            "Loss:0.5472647547721863\n",
            "Loss:0.5467702150344849\n",
            "Loss:0.5462757349014282\n",
            "Loss:0.545781135559082\n",
            "Loss:0.5452865362167358\n",
            "Epoch: 20 | Loss: 0.5452865362167358 | Test loss: 0.5753031969070435\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7610]])), ('linear_layer.bias', tensor([0.8210]))])\n",
            "Loss:0.5447919368743896\n",
            "Loss:0.5442973375320435\n",
            "Loss:0.5438028573989868\n",
            "Loss:0.5433082580566406\n",
            "Loss:0.5428136587142944\n",
            "Loss:0.542319118976593\n",
            "Loss:0.5418245792388916\n",
            "Loss:0.5413299798965454\n",
            "Loss:0.5408353805541992\n",
            "Loss:0.5403408408164978\n",
            "Epoch: 30 | Loss: 0.5403408408164978 | Test loss: 0.5695203542709351\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7593]])), ('linear_layer.bias', tensor([0.8167]))])\n",
            "Loss:0.5398462414741516\n",
            "Loss:0.5393517017364502\n",
            "Loss:0.538857102394104\n",
            "Loss:0.5383625030517578\n",
            "Loss:0.5378679633140564\n",
            "Loss:0.537373423576355\n",
            "Loss:0.5368788242340088\n",
            "Loss:0.5363842248916626\n",
            "Loss:0.5358896851539612\n",
            "Loss:0.5353951454162598\n",
            "Epoch: 40 | Loss: 0.5353951454162598 | Test loss: 0.5637375712394714\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7577]])), ('linear_layer.bias', tensor([0.8124]))])\n",
            "Loss:0.5349005460739136\n",
            "Loss:0.5344060063362122\n",
            "Loss:0.533911406993866\n",
            "Loss:0.5334168672561646\n",
            "Loss:0.5329222679138184\n",
            "Loss:0.5324276685714722\n",
            "Loss:0.5319331288337708\n",
            "Loss:0.5314385294914246\n",
            "Loss:0.5309439897537231\n",
            "Loss:0.5304494500160217\n",
            "Epoch: 50 | Loss: 0.5304494500160217 | Test loss: 0.5579546689987183\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7560]])), ('linear_layer.bias', tensor([0.8081]))])\n",
            "Loss:0.5299548506736755\n",
            "Loss:0.5294603109359741\n",
            "Loss:0.5289657115936279\n",
            "Loss:0.5284711122512817\n",
            "Loss:0.5279765725135803\n",
            "Loss:0.5274820327758789\n",
            "Loss:0.5269874334335327\n",
            "Loss:0.5264928340911865\n",
            "Loss:0.5259982943534851\n",
            "Loss:0.5255037546157837\n",
            "Epoch: 60 | Loss: 0.5255037546157837 | Test loss: 0.5521718263626099\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7543]])), ('linear_layer.bias', tensor([0.8038]))])\n",
            "Loss:0.5250091552734375\n",
            "Loss:0.5245145559310913\n",
            "Loss:0.5240200161933899\n",
            "Loss:0.5235254168510437\n",
            "Loss:0.5230308771133423\n",
            "Loss:0.5225362777709961\n",
            "Loss:0.5220417976379395\n",
            "Loss:0.5215471386909485\n",
            "Loss:0.5210525989532471\n",
            "Loss:0.5205579996109009\n",
            "Epoch: 70 | Loss: 0.5205579996109009 | Test loss: 0.5463889837265015\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7527]])), ('linear_layer.bias', tensor([0.7995]))])\n",
            "Loss:0.5200634598731995\n",
            "Loss:0.519568920135498\n",
            "Loss:0.5190743207931519\n",
            "Loss:0.5185797810554504\n",
            "Loss:0.5180851817131042\n",
            "Loss:0.5175906419754028\n",
            "Loss:0.5170959830284119\n",
            "Loss:0.5166014432907104\n",
            "Loss:0.516106903553009\n",
            "Loss:0.5156123042106628\n",
            "Epoch: 80 | Loss: 0.5156123042106628 | Test loss: 0.5406061410903931\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7510]])), ('linear_layer.bias', tensor([0.7952]))])\n",
            "Loss:0.5151177644729614\n",
            "Loss:0.5146231651306152\n",
            "Loss:0.514128565788269\n",
            "Loss:0.5136340856552124\n",
            "Loss:0.5131394863128662\n",
            "Loss:0.5126449465751648\n",
            "Loss:0.5121502876281738\n",
            "Loss:0.5116557478904724\n",
            "Loss:0.511161208152771\n",
            "Loss:0.5106666684150696\n",
            "Epoch: 90 | Loss: 0.5106666684150696 | Test loss: 0.5348232984542847\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7493]])), ('linear_layer.bias', tensor([0.7909]))])\n",
            "Loss:0.5101720094680786\n",
            "Loss:0.5096774697303772\n",
            "Loss:0.509182870388031\n",
            "Loss:0.5086883306503296\n",
            "Loss:0.5081937909126282\n",
            "Loss:0.507699191570282\n",
            "Loss:0.5072046518325806\n",
            "Loss:0.5067099928855896\n",
            "Loss:0.506215512752533\n",
            "Loss:0.5057209134101868\n",
            "Epoch: 100 | Loss: 0.5057209134101868 | Test loss: 0.5290404558181763\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7476]])), ('linear_layer.bias', tensor([0.7867]))])\n",
            "Loss:0.5052263140678406\n",
            "Loss:0.5047317743301392\n",
            "Loss:0.504237174987793\n",
            "Loss:0.5037426352500916\n",
            "Loss:0.5032480359077454\n",
            "Loss:0.502753496170044\n",
            "Loss:0.5022588968276978\n",
            "Loss:0.5017643570899963\n",
            "Loss:0.5012698173522949\n",
            "Loss:0.500775158405304\n",
            "Epoch: 110 | Loss: 0.500775158405304 | Test loss: 0.5232576131820679\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7460]])), ('linear_layer.bias', tensor([0.7824]))])\n",
            "Loss:0.5002806782722473\n",
            "Loss:0.49978604912757874\n",
            "Loss:0.4992915093898773\n",
            "Loss:0.4987969994544983\n",
            "Loss:0.4983023703098297\n",
            "Loss:0.4978078007698059\n",
            "Loss:0.4973132014274597\n",
            "Loss:0.4968186914920807\n",
            "Loss:0.4963241219520569\n",
            "Loss:0.4958294928073883\n",
            "Epoch: 120 | Loss: 0.4958294928073883 | Test loss: 0.5174747109413147\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7443]])), ('linear_layer.bias', tensor([0.7781]))])\n",
            "Loss:0.4953349530696869\n",
            "Loss:0.4948403835296631\n",
            "Loss:0.4943458139896393\n",
            "Loss:0.4938512444496155\n",
            "Loss:0.4933566451072693\n",
            "Loss:0.49286213517189026\n",
            "Loss:0.4923675060272217\n",
            "Loss:0.49187296628952026\n",
            "Loss:0.49137839674949646\n",
            "Loss:0.49088382720947266\n",
            "Epoch: 130 | Loss: 0.49088382720947266 | Test loss: 0.5116918683052063\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7426]])), ('linear_layer.bias', tensor([0.7738]))])\n",
            "Loss:0.49038925766944885\n",
            "Loss:0.48989468812942505\n",
            "Loss:0.48940008878707886\n",
            "Loss:0.48890551924705505\n",
            "Loss:0.48841094970703125\n",
            "Loss:0.48791638016700745\n",
            "Loss:0.48742184042930603\n",
            "Loss:0.4869272708892822\n",
            "Loss:0.48643264174461365\n",
            "Loss:0.4859381318092346\n",
            "Epoch: 140 | Loss: 0.4859381318092346 | Test loss: 0.5059090852737427\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7409]])), ('linear_layer.bias', tensor([0.7695]))])\n",
            "Loss:0.4854435324668884\n",
            "Loss:0.4849489629268646\n",
            "Loss:0.4844544529914856\n",
            "Loss:0.483959823846817\n",
            "Loss:0.4834652543067932\n",
            "Loss:0.4829707145690918\n",
            "Loss:0.4824760854244232\n",
            "Loss:0.4819815754890442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 86%| | 86/100 [00:26<00:04,  3.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.481486976146698\n",
            "Loss:0.4809923768043518\n",
            "Epoch: 150 | Loss: 0.4809923768043518 | Test loss: 0.5001262426376343\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7393]])), ('linear_layer.bias', tensor([0.7652]))])\n",
            "Loss:0.4804978370666504\n",
            "Loss:0.4800032675266266\n",
            "Loss:0.4795086979866028\n",
            "Loss:0.4790140986442566\n",
            "Loss:0.47851958870887756\n",
            "Loss:0.478024959564209\n",
            "Loss:0.47753041982650757\n",
            "Loss:0.47703590989112854\n",
            "Loss:0.4765412211418152\n",
            "Loss:0.47604671120643616\n",
            "Epoch: 160 | Loss: 0.47604671120643616 | Test loss: 0.4943433403968811\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7376]])), ('linear_layer.bias', tensor([0.7609]))])\n",
            "Loss:0.47555214166641235\n",
            "Loss:0.47505754232406616\n",
            "Loss:0.47456297278404236\n",
            "Loss:0.47406840324401855\n",
            "Loss:0.47357386350631714\n",
            "Loss:0.47307929396629333\n",
            "Loss:0.47258472442626953\n",
            "Loss:0.4720901548862457\n",
            "Loss:0.4715955853462219\n",
            "Loss:0.4711010456085205\n",
            "Epoch: 170 | Loss: 0.4711010456085205 | Test loss: 0.4885604977607727\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7359]])), ('linear_layer.bias', tensor([0.7566]))])\n",
            "Loss:0.4706064760684967\n",
            "Loss:0.4701118469238281\n",
            "Loss:0.4696172773838043\n",
            "Loss:0.4691227078437805\n",
            "Loss:0.4686281681060791\n",
            "Loss:0.4681335985660553\n",
            "Loss:0.4676389694213867\n",
            "Loss:0.4671444296836853\n",
            "Loss:0.4666499197483063\n",
            "Loss:0.46615535020828247\n",
            "Epoch: 180 | Loss: 0.46615535020828247 | Test loss: 0.4827776849269867\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7342]])), ('linear_layer.bias', tensor([0.7523]))])\n",
            "Loss:0.4656607508659363\n",
            "Loss:0.4651660919189453\n",
            "Loss:0.4646715521812439\n",
            "Loss:0.46417704224586487\n",
            "Loss:0.46368247270584106\n",
            "Loss:0.46318793296813965\n",
            "Loss:0.46269330382347107\n",
            "Loss:0.46219873428344727\n",
            "Loss:0.46170416474342346\n",
            "Loss:0.46120962500572205\n",
            "Epoch: 190 | Loss: 0.46120962500572205 | Test loss: 0.47699475288391113\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7326]])), ('linear_layer.bias', tensor([0.7480]))])\n",
            "Loss:0.46071499586105347\n",
            "Loss:0.46022042632102966\n",
            "Loss:0.45972585678100586\n",
            "Loss:0.4592313766479492\n",
            "Loss:0.4587368071079254\n",
            "Loss:0.4582422375679016\n",
            "Loss:0.45774760842323303\n",
            "Loss:0.4572530686855316\n",
            "Loss:0.4567584991455078\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5868621468544006\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5546774864196777\n",
            "Loss:0.5541771650314331\n",
            "Loss:0.5536767244338989\n",
            "Loss:0.5531762838363647\n",
            "Loss:0.5526759028434753\n",
            "Loss:0.5521755218505859\n",
            "Loss:0.551675021648407\n",
            "Loss:0.5511747598648071\n",
            "Loss:0.550674319267273\n",
            "Loss:0.5501738786697388\n",
            "Epoch: 10 | Loss: 0.5501738786697388 | Test loss: 0.5810110569000244\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7627]])), ('linear_layer.bias', tensor([0.8252]))])\n",
            "Loss:0.5496734976768494\n",
            "Loss:0.5491730570793152\n",
            "Loss:0.5486726760864258\n",
            "Loss:0.5481722950935364\n",
            "Loss:0.547671914100647\n",
            "Loss:0.5471714735031128\n",
            "Loss:0.5466710329055786\n",
            "Loss:0.5461706519126892\n",
            "Loss:0.545670211315155\n",
            "Loss:0.5451698303222656\n",
            "Epoch: 20 | Loss: 0.5451698303222656 | Test loss: 0.5751600861549377\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7610]])), ('linear_layer.bias', tensor([0.8209]))])\n",
            "Loss:0.5446694493293762\n",
            "Loss:0.5441690683364868\n",
            "Loss:0.5436686277389526\n",
            "Loss:0.5431682467460632\n",
            "Loss:0.542667806148529\n",
            "Loss:0.5421674251556396\n",
            "Loss:0.5416670441627502\n",
            "Loss:0.5411666631698608\n",
            "Loss:0.5406662225723267\n",
            "Loss:0.5401657819747925\n",
            "Epoch: 30 | Loss: 0.5401657819747925 | Test loss: 0.5693090558052063\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7593]])), ('linear_layer.bias', tensor([0.8165]))])\n",
            "Loss:0.5396654009819031\n",
            "Loss:0.5391649603843689\n",
            "Loss:0.5386645793914795\n",
            "Loss:0.5381641983985901\n",
            "Loss:0.5376638174057007\n",
            "Loss:0.5371634364128113\n",
            "Loss:0.5366629362106323\n",
            "Loss:0.5361625552177429\n",
            "Loss:0.5356622338294983\n",
            "Loss:0.5351617932319641\n",
            "Epoch: 40 | Loss: 0.5351617932319641 | Test loss: 0.5634579658508301\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7576]])), ('linear_layer.bias', tensor([0.8122]))])\n",
            "Loss:0.5346614122390747\n",
            "Loss:0.5341609716415405\n",
            "Loss:0.5336605906486511\n",
            "Loss:0.5331602096557617\n",
            "Loss:0.5326597690582275\n",
            "Loss:0.5321593880653381\n",
            "Loss:0.5316590070724487\n",
            "Loss:0.5311585664749146\n",
            "Loss:0.5306581258773804\n",
            "Loss:0.530157744884491\n",
            "Epoch: 50 | Loss: 0.530157744884491 | Test loss: 0.5576069951057434\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7559]])), ('linear_layer.bias', tensor([0.8079]))])\n",
            "Loss:0.5296573638916016\n",
            "Loss:0.5291569828987122\n",
            "Loss:0.5286566019058228\n",
            "Loss:0.5281561613082886\n",
            "Loss:0.5276557207107544\n",
            "Loss:0.5271552801132202\n",
            "Loss:0.5266548991203308\n",
            "Loss:0.5261545181274414\n",
            "Loss:0.525654137134552\n",
            "Loss:0.5251537561416626\n",
            "Epoch: 60 | Loss: 0.5251537561416626 | Test loss: 0.5517560243606567\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7542]])), ('linear_layer.bias', tensor([0.8035]))])\n",
            "Loss:0.5246533155441284\n",
            "Loss:0.5241528749465942\n",
            "Loss:0.5236524939537048\n",
            "Loss:0.5231520533561707\n",
            "Loss:0.5226516723632812\n",
            "Loss:0.5221513509750366\n",
            "Loss:0.5216509103775024\n",
            "Loss:0.5211504697799683\n",
            "Loss:0.5206500887870789\n",
            "Loss:0.5201496481895447\n",
            "Epoch: 70 | Loss: 0.5201496481895447 | Test loss: 0.5459049344062805\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7525]])), ('linear_layer.bias', tensor([0.7992]))])\n",
            "Loss:0.5196492671966553\n",
            "Loss:0.5191488265991211\n",
            "Loss:0.5186484456062317\n",
            "Loss:0.5181480646133423\n",
            "Loss:0.5176476240158081\n",
            "Loss:0.5171472430229187\n",
            "Loss:0.5166468620300293\n",
            "Loss:0.5161464810371399\n",
            "Loss:0.5156461000442505\n",
            "Loss:0.5151455998420715\n",
            "Epoch: 80 | Loss: 0.5151455998420715 | Test loss: 0.5400539636611938\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7508]])), ('linear_layer.bias', tensor([0.7948]))])\n",
            "Loss:0.5146452188491821\n",
            "Loss:0.514144778251648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%| | 87/100 [00:27<00:04,  3.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5136443972587585\n",
            "Loss:0.5131440162658691\n",
            "Loss:0.512643575668335\n",
            "Loss:0.5121432542800903\n",
            "Loss:0.5116428136825562\n",
            "Loss:0.5111424326896667\n",
            "Loss:0.5106420516967773\n",
            "Loss:0.5101416110992432\n",
            "Epoch: 90 | Loss: 0.5101416110992432 | Test loss: 0.5342029333114624\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7491]])), ('linear_layer.bias', tensor([0.7905]))])\n",
            "Loss:0.509641170501709\n",
            "Loss:0.5091408491134644\n",
            "Loss:0.5086404085159302\n",
            "Loss:0.508139967918396\n",
            "Loss:0.5076395869255066\n",
            "Loss:0.5071392059326172\n",
            "Loss:0.506638765335083\n",
            "Loss:0.5061383843421936\n",
            "Loss:0.5056380033493042\n",
            "Loss:0.50513756275177\n",
            "Epoch: 100 | Loss: 0.50513756275177 | Test loss: 0.528351902961731\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7474]])), ('linear_layer.bias', tensor([0.7861]))])\n",
            "Loss:0.5046371221542358\n",
            "Loss:0.5041367411613464\n",
            "Loss:0.5036364197731018\n",
            "Loss:0.5031360387802124\n",
            "Loss:0.5026355981826782\n",
            "Loss:0.502135157585144\n",
            "Loss:0.5016347169876099\n",
            "Loss:0.5011343359947205\n",
            "Loss:0.5006338953971863\n",
            "Loss:0.5001335740089417\n",
            "Epoch: 110 | Loss: 0.5001335740089417 | Test loss: 0.5225008726119995\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7457]])), ('linear_layer.bias', tensor([0.7818]))])\n",
            "Loss:0.49963313341140747\n",
            "Loss:0.4991327226161957\n",
            "Loss:0.4986323416233063\n",
            "Loss:0.4981319308280945\n",
            "Loss:0.4976314902305603\n",
            "Loss:0.4971310496330261\n",
            "Loss:0.4966307580471039\n",
            "Loss:0.4961303174495697\n",
            "Loss:0.4956298768520355\n",
            "Loss:0.4951294958591461\n",
            "Epoch: 120 | Loss: 0.4951294958591461 | Test loss: 0.5166498422622681\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7440]])), ('linear_layer.bias', tensor([0.7775]))])\n",
            "Loss:0.49462905526161194\n",
            "Loss:0.49412864446640015\n",
            "Loss:0.4936283230781555\n",
            "Loss:0.4931279122829437\n",
            "Loss:0.49262747168540955\n",
            "Loss:0.49212709069252014\n",
            "Loss:0.49162665009498596\n",
            "Loss:0.49112623929977417\n",
            "Loss:0.49062585830688477\n",
            "Loss:0.49012547731399536\n",
            "Epoch: 130 | Loss: 0.49012547731399536 | Test loss: 0.5107988119125366\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7423]])), ('linear_layer.bias', tensor([0.7731]))])\n",
            "Loss:0.48962506651878357\n",
            "Loss:0.48912468552589417\n",
            "Loss:0.48862424492836\n",
            "Loss:0.4881238341331482\n",
            "Loss:0.4876234531402588\n",
            "Loss:0.4871230125427246\n",
            "Loss:0.4866226315498352\n",
            "Loss:0.4861222207546234\n",
            "Loss:0.485621839761734\n",
            "Loss:0.4851214289665222\n",
            "Epoch: 140 | Loss: 0.4851214289665222 | Test loss: 0.5049477815628052\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7407]])), ('linear_layer.bias', tensor([0.7688]))])\n",
            "Loss:0.48462098836898804\n",
            "Loss:0.4841206669807434\n",
            "Loss:0.48362022638320923\n",
            "Loss:0.48311978578567505\n",
            "Loss:0.48261937499046326\n",
            "Loss:0.48211902379989624\n",
            "Loss:0.48161858320236206\n",
            "Loss:0.48111820220947266\n",
            "Loss:0.48061782121658325\n",
            "Loss:0.4801173806190491\n",
            "Epoch: 150 | Loss: 0.4801173806190491 | Test loss: 0.4990968108177185\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7390]])), ('linear_layer.bias', tensor([0.7644]))])\n",
            "Loss:0.4796169698238373\n",
            "Loss:0.47911661863327026\n",
            "Loss:0.4786161780357361\n",
            "Loss:0.4781157970428467\n",
            "Loss:0.4776153564453125\n",
            "Loss:0.4771149754524231\n",
            "Loss:0.4766145646572113\n",
            "Loss:0.4761141240596771\n",
            "Loss:0.4756137728691101\n",
            "Loss:0.4751133918762207\n",
            "Epoch: 160 | Loss: 0.4751133918762207 | Test loss: 0.49324578046798706\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7373]])), ('linear_layer.bias', tensor([0.7601]))])\n",
            "Loss:0.4746129512786865\n",
            "Loss:0.4741125702857971\n",
            "Loss:0.4736121594905853\n",
            "Loss:0.47311171889305115\n",
            "Loss:0.47261133790016174\n",
            "Loss:0.47211092710494995\n",
            "Loss:0.47161054611206055\n",
            "Loss:0.47111010551452637\n",
            "Loss:0.47060972452163696\n",
            "Loss:0.47010931372642517\n",
            "Epoch: 170 | Loss: 0.47010931372642517 | Test loss: 0.4873947501182556\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7356]])), ('linear_layer.bias', tensor([0.7557]))])\n",
            "Loss:0.46960893273353577\n",
            "Loss:0.4691084921360016\n",
            "Loss:0.4686080813407898\n",
            "Loss:0.4681077003479004\n",
            "Loss:0.467607319355011\n",
            "Loss:0.4671069085597992\n",
            "Loss:0.4666065275669098\n",
            "Loss:0.4661060869693756\n",
            "Loss:0.4656056761741638\n",
            "Loss:0.46510523557662964\n",
            "Epoch: 180 | Loss: 0.46510523557662964 | Test loss: 0.48154377937316895\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7339]])), ('linear_layer.bias', tensor([0.7514]))])\n",
            "Loss:0.46460485458374023\n",
            "Loss:0.46410447359085083\n",
            "Loss:0.46360406279563904\n",
            "Loss:0.46310368180274963\n",
            "Loss:0.46260324120521545\n",
            "Loss:0.46210283041000366\n",
            "Loss:0.46160244941711426\n",
            "Loss:0.4611020088195801\n",
            "Loss:0.4606016278266907\n",
            "Loss:0.4601012170314789\n",
            "Epoch: 190 | Loss: 0.4601012170314789 | Test loss: 0.4756927490234375\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7322]])), ('linear_layer.bias', tensor([0.7470]))])\n",
            "Loss:0.4596008360385895\n",
            "Loss:0.4591004252433777\n",
            "Loss:0.4585999846458435\n",
            "Loss:0.4580996036529541\n",
            "Loss:0.4575992226600647\n",
            "Loss:0.4570988118648529\n",
            "Loss:0.4565984308719635\n",
            "Loss:0.4560980200767517\n",
            "Loss:0.45559757947921753\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5868552923202515\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5546717047691345\n",
            "Loss:0.5541655421257019\n",
            "Loss:0.553659200668335\n",
            "Loss:0.5531530380249023\n",
            "Loss:0.5526467561721802\n",
            "Loss:0.5521405339241028\n",
            "Loss:0.5516342520713806\n",
            "Loss:0.5511280298233032\n",
            "Loss:0.5506218075752258\n",
            "Loss:0.5501155853271484\n",
            "Epoch: 10 | Loss: 0.5501155853271484 | Test loss: 0.580936074256897\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7627]])), ('linear_layer.bias', tensor([0.8252]))])\n",
            "Loss:0.5496093034744263\n",
            "Loss:0.5491030812263489\n",
            "Loss:0.5485968589782715\n",
            "Loss:0.5480905771255493\n",
            "Loss:0.5475844144821167\n",
            "Loss:0.5470781326293945\n",
            "Loss:0.5465719103813171\n",
            "Loss:0.5460656881332397\n",
            "Loss:0.5455594658851624\n",
            "Loss:0.5450531244277954\n",
            "Epoch: 20 | Loss: 0.5450531244277954 | Test loss: 0.5750169157981873\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7609]])), ('linear_layer.bias', tensor([0.8208]))])\n",
            "Loss:0.5445470213890076\n",
            "Loss:0.5440406799316406\n",
            "Loss:0.5435344576835632\n",
            "Loss:0.5430282354354858\n",
            "Loss:0.5425220727920532\n",
            "Loss:0.542015790939331\n",
            "Loss:0.5415095090866089\n",
            "Loss:0.5410033464431763\n",
            "Loss:0.5404970049858093\n",
            "Loss:0.5399907827377319\n",
            "Epoch: 30 | Loss: 0.5399907827377319 | Test loss: 0.5690977573394775\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7592]])), ('linear_layer.bias', tensor([0.8164]))])\n",
            "Loss:0.5394846200942993\n",
            "Loss:0.5389783382415771\n",
            "Loss:0.538472056388855\n",
            "Loss:0.5379658937454224\n",
            "Loss:0.537459671497345\n",
            "Loss:0.5369534492492676\n",
            "Loss:0.5364471673965454\n",
            "Loss:0.5359408855438232\n",
            "Loss:0.5354346036911011\n",
            "Loss:0.5349284410476685\n",
            "Epoch: 40 | Loss: 0.5349284410476685 | Test loss: 0.563178539276123\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7575]])), ('linear_layer.bias', tensor([0.8120]))])\n",
            "Loss:0.5344222187995911\n",
            "Loss:0.5339159369468689\n",
            "Loss:0.5334097146987915\n",
            "Loss:0.5329034924507141\n",
            "Loss:0.5323972105979919\n",
            "Loss:0.5318909883499146\n",
            "Loss:0.5313847661018372\n",
            "Loss:0.5308785438537598\n",
            "Loss:0.5303722620010376\n",
            "Loss:0.529866099357605\n",
            "Epoch: 50 | Loss: 0.529866099357605 | Test loss: 0.5572593212127686\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7558]])), ('linear_layer.bias', tensor([0.8076]))])\n",
            "Loss:0.5293598175048828\n",
            "Loss:0.5288535952568054\n",
            "Loss:0.528347373008728\n",
            "Loss:0.5278411507606506\n",
            "Loss:0.5273348689079285\n",
            "Loss:0.5268286466598511\n",
            "Loss:0.5263224244117737\n",
            "Loss:0.5258162021636963\n",
            "Loss:0.5253099203109741\n",
            "Loss:0.5248037576675415\n",
            "Epoch: 60 | Loss: 0.5248037576675415 | Test loss: 0.5513401031494141\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7541]])), ('linear_layer.bias', tensor([0.8032]))])\n",
            "Loss:0.5242974758148193\n",
            "Loss:0.5237912535667419\n",
            "Loss:0.5232849717140198\n",
            "Loss:0.5227788090705872\n",
            "Loss:0.522272527217865\n",
            "Loss:0.5217663049697876\n",
            "Loss:0.5212600827217102\n",
            "Loss:0.5207538604736328\n",
            "Loss:0.5202475786209106\n",
            "Loss:0.5197413563728333\n",
            "Epoch: 70 | Loss: 0.5197413563728333 | Test loss: 0.5454209446907043\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7524]])), ('linear_layer.bias', tensor([0.7988]))])\n",
            "Loss:0.5192350745201111\n",
            "Loss:0.5187288522720337\n",
            "Loss:0.5182226300239563\n",
            "Loss:0.5177164077758789\n",
            "Loss:0.5172101259231567\n",
            "Loss:0.5167039036750793\n",
            "Loss:0.516197681427002\n",
            "Loss:0.5156913995742798\n",
            "Loss:0.5151852369308472\n",
            "Loss:0.514678955078125\n",
            "Epoch: 80 | Loss: 0.514678955078125 | Test loss: 0.5395017862319946\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7507]])), ('linear_layer.bias', tensor([0.7944]))])\n",
            "Loss:0.5141727328300476\n",
            "Loss:0.5136665105819702\n",
            "Loss:0.5131602883338928\n",
            "Loss:0.5126539468765259\n",
            "Loss:0.512147843837738\n",
            "Loss:0.5116415023803711\n",
            "Loss:0.5111352801322937\n",
            "Loss:0.5106290578842163\n",
            "Loss:0.5101228952407837\n",
            "Loss:0.5096165537834167\n",
            "Epoch: 90 | Loss: 0.5096165537834167 | Test loss: 0.5335825681686401\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7489]])), ('linear_layer.bias', tensor([0.7900]))])\n",
            "Loss:0.5091103315353394\n",
            "Loss:0.5086041688919067\n",
            "Loss:0.5080978870391846\n",
            "Loss:0.5075916051864624\n",
            "Loss:0.5070854425430298\n",
            "Loss:0.5065791606903076\n",
            "Loss:0.5060728788375854\n",
            "Loss:0.5055667161941528\n",
            "Loss:0.5050604939460754\n",
            "Loss:0.5045542120933533\n",
            "Epoch: 100 | Loss: 0.5045542120933533 | Test loss: 0.5276634097099304\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7472]])), ('linear_layer.bias', tensor([0.7856]))])\n",
            "Loss:0.5040479898452759\n",
            "Loss:0.5035417675971985\n",
            "Loss:0.5030354261398315\n",
            "Loss:0.5025292634963989\n",
            "Loss:0.5020230412483215\n",
            "Loss:0.5015167593955994\n",
            "Loss:0.501010537147522\n",
            "Loss:0.5005043745040894\n",
            "Loss:0.4999980926513672\n",
            "Loss:0.4994918406009674\n",
            "Epoch: 110 | Loss: 0.4994918406009674 | Test loss: 0.5217442512512207\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 88%| | 88/100 [00:27<00:04,  2.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('linear_layer.weight', tensor([[0.7455]])), ('linear_layer.bias', tensor([0.7812]))])\n",
            "Loss:0.4989855885505676\n",
            "Loss:0.49847936630249023\n",
            "Loss:0.49797311425209045\n",
            "Loss:0.49746689200401306\n",
            "Loss:0.4969606399536133\n",
            "Loss:0.4964544177055359\n",
            "Loss:0.4959481656551361\n",
            "Loss:0.49544191360473633\n",
            "Loss:0.49493569135665894\n",
            "Loss:0.49442943930625916\n",
            "Epoch: 120 | Loss: 0.49442943930625916 | Test loss: 0.5158250331878662\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7438]])), ('linear_layer.bias', tensor([0.7768]))])\n",
            "Loss:0.49392324686050415\n",
            "Loss:0.49341702461242676\n",
            "Loss:0.4929107129573822\n",
            "Loss:0.4924044609069824\n",
            "Loss:0.49189823865890503\n",
            "Loss:0.49139204621315\n",
            "Loss:0.49088579416275024\n",
            "Loss:0.4903796315193176\n",
            "Loss:0.48987334966659546\n",
            "Loss:0.4893670976161957\n",
            "Epoch: 130 | Loss: 0.4893670976161957 | Test loss: 0.5099058151245117\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7421]])), ('linear_layer.bias', tensor([0.7724]))])\n",
            "Loss:0.4888609051704407\n",
            "Loss:0.4883546829223633\n",
            "Loss:0.4878484308719635\n",
            "Loss:0.4873421788215637\n",
            "Loss:0.48683589696884155\n",
            "Loss:0.4863296449184418\n",
            "Loss:0.48582345247268677\n",
            "Loss:0.4853171706199646\n",
            "Loss:0.4848109781742096\n",
            "Loss:0.4843047261238098\n",
            "Epoch: 140 | Loss: 0.4843047261238098 | Test loss: 0.5039865970611572\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7404]])), ('linear_layer.bias', tensor([0.7681]))])\n",
            "Loss:0.4837985038757324\n",
            "Loss:0.48329225182533264\n",
            "Loss:0.48278602957725525\n",
            "Loss:0.48227977752685547\n",
            "Loss:0.4817735552787781\n",
            "Loss:0.4812673032283783\n",
            "Loss:0.4807611107826233\n",
            "Loss:0.48025479912757874\n",
            "Loss:0.47974857687950134\n",
            "Loss:0.47924232482910156\n",
            "Epoch: 150 | Loss: 0.47924232482910156 | Test loss: 0.4980674386024475\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7387]])), ('linear_layer.bias', tensor([0.7637]))])\n",
            "Loss:0.47873616218566895\n",
            "Loss:0.4782298505306244\n",
            "Loss:0.4777236878871918\n",
            "Loss:0.4772173762321472\n",
            "Loss:0.4767111837863922\n",
            "Loss:0.47620493173599243\n",
            "Loss:0.47569870948791504\n",
            "Loss:0.47519245743751526\n",
            "Loss:0.47468623518943787\n",
            "Loss:0.4741799831390381\n",
            "Epoch: 160 | Loss: 0.4741799831390381 | Test loss: 0.4921482503414154\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7369]])), ('linear_layer.bias', tensor([0.7593]))])\n",
            "Loss:0.4736737310886383\n",
            "Loss:0.4731675088405609\n",
            "Loss:0.4726613163948059\n",
            "Loss:0.47215503454208374\n",
            "Loss:0.47164878249168396\n",
            "Loss:0.47114259004592896\n",
            "Loss:0.4706362783908844\n",
            "Loss:0.4701301157474518\n",
            "Loss:0.469623863697052\n",
            "Loss:0.46911758184432983\n",
            "Epoch: 170 | Loss: 0.46911758184432983 | Test loss: 0.4862290322780609\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7352]])), ('linear_layer.bias', tensor([0.7549]))])\n",
            "Loss:0.46861138939857483\n",
            "Loss:0.46810513734817505\n",
            "Loss:0.46759891510009766\n",
            "Loss:0.4670926630496979\n",
            "Loss:0.4665864109992981\n",
            "Loss:0.4660801887512207\n",
            "Loss:0.4655739367008209\n",
            "Loss:0.46506771445274353\n",
            "Loss:0.4645615220069885\n",
            "Loss:0.46405524015426636\n",
            "Epoch: 180 | Loss: 0.46405524015426636 | Test loss: 0.4803099036216736\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7335]])), ('linear_layer.bias', tensor([0.7505]))])\n",
            "Loss:0.4635489881038666\n",
            "Loss:0.4630427956581116\n",
            "Loss:0.4625365138053894\n",
            "Loss:0.4620303213596344\n",
            "Loss:0.4615240693092346\n",
            "Loss:0.4610178470611572\n",
            "Loss:0.46051159501075745\n",
            "Loss:0.4600052833557129\n",
            "Loss:0.4594991207122803\n",
            "Loss:0.4589928686618805\n",
            "Epoch: 190 | Loss: 0.4589928686618805 | Test loss: 0.4743906855583191\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7318]])), ('linear_layer.bias', tensor([0.7461]))])\n",
            "Loss:0.4584866166114807\n",
            "Loss:0.4579804539680481\n",
            "Loss:0.4574741721153259\n",
            "Loss:0.45696792006492615\n",
            "Loss:0.45646172761917114\n",
            "Loss:0.455955445766449\n",
            "Loss:0.4554491937160492\n",
            "Loss:0.4549430012702942\n",
            "Loss:0.454436719417572\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5868484973907471\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5546658635139465\n",
            "Loss:0.5541538000106812\n",
            "Loss:0.553641676902771\n",
            "Loss:0.5531296730041504\n",
            "Loss:0.5526175498962402\n",
            "Loss:0.5521055459976196\n",
            "Loss:0.5515934228897095\n",
            "Loss:0.5510812997817993\n",
            "Loss:0.5505692958831787\n",
            "Loss:0.5500572323799133\n",
            "Epoch: 10 | Loss: 0.5500572323799133 | Test loss: 0.5808610320091248\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8251]))])\n",
            "Loss:0.549545168876648\n",
            "Loss:0.5490330457687378\n",
            "Loss:0.5485209822654724\n",
            "Loss:0.5480089783668518\n",
            "Loss:0.5474969148635864\n",
            "Loss:0.5469847917556763\n",
            "Loss:0.5464727282524109\n",
            "Loss:0.5459606051445007\n",
            "Loss:0.5454485416412354\n",
            "Loss:0.54493647813797\n",
            "Epoch: 20 | Loss: 0.54493647813797 | Test loss: 0.5748738050460815\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7609]])), ('linear_layer.bias', tensor([0.8207]))])\n",
            "Loss:0.5444244742393494\n",
            "Loss:0.5439123511314392\n",
            "Loss:0.5434003472328186\n",
            "Loss:0.5428882241249084\n",
            "Loss:0.5423761606216431\n",
            "Loss:0.5418640971183777\n",
            "Loss:0.5413520932197571\n",
            "Loss:0.5408399701118469\n",
            "Loss:0.5403278470039368\n",
            "Loss:0.5398157835006714\n",
            "Epoch: 30 | Loss: 0.5398157835006714 | Test loss: 0.568886399269104\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7592]])), ('linear_layer.bias', tensor([0.8162]))])\n",
            "Loss:0.5393036603927612\n",
            "Loss:0.5387916564941406\n",
            "Loss:0.53827965259552\n",
            "Loss:0.5377675294876099\n",
            "Loss:0.5372554659843445\n",
            "Loss:0.5367433428764343\n",
            "Loss:0.536231279373169\n",
            "Loss:0.5357192754745483\n",
            "Loss:0.535207211971283\n",
            "Loss:0.5346951484680176\n",
            "Epoch: 40 | Loss: 0.5346951484680176 | Test loss: 0.5628989934921265\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7574]])), ('linear_layer.bias', tensor([0.8118]))])\n",
            "Loss:0.5341829061508179\n",
            "Loss:0.533670961856842\n",
            "Loss:0.5331588983535767\n",
            "Loss:0.5326468348503113\n",
            "Loss:0.5321347713470459\n",
            "Loss:0.5316226482391357\n",
            "Loss:0.5311105847358704\n",
            "Loss:0.530598521232605\n",
            "Loss:0.5300864577293396\n",
            "Loss:0.5295743942260742\n",
            "Epoch: 50 | Loss: 0.5295743942260742 | Test loss: 0.5569117069244385\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7557]])), ('linear_layer.bias', tensor([0.8073]))])\n",
            "Loss:0.5290623903274536\n",
            "Loss:0.5285502672195435\n",
            "Loss:0.5280382037162781\n",
            "Loss:0.5275260806083679\n",
            "Loss:0.5270140171051025\n",
            "Loss:0.5265020132064819\n",
            "Loss:0.5259898900985718\n",
            "Loss:0.5254778265953064\n",
            "Loss:0.524965763092041\n",
            "Loss:0.5244536399841309\n",
            "Epoch: 60 | Loss: 0.5244536399841309 | Test loss: 0.5509243607521057\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7540]])), ('linear_layer.bias', tensor([0.8029]))])\n",
            "Loss:0.5239415764808655\n",
            "Loss:0.5234295129776001\n",
            "Loss:0.5229174494743347\n",
            "Loss:0.5224054455757141\n",
            "Loss:0.521893322467804\n",
            "Loss:0.5213812589645386\n",
            "Loss:0.5208691358566284\n",
            "Loss:0.5203571319580078\n",
            "Loss:0.5198450684547424\n",
            "Loss:0.519333004951477\n",
            "Epoch: 70 | Loss: 0.519333004951477 | Test loss: 0.5449369549751282\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7522]])), ('linear_layer.bias', tensor([0.7985]))])\n",
            "Loss:0.5188209414482117\n",
            "Loss:0.5183088183403015\n",
            "Loss:0.5177967548370361\n",
            "Loss:0.5172847509384155\n",
            "Loss:0.5167726278305054\n",
            "Loss:0.51626056432724\n",
            "Loss:0.5157485008239746\n",
            "Loss:0.515236496925354\n",
            "Loss:0.5147243738174438\n",
            "Loss:0.5142122507095337\n",
            "Epoch: 80 | Loss: 0.5142122507095337 | Test loss: 0.5389496088027954\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7505]])), ('linear_layer.bias', tensor([0.7940]))])\n",
            "Loss:0.5137001872062683\n",
            "Loss:0.5131881237030029\n",
            "Loss:0.5126760601997375\n",
            "Loss:0.5121639966964722\n",
            "Loss:0.511651873588562\n",
            "Loss:0.5111398100852966\n",
            "Loss:0.510627806186676\n",
            "Loss:0.5101157426834106\n",
            "Loss:0.5096036791801453\n",
            "Loss:0.5090915560722351\n",
            "Epoch: 90 | Loss: 0.5090915560722351 | Test loss: 0.5329623222351074\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7488]])), ('linear_layer.bias', tensor([0.7896]))])\n",
            "Loss:0.5085794925689697\n",
            "Loss:0.5080674290657043\n",
            "Loss:0.507555365562439\n",
            "Loss:0.5070433020591736\n",
            "Loss:0.5065312385559082\n",
            "Loss:0.506019115447998\n",
            "Loss:0.5055070519447327\n",
            "Loss:0.5049950480461121\n",
            "Loss:0.5044829845428467\n",
            "Loss:0.5039709210395813\n",
            "Epoch: 100 | Loss: 0.5039709210395813 | Test loss: 0.5269749760627747\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7470]])), ('linear_layer.bias', tensor([0.7851]))])\n",
            "Loss:0.5034588575363159\n",
            "Loss:0.5029467344284058\n",
            "Loss:0.5024346113204956\n",
            "Loss:0.5019225478172302\n",
            "Loss:0.5014104843139648\n",
            "Loss:0.5008984804153442\n",
            "Loss:0.5003863573074341\n",
            "Loss:0.4998742938041687\n",
            "Loss:0.49936217069625854\n",
            "Loss:0.49885016679763794\n",
            "Epoch: 110 | Loss: 0.49885016679763794 | Test loss: 0.5209875106811523\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7453]])), ('linear_layer.bias', tensor([0.7807]))])\n",
            "Loss:0.49833813309669495\n",
            "Loss:0.4978260397911072\n",
            "Loss:0.4973139762878418\n",
            "Loss:0.49680185317993164\n",
            "Loss:0.49628978967666626\n",
            "Loss:0.49577775597572327\n",
            "Loss:0.4952656626701355\n",
            "Loss:0.49475353956222534\n",
            "Loss:0.49424153566360474\n",
            "Loss:0.49372944235801697\n",
            "Epoch: 120 | Loss: 0.49372944235801697 | Test loss: 0.5150001645088196\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7436]])), ('linear_layer.bias', tensor([0.7762]))])\n",
            "Loss:0.4932173788547516\n",
            "Loss:0.4927052855491638\n",
            "Loss:0.4921932816505432\n",
            "Loss:0.49168118834495544\n",
            "Loss:0.4911690652370453\n",
            "Loss:0.4906570315361023\n",
            "Loss:0.4901449680328369\n",
            "Loss:0.48963290452957153\n",
            "Loss:0.48912081122398376\n",
            "Loss:0.4886087477207184\n",
            "Epoch: 130 | Loss: 0.4886087477207184 | Test loss: 0.5090128183364868\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7418]])), ('linear_layer.bias', tensor([0.7718]))])\n",
            "Loss:0.4880966544151306\n",
            "Loss:0.48758459091186523\n",
            "Loss:0.48707252740859985\n",
            "Loss:0.4865604341030121\n",
            "Loss:0.4860484004020691\n",
            "Loss:0.4855363368988037\n",
            "Loss:0.48502427339553833\n",
            "Loss:0.48451218008995056\n",
            "Loss:0.4840001165866852\n",
            "Loss:0.4834880232810974\n",
            "Epoch: 140 | Loss: 0.4834880232810974 | Test loss: 0.5030254125595093\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7401]])), ('linear_layer.bias', tensor([0.7673]))])"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 89%| | 89/100 [00:28<00:04,  2.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loss:0.48297595977783203\n",
            "Loss:0.4824638366699219\n",
            "Loss:0.4819518029689789\n",
            "Loss:0.4814397394657135\n",
            "Loss:0.48092764616012573\n",
            "Loss:0.4804156422615051\n",
            "Loss:0.47990354895591736\n",
            "Loss:0.479391485452652\n",
            "Loss:0.4788793623447418\n",
            "Loss:0.47836732864379883\n",
            "Epoch: 150 | Loss: 0.47836732864379883 | Test loss: 0.4970380365848541\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7384]])), ('linear_layer.bias', tensor([0.7629]))])\n",
            "Loss:0.47785526514053345\n",
            "Loss:0.47734323143959045\n",
            "Loss:0.4768311083316803\n",
            "Loss:0.47631901502609253\n",
            "Loss:0.4758070111274719\n",
            "Loss:0.47529488801956177\n",
            "Loss:0.4747828543186188\n",
            "Loss:0.474270761013031\n",
            "Loss:0.4737587571144104\n",
            "Loss:0.47324666380882263\n",
            "Epoch: 160 | Loss: 0.47324666380882263 | Test loss: 0.49105072021484375\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7366]])), ('linear_layer.bias', tensor([0.7584]))])\n",
            "Loss:0.4727345407009125\n",
            "Loss:0.4722225069999695\n",
            "Loss:0.4717104434967041\n",
            "Loss:0.47119832038879395\n",
            "Loss:0.47068628668785095\n",
            "Loss:0.47017422318458557\n",
            "Loss:0.4696621000766754\n",
            "Loss:0.46915000677108765\n",
            "Loss:0.46863803267478943\n",
            "Loss:0.46812596917152405\n",
            "Epoch: 170 | Loss: 0.46812596917152405 | Test loss: 0.4850634038448334\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7349]])), ('linear_layer.bias', tensor([0.7540]))])\n",
            "Loss:0.4676138758659363\n",
            "Loss:0.4671017527580261\n",
            "Loss:0.46658968925476074\n",
            "Loss:0.46607762575149536\n",
            "Loss:0.46556559205055237\n",
            "Loss:0.4650534987449646\n",
            "Loss:0.4645414352416992\n",
            "Loss:0.46402931213378906\n",
            "Loss:0.4635172486305237\n",
            "Loss:0.4630051553249359\n",
            "Epoch: 180 | Loss: 0.4630051553249359 | Test loss: 0.4790760576725006\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7332]])), ('linear_layer.bias', tensor([0.7496]))])\n",
            "Loss:0.4624931216239929\n",
            "Loss:0.46198105812072754\n",
            "Loss:0.46146902441978455\n",
            "Loss:0.46095696091651917\n",
            "Loss:0.460444837808609\n",
            "Loss:0.459932804107666\n",
            "Loss:0.45942074060440063\n",
            "Loss:0.45890864729881287\n",
            "Loss:0.4583965837955475\n",
            "Loss:0.4578844904899597\n",
            "Epoch: 190 | Loss: 0.4578844904899597 | Test loss: 0.47308868169784546\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7314]])), ('linear_layer.bias', tensor([0.7451]))])\n",
            "Loss:0.4573724865913391\n",
            "Loss:0.45686036348342896\n",
            "Loss:0.4563482701778412\n",
            "Loss:0.4558362364768982\n",
            "Loss:0.4553241729736328\n",
            "Loss:0.45481210947036743\n",
            "Loss:0.4542999863624573\n",
            "Loss:0.4537879526615143\n",
            "Loss:0.4532758593559265\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5868417024612427\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5546600818634033\n",
            "Loss:0.5541422367095947\n",
            "Loss:0.5536243319511414\n",
            "Loss:0.5531065464019775\n",
            "Loss:0.5525887608528137\n",
            "Loss:0.5520709156990051\n",
            "Loss:0.5515530109405518\n",
            "Loss:0.5510351657867432\n",
            "Loss:0.5505174398422241\n",
            "Loss:0.5499995350837708\n",
            "Epoch: 10 | Loss: 0.5499995350837708 | Test loss: 0.5807867646217346\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8251]))])\n",
            "Loss:0.5494816303253174\n",
            "Loss:0.5489638447761536\n",
            "Loss:0.5484459400177002\n",
            "Loss:0.5479280948638916\n",
            "Loss:0.5474103093147278\n",
            "Loss:0.5468924045562744\n",
            "Loss:0.5463745594024658\n",
            "Loss:0.5458567142486572\n",
            "Loss:0.5453388690948486\n",
            "Loss:0.54482102394104\n",
            "Epoch: 20 | Loss: 0.54482102394104 | Test loss: 0.5747318267822266\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7609]])), ('linear_layer.bias', tensor([0.8206]))])\n",
            "Loss:0.5443032383918762\n",
            "Loss:0.5437853336334229\n",
            "Loss:0.5432674884796143\n",
            "Loss:0.5427495837211609\n",
            "Loss:0.5422317981719971\n",
            "Loss:0.5417139530181885\n",
            "Loss:0.5411961674690247\n",
            "Loss:0.5406783223152161\n",
            "Loss:0.5401604175567627\n",
            "Loss:0.5396426916122437\n",
            "Epoch: 30 | Loss: 0.5396426916122437 | Test loss: 0.5686768889427185\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7591]])), ('linear_layer.bias', tensor([0.8161]))])\n",
            "Loss:0.5391247868537903\n",
            "Loss:0.5386068820953369\n",
            "Loss:0.5380890965461731\n",
            "Loss:0.5375711917877197\n",
            "Loss:0.5370533466339111\n",
            "Loss:0.5365356206893921\n",
            "Loss:0.536017656326294\n",
            "Loss:0.5354998707771301\n",
            "Loss:0.5349820256233215\n",
            "Loss:0.5344641804695129\n",
            "Epoch: 40 | Loss: 0.5344641804695129 | Test loss: 0.5626219511032104\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7574]])), ('linear_layer.bias', tensor([0.8116]))])\n",
            "Loss:0.5339462757110596\n",
            "Loss:0.5334284901618958\n",
            "Loss:0.5329105854034424\n",
            "Loss:0.5323927998542786\n",
            "Loss:0.5318748950958252\n",
            "Loss:0.5313571095466614\n",
            "Loss:0.5308392643928528\n",
            "Loss:0.530321478843689\n",
            "Loss:0.5298035740852356\n",
            "Loss:0.529285728931427\n",
            "Epoch: 50 | Loss: 0.529285728931427 | Test loss: 0.5565670728683472\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7556]])), ('linear_layer.bias', tensor([0.8071]))])\n",
            "Loss:0.5287678837776184\n",
            "Loss:0.5282500982284546\n",
            "Loss:0.5277321338653564\n",
            "Loss:0.5272143483161926\n",
            "Loss:0.5266964435577393\n",
            "Loss:0.5261785984039307\n",
            "Loss:0.5256608128547668\n",
            "Loss:0.5251429677009583\n",
            "Loss:0.5246250629425049\n",
            "Loss:0.5241072773933411\n",
            "Epoch: 60 | Loss: 0.5241072773933411 | Test loss: 0.5505121946334839\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7538]])), ('linear_layer.bias', tensor([0.8026]))])\n",
            "Loss:0.5235894322395325\n",
            "Loss:0.5230715870857239\n",
            "Loss:0.5225537419319153\n",
            "Loss:0.5220358371734619\n",
            "Loss:0.5215179920196533\n",
            "Loss:0.5210002064704895\n",
            "Loss:0.5204823613166809\n",
            "Loss:0.5199645161628723\n",
            "Loss:0.5194466710090637\n",
            "Loss:0.5189288854598999\n",
            "Epoch: 70 | Loss: 0.5189288854598999 | Test loss: 0.544457197189331\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7521]])), ('linear_layer.bias', tensor([0.7981]))])\n",
            "Loss:0.5184109807014465\n",
            "Loss:0.5178931355476379\n",
            "Loss:0.5173752903938293\n",
            "Loss:0.5168574452400208\n",
            "Loss:0.5163396000862122\n",
            "Loss:0.5158218145370483\n",
            "Loss:0.5153038501739502\n",
            "Loss:0.5147860646247864\n",
            "Loss:0.5142682194709778\n",
            "Loss:0.5137503743171692\n",
            "Epoch: 80 | Loss: 0.5137503743171692 | Test loss: 0.538402259349823\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7503]])), ('linear_layer.bias', tensor([0.7936]))])\n",
            "Loss:0.5132325291633606\n",
            "Loss:0.5127147436141968\n",
            "Loss:0.5121968388557434\n",
            "Loss:0.5116789937019348\n",
            "Loss:0.5111611485481262\n",
            "Loss:0.5106433033943176\n",
            "Loss:0.510125458240509\n",
            "Loss:0.5096076130867004\n",
            "Loss:0.5090897679328918\n",
            "Loss:0.508571982383728\n",
            "Epoch: 90 | Loss: 0.508571982383728 | Test loss: 0.5323473215103149\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7486]])), ('linear_layer.bias', tensor([0.7891]))])\n",
            "Loss:0.5080541372299194\n",
            "Loss:0.5075361728668213\n",
            "Loss:0.5070184469223022\n",
            "Loss:0.5065005421638489\n",
            "Loss:0.5059826970100403\n",
            "Loss:0.5054649114608765\n",
            "Loss:0.5049470663070679\n",
            "Loss:0.5044291615486145\n",
            "Loss:0.5039113759994507\n",
            "Loss:0.5033934712409973\n",
            "Epoch: 100 | Loss: 0.5033934712409973 | Test loss: 0.5262924432754517\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7468]])), ('linear_layer.bias', tensor([0.7846]))])\n",
            "Loss:0.5028756260871887\n",
            "Loss:0.5023578405380249\n",
            "Loss:0.5018399953842163\n",
            "Loss:0.5013220906257629\n",
            "Loss:0.5008043050765991\n",
            "Loss:0.5002864003181458\n",
            "Loss:0.49976855516433716\n",
            "Loss:0.49925073981285095\n",
            "Loss:0.49873286485671997\n",
            "Loss:0.49821504950523376\n",
            "Epoch: 110 | Loss: 0.49821504950523376 | Test loss: 0.5202375054359436\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7451]])), ('linear_layer.bias', tensor([0.7801]))])\n",
            "Loss:0.4976971745491028\n",
            "Loss:0.4971793591976166\n",
            "Loss:0.4966614842414856\n",
            "Loss:0.49614372849464417\n",
            "Loss:0.4956258237361908\n",
            "Loss:0.4951079487800598\n",
            "Loss:0.4945901334285736\n",
            "Loss:0.494072288274765\n",
            "Loss:0.49355441331863403\n",
            "Loss:0.4930365979671478\n",
            "Epoch: 120 | Loss: 0.4930365979671478 | Test loss: 0.5141825079917908\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7433]])), ('linear_layer.bias', tensor([0.7756]))])\n",
            "Loss:0.49251872301101685\n",
            "Loss:0.49200087785720825\n",
            "Loss:0.49148306250572205\n",
            "Loss:0.49096521735191345\n",
            "Loss:0.49044734239578247\n",
            "Loss:0.48992952704429626\n",
            "Loss:0.48941168189048767\n",
            "Loss:0.4888938069343567\n",
            "Loss:0.4883759915828705\n",
            "Loss:0.4878581464290619\n",
            "Epoch: 130 | Loss: 0.4878581464290619 | Test loss: 0.5081275701522827\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7416]])), ('linear_layer.bias', tensor([0.7711]))])\n",
            "Loss:0.4873402714729309\n",
            "Loss:0.4868224561214447\n",
            "Loss:0.4863046109676361\n",
            "Loss:0.4857868254184723\n",
            "Loss:0.4852689802646637\n",
            "Loss:0.4847510755062103\n",
            "Loss:0.48423323035240173\n",
            "Loss:0.48371538519859314\n",
            "Loss:0.48319754004478455\n",
            "Loss:0.48267969489097595\n",
            "Epoch: 140 | Loss: 0.48267969489097595 | Test loss: 0.5020726323127747\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7398]])), ('linear_layer.bias', tensor([0.7666]))])\n",
            "Loss:0.48216184973716736\n",
            "Loss:0.4816439747810364\n",
            "Loss:0.4811261296272278\n",
            "Loss:0.4806083142757416\n",
            "Loss:0.480090469121933\n",
            "Loss:0.4795726239681244\n",
            "Loss:0.47905483841896057\n",
            "Loss:0.4785369336605072\n",
            "Loss:0.4780190587043762\n",
            "Loss:0.47750124335289\n",
            "Epoch: 150 | Loss: 0.47750124335289 | Test loss: 0.4960177540779114\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7381]])), ('linear_layer.bias', tensor([0.7621]))])\n",
            "Loss:0.4769833981990814\n",
            "Loss:0.4764656126499176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%| | 90/100 [00:28<00:04,  2.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.47594770789146423\n",
            "Loss:0.47542986273765564\n",
            "Loss:0.47491198778152466\n",
            "Loss:0.4743942320346832\n",
            "Loss:0.47387632727622986\n",
            "Loss:0.47335848212242126\n",
            "Loss:0.47284063696861267\n",
            "Loss:0.4723227918148041\n",
            "Epoch: 160 | Loss: 0.4723227918148041 | Test loss: 0.48996275663375854\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7363]])), ('linear_layer.bias', tensor([0.7576]))])\n",
            "Loss:0.47180500626564026\n",
            "Loss:0.4712871015071869\n",
            "Loss:0.4707692563533783\n",
            "Loss:0.4702513813972473\n",
            "Loss:0.4697335660457611\n",
            "Loss:0.4692157804965973\n",
            "Loss:0.46869784593582153\n",
            "Loss:0.4681800305843353\n",
            "Loss:0.46766218543052673\n",
            "Loss:0.46714434027671814\n",
            "Epoch: 170 | Loss: 0.46714434027671814 | Test loss: 0.48390787839889526\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7346]])), ('linear_layer.bias', tensor([0.7531]))])\n",
            "Loss:0.4666265547275543\n",
            "Loss:0.46610864996910095\n",
            "Loss:0.46559080481529236\n",
            "Loss:0.46507301926612854\n",
            "Loss:0.46455511450767517\n",
            "Loss:0.46403732895851135\n",
            "Loss:0.46351948380470276\n",
            "Loss:0.4630015790462494\n",
            "Loss:0.46248379349708557\n",
            "Loss:0.4619658887386322\n",
            "Epoch: 180 | Loss: 0.4619658887386322 | Test loss: 0.4778529703617096\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7328]])), ('linear_layer.bias', tensor([0.7487]))])\n",
            "Loss:0.4614481031894684\n",
            "Loss:0.460930198431015\n",
            "Loss:0.4604124128818512\n",
            "Loss:0.4598945677280426\n",
            "Loss:0.45937666296958923\n",
            "Loss:0.45885881781578064\n",
            "Loss:0.45834097266197205\n",
            "Loss:0.45782312750816345\n",
            "Loss:0.45730528235435486\n",
            "Loss:0.45678749680519104\n",
            "Epoch: 190 | Loss: 0.45678749680519104 | Test loss: 0.47179800271987915\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7311]])), ('linear_layer.bias', tensor([0.7442]))])\n",
            "Loss:0.45626965165138245\n",
            "Loss:0.45575180649757385\n",
            "Loss:0.4552339017391205\n",
            "Loss:0.4547160565853119\n",
            "Loss:0.45419827103614807\n",
            "Loss:0.4536803662776947\n",
            "Loss:0.4531625211238861\n",
            "Loss:0.4526447355747223\n",
            "Loss:0.4521268904209137\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5868349075317383\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8296]))])\n",
            "Loss:0.5546542406082153\n",
            "Loss:0.5541306138038635\n",
            "Loss:0.5536068677902222\n",
            "Loss:0.5530832409858704\n",
            "Loss:0.552559494972229\n",
            "Loss:0.552035927772522\n",
            "Loss:0.5515121817588806\n",
            "Loss:0.550988495349884\n",
            "Loss:0.5504648685455322\n",
            "Loss:0.5499411225318909\n",
            "Epoch: 10 | Loss: 0.5499411225318909 | Test loss: 0.580711841583252\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8250]))])\n",
            "Loss:0.5494174957275391\n",
            "Loss:0.5488938093185425\n",
            "Loss:0.5483701825141907\n",
            "Loss:0.5478464365005493\n",
            "Loss:0.5473227500915527\n",
            "Loss:0.5467990636825562\n",
            "Loss:0.5462753772735596\n",
            "Loss:0.5457517504692078\n",
            "Loss:0.5452280044555664\n",
            "Loss:0.5447043180465698\n",
            "Epoch: 20 | Loss: 0.5447043180465698 | Test loss: 0.5745887160301208\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7608]])), ('linear_layer.bias', tensor([0.8205]))])\n",
            "Loss:0.544180691242218\n",
            "Loss:0.5436570048332214\n",
            "Loss:0.5431333780288696\n",
            "Loss:0.5426096320152283\n",
            "Loss:0.5420860052108765\n",
            "Loss:0.5415622591972351\n",
            "Loss:0.5410386323928833\n",
            "Loss:0.5405149459838867\n",
            "Loss:0.5399912595748901\n",
            "Loss:0.5394675731658936\n",
            "Epoch: 30 | Loss: 0.5394675731658936 | Test loss: 0.5684655904769897\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7590]])), ('linear_layer.bias', tensor([0.8159]))])\n",
            "Loss:0.5389439463615417\n",
            "Loss:0.5384202003479004\n",
            "Loss:0.5378965735435486\n",
            "Loss:0.537372887134552\n",
            "Loss:0.5368492007255554\n",
            "Loss:0.5363255739212036\n",
            "Loss:0.5358018279075623\n",
            "Loss:0.5352781414985657\n",
            "Loss:0.5347545146942139\n",
            "Loss:0.5342308282852173\n",
            "Epoch: 40 | Loss: 0.5342308282852173 | Test loss: 0.5623425245285034\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7573]])), ('linear_layer.bias', tensor([0.8114]))])\n",
            "Loss:0.5337071418762207\n",
            "Loss:0.5331834554672241\n",
            "Loss:0.5326597690582275\n",
            "Loss:0.532136082649231\n",
            "Loss:0.5316124558448792\n",
            "Loss:0.5310887694358826\n",
            "Loss:0.5305651426315308\n",
            "Loss:0.5300413370132446\n",
            "Loss:0.529517650604248\n",
            "Loss:0.5289939641952515\n",
            "Epoch: 50 | Loss: 0.5289939641952515 | Test loss: 0.5562194585800171\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7555]])), ('linear_layer.bias', tensor([0.8068]))])\n",
            "Loss:0.5284703969955444\n",
            "Loss:0.5279466509819031\n",
            "Loss:0.5274230241775513\n",
            "Loss:0.5268993377685547\n",
            "Loss:0.5263756513595581\n",
            "Loss:0.5258519649505615\n",
            "Loss:0.5253282785415649\n",
            "Loss:0.5248045921325684\n",
            "Loss:0.5242809057235718\n",
            "Loss:0.5237571597099304\n",
            "Epoch: 60 | Loss: 0.5237571597099304 | Test loss: 0.5500962734222412\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7537]])), ('linear_layer.bias', tensor([0.8023]))])\n",
            "Loss:0.5232335329055786\n",
            "Loss:0.5227099061012268\n",
            "Loss:0.5221861600875854\n",
            "Loss:0.5216625332832336\n",
            "Loss:0.5211388468742371\n",
            "Loss:0.5206152200698853\n",
            "Loss:0.5200914740562439\n",
            "Loss:0.5195678472518921\n",
            "Loss:0.5190441012382507\n",
            "Loss:0.5185204744338989\n",
            "Epoch: 70 | Loss: 0.5185204744338989 | Test loss: 0.5439732074737549\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7520]])), ('linear_layer.bias', tensor([0.7977]))])\n",
            "Loss:0.5179967880249023\n",
            "Loss:0.5174731016159058\n",
            "Loss:0.5169494152069092\n",
            "Loss:0.5164257287979126\n",
            "Loss:0.5159021019935608\n",
            "Loss:0.5153783559799194\n",
            "Loss:0.5148547887802124\n",
            "Loss:0.514331042766571\n",
            "Loss:0.5138073563575745\n",
            "Loss:0.5132836699485779\n",
            "Epoch: 80 | Loss: 0.5132836699485779 | Test loss: 0.537850022315979\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7502]])), ('linear_layer.bias', tensor([0.7932]))])\n",
            "Loss:0.5127600431442261\n",
            "Loss:0.5122362971305847\n",
            "Loss:0.5117126703262329\n",
            "Loss:0.5111890435218811\n",
            "Loss:0.5106652975082397\n",
            "Loss:0.5101416707038879\n",
            "Loss:0.5096179246902466\n",
            "Loss:0.5090943574905396\n",
            "Loss:0.5085705518722534\n",
            "Loss:0.5080469250679016\n",
            "Epoch: 90 | Loss: 0.5080469250679016 | Test loss: 0.5317270159721375\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7484]])), ('linear_layer.bias', tensor([0.7886]))])\n",
            "Loss:0.5075232982635498\n",
            "Loss:0.5069995522499084\n",
            "Loss:0.5064758658409119\n",
            "Loss:0.5059521794319153\n",
            "Loss:0.5054284930229187\n",
            "Loss:0.5049048662185669\n",
            "Loss:0.5043811798095703\n",
            "Loss:0.5038574934005737\n",
            "Loss:0.5033337473869324\n",
            "Loss:0.5028101205825806\n",
            "Epoch: 100 | Loss: 0.5028101205825806 | Test loss: 0.5256038904190063\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7466]])), ('linear_layer.bias', tensor([0.7841]))])\n",
            "Loss:0.5022863745689392\n",
            "Loss:0.5017627477645874\n",
            "Loss:0.5012391209602356\n",
            "Loss:0.5007153749465942\n",
            "Loss:0.5001917481422424\n",
            "Loss:0.49966806173324585\n",
            "Loss:0.49914437532424927\n",
            "Loss:0.4986206889152527\n",
            "Loss:0.49809709191322327\n",
            "Loss:0.4975733757019043\n",
            "Epoch: 110 | Loss: 0.4975733757019043 | Test loss: 0.5194807052612305\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7449]])), ('linear_layer.bias', tensor([0.7796]))])\n",
            "Loss:0.4970496594905853\n",
            "Loss:0.49652600288391113\n",
            "Loss:0.49600228667259216\n",
            "Loss:0.49547863006591797\n",
            "Loss:0.4949549734592438\n",
            "Loss:0.4944313168525696\n",
            "Loss:0.49390754103660583\n",
            "Loss:0.4933839440345764\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 91%| | 91/100 [00:29<00:04,  2.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.49286025762557983\n",
            "Loss:0.49233657121658325\n",
            "Epoch: 120 | Loss: 0.49233657121658325 | Test loss: 0.5133576989173889\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7431]])), ('linear_layer.bias', tensor([0.7750]))])\n",
            "Loss:0.49181288480758667\n",
            "Loss:0.4912892282009125\n",
            "Loss:0.4907655119895935\n",
            "Loss:0.4902418553829193\n",
            "Loss:0.4897181987762451\n",
            "Loss:0.48919448256492615\n",
            "Loss:0.4886707663536072\n",
            "Loss:0.48814716935157776\n",
            "Loss:0.487623393535614\n",
            "Loss:0.4870997965335846\n",
            "Epoch: 130 | Loss: 0.4870997965335846 | Test loss: 0.5072345733642578\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7413]])), ('linear_layer.bias', tensor([0.7705]))])\n",
            "Loss:0.4865761399269104\n",
            "Loss:0.48605242371559143\n",
            "Loss:0.48552870750427246\n",
            "Loss:0.48500508069992065\n",
            "Loss:0.48448142409324646\n",
            "Loss:0.4839577078819275\n",
            "Loss:0.4834340214729309\n",
            "Loss:0.4829103350639343\n",
            "Loss:0.48238664865493774\n",
            "Loss:0.48186296224594116\n",
            "Epoch: 140 | Loss: 0.48186296224594116 | Test loss: 0.5011114478111267\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7395]])), ('linear_layer.bias', tensor([0.7659]))])\n",
            "Loss:0.48133936524391174\n",
            "Loss:0.4808156490325928\n",
            "Loss:0.4802919924259186\n",
            "Loss:0.4797683358192444\n",
            "Loss:0.4792446196079254\n",
            "Loss:0.4787209630012512\n",
            "Loss:0.47819727659225464\n",
            "Loss:0.47767359018325806\n",
            "Loss:0.4771498739719391\n",
            "Loss:0.4766262471675873\n",
            "Epoch: 150 | Loss: 0.4766262471675873 | Test loss: 0.494988352060318\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7378]])), ('linear_layer.bias', tensor([0.7614]))])\n",
            "Loss:0.4761025309562683\n",
            "Loss:0.4755788743495941\n",
            "Loss:0.4750552177429199\n",
            "Loss:0.47453147172927856\n",
            "Loss:0.474007785320282\n",
            "Loss:0.47348418831825256\n",
            "Loss:0.4729604721069336\n",
            "Loss:0.4724368155002594\n",
            "Loss:0.4719131588935852\n",
            "Loss:0.47138938307762146\n",
            "Epoch: 160 | Loss: 0.47138938307762146 | Test loss: 0.4888652265071869\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7360]])), ('linear_layer.bias', tensor([0.7568]))])\n",
            "Loss:0.47086572647094727\n",
            "Loss:0.47034206986427307\n",
            "Loss:0.4698184132575989\n",
            "Loss:0.4692947268486023\n",
            "Loss:0.4687710404396057\n",
            "Loss:0.4682474136352539\n",
            "Loss:0.46772369742393494\n",
            "Loss:0.46720004081726074\n",
            "Loss:0.46667638421058655\n",
            "Loss:0.4661526679992676\n",
            "Epoch: 170 | Loss: 0.4661526679992676 | Test loss: 0.48274216055870056\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7342]])), ('linear_layer.bias', tensor([0.7523]))])\n",
            "Loss:0.4656289517879486\n",
            "Loss:0.4651053547859192\n",
            "Loss:0.46458157896995544\n",
            "Loss:0.464057981967926\n",
            "Loss:0.46353426575660706\n",
            "Loss:0.46301060914993286\n",
            "Loss:0.4624868929386139\n",
            "Loss:0.4619632661342621\n",
            "Loss:0.4614395201206207\n",
            "Loss:0.4609158933162689\n",
            "Epoch: 180 | Loss: 0.4609158933162689 | Test loss: 0.47661906480789185\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7325]])), ('linear_layer.bias', tensor([0.7477]))])\n",
            "Loss:0.46039217710494995\n",
            "Loss:0.45986852049827576\n",
            "Loss:0.45934486389160156\n",
            "Loss:0.4588211476802826\n",
            "Loss:0.4582975506782532\n",
            "Loss:0.45777377486228943\n",
            "Loss:0.45725011825561523\n",
            "Loss:0.4567264914512634\n",
            "Loss:0.45620280504226685\n",
            "Loss:0.4556790888309479\n",
            "Epoch: 190 | Loss: 0.4556790888309479 | Test loss: 0.4704959988594055\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7307]])), ('linear_layer.bias', tensor([0.7432]))])\n",
            "Loss:0.4551554322242737\n",
            "Loss:0.4546317160129547\n",
            "Loss:0.4541080594062805\n",
            "Loss:0.45358437299728394\n",
            "Loss:0.45306071639060974\n",
            "Loss:0.45253705978393555\n",
            "Loss:0.4520133435726166\n",
            "Loss:0.4514896869659424\n",
            "Loss:0.450965940952301\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5868280529975891\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8295]))])\n",
            "Loss:0.5546484589576721\n",
            "Loss:0.5541189908981323\n",
            "Loss:0.5535894632339478\n",
            "Loss:0.5530599355697632\n",
            "Loss:0.5525304079055786\n",
            "Loss:0.552000880241394\n",
            "Loss:0.5514713525772095\n",
            "Loss:0.5509418249130249\n",
            "Loss:0.5504123568534851\n",
            "Loss:0.5498828887939453\n",
            "Epoch: 10 | Loss: 0.5498828887939453 | Test loss: 0.5806367993354797\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7626]])), ('linear_layer.bias', tensor([0.8250]))])\n",
            "Loss:0.549353301525116\n",
            "Loss:0.5488237738609314\n",
            "Loss:0.5482942461967468\n",
            "Loss:0.547764778137207\n",
            "Loss:0.5472352504730225\n",
            "Loss:0.5467057824134827\n",
            "Loss:0.5461761951446533\n",
            "Loss:0.5456466674804688\n",
            "Loss:0.5451172590255737\n",
            "Loss:0.5445877313613892\n",
            "Epoch: 20 | Loss: 0.5445877313613892 | Test loss: 0.5744454860687256\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7608]])), ('linear_layer.bias', tensor([0.8204]))])\n",
            "Loss:0.5440582036972046\n",
            "Loss:0.54352867603302\n",
            "Loss:0.5429991483688354\n",
            "Loss:0.5424696207046509\n",
            "Loss:0.5419400930404663\n",
            "Loss:0.5414106249809265\n",
            "Loss:0.5408810973167419\n",
            "Loss:0.5403516888618469\n",
            "Loss:0.5398220419883728\n",
            "Loss:0.5392926335334778\n",
            "Epoch: 30 | Loss: 0.5392926335334778 | Test loss: 0.568254292011261\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7590]])), ('linear_layer.bias', tensor([0.8158]))])\n",
            "Loss:0.5387630462646484\n",
            "Loss:0.5382335782051086\n",
            "Loss:0.5377041101455688\n",
            "Loss:0.5371745228767395\n",
            "Loss:0.5366450548171997\n",
            "Loss:0.5361155271530151\n",
            "Loss:0.5355859994888306\n",
            "Loss:0.5350565314292908\n",
            "Loss:0.5345269441604614\n",
            "Loss:0.5339974761009216\n",
            "Epoch: 40 | Loss: 0.5339974761009216 | Test loss: 0.5620630383491516\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7572]])), ('linear_layer.bias', tensor([0.8112]))])\n",
            "Loss:0.5334679484367371\n",
            "Loss:0.5329384803771973\n",
            "Loss:0.5324089527130127\n",
            "Loss:0.5318794250488281\n",
            "Loss:0.5313498973846436\n",
            "Loss:0.530820369720459\n",
            "Loss:0.5302909016609192\n",
            "Loss:0.5297614336013794\n",
            "Loss:0.5292319059371948\n",
            "Loss:0.5287023782730103\n",
            "Epoch: 50 | Loss: 0.5287023782730103 | Test loss: 0.5558716654777527\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7554]])), ('linear_layer.bias', tensor([0.8066]))])\n",
            "Loss:0.5281728506088257\n",
            "Loss:0.5276433229446411\n",
            "Loss:0.5271137952804565\n",
            "Loss:0.526584267616272\n",
            "Loss:0.5260547995567322\n",
            "Loss:0.5255252718925476\n",
            "Loss:0.524995744228363\n",
            "Loss:0.5244662165641785\n",
            "Loss:0.5239367485046387\n",
            "Loss:0.5234072208404541\n",
            "Epoch: 60 | Loss: 0.5234072208404541 | Test loss: 0.5496804714202881\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7536]])), ('linear_layer.bias', tensor([0.8020]))])\n",
            "Loss:0.5228777527809143\n",
            "Loss:0.5223482251167297\n",
            "Loss:0.5218186974525452\n",
            "Loss:0.5212891697883606\n",
            "Loss:0.5207597017288208\n",
            "Loss:0.5202301740646362\n",
            "Loss:0.5197006464004517\n",
            "Loss:0.5191711187362671\n",
            "Loss:0.5186416506767273\n",
            "Loss:0.518112063407898\n",
            "Epoch: 70 | Loss: 0.518112063407898 | Test loss: 0.5434890985488892\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7518]])), ('linear_layer.bias', tensor([0.7974]))])\n",
            "Loss:0.5175825953483582\n",
            "Loss:0.5170531272888184\n",
            "Loss:0.5165236592292786\n",
            "Loss:0.515994131565094\n",
            "Loss:0.5154646039009094\n",
            "Loss:0.5149350762367249\n",
            "Loss:0.5144055485725403\n",
            "Loss:0.5138760209083557\n",
            "Loss:0.5133464932441711\n",
            "Loss:0.5128170251846313\n",
            "Epoch: 80 | Loss: 0.5128170251846313 | Test loss: 0.5372979044914246\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7500]])), ('linear_layer.bias', tensor([0.7928]))])\n",
            "Loss:0.5122874975204468\n",
            "Loss:0.5117579698562622\n",
            "Loss:0.5112284421920776\n",
            "Loss:0.5106989741325378\n",
            "Loss:0.5101694464683533\n",
            "Loss:0.5096399188041687\n",
            "Loss:0.5091104507446289\n",
            "Loss:0.5085809230804443\n",
            "Loss:0.5080513954162598\n",
            "Loss:0.50752192735672\n",
            "Epoch: 90 | Loss: 0.50752192735672 | Test loss: 0.5311066508293152\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7482]])), ('linear_layer.bias', tensor([0.7882]))])\n",
            "Loss:0.5069923400878906\n",
            "Loss:0.5064628720283508\n",
            "Loss:0.505933403968811\n",
            "Loss:0.5054038763046265\n",
            "Loss:0.5048742890357971\n",
            "Loss:0.5043448209762573\n",
            "Loss:0.5038152933120728\n",
            "Loss:0.503285825252533\n",
            "Loss:0.5027562975883484\n",
            "Loss:0.502226710319519\n",
            "Epoch: 100 | Loss: 0.502226710319519 | Test loss: 0.524915337562561\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7464]])), ('linear_layer.bias', tensor([0.7836]))])\n",
            "Loss:0.5016972422599792\n",
            "Loss:0.5011677742004395\n",
            "Loss:0.5006381869316101\n",
            "Loss:0.5001087188720703\n",
            "Loss:0.4995792508125305\n",
            "Loss:0.49904975295066833\n",
            "Loss:0.4985201954841614\n",
            "Loss:0.4979906976222992\n",
            "Loss:0.49746114015579224\n",
            "Loss:0.49693164229393005\n",
            "Epoch: 110 | Loss: 0.49693164229393005 | Test loss: 0.5187240839004517\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7446]])), ('linear_layer.bias', tensor([0.7790]))])\n",
            "Loss:0.4964021146297455\n",
            "Loss:0.4958726763725281\n",
            "Loss:0.4953431189060211\n",
            "Loss:0.49481362104415894\n",
            "Loss:0.49428409337997437\n",
            "Loss:0.49375462532043457\n",
            "Loss:0.49322509765625\n",
            "Loss:0.49269551038742065\n",
            "Loss:0.49216604232788086\n",
            "Loss:0.49163657426834106\n",
            "Epoch: 120 | Loss: 0.49163657426834106 | Test loss: 0.5125328302383423\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7429]])), ('linear_layer.bias', tensor([0.7744]))])\n",
            "Loss:0.4911070466041565\n",
            "Loss:0.4905775189399719\n",
            "Loss:0.49004799127578735\n",
            "Loss:0.48951849341392517\n",
            "Loss:0.4889890253543854\n",
            "Loss:0.48845943808555603\n",
            "Loss:0.48792997002601624\n",
            "Loss:0.48740047216415405\n",
            "Loss:0.4868709444999695\n",
            "Loss:0.4863414168357849\n",
            "Epoch: 130 | Loss: 0.4863414168357849 | Test loss: 0.5063415765762329\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7411]])), ('linear_layer.bias', tensor([0.7698]))])\n",
            "Loss:0.4858119487762451\n",
            "Loss:0.48528242111206055\n",
            "Loss:0.4847528338432312\n",
            "Loss:0.4842233657836914\n",
            "Loss:0.48369383811950684\n",
            "Loss:0.48316437005996704\n",
            "Loss:0.48263484239578247\n",
            "Loss:0.4821053445339203\n",
            "Loss:0.48157578706741333\n",
            "Loss:0.48104628920555115\n",
            "Epoch: 140 | Loss: 0.48104628920555115 | Test loss: 0.5001502633094788\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7393]])), ('linear_layer.bias', tensor([0.7652]))])\n",
            "Loss:0.48051682114601135\n",
            "Loss:0.479987233877182\n",
            "Loss:0.4794577658176422\n",
            "Loss:0.47892826795578003\n",
            "Loss:0.47839874029159546\n",
            "Loss:0.47786927223205566\n",
            "Loss:0.4773397445678711\n",
            "Loss:0.4768102765083313\n",
            "Loss:0.47628074884414673\n",
            "Loss:0.47575122117996216\n",
            "Epoch: 150 | Loss: 0.47575122117996216 | Test loss: 0.4939590096473694\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7375]])), ('linear_layer.bias', tensor([0.7606]))])\n",
            "Loss:0.4752216935157776\n",
            "Loss:0.4746921956539154\n",
            "Loss:0.47416266798973083\n",
            "Loss:0.47363314032554626\n",
            "Loss:0.4731036126613617\n",
            "Loss:0.4725741446018219\n",
            "Loss:0.47204455733299255\n",
            "Loss:0.47151511907577515\n",
            "Loss:0.4709855616092682\n",
            "Loss:0.470456063747406\n",
            "Epoch: 160 | Loss: 0.470456063747406 | Test loss: 0.48776775598526\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7357]])), ('linear_layer.bias', tensor([0.7560]))])\n",
            "Loss:0.4699265956878662\n",
            "Loss:0.46939706802368164\n",
            "Loss:0.46886754035949707\n",
            "Loss:0.4683380126953125\n",
            "Loss:0.4678085446357727\n",
            "Loss:0.46727901697158813\n",
            "Loss:0.46674948930740356\n",
            "Loss:0.466219961643219\n",
            "Loss:0.4656904637813568\n",
            "Loss:0.46516093611717224\n",
            "Epoch: 170 | Loss: 0.46516093611717224 | Test loss: 0.48157650232315063\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7339]])), ('linear_layer.bias', tensor([0.7514]))])\n",
            "Loss:0.46463146805763245\n",
            "Loss:0.4641018807888031\n",
            "Loss:0.46357235312461853\n",
            "Loss:0.4630429148674011\n",
            "Loss:0.46251344680786133\n",
            "Loss:0.46198397874832153\n",
            "Loss:0.4614543914794922\n",
            "Loss:0.4609249234199524\n",
            "Loss:0.46039533615112305\n",
            "Loss:0.45986586809158325\n",
            "Epoch: 180 | Loss: 0.45986586809158325 | Test loss: 0.4753851294517517\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7321]])), ('linear_layer.bias', tensor([0.7468]))])\n",
            "Loss:0.45933637022972107"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 92%|| 92/100 [00:29<00:03,  2.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loss:0.4588068425655365\n",
            "Loss:0.45827731490135193\n",
            "Loss:0.45774784684181213\n",
            "Loss:0.4572182595729828\n",
            "Loss:0.456688791513443\n",
            "Loss:0.4561592936515808\n",
            "Loss:0.45562973618507385\n",
            "Loss:0.45510023832321167\n",
            "Loss:0.4545707106590271\n",
            "Epoch: 190 | Loss: 0.4545707106590271 | Test loss: 0.4691939353942871\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7303]])), ('linear_layer.bias', tensor([0.7422]))])\n",
            "Loss:0.4540412425994873\n",
            "Loss:0.45351171493530273\n",
            "Loss:0.45298224687576294\n",
            "Loss:0.45245271921157837\n",
            "Loss:0.4519231915473938\n",
            "Loss:0.45139366388320923\n",
            "Loss:0.45086413621902466\n",
            "Loss:0.4503346383571625\n",
            "Loss:0.4498051702976227\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5868212580680847\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8295]))])\n",
            "Loss:0.5546426177024841\n",
            "Loss:0.5541073679924011\n",
            "Loss:0.5535720586776733\n",
            "Loss:0.5530368089675903\n",
            "Loss:0.5525014996528625\n",
            "Loss:0.5519662499427795\n",
            "Loss:0.5514309406280518\n",
            "Loss:0.5508956909179688\n",
            "Loss:0.5503603219985962\n",
            "Loss:0.549825131893158\n",
            "Epoch: 10 | Loss: 0.549825131893158 | Test loss: 0.5805625319480896\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7625]])), ('linear_layer.bias', tensor([0.8249]))])\n",
            "Loss:0.5492898225784302\n",
            "Loss:0.5487545132637024\n",
            "Loss:0.5482192039489746\n",
            "Loss:0.5476839542388916\n",
            "Loss:0.547148585319519\n",
            "Loss:0.546613335609436\n",
            "Loss:0.546078085899353\n",
            "Loss:0.5455427765846252\n",
            "Loss:0.5450075268745422\n",
            "Loss:0.5444721579551697\n",
            "Epoch: 20 | Loss: 0.5444721579551697 | Test loss: 0.5743036270141602\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7607]])), ('linear_layer.bias', tensor([0.8203]))])\n",
            "Loss:0.5439369082450867\n",
            "Loss:0.5434015989303589\n",
            "Loss:0.5428663492202759\n",
            "Loss:0.5423310995101929\n",
            "Loss:0.5417958498001099\n",
            "Loss:0.5412605404853821\n",
            "Loss:0.5407252907752991\n",
            "Loss:0.5401899218559265\n",
            "Loss:0.5396546125411987\n",
            "Loss:0.5391193628311157\n",
            "Epoch: 30 | Loss: 0.5391193628311157 | Test loss: 0.5680447816848755\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7589]])), ('linear_layer.bias', tensor([0.8156]))])\n",
            "Loss:0.5385841131210327\n",
            "Loss:0.5380488634109497\n",
            "Loss:0.5375135540962219\n",
            "Loss:0.5369782447814941\n",
            "Loss:0.5364429354667664\n",
            "Loss:0.5359076261520386\n",
            "Loss:0.5353723764419556\n",
            "Loss:0.5348371267318726\n",
            "Loss:0.5343018174171448\n",
            "Loss:0.5337665677070618\n",
            "Epoch: 40 | Loss: 0.5337665677070618 | Test loss: 0.5617859363555908\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7571]])), ('linear_layer.bias', tensor([0.8110]))])\n",
            "Loss:0.5332311987876892\n",
            "Loss:0.5326959490776062\n",
            "Loss:0.5321606397628784\n",
            "Loss:0.5316253900527954\n",
            "Loss:0.5310900807380676\n",
            "Loss:0.5305548310279846\n",
            "Loss:0.5300194621086121\n",
            "Loss:0.529484212398529\n",
            "Loss:0.528948962688446\n",
            "Loss:0.5284136533737183\n",
            "Epoch: 50 | Loss: 0.5284136533737183 | Test loss: 0.5555270910263062\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7553]])), ('linear_layer.bias', tensor([0.8063]))])\n",
            "Loss:0.5278783440589905\n",
            "Loss:0.5273430943489075\n",
            "Loss:0.5268078446388245\n",
            "Loss:0.5262725353240967\n",
            "Loss:0.5257372260093689\n",
            "Loss:0.5252019166946411\n",
            "Loss:0.5246666669845581\n",
            "Loss:0.5241314172744751\n",
            "Loss:0.5235961079597473\n",
            "Loss:0.5230607986450195\n",
            "Epoch: 60 | Loss: 0.5230607986450195 | Test loss: 0.5492682456970215\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7535]])), ('linear_layer.bias', tensor([0.8017]))])\n",
            "Loss:0.5225254893302917\n",
            "Loss:0.521990180015564\n",
            "Loss:0.5214549899101257\n",
            "Loss:0.520919680595398\n",
            "Loss:0.5203843712806702\n",
            "Loss:0.5198491215705872\n",
            "Loss:0.5193138122558594\n",
            "Loss:0.5187785029411316\n",
            "Loss:0.5182431936264038\n",
            "Loss:0.5177079439163208\n",
            "Epoch: 70 | Loss: 0.5177079439163208 | Test loss: 0.5430094003677368\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7517]])), ('linear_layer.bias', tensor([0.7970]))])\n",
            "Loss:0.5171726942062378\n",
            "Loss:0.5166374444961548\n",
            "Loss:0.5161020755767822\n",
            "Loss:0.5155668258666992\n",
            "Loss:0.5150315165519714\n",
            "Loss:0.5144962072372437\n",
            "Loss:0.5139609575271606\n",
            "Loss:0.5134257078170776\n",
            "Loss:0.5128903985023499\n",
            "Loss:0.5123550891876221\n",
            "Epoch: 80 | Loss: 0.5123550891876221 | Test loss: 0.5367504954338074\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7499]])), ('linear_layer.bias', tensor([0.7924]))])\n",
            "Loss:0.5118197202682495\n",
            "Loss:0.5112844705581665\n",
            "Loss:0.5107492208480835\n",
            "Loss:0.5102139711380005\n",
            "Loss:0.5096787214279175\n",
            "Loss:0.5091433525085449\n",
            "Loss:0.5086081027984619\n",
            "Loss:0.5080727934837341\n",
            "Loss:0.5075375437736511\n",
            "Loss:0.5070022344589233\n",
            "Epoch: 90 | Loss: 0.5070022344589233 | Test loss: 0.5304917097091675\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7480]])), ('linear_layer.bias', tensor([0.7877]))])\n",
            "Loss:0.5064669847488403\n",
            "Loss:0.5059316754341125\n",
            "Loss:0.5053963661193848\n",
            "Loss:0.5048611760139465\n",
            "Loss:0.504325807094574\n",
            "Loss:0.503790557384491\n",
            "Loss:0.5032552480697632\n",
            "Loss:0.5027199387550354\n",
            "Loss:0.5021846890449524\n",
            "Loss:0.5016493797302246\n",
            "Epoch: 100 | Loss: 0.5016493797302246 | Test loss: 0.5242328643798828\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7462]])), ('linear_layer.bias', tensor([0.7831]))])\n",
            "Loss:0.5011140704154968\n",
            "Loss:0.5005788207054138\n",
            "Loss:0.500043511390686\n",
            "Loss:0.4995082914829254\n",
            "Loss:0.49897295236587524\n",
            "Loss:0.49843770265579224\n",
            "Loss:0.4979023337364197\n",
            "Loss:0.49736714363098145\n",
            "Loss:0.4968318045139313\n",
            "Loss:0.49629655480384827\n",
            "Epoch: 110 | Loss: 0.49629655480384827 | Test loss: 0.5179740190505981\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7444]])), ('linear_layer.bias', tensor([0.7784]))])\n",
            "Loss:0.4957612156867981\n",
            "Loss:0.4952259659767151\n",
            "Loss:0.4946906566619873\n",
            "Loss:0.4941553473472595\n",
            "Loss:0.4936200976371765\n",
            "Loss:0.4930848181247711\n",
            "Loss:0.49254950881004333\n",
            "Loss:0.4920142590999603\n",
            "Loss:0.49147897958755493\n",
            "Loss:0.4909436106681824\n",
            "Epoch: 120 | Loss: 0.4909436106681824 | Test loss: 0.5117151737213135\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7426]])), ('linear_layer.bias', tensor([0.7738]))])\n",
            "Loss:0.49040836095809937\n",
            "Loss:0.48987308144569397\n",
            "Loss:0.48933783173561096\n",
            "Loss:0.4888025224208832\n",
            "Loss:0.4882672429084778\n",
            "Loss:0.48773193359375\n",
            "Loss:0.487196683883667\n",
            "Loss:0.486661434173584\n",
            "Loss:0.4861260950565338\n",
            "Loss:0.4855908453464508\n",
            "Epoch: 130 | Loss: 0.4855908453464508 | Test loss: 0.5054563283920288\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7408]])), ('linear_layer.bias', tensor([0.7691]))])\n",
            "Loss:0.48505550622940063\n",
            "Loss:0.4845202565193176\n",
            "Loss:0.48398494720458984\n",
            "Loss:0.48344969749450684\n",
            "Loss:0.48291438817977905\n",
            "Loss:0.48237910866737366\n",
            "Loss:0.4818437993526459\n",
            "Loss:0.48130854964256287\n",
            "Loss:0.4807732105255127\n",
            "Loss:0.4802379608154297\n",
            "Epoch: 140 | Loss: 0.4802379608154297 | Test loss: 0.49919742345809937\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7390]])), ('linear_layer.bias', tensor([0.7645]))])\n",
            "Loss:0.4797026515007019\n",
            "Loss:0.4791674017906189\n",
            "Loss:0.4786320626735687\n",
            "Loss:0.4780968129634857\n",
            "Loss:0.47756147384643555\n",
            "Loss:0.47702622413635254\n",
            "Loss:0.47649097442626953\n",
            "Loss:0.47595566511154175\n",
            "Loss:0.47542041540145874\n",
            "Loss:0.47488507628440857\n",
            "Epoch: 150 | Loss: 0.47488507628440857 | Test loss: 0.49293866753578186\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7372]])), ('linear_layer.bias', tensor([0.7599]))])\n",
            "Loss:0.47434982657432556\n",
            "Loss:0.47381454706192017\n",
            "Loss:0.4732792377471924\n",
            "Loss:0.4727439284324646\n",
            "Loss:0.4722086787223816\n",
            "Loss:0.4716733992099762\n",
            "Loss:0.4711380898952484\n",
            "Loss:0.470602810382843\n",
            "Loss:0.47006756067276\n",
            "Loss:0.469532310962677\n",
            "Epoch: 160 | Loss: 0.469532310962677 | Test loss: 0.48667973279953003\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7354]])), ('linear_layer.bias', tensor([0.7552]))])\n",
            "Loss:0.46899694204330444\n",
            "Loss:0.46846169233322144\n",
            "Loss:0.46792641282081604\n",
            "Loss:0.46739116311073303\n",
            "Loss:0.46685582399368286\n",
            "Loss:0.46632057428359985\n",
            "Loss:0.46578526496887207\n",
            "Loss:0.46525001525878906\n",
            "Loss:0.4647146761417389"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|| 93/100 [00:30<00:03,  1.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loss:0.4641793668270111\n",
            "Epoch: 170 | Loss: 0.4641793668270111 | Test loss: 0.48042091727256775\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7336]])), ('linear_layer.bias', tensor([0.7506]))])\n",
            "Loss:0.4636441171169281\n",
            "Loss:0.4631088376045227\n",
            "Loss:0.4625735282897949\n",
            "Loss:0.4620382785797119\n",
            "Loss:0.46150293946266174\n",
            "Loss:0.46096768975257874\n",
            "Loss:0.4604324400424957\n",
            "Loss:0.45989710092544556\n",
            "Loss:0.45936188101768494\n",
            "Loss:0.45882654190063477\n",
            "Epoch: 180 | Loss: 0.45882654190063477 | Test loss: 0.47416210174560547\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7317]])), ('linear_layer.bias', tensor([0.7459]))])\n",
            "Loss:0.458291232585907\n",
            "Loss:0.457755982875824\n",
            "Loss:0.4572207033634186\n",
            "Loss:0.4566853940486908\n",
            "Loss:0.4561501145362854\n",
            "Loss:0.4556148648262024\n",
            "Loss:0.4550795555114746\n",
            "Loss:0.4545442461967468\n",
            "Loss:0.45400896668434143\n",
            "Loss:0.45347365736961365\n",
            "Epoch: 190 | Loss: 0.45347365736961365 | Test loss: 0.4679032862186432\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7299]])), ('linear_layer.bias', tensor([0.7413]))])\n",
            "Loss:0.45293840765953064\n",
            "Loss:0.45240315794944763\n",
            "Loss:0.45186781883239746\n",
            "Loss:0.45133256912231445\n",
            "Loss:0.45079725980758667\n",
            "Loss:0.45026201009750366\n",
            "Loss:0.4497266709804535\n",
            "Loss:0.4491914212703705\n",
            "Loss:0.4486561417579651\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5868145227432251\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8295]))])\n",
            "Loss:0.5546367764472961\n",
            "Loss:0.5540956258773804\n",
            "Loss:0.5535545945167542\n",
            "Loss:0.5530134439468384\n",
            "Loss:0.5524723529815674\n",
            "Loss:0.5519312620162964\n",
            "Loss:0.5513900518417358\n",
            "Loss:0.5508489608764648\n",
            "Loss:0.5503078699111938\n",
            "Loss:0.5497667193412781\n",
            "Epoch: 10 | Loss: 0.5497667193412781 | Test loss: 0.5804874897003174\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7625]])), ('linear_layer.bias', tensor([0.8248]))])\n",
            "Loss:0.5492256283760071\n",
            "Loss:0.5486844778060913\n",
            "Loss:0.5481433868408203\n",
            "Loss:0.5476022362709045\n",
            "Loss:0.5470611453056335\n",
            "Loss:0.5465201139450073\n",
            "Loss:0.5459789037704468\n",
            "Loss:0.5454378128051758\n",
            "Loss:0.54489666223526\n",
            "Loss:0.5443555116653442\n",
            "Epoch: 20 | Loss: 0.5443555116653442 | Test loss: 0.5741605162620544\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7607]])), ('linear_layer.bias', tensor([0.8201]))])\n",
            "Loss:0.5438144207000732\n",
            "Loss:0.5432733297348022\n",
            "Loss:0.5427321791648865\n",
            "Loss:0.5421910285949707\n",
            "Loss:0.5416499972343445\n",
            "Loss:0.5411087870597839\n",
            "Loss:0.5405676960945129\n",
            "Loss:0.5400265455245972\n",
            "Loss:0.539485514163971\n",
            "Loss:0.5389443635940552\n",
            "Epoch: 30 | Loss: 0.5389443635940552 | Test loss: 0.5678334832191467\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7589]])), ('linear_layer.bias', tensor([0.8154]))])\n",
            "Loss:0.5384032726287842\n",
            "Loss:0.5378621220588684\n",
            "Loss:0.5373209714889526\n",
            "Loss:0.5367798805236816\n",
            "Loss:0.5362387895584106\n",
            "Loss:0.5356975793838501\n",
            "Loss:0.5351565480232239\n",
            "Loss:0.5346153974533081\n",
            "Loss:0.5340742468833923\n",
            "Loss:0.5335332155227661\n",
            "Epoch: 40 | Loss: 0.5335332155227661 | Test loss: 0.5615063905715942\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7570]])), ('linear_layer.bias', tensor([0.8108]))])\n",
            "Loss:0.5329920649528503\n",
            "Loss:0.5324509739875793\n",
            "Loss:0.5319098234176636\n",
            "Loss:0.5313687324523926\n",
            "Loss:0.5308275818824768\n",
            "Loss:0.530286431312561\n",
            "Loss:0.52974534034729\n",
            "Loss:0.529204249382019\n",
            "Loss:0.5286630392074585\n",
            "Loss:0.5281219482421875\n",
            "Epoch: 50 | Loss: 0.5281219482421875 | Test loss: 0.5551794767379761\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7552]])), ('linear_layer.bias', tensor([0.8061]))])\n",
            "Loss:0.5275808572769165\n",
            "Loss:0.5270397067070007\n",
            "Loss:0.5264986753463745\n",
            "Loss:0.525957465171814\n",
            "Loss:0.5254164338111877\n",
            "Loss:0.524875283241272\n",
            "Loss:0.524334192276001\n",
            "Loss:0.5237930417060852\n",
            "Loss:0.5232518911361694\n",
            "Loss:0.5227108001708984\n",
            "Epoch: 60 | Loss: 0.5227108001708984 | Test loss: 0.5488523840904236\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7534]])), ('linear_layer.bias', tensor([0.8014]))])\n",
            "Loss:0.5221697092056274\n",
            "Loss:0.5216285586357117\n",
            "Loss:0.5210874676704407\n",
            "Loss:0.5205463171005249\n",
            "Loss:0.5200052261352539\n",
            "Loss:0.5194640159606934\n",
            "Loss:0.5189229249954224\n",
            "Loss:0.5183818936347961\n",
            "Loss:0.5178407430648804\n",
            "Loss:0.5172995328903198\n",
            "Epoch: 70 | Loss: 0.5172995328903198 | Test loss: 0.5425254106521606\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7515]])), ('linear_layer.bias', tensor([0.7967]))])\n",
            "Loss:0.5167585015296936\n",
            "Loss:0.5162173509597778\n",
            "Loss:0.5156762599945068\n",
            "Loss:0.5151351094245911\n",
            "Loss:0.5145940184593201\n",
            "Loss:0.5140528678894043\n",
            "Loss:0.5135117769241333\n",
            "Loss:0.5129706263542175\n",
            "Loss:0.5124295949935913\n",
            "Loss:0.5118883848190308\n",
            "Epoch: 80 | Loss: 0.5118883848190308 | Test loss: 0.5361983776092529\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7497]])), ('linear_layer.bias', tensor([0.7920]))])\n",
            "Loss:0.5113472938537598\n",
            "Loss:0.5108062028884888\n",
            "Loss:0.510265052318573\n",
            "Loss:0.5097239017486572\n",
            "Loss:0.5091828107833862\n",
            "Loss:0.5086416602134705\n",
            "Loss:0.5081006288528442\n",
            "Loss:0.5075594782829285\n",
            "Loss:0.5070183873176575\n",
            "Loss:0.5064772367477417\n",
            "Epoch: 90 | Loss: 0.5064772367477417 | Test loss: 0.5298713445663452\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7479]])), ('linear_layer.bias', tensor([0.7873]))])\n",
            "Loss:0.5059361457824707\n",
            "Loss:0.5053949952125549\n",
            "Loss:0.5048538446426392\n",
            "Loss:0.5043127536773682\n",
            "Loss:0.5037716627120972\n",
            "Loss:0.5032305121421814\n",
            "Loss:0.5026894211769104\n",
            "Loss:0.5021482706069946\n",
            "Loss:0.5016071200370789\n",
            "Loss:0.5010660290718079\n",
            "Epoch: 100 | Loss: 0.5010660290718079 | Test loss: 0.523544430732727\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7460]])), ('linear_layer.bias', tensor([0.7826]))])\n",
            "Loss:0.5005248785018921\n",
            "Loss:0.4999837875366211\n",
            "Loss:0.4994426667690277\n",
            "Loss:0.4989015460014343\n",
            "Loss:0.49836045503616333\n",
            "Loss:0.49781933426856995\n",
            "Loss:0.49727821350097656\n",
            "Loss:0.4967370927333832\n",
            "Loss:0.4961959719657898\n",
            "Loss:0.495654821395874\n",
            "Epoch: 110 | Loss: 0.495654821395874 | Test loss: 0.5172172784805298\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7442]])), ('linear_layer.bias', tensor([0.7779]))])\n",
            "Loss:0.4951137602329254\n",
            "Loss:0.49457257986068726\n",
            "Loss:0.49403151869773865\n",
            "Loss:0.49349039793014526\n",
            "Loss:0.49294930696487427\n",
            "Loss:0.4924081861972809\n",
            "Loss:0.4918670058250427\n",
            "Loss:0.49132585525512695\n",
            "Loss:0.49078473448753357\n",
            "Loss:0.49024367332458496\n",
            "Epoch: 120 | Loss: 0.49024367332458496 | Test loss: 0.5108903646469116\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7424]])), ('linear_layer.bias', tensor([0.7732]))])\n",
            "Loss:0.48970261216163635\n",
            "Loss:0.4891614019870758\n",
            "Loss:0.4886202812194824\n",
            "Loss:0.48807916045188904\n",
            "Loss:0.48753803968429565\n",
            "Loss:0.4869968891143799\n",
            "Loss:0.4864558279514313\n",
            "Loss:0.4859147071838379\n",
            "Loss:0.4853735864162445\n",
            "Loss:0.48483243584632874\n",
            "Epoch: 130 | Loss: 0.48483243584632874 | Test loss: 0.5045632719993591\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7405]])), ('linear_layer.bias', tensor([0.7685]))])\n",
            "Loss:0.4842913746833801\n",
            "Loss:0.4837501645088196\n",
            "Loss:0.4832090735435486\n",
            "Loss:0.4826679825782776\n",
            "Loss:0.4821268618106842\n",
            "Loss:0.4815857410430908\n",
            "Loss:0.48104462027549744\n",
            "Loss:0.48050349950790405\n",
            "Loss:0.47996243834495544\n",
            "Loss:0.4794212281703949\n",
            "Epoch: 140 | Loss: 0.4794212281703949 | Test loss: 0.4982362687587738\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7387]])), ('linear_layer.bias', tensor([0.7638]))])\n",
            "Loss:0.4788801074028015\n",
            "Loss:0.4783390164375305\n",
            "Loss:0.4777979254722595\n",
            "Loss:0.47725677490234375\n",
            "Loss:0.47671571373939514\n",
            "Loss:0.47617459297180176\n",
            "Loss:0.4756334722042084\n",
            "Loss:0.4750923216342926\n",
            "Loss:0.4745512008666992\n",
            "Loss:0.47401008009910583\n",
            "Epoch: 150 | Loss: 0.47401008009910583 | Test loss: 0.49190932512283325\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7369]])), ('linear_layer.bias', tensor([0.7591]))])\n",
            "Loss:0.47346895933151245\n",
            "Loss:0.47292786836624146\n",
            "Loss:0.47238674759864807\n",
            "Loss:0.4718456268310547\n",
            "Loss:0.4713045060634613\n",
            "Loss:0.4707633852958679\n",
            "Loss:0.47022223472595215\n",
            "Loss:0.46968111395835876\n",
            "Loss:0.4691399931907654\n",
            "Loss:0.4685989022254944\n",
            "Epoch: 160 | Loss: 0.4685989022254944 | Test loss: 0.48558226227760315\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7350]])), ('linear_layer.bias', tensor([0.7544]))])\n",
            "Loss:0.468057781457901\n",
            "Loss:0.4675167202949524\n",
            "Loss:0.46697553992271423\n",
            "Loss:0.4664344787597656\n",
            "Loss:0.4658932685852051\n",
            "Loss:0.46535220742225647\n",
            "Loss:0.4648110270500183\n",
            "Loss:0.4642699658870697\n",
            "Loss:0.46372881531715393\n",
            "Loss:0.4631877541542053\n",
            "Epoch: 170 | Loss: 0.4631877541542053 | Test loss: 0.47925519943237305\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7332]])), ('linear_layer.bias', tensor([0.7497]))])\n",
            "Loss:0.46264657378196716\n",
            "Loss:0.46210557222366333\n",
            "Loss:0.4615643620491028\n",
            "Loss:0.4610231816768646\n",
            "Loss:0.460482120513916\n",
            "Loss:0.45994096994400024\n",
            "Loss:0.45939987897872925\n",
            "Loss:0.4588587284088135\n",
            "Loss:0.45831766724586487\n",
            "Loss:0.4577765464782715\n",
            "Epoch: 180 | Loss: 0.4577765464782715 | Test loss: 0.4729281961917877\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7314]])), ('linear_layer.bias', tensor([0.7450]))])\n",
            "Loss:0.4572354257106781\n",
            "Loss:0.45669427514076233\n",
            "Loss:0.45615315437316895"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 94%|| 94/100 [00:31<00:03,  1.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loss:0.45561209321022034\n",
            "Loss:0.45507097244262695\n",
            "Loss:0.45452985167503357\n",
            "Loss:0.4539887011051178\n",
            "Loss:0.4534475803375244\n",
            "Loss:0.45290642976760864\n",
            "Loss:0.45236530900001526\n",
            "Epoch: 190 | Loss: 0.45236530900001526 | Test loss: 0.4666012227535248\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7296]])), ('linear_layer.bias', tensor([0.7403]))])\n",
            "Loss:0.4518241882324219\n",
            "Loss:0.4512830674648285\n",
            "Loss:0.4507419466972351\n",
            "Loss:0.4502008557319641\n",
            "Loss:0.4496597349643707\n",
            "Loss:0.44911861419677734\n",
            "Loss:0.44857749342918396\n",
            "Loss:0.4480363428592682\n",
            "Loss:0.4474952816963196\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5868076682090759\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8295]))])\n",
            "Loss:0.5546310544013977\n",
            "Loss:0.5540840029716492\n",
            "Loss:0.5535370707511902\n",
            "Loss:0.5529901385307312\n",
            "Loss:0.5524431467056274\n",
            "Loss:0.5518962144851685\n",
            "Loss:0.5513492822647095\n",
            "Loss:0.5508022904396057\n",
            "Loss:0.5502553582191467\n",
            "Loss:0.5497084259986877\n",
            "Epoch: 10 | Loss: 0.5497084259986877 | Test loss: 0.5804124474525452\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7625]])), ('linear_layer.bias', tensor([0.8248]))])\n",
            "Loss:0.549161434173584\n",
            "Loss:0.548614501953125\n",
            "Loss:0.548067569732666\n",
            "Loss:0.547520637512207\n",
            "Loss:0.5469736456871033\n",
            "Loss:0.5464266538619995\n",
            "Loss:0.5458797216415405\n",
            "Loss:0.5453327894210815\n",
            "Loss:0.5447858572006226\n",
            "Loss:0.5442389249801636\n",
            "Epoch: 20 | Loss: 0.5442389249801636 | Test loss: 0.5740174055099487\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7607]])), ('linear_layer.bias', tensor([0.8200]))])\n",
            "Loss:0.5436919331550598\n",
            "Loss:0.5431450009346008\n",
            "Loss:0.5425980091094971\n",
            "Loss:0.5420510172843933\n",
            "Loss:0.5415040850639343\n",
            "Loss:0.5409571528434753\n",
            "Loss:0.5404102206230164\n",
            "Loss:0.5398632287979126\n",
            "Loss:0.5393162965774536\n",
            "Loss:0.5387693643569946\n",
            "Epoch: 30 | Loss: 0.5387693643569946 | Test loss: 0.5676220655441284\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7588]])), ('linear_layer.bias', tensor([0.8153]))])\n",
            "Loss:0.5382224321365356\n",
            "Loss:0.5376754999160767\n",
            "Loss:0.5371285080909729\n",
            "Loss:0.5365815162658691\n",
            "Loss:0.5360345840454102\n",
            "Loss:0.5354875922203064\n",
            "Loss:0.5349406599998474\n",
            "Loss:0.5343937277793884\n",
            "Loss:0.5338467359542847\n",
            "Loss:0.5332998037338257\n",
            "Epoch: 40 | Loss: 0.5332998037338257 | Test loss: 0.5612269639968872\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7569]])), ('linear_layer.bias', tensor([0.8105]))])\n",
            "Loss:0.5327528715133667\n",
            "Loss:0.5322059392929077\n",
            "Loss:0.5316590070724487\n",
            "Loss:0.531112015247345\n",
            "Loss:0.530565083026886\n",
            "Loss:0.530018150806427\n",
            "Loss:0.5294710993766785\n",
            "Loss:0.5289242267608643\n",
            "Loss:0.5283772945404053\n",
            "Loss:0.5278303027153015\n",
            "Epoch: 50 | Loss: 0.5278303027153015 | Test loss: 0.5548317432403564\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7551]])), ('linear_layer.bias', tensor([0.8058]))])\n",
            "Loss:0.5272833108901978\n",
            "Loss:0.5267363786697388\n",
            "Loss:0.5261894464492798\n",
            "Loss:0.5256425142288208\n",
            "Loss:0.525095522403717\n",
            "Loss:0.5245486497879028\n",
            "Loss:0.5240015983581543\n",
            "Loss:0.5234546661376953\n",
            "Loss:0.5229077935218811\n",
            "Loss:0.5223607420921326\n",
            "Epoch: 60 | Loss: 0.5223607420921326 | Test loss: 0.5484365820884705\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7532]])), ('linear_layer.bias', tensor([0.8010]))])\n",
            "Loss:0.5218138694763184\n",
            "Loss:0.5212668776512146\n",
            "Loss:0.5207199454307556\n",
            "Loss:0.5201729536056519\n",
            "Loss:0.5196260213851929\n",
            "Loss:0.5190790295600891\n",
            "Loss:0.5185320973396301\n",
            "Loss:0.5179852247238159\n",
            "Loss:0.5174382328987122\n",
            "Loss:0.5168912410736084\n",
            "Epoch: 70 | Loss: 0.5168912410736084 | Test loss: 0.5420414209365845\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7514]])), ('linear_layer.bias', tensor([0.7963]))])\n",
            "Loss:0.5163442492485046\n",
            "Loss:0.5157973766326904\n",
            "Loss:0.5152503848075867\n",
            "Loss:0.5147034525871277\n",
            "Loss:0.5141565203666687\n",
            "Loss:0.5136095285415649\n",
            "Loss:0.513062596321106\n",
            "Loss:0.5125156044960022\n",
            "Loss:0.511968731880188\n",
            "Loss:0.5114216804504395\n",
            "Epoch: 80 | Loss: 0.5114216804504395 | Test loss: 0.5356461405754089\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7495]])), ('linear_layer.bias', tensor([0.7916]))])\n",
            "Loss:0.5108748078346252\n",
            "Loss:0.5103277564048767\n",
            "Loss:0.5097808241844177\n",
            "Loss:0.5092339515686035\n",
            "Loss:0.5086870193481445\n",
            "Loss:0.508139967918396\n",
            "Loss:0.507593035697937\n",
            "Loss:0.507046103477478\n",
            "Loss:0.5064991116523743\n",
            "Loss:0.5059522390365601\n",
            "Epoch: 90 | Loss: 0.5059522390365601 | Test loss: 0.5292510390281677\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7477]])), ('linear_layer.bias', tensor([0.7868]))])\n",
            "Loss:0.5054053068161011\n",
            "Loss:0.5048582553863525\n",
            "Loss:0.5043113827705383\n",
            "Loss:0.5037643909454346\n",
            "Loss:0.5032174587249756\n",
            "Loss:0.5026704668998718\n",
            "Loss:0.5021235346794128\n",
            "Loss:0.5015765428543091\n",
            "Loss:0.5010296106338501\n",
            "Loss:0.5004826784133911\n",
            "Epoch: 100 | Loss: 0.5004826784133911 | Test loss: 0.5228558778762817\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7458]])), ('linear_layer.bias', tensor([0.7821]))])\n",
            "Loss:0.49993571639060974\n",
            "Loss:0.49938878417015076\n",
            "Loss:0.4988418519496918\n",
            "Loss:0.4982948899269104\n",
            "Loss:0.49774789810180664\n",
            "Loss:0.49720096588134766\n",
            "Loss:0.49665403366088867\n",
            "Loss:0.4961070418357849\n",
            "Loss:0.4955601096153259\n",
            "Loss:0.4950130879878998\n",
            "Epoch: 110 | Loss: 0.4950130879878998 | Test loss: 0.516460657119751\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7440]])), ('linear_layer.bias', tensor([0.7773]))])\n",
            "Loss:0.49446621537208557\n",
            "Loss:0.4939192831516266\n",
            "Loss:0.4933722913265228\n",
            "Loss:0.49282535910606384\n",
            "Loss:0.49227839708328247\n",
            "Loss:0.4917314648628235\n",
            "Loss:0.4911845326423645\n",
            "Loss:0.49063754081726074\n",
            "Loss:0.490090548992157\n",
            "Loss:0.489543616771698\n",
            "Epoch: 120 | Loss: 0.489543616771698 | Test loss: 0.5100655555725098\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7421]])), ('linear_layer.bias', tensor([0.7726]))])\n",
            "Loss:0.488996684551239\n",
            "Loss:0.48844972252845764\n",
            "Loss:0.48790279030799866\n",
            "Loss:0.4873557984828949\n",
            "Loss:0.4868088662624359\n",
            "Loss:0.48626193404197693\n",
            "Loss:0.48571497201919556\n",
            "Loss:0.4851680397987366\n",
            "Loss:0.4846210479736328\n",
            "Loss:0.48407411575317383\n",
            "Epoch: 130 | Loss: 0.48407411575317383 | Test loss: 0.5036702752113342\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7403]])), ('linear_layer.bias', tensor([0.7678]))])\n",
            "Loss:0.48352712392807007\n",
            "Loss:0.4829801917076111\n",
            "Loss:0.4824332296848297\n",
            "Loss:0.4818863272666931\n",
            "Loss:0.48133936524391174\n",
            "Loss:0.480792373418808\n",
            "Loss:0.4802454113960266\n",
            "Loss:0.47969850897789\n",
            "Loss:0.47915154695510864\n",
            "Loss:0.4786045551300049\n",
            "Epoch: 140 | Loss: 0.4786045551300049 | Test loss: 0.49727511405944824\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7384]])), ('linear_layer.bias', tensor([0.7631]))])\n",
            "Loss:0.4780576229095459\n",
            "Loss:0.4775106906890869\n",
            "Loss:0.47696375846862793\n",
            "Loss:0.47641676664352417\n",
            "Loss:0.4758698046207428\n",
            "Loss:0.4753228724002838\n",
            "Loss:0.47477594017982483\n",
            "Loss:0.47422894835472107\n",
            "Loss:0.4736819863319397\n",
            "Loss:0.4731350541114807\n",
            "Epoch: 150 | Loss: 0.4731350541114807 | Test loss: 0.4908798635005951\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7366]])), ('linear_layer.bias', tensor([0.7583]))])\n",
            "Loss:0.47258806228637695\n",
            "Loss:0.47204113006591797\n",
            "Loss:0.471494197845459\n",
            "Loss:0.4709472060203552\n",
            "Loss:0.47040027379989624\n",
            "Loss:0.46985334157943726\n",
            "Loss:0.46930640935897827\n",
            "Loss:0.4687594473361969\n",
            "Loss:0.4682125151157379\n",
            "Loss:0.46766549348831177\n",
            "Epoch: 160 | Loss: 0.46766549348831177 | Test loss: 0.4844847321510315\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7347]])), ('linear_layer.bias', tensor([0.7536]))])\n",
            "Loss:0.46711865067481995\n",
            "Loss:0.4665716290473938\n",
            "Loss:0.46602463722229004\n",
            "Loss:0.46547776460647583\n",
            "Loss:0.46493077278137207\n",
            "Loss:0.4643837809562683\n",
            "Loss:0.4638368487358093\n",
            "Loss:0.46328988671302795\n",
            "Loss:0.46274298429489136\n",
            "Loss:0.46219602227211\n",
            "Epoch: 170 | Loss: 0.46219602227211 | Test loss: 0.47808951139450073\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7329]])), ('linear_layer.bias', tensor([0.7488]))])\n",
            "Loss:0.4616490304470062\n",
            "Loss:0.46110209822654724\n",
            "Loss:0.46055516600608826\n",
            "Loss:0.4600082039833069\n",
            "Loss:0.4594612717628479\n",
            "Loss:0.4589143395423889\n",
            "Loss:0.45836734771728516\n",
            "Loss:0.45782047510147095\n",
            "Loss:0.4572734236717224\n",
            "Loss:0.45672646164894104\n",
            "Epoch: 180 | Loss: 0.45672646164894104 | Test loss: 0.47169432044029236\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7310]])), ('linear_layer.bias', tensor([0.7441]))])\n",
            "Loss:0.45617952942848206\n",
            "Loss:0.45563259720802307\n",
            "Loss:0.4550856053829193\n",
            "Loss:0.45453864336013794\n",
            "Loss:0.45399171113967896\n",
            "Loss:0.45344477891921997\n",
            "Loss:0.452897846698761"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 95%|| 95/100 [00:32<00:03,  1.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loss:0.4523508548736572\n",
            "Loss:0.45180392265319824\n",
            "Loss:0.4512569308280945\n",
            "Epoch: 190 | Loss: 0.4512569308280945 | Test loss: 0.46529918909072876\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7292]])), ('linear_layer.bias', tensor([0.7393]))])\n",
            "Loss:0.4507099986076355\n",
            "Loss:0.4501630365848541\n",
            "Loss:0.44961604475975037\n",
            "Loss:0.44906917214393616\n",
            "Loss:0.4485221803188324\n",
            "Loss:0.4479752480983734\n",
            "Loss:0.44742828607559204\n",
            "Loss:0.44688135385513306\n",
            "Loss:0.4463343620300293\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5868008136749268\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7644]])), ('linear_layer.bias', tensor([0.8295]))])\n",
            "Loss:0.5546251535415649\n",
            "Loss:0.554072380065918\n",
            "Loss:0.553519606590271\n",
            "Loss:0.5529667735099792\n",
            "Loss:0.552414059638977\n",
            "Loss:0.5518612265586853\n",
            "Loss:0.5513084530830383\n",
            "Loss:0.5507556796073914\n",
            "Loss:0.5502028465270996\n",
            "Loss:0.5496500730514526\n",
            "Epoch: 10 | Loss: 0.5496500730514526 | Test loss: 0.5803374648094177\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7625]])), ('linear_layer.bias', tensor([0.8247]))])\n",
            "Loss:0.5490972995758057\n",
            "Loss:0.5485445261001587\n",
            "Loss:0.5479917526245117\n",
            "Loss:0.54743891954422\n",
            "Loss:0.546886146068573\n",
            "Loss:0.5463334321975708\n",
            "Loss:0.5457805395126343\n",
            "Loss:0.5452278256416321\n",
            "Loss:0.5446749925613403\n",
            "Loss:0.5441222190856934\n",
            "Epoch: 20 | Loss: 0.5441222190856934 | Test loss: 0.5738742351531982\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7606]])), ('linear_layer.bias', tensor([0.8199]))])\n",
            "Loss:0.5435694456100464\n",
            "Loss:0.5430166721343994\n",
            "Loss:0.5424638986587524\n",
            "Loss:0.5419110059738159\n",
            "Loss:0.5413582921028137\n",
            "Loss:0.5408055186271667\n",
            "Loss:0.5402527451515198\n",
            "Loss:0.539699912071228\n",
            "Loss:0.539147138595581\n",
            "Loss:0.5385943651199341\n",
            "Epoch: 30 | Loss: 0.5385943651199341 | Test loss: 0.5674108266830444\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7587]])), ('linear_layer.bias', tensor([0.8151]))])\n",
            "Loss:0.5380415320396423\n",
            "Loss:0.5374888181686401\n",
            "Loss:0.5369359850883484\n",
            "Loss:0.5363832116127014\n",
            "Loss:0.5358303785324097\n",
            "Loss:0.5352776050567627\n",
            "Loss:0.5347248911857605\n",
            "Loss:0.5341720581054688\n",
            "Loss:0.5336192846298218\n",
            "Loss:0.53306645154953\n",
            "Epoch: 40 | Loss: 0.53306645154953 | Test loss: 0.5609474778175354\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7569]])), ('linear_layer.bias', tensor([0.8103]))])\n",
            "Loss:0.5325137376785278\n",
            "Loss:0.5319609642028809\n",
            "Loss:0.5314081907272339\n",
            "Loss:0.5308553576469421\n",
            "Loss:0.5303025841712952\n",
            "Loss:0.5297497510910034\n",
            "Loss:0.5291970372200012\n",
            "Loss:0.5286442041397095\n",
            "Loss:0.5280914306640625\n",
            "Loss:0.5275386571884155\n",
            "Epoch: 50 | Loss: 0.5275386571884155 | Test loss: 0.5544840693473816\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7550]])), ('linear_layer.bias', tensor([0.8055]))])\n",
            "Loss:0.5269858241081238\n",
            "Loss:0.5264330506324768\n",
            "Loss:0.5258802771568298\n",
            "Loss:0.5253275036811829\n",
            "Loss:0.5247746706008911\n",
            "Loss:0.5242218971252441\n",
            "Loss:0.5236691236495972\n",
            "Loss:0.5231163501739502\n",
            "Loss:0.5225635766983032\n",
            "Loss:0.5220108032226562\n",
            "Epoch: 60 | Loss: 0.5220108032226562 | Test loss: 0.5480207204818726\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7531]])), ('linear_layer.bias', tensor([0.8007]))])\n",
            "Loss:0.5214579701423645\n",
            "Loss:0.5209051966667175\n",
            "Loss:0.5203524231910706\n",
            "Loss:0.5197995901107788\n",
            "Loss:0.5192468762397766\n",
            "Loss:0.5186940431594849\n",
            "Loss:0.5181412696838379\n",
            "Loss:0.5175884962081909\n",
            "Loss:0.5170356631278992\n",
            "Loss:0.516482949256897\n",
            "Epoch: 70 | Loss: 0.516482949256897 | Test loss: 0.5415573716163635\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7513]])), ('linear_layer.bias', tensor([0.7959]))])\n",
            "Loss:0.5159301161766052\n",
            "Loss:0.5153773427009583\n",
            "Loss:0.5148245692253113\n",
            "Loss:0.5142717957496643\n",
            "Loss:0.5137189626693726\n",
            "Loss:0.5131662487983704\n",
            "Loss:0.5126134157180786\n",
            "Loss:0.5120605826377869\n",
            "Loss:0.5115078687667847\n",
            "Loss:0.5109550356864929\n",
            "Epoch: 80 | Loss: 0.5109550356864929 | Test loss: 0.5350939631462097\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7494]])), ('linear_layer.bias', tensor([0.7911]))])\n",
            "Loss:0.5104023218154907\n",
            "Loss:0.5098494291305542\n",
            "Loss:0.509296715259552\n",
            "Loss:0.508743941783905\n",
            "Loss:0.5081911087036133\n",
            "Loss:0.5076383352279663\n",
            "Loss:0.5070855021476746\n",
            "Loss:0.5065327882766724\n",
            "Loss:0.5059800148010254\n",
            "Loss:0.5054271817207336\n",
            "Epoch: 90 | Loss: 0.5054271817207336 | Test loss: 0.5286306738853455\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7475]])), ('linear_layer.bias', tensor([0.7863]))])\n",
            "Loss:0.5048744678497314\n",
            "Loss:0.5043216347694397\n",
            "Loss:0.503768801689148\n",
            "Loss:0.5032160878181458\n",
            "Loss:0.502663254737854\n",
            "Loss:0.502110481262207\n",
            "Loss:0.5015577077865601\n",
            "Loss:0.5010048747062683\n",
            "Loss:0.5004521608352661\n",
            "Loss:0.49989932775497437\n",
            "Epoch: 100 | Loss: 0.49989932775497437 | Test loss: 0.5221673250198364\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7456]])), ('linear_layer.bias', tensor([0.7815]))])\n",
            "Loss:0.4993465542793274\n",
            "Loss:0.4987937808036804\n",
            "Loss:0.49824094772338867\n",
            "Loss:0.4976882040500641\n",
            "Loss:0.4971354603767395\n",
            "Loss:0.49658259749412537\n",
            "Loss:0.4960298538208008\n",
            "Loss:0.49547702074050903\n",
            "Loss:0.49492424726486206\n",
            "Loss:0.4943714737892151\n",
            "Epoch: 110 | Loss: 0.4943714737892151 | Test loss: 0.5157040357589722\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7438]])), ('linear_layer.bias', tensor([0.7767]))])\n",
            "Loss:0.4938187003135681\n",
            "Loss:0.49326592683792114\n",
            "Loss:0.4927131235599518\n",
            "Loss:0.4921603202819824\n",
            "Loss:0.49160751700401306\n",
            "Loss:0.4910547733306885\n",
            "Loss:0.4905019700527191\n",
            "Loss:0.48994916677474976\n",
            "Loss:0.4893963932991028\n",
            "Loss:0.4888436198234558\n",
            "Epoch: 120 | Loss: 0.4888436198234558 | Test loss: 0.5092406272888184\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7419]])), ('linear_layer.bias', tensor([0.7720]))])\n",
            "Loss:0.48829084634780884\n",
            "Loss:0.4877380430698395\n",
            "Loss:0.4871852397918701\n",
            "Loss:0.48663243651390076\n",
            "Loss:0.48607969284057617\n",
            "Loss:0.4855269491672516\n",
            "Loss:0.48497408628463745\n",
            "Loss:0.48442134261131287\n",
            "Loss:0.4838685095310211\n",
            "Loss:0.48331576585769653\n",
            "Epoch: 130 | Loss: 0.48331576585769653 | Test loss: 0.5027772784233093\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7400]])), ('linear_layer.bias', tensor([0.7672]))])\n",
            "Loss:0.48276299238204956\n",
            "Loss:0.4822101593017578\n",
            "Loss:0.4816574156284332\n",
            "Loss:0.48110461235046387\n",
            "Loss:0.4805518090724945\n",
            "Loss:0.47999900579452515\n",
            "Loss:0.47944626212120056\n",
            "Loss:0.4788934588432312\n",
            "Loss:0.4783407151699066\n",
            "Loss:0.47778791189193726\n",
            "Epoch: 140 | Loss: 0.47778791189193726 | Test loss: 0.4963138997554779\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7382]])), ('linear_layer.bias', tensor([0.7624]))])\n",
            "Loss:0.4772350788116455\n",
            "Loss:0.4766823351383209\n",
            "Loss:0.47612953186035156\n",
            "Loss:0.4755767285823822\n",
            "Loss:0.47502392530441284\n",
            "Loss:0.47447118163108826\n",
            "Loss:0.47391843795776367\n",
            "Loss:0.4733656048774719\n",
            "Loss:0.47281283140182495\n",
            "Loss:0.4722599983215332\n",
            "Epoch: 150 | Loss: 0.4722599983215332 | Test loss: 0.4898505210876465\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7363]])), ('linear_layer.bias', tensor([0.7576]))])\n",
            "Loss:0.4717072546482086\n",
            "Loss:0.47115451097488403\n",
            "Loss:0.4706017076969147\n",
            "Loss:0.4700489044189453\n",
            "Loss:0.46949610114097595\n",
            "Loss:0.4689432978630066\n",
            "Loss:0.4683905243873596\n",
            "Loss:0.46783775091171265\n",
            "Loss:0.4672849774360657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 96%|| 96/100 [00:32<00:02,  1.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.4667321741580963\n",
            "Epoch: 160 | Loss: 0.4667321741580963 | Test loss: 0.48338714241981506\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7344]])), ('linear_layer.bias', tensor([0.7528]))])\n",
            "Loss:0.46617943048477173\n",
            "Loss:0.4656265676021576\n",
            "Loss:0.465073823928833\n",
            "Loss:0.46452102065086365\n",
            "Loss:0.4639682173728943\n",
            "Loss:0.4634154438972473\n",
            "Loss:0.46286267042160034\n",
            "Loss:0.46230992674827576\n",
            "Loss:0.461757093667984\n",
            "Loss:0.4612043499946594\n",
            "Epoch: 170 | Loss: 0.4612043499946594 | Test loss: 0.4769238531589508\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7325]])), ('linear_layer.bias', tensor([0.7480]))])\n",
            "Loss:0.4606514871120453\n",
            "Loss:0.4600987434387207\n",
            "Loss:0.45954591035842896\n",
            "Loss:0.458993136882782\n",
            "Loss:0.4584403932094574\n",
            "Loss:0.45788758993148804\n",
            "Loss:0.45733481645584106\n",
            "Loss:0.4567820131778717\n",
            "Loss:0.4562292695045471\n",
            "Loss:0.45567646622657776\n",
            "Epoch: 180 | Loss: 0.45567646622657776 | Test loss: 0.4704604744911194\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7307]])), ('linear_layer.bias', tensor([0.7432]))])\n",
            "Loss:0.4551236629486084\n",
            "Loss:0.4545709192752838\n",
            "Loss:0.45401811599731445\n",
            "Loss:0.4534653127193451\n",
            "Loss:0.45291250944137573\n",
            "Loss:0.45235976576805115\n",
            "Loss:0.4518069326877594\n",
            "Loss:0.4512541890144348\n",
            "Loss:0.45070141553878784\n",
            "Loss:0.4501485824584961\n",
            "Epoch: 190 | Loss: 0.4501485824584961 | Test loss: 0.46399712562561035\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7288]])), ('linear_layer.bias', tensor([0.7384]))])\n",
            "Loss:0.44959577918052673\n",
            "Loss:0.4490429759025574\n",
            "Loss:0.4484902322292328\n",
            "Loss:0.4479374885559082\n",
            "Loss:0.44738465547561646\n",
            "Loss:0.4468318819999695\n",
            "Loss:0.4462791085243225\n",
            "Loss:0.44572630524635315\n",
            "Loss:0.4451735019683838\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5867940783500671\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8295]))])\n",
            "Loss:0.5546193718910217\n",
            "Loss:0.5540608167648315\n",
            "Loss:0.5535022616386414\n",
            "Loss:0.552943766117096\n",
            "Loss:0.552385151386261\n",
            "Loss:0.5518265962600708\n",
            "Loss:0.5512679815292358\n",
            "Loss:0.5507093667984009\n",
            "Loss:0.5501508712768555\n",
            "Loss:0.5495923757553101\n",
            "Epoch: 10 | Loss: 0.5495923757553101 | Test loss: 0.5802631974220276\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7625]])), ('linear_layer.bias', tensor([0.8247]))])\n",
            "Loss:0.5490337610244751\n",
            "Loss:0.5484752655029297\n",
            "Loss:0.5479167103767395\n",
            "Loss:0.5473581552505493\n",
            "Loss:0.5467996001243591\n",
            "Loss:0.5462409853935242\n",
            "Loss:0.5456824898719788\n",
            "Loss:0.5451238751411438\n",
            "Loss:0.5445653200149536\n",
            "Loss:0.5440067052841187\n",
            "Epoch: 20 | Loss: 0.5440067052841187 | Test loss: 0.5737322568893433\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7606]])), ('linear_layer.bias', tensor([0.8198]))])\n",
            "Loss:0.5434482097625732\n",
            "Loss:0.5428895950317383\n",
            "Loss:0.5423310995101929\n",
            "Loss:0.5417724847793579\n",
            "Loss:0.541213870048523\n",
            "Loss:0.5406553745269775\n",
            "Loss:0.5400968790054321\n",
            "Loss:0.5395382642745972\n",
            "Loss:0.538979709148407\n",
            "Loss:0.538421094417572\n",
            "Epoch: 30 | Loss: 0.538421094417572 | Test loss: 0.5672013163566589\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7587]])), ('linear_layer.bias', tensor([0.8150]))])\n",
            "Loss:0.5378625392913818\n",
            "Loss:0.5373039841651917\n",
            "Loss:0.5367454290390015\n",
            "Loss:0.5361868739128113\n",
            "Loss:0.5356283187866211\n",
            "Loss:0.5350698232650757\n",
            "Loss:0.5345112085342407\n",
            "Loss:0.5339525938034058\n",
            "Loss:0.5333941578865051\n",
            "Loss:0.5328354835510254\n",
            "Epoch: 40 | Loss: 0.5328354835510254 | Test loss: 0.5606703758239746\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7568]])), ('linear_layer.bias', tensor([0.8101]))])\n",
            "Loss:0.53227698802948\n",
            "Loss:0.5317184329032898\n",
            "Loss:0.5311598777770996\n",
            "Loss:0.5306013226509094\n",
            "Loss:0.5300427675247192\n",
            "Loss:0.529484212398529\n",
            "Loss:0.5289255976676941\n",
            "Loss:0.5283670425415039\n",
            "Loss:0.5278084874153137\n",
            "Loss:0.5272499322891235\n",
            "Epoch: 50 | Loss: 0.5272499322891235 | Test loss: 0.5541394948959351\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7549]])), ('linear_layer.bias', tensor([0.8053]))])\n",
            "Loss:0.5266913175582886\n",
            "Loss:0.5261327624320984\n",
            "Loss:0.525574266910553\n",
            "Loss:0.5250157117843628\n",
            "Loss:0.5244571566581726\n",
            "Loss:0.5238986015319824\n",
            "Loss:0.5233400464057922\n",
            "Loss:0.522781491279602\n",
            "Loss:0.5222228765487671\n",
            "Loss:0.5216643214225769\n",
            "Epoch: 60 | Loss: 0.5216643214225769 | Test loss: 0.547608494758606\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7530]])), ('linear_layer.bias', tensor([0.8004]))])\n",
            "Loss:0.5211057662963867\n",
            "Loss:0.5205472707748413\n",
            "Loss:0.5199886560440063\n",
            "Loss:0.5194300413131714\n",
            "Loss:0.5188716053962708\n",
            "Loss:0.5183129906654358\n",
            "Loss:0.5177544355392456\n",
            "Loss:0.5171958208084106\n",
            "Loss:0.5166373252868652\n",
            "Loss:0.516078770160675\n",
            "Epoch: 70 | Loss: 0.516078770160675 | Test loss: 0.5410776138305664\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7511]])), ('linear_layer.bias', tensor([0.7956]))])\n",
            "Loss:0.5155202150344849\n",
            "Loss:0.5149616003036499\n",
            "Loss:0.5144031047821045\n",
            "Loss:0.5138444900512695\n",
            "Loss:0.5132859945297241\n",
            "Loss:0.5127273797988892\n",
            "Loss:0.5121687650680542\n",
            "Loss:0.5116103291511536\n",
            "Loss:0.5110517740249634\n",
            "Loss:0.5104931592941284\n",
            "Epoch: 80 | Loss: 0.5104931592941284 | Test loss: 0.5345467329025269\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7492]])), ('linear_layer.bias', tensor([0.7907]))])\n",
            "Loss:0.5099346041679382\n",
            "Loss:0.509376049041748\n",
            "Loss:0.5088174939155579\n",
            "Loss:0.5082589387893677\n",
            "Loss:0.5077003240585327\n",
            "Loss:0.5071417689323425\n",
            "Loss:0.5065832138061523\n",
            "Loss:0.5060247182846069\n",
            "Loss:0.505466103553772\n",
            "Loss:0.5049075484275818\n",
            "Epoch: 90 | Loss: 0.5049075484275818 | Test loss: 0.5280157327651978\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7473]])), ('linear_layer.bias', tensor([0.7859]))])\n",
            "Loss:0.5043489933013916\n",
            "Loss:0.5037904977798462\n",
            "Loss:0.5032318830490112\n",
            "Loss:0.502673327922821\n",
            "Loss:0.5021147727966309\n",
            "Loss:0.5015562176704407\n",
            "Loss:0.5009976625442505\n",
            "Loss:0.5004390478134155\n",
            "Loss:0.4998805522918701\n",
            "Loss:0.49932193756103516\n",
            "Epoch: 100 | Loss: 0.49932193756103516 | Test loss: 0.5214847922325134\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7454]])), ('linear_layer.bias', tensor([0.7810]))])\n",
            "Loss:0.49876338243484497\n",
            "Loss:0.4982048571109772\n",
            "Loss:0.4976462721824646\n",
            "Loss:0.49708765745162964\n",
            "Loss:0.49652910232543945\n",
            "Loss:0.49597054719924927\n",
            "Loss:0.49541205167770386\n",
            "Loss:0.49485349655151367\n",
            "Loss:0.4942949414253235\n",
            "Loss:0.4937363266944885\n",
            "Epoch: 110 | Loss: 0.4937363266944885 | Test loss: 0.5149538516998291\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7436]])), ('linear_layer.bias', tensor([0.7762]))])\n",
            "Loss:0.49317774176597595\n",
            "Loss:0.49261921644210815\n",
            "Loss:0.4920606017112732\n",
            "Loss:0.4915021061897278\n",
            "Loss:0.4909435212612152\n",
            "Loss:0.490384966135025\n",
            "Loss:0.48982638120651245\n",
            "Loss:0.48926782608032227\n",
            "Loss:0.48870936036109924\n",
            "Loss:0.4881506860256195\n",
            "Epoch: 120 | Loss: 0.4881506860256195 | Test loss: 0.5084229707717896\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7417]])), ('linear_layer.bias', tensor([0.7713]))])\n",
            "Loss:0.4875921607017517\n",
            "Loss:0.4870336651802063\n",
            "Loss:0.48647505044937134\n",
            "Loss:0.48591652512550354\n",
            "Loss:0.48535794019699097\n",
            "Loss:0.4847993850708008\n",
            "Loss:0.484240859746933\n",
            "Loss:0.483682245016098\n",
            "Loss:0.48312368988990784\n",
            "Loss:0.48256510496139526\n",
            "Epoch: 130 | Loss: 0.48256510496139526 | Test loss: 0.5018920302391052\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7398]])), ('linear_layer.bias', tensor([0.7665]))])\n",
            "Loss:0.4820065498352051\n",
            "Loss:0.4814479947090149\n",
            "Loss:0.4808894991874695\n",
            "Loss:0.4803309440612793\n",
            "Loss:0.4797723889350891\n",
            "Loss:0.47921380400657654\n",
            "Loss:0.47865524888038635\n",
            "Loss:0.4780966639518738\n",
            "Loss:0.4775381088256836\n",
            "Loss:0.4769795536994934\n",
            "Epoch: 140 | Loss: 0.4769795536994934 | Test loss: 0.4953610897064209\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7379]])), ('linear_layer.bias', tensor([0.7616]))])\n",
            "Loss:0.47642096877098083\n",
            "Loss:0.47586241364479065\n",
            "Loss:0.47530388832092285\n",
            "Loss:0.47474533319473267\n",
            "Loss:0.4741867184638977\n",
            "Loss:0.4736282229423523\n",
            "Loss:0.47306960821151733\n",
            "Loss:0.47251105308532715\n",
            "Loss:0.47195252776145935\n",
            "Loss:0.47139397263526917\n",
            "Epoch: 150 | Loss: 0.47139397263526917 | Test loss: 0.4888301491737366\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7360]])), ('linear_layer.bias', tensor([0.7568]))])\n",
            "Loss:0.4708353579044342\n",
            "Loss:0.4702768325805664\n",
            "Loss:0.4697182774543762\n",
            "Loss:0.46915969252586365\n",
            "Loss:0.46860113739967346\n",
            "Loss:0.4680425524711609\n",
            "Loss:0.4674839973449707\n",
            "Loss:0.4669254422187805\n",
            "Loss:0.4663669466972351\n",
            "Loss:0.4658083915710449\n",
            "Epoch: 160 | Loss: 0.4658083915710449 | Test loss: 0.48229923844337463\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7341]])), ('linear_layer.bias', tensor([0.7520]))])\n",
            "Loss:0.46524983644485474\n",
            "Loss:0.46469125151634216\n",
            "Loss:0.464132696390152\n",
            "Loss:0.4635741710662842\n",
            "Loss:0.4630155563354492\n",
            "Loss:0.46245700120925903\n",
            "Loss:0.46189841628074646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 97%|| 97/100 [00:33<00:01,  1.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.4613398611545563\n",
            "Loss:0.4607812762260437\n",
            "Loss:0.4602227210998535\n",
            "Epoch: 170 | Loss: 0.4602227210998535 | Test loss: 0.4757683277130127\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7322]])), ('linear_layer.bias', tensor([0.7471]))])\n",
            "Loss:0.45966416597366333\n",
            "Loss:0.4591056704521179\n",
            "Loss:0.45854711532592773\n",
            "Loss:0.45798856019973755\n",
            "Loss:0.457429975271225\n",
            "Loss:0.4568714201450348\n",
            "Loss:0.4563128352165222\n",
            "Loss:0.45575428009033203\n",
            "Loss:0.45519572496414185\n",
            "Loss:0.4546371400356293\n",
            "Epoch: 180 | Loss: 0.4546371400356293 | Test loss: 0.46923738718032837\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7303]])), ('linear_layer.bias', tensor([0.7423]))])\n",
            "Loss:0.4540785849094391\n",
            "Loss:0.4535199999809265\n",
            "Loss:0.4529615044593811\n",
            "Loss:0.45240291953086853\n",
            "Loss:0.45184436440467834\n",
            "Loss:0.45128577947616577\n",
            "Loss:0.45072728395462036\n",
            "Loss:0.4501686990261078\n",
            "Loss:0.4496100842952728\n",
            "Loss:0.44905152916908264\n",
            "Epoch: 190 | Loss: 0.44905152916908264 | Test loss: 0.46270641684532166\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7284]])), ('linear_layer.bias', tensor([0.7374]))])\n",
            "Loss:0.44849300384521484\n",
            "Loss:0.44793444871902466\n",
            "Loss:0.4473758637905121\n",
            "Loss:0.4468173384666443\n",
            "Loss:0.4462587237358093\n",
            "Loss:0.44570016860961914\n",
            "Loss:0.44514164328575134\n",
            "Loss:0.44458308815956116\n",
            "Loss:0.4440245032310486\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5867872834205627\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8295]))])\n",
            "Loss:0.5546135306358337\n",
            "Loss:0.5540491938591003\n",
            "Loss:0.5534847378730774\n",
            "Loss:0.5529203414916992\n",
            "Loss:0.552355945110321\n",
            "Loss:0.5517916083335876\n",
            "Loss:0.5512272119522095\n",
            "Loss:0.5506627559661865\n",
            "Loss:0.5500983595848083\n",
            "Loss:0.5495339632034302\n",
            "Epoch: 10 | Loss: 0.5495339632034302 | Test loss: 0.5801882147789001\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7624]])), ('linear_layer.bias', tensor([0.8246]))])\n",
            "Loss:0.5489696264266968\n",
            "Loss:0.5484052896499634\n",
            "Loss:0.5478407740592957\n",
            "Loss:0.5472763776779175\n",
            "Loss:0.5467119812965393\n",
            "Loss:0.5461476445198059\n",
            "Loss:0.5455832481384277\n",
            "Loss:0.5450188517570496\n",
            "Loss:0.5444544553756714\n",
            "Loss:0.543890118598938\n",
            "Epoch: 20 | Loss: 0.543890118598938 | Test loss: 0.5735891461372375\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7605]])), ('linear_layer.bias', tensor([0.8197]))])\n",
            "Loss:0.5433257222175598\n",
            "Loss:0.5427612662315369\n",
            "Loss:0.5421968698501587\n",
            "Loss:0.5416324734687805\n",
            "Loss:0.5410681366920471\n",
            "Loss:0.5405036807060242\n",
            "Loss:0.539939284324646\n",
            "Loss:0.5393748879432678\n",
            "Loss:0.5388105511665344\n",
            "Loss:0.5382460951805115\n",
            "Epoch: 30 | Loss: 0.5382460951805115 | Test loss: 0.5669900178909302\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7586]])), ('linear_layer.bias', tensor([0.8148]))])\n",
            "Loss:0.5376816987991333\n",
            "Loss:0.5371173620223999\n",
            "Loss:0.5365530252456665\n",
            "Loss:0.5359885692596436\n",
            "Loss:0.5354241132736206\n",
            "Loss:0.5348597764968872\n",
            "Loss:0.534295380115509\n",
            "Loss:0.5337309837341309\n",
            "Loss:0.5331665873527527\n",
            "Loss:0.5326021909713745\n",
            "Epoch: 40 | Loss: 0.5326021909713745 | Test loss: 0.5603908896446228\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7567]])), ('linear_layer.bias', tensor([0.8099]))])\n",
            "Loss:0.5320378541946411\n",
            "Loss:0.5314733386039734\n",
            "Loss:0.5309089422225952\n",
            "Loss:0.5303446054458618\n",
            "Loss:0.5297802090644836\n",
            "Loss:0.5292158722877502\n",
            "Loss:0.5286514163017273\n",
            "Loss:0.5280870199203491\n",
            "Loss:0.527522623538971\n",
            "Loss:0.5269582867622375\n",
            "Epoch: 50 | Loss: 0.5269582867622375 | Test loss: 0.5537918210029602\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7548]])), ('linear_layer.bias', tensor([0.8050]))])\n",
            "Loss:0.5263938307762146\n",
            "Loss:0.5258294343948364\n",
            "Loss:0.525265097618103\n",
            "Loss:0.5247007012367249\n",
            "Loss:0.5241363048553467\n",
            "Loss:0.5235719084739685\n",
            "Loss:0.5230075120925903\n",
            "Loss:0.5224431157112122\n",
            "Loss:0.521878719329834\n",
            "Loss:0.5213143229484558\n",
            "Epoch: 60 | Loss: 0.5213143229484558 | Test loss: 0.5471926927566528\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7529]])), ('linear_layer.bias', tensor([0.8001]))])\n",
            "Loss:0.5207499265670776\n",
            "Loss:0.5201855897903442\n",
            "Loss:0.5196211338043213\n",
            "Loss:0.5190567970275879\n",
            "Loss:0.5184923410415649\n",
            "Loss:0.5179279446601868\n",
            "Loss:0.5173635482788086\n",
            "Loss:0.5167990922927856\n",
            "Loss:0.516234815120697\n",
            "Loss:0.5156704187393188\n",
            "Epoch: 70 | Loss: 0.5156704187393188 | Test loss: 0.5405936241149902\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7510]])), ('linear_layer.bias', tensor([0.7952]))])\n",
            "Loss:0.5151060223579407\n",
            "Loss:0.5145415663719177\n",
            "Loss:0.5139772295951843\n",
            "Loss:0.5134128332138062\n",
            "Loss:0.512848436832428\n",
            "Loss:0.5122840404510498\n",
            "Loss:0.5117196440696716\n",
            "Loss:0.5111551880836487\n",
            "Loss:0.5105908513069153\n",
            "Loss:0.5100264549255371\n",
            "Epoch: 80 | Loss: 0.5100264549255371 | Test loss: 0.5339944958686829\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7491]])), ('linear_layer.bias', tensor([0.7903]))])\n",
            "Loss:0.5094620585441589\n",
            "Loss:0.5088976621627808\n",
            "Loss:0.5083333253860474\n",
            "Loss:0.5077688694000244\n",
            "Loss:0.5072044730186462\n",
            "Loss:0.5066400766372681\n",
            "Loss:0.5060756802558899\n",
            "Loss:0.5055112838745117\n",
            "Loss:0.5049468874931335\n",
            "Loss:0.5043824911117554\n",
            "Epoch: 90 | Loss: 0.5043824911117554 | Test loss: 0.5273954272270203\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7472]])), ('linear_layer.bias', tensor([0.7854]))])\n",
            "Loss:0.503818154335022\n",
            "Loss:0.5032537579536438\n",
            "Loss:0.5026893019676208\n",
            "Loss:0.5021249055862427\n",
            "Loss:0.5015605688095093\n",
            "Loss:0.5009961724281311\n",
            "Loss:0.5004317760467529\n",
            "Loss:0.49986737966537476\n",
            "Loss:0.4993029534816742\n",
            "Loss:0.4987386167049408\n",
            "Epoch: 100 | Loss: 0.4987386167049408 | Test loss: 0.5207963585853577\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7452]])), ('linear_layer.bias', tensor([0.7805]))])\n",
            "Loss:0.49817419052124023\n",
            "Loss:0.49760979413986206\n",
            "Loss:0.4970454275608063\n",
            "Loss:0.49648094177246094\n",
            "Loss:0.49591660499572754\n",
            "Loss:0.49535220861434937\n",
            "Loss:0.4947878420352936\n",
            "Loss:0.494223415851593\n",
            "Loss:0.49365901947021484\n",
            "Loss:0.49309462308883667\n",
            "Epoch: 110 | Loss: 0.49309462308883667 | Test loss: 0.5141972303390503\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7433]])), ('linear_layer.bias', tensor([0.7756]))])\n",
            "Loss:0.4925302565097809\n",
            "Loss:0.4919658601284027\n",
            "Loss:0.4914014935493469\n",
            "Loss:0.49083709716796875\n",
            "Loss:0.4902726709842682\n",
            "Loss:0.4897083342075348\n",
            "Loss:0.48914390802383423\n",
            "Loss:0.4885794520378113\n",
            "Loss:0.4880151152610779\n",
            "Loss:0.4874507486820221\n",
            "Epoch: 120 | Loss: 0.4874507486820221 | Test loss: 0.5075981020927429\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7414]])), ('linear_layer.bias', tensor([0.7707]))])\n",
            "Loss:0.4868863523006439\n",
            "Loss:0.48632192611694336\n",
            "Loss:0.4857575297355652\n",
            "Loss:0.4851931631565094\n",
            "Loss:0.48462873697280884\n",
            "Loss:0.48406440019607544\n",
            "Loss:0.4834999442100525\n",
            "Loss:0.48293551802635193\n",
            "Loss:0.48237118124961853\n",
            "Loss:0.48180675506591797\n",
            "Epoch: 130 | Loss: 0.48180675506591797 | Test loss: 0.5009990334510803\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7395]])), ('linear_layer.bias', tensor([0.7658]))])\n",
            "Loss:0.48124241828918457\n",
            "Loss:0.480677992105484\n",
            "Loss:0.48011359572410583\n",
            "Loss:0.4795491695404053\n",
            "Loss:0.4789848327636719\n",
            "Loss:0.4784204363822937\n",
            "Loss:0.47785601019859314\n",
            "Loss:0.47729164361953735\n",
            "Loss:0.4767272472381592\n",
            "Loss:0.4761628210544586\n",
            "Epoch: 140 | Loss: 0.4761628210544586 | Test loss: 0.49439993500709534\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7376]])), ('linear_layer.bias', tensor([0.7609]))])\n",
            "Loss:0.4755984842777252\n",
            "Loss:0.47503405809402466\n",
            "Loss:0.4744696617126465\n",
            "Loss:0.4739052653312683\n",
            "Loss:0.4733408987522125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 98%|| 98/100 [00:33<00:01,  1.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.47277650237083435\n",
            "Loss:0.47221213579177856\n",
            "Loss:0.4716476798057556\n",
            "Loss:0.4710833430290222\n",
            "Loss:0.47051891684532166\n",
            "Epoch: 150 | Loss: 0.47051891684532166 | Test loss: 0.4878007769584656\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7357]])), ('linear_layer.bias', tensor([0.7560]))])\n",
            "Loss:0.4699544906616211\n",
            "Loss:0.4693901538848877\n",
            "Loss:0.46882572770118713\n",
            "Loss:0.46826133131980896\n",
            "Loss:0.4676969647407532\n",
            "Loss:0.467132568359375\n",
            "Loss:0.4665681719779968\n",
            "Loss:0.46600374579429626\n",
            "Loss:0.4654393792152405\n",
            "Loss:0.4648749828338623\n",
            "Epoch: 160 | Loss: 0.4648749828338623 | Test loss: 0.481201708316803\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7338]])), ('linear_layer.bias', tensor([0.7511]))])\n",
            "Loss:0.46431055665016174\n",
            "Loss:0.46374621987342834\n",
            "Loss:0.4631817936897278\n",
            "Loss:0.4626173973083496\n",
            "Loss:0.46205300092697144\n",
            "Loss:0.46148866415023804\n",
            "Loss:0.4609242379665375\n",
            "Loss:0.46035975217819214\n",
            "Loss:0.4597954750061035\n",
            "Loss:0.4592309892177582\n",
            "Epoch: 170 | Loss: 0.4592309892177582 | Test loss: 0.474602609872818\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7319]])), ('linear_layer.bias', tensor([0.7462]))])\n",
            "Loss:0.4586666524410248\n",
            "Loss:0.458102285861969\n",
            "Loss:0.45753782987594604\n",
            "Loss:0.45697346329689026\n",
            "Loss:0.4564090669155121\n",
            "Loss:0.4558447003364563\n",
            "Loss:0.4552803039550781\n",
            "Loss:0.45471587777137756\n",
            "Loss:0.4541514813899994\n",
            "Loss:0.4535871148109436\n",
            "Epoch: 180 | Loss: 0.4535871148109436 | Test loss: 0.4680035710334778\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7300]])), ('linear_layer.bias', tensor([0.7413]))])\n",
            "Loss:0.45302271842956543\n",
            "Loss:0.45245838165283203\n",
            "Loss:0.45189395546913147\n",
            "Loss:0.4513295590877533\n",
            "Loss:0.45076513290405273\n",
            "Loss:0.45020073652267456\n",
            "Loss:0.4496363699436188\n",
            "Loss:0.4490719735622406\n",
            "Loss:0.4485076069831848\n",
            "Loss:0.44794321060180664\n",
            "Epoch: 190 | Loss: 0.44794321060180664 | Test loss: 0.4614044725894928\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7281]])), ('linear_layer.bias', tensor([0.7364]))])\n",
            "Loss:0.44737881422042847\n",
            "Loss:0.4468143880367279\n",
            "Loss:0.4462500214576721\n",
            "Loss:0.44568556547164917\n",
            "Loss:0.4451211988925934\n",
            "Loss:0.4445568025112152\n",
            "Loss:0.4439924359321594\n",
            "Loss:0.44342803955078125\n",
            "Loss:0.4428636431694031\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5867804288864136\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8295]))])\n",
            "Loss:0.5546076893806458\n",
            "Loss:0.5540373921394348\n",
            "Loss:0.5534672141075134\n",
            "Loss:0.5528969168663025\n",
            "Loss:0.5523266792297363\n",
            "Loss:0.5517565011978149\n",
            "Loss:0.551186203956604\n",
            "Loss:0.5506159067153931\n",
            "Loss:0.5500456690788269\n",
            "Loss:0.549475371837616\n",
            "Epoch: 10 | Loss: 0.549475371837616 | Test loss: 0.5801125764846802\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7624]])), ('linear_layer.bias', tensor([0.8246]))])\n",
            "Loss:0.5489051938056946\n",
            "Loss:0.5483349561691284\n",
            "Loss:0.5477646589279175\n",
            "Loss:0.5471943616867065\n",
            "Loss:0.5466241836547852\n",
            "Loss:0.5460540056228638\n",
            "Loss:0.5454837083816528\n",
            "Loss:0.5449134111404419\n",
            "Loss:0.5443431735038757\n",
            "Loss:0.5437728762626648\n",
            "Epoch: 20 | Loss: 0.5437728762626648 | Test loss: 0.5734447836875916\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7605]])), ('linear_layer.bias', tensor([0.8196]))])\n",
            "Loss:0.5432026982307434\n",
            "Loss:0.5426324605941772\n",
            "Loss:0.5420621633529663\n",
            "Loss:0.5414919257164001\n",
            "Loss:0.540921688079834\n",
            "Loss:0.5403514504432678\n",
            "Loss:0.5397812128067017\n",
            "Loss:0.5392109155654907\n",
            "Loss:0.5386406779289246\n",
            "Loss:0.5380703806877136\n",
            "Epoch: 30 | Loss: 0.5380703806877136 | Test loss: 0.5667771100997925\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7586]])), ('linear_layer.bias', tensor([0.8147]))])\n",
            "Loss:0.5375001430511475\n",
            "Loss:0.5369299650192261\n",
            "Loss:0.5363596677780151\n",
            "Loss:0.535789430141449\n",
            "Loss:0.5352191925048828\n",
            "Loss:0.5346488952636719\n",
            "Loss:0.5340787172317505\n",
            "Loss:0.5335084199905396\n",
            "Loss:0.5329381823539734\n",
            "Loss:0.5323678851127625\n",
            "Epoch: 40 | Loss: 0.5323678851127625 | Test loss: 0.5601091980934143\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7566]])), ('linear_layer.bias', tensor([0.8097]))])\n",
            "Loss:0.5317976474761963\n",
            "Loss:0.5312274694442749\n",
            "Loss:0.530657172203064\n",
            "Loss:0.530086874961853\n",
            "Loss:0.5295166969299316\n",
            "Loss:0.5289464592933655\n",
            "Loss:0.5283761620521545\n",
            "Loss:0.5278059244155884\n",
            "Loss:0.5272356867790222\n",
            "Loss:0.5266653895378113\n",
            "Epoch: 50 | Loss: 0.5266653895378113 | Test loss: 0.5534414649009705\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7547]])), ('linear_layer.bias', tensor([0.8048]))])\n",
            "Loss:0.5260951519012451\n",
            "Loss:0.525524914264679\n",
            "Loss:0.5249546766281128\n",
            "Loss:0.5243843793869019\n",
            "Loss:0.5238142013549805\n",
            "Loss:0.5232439041137695\n",
            "Loss:0.5226736664772034\n",
            "Loss:0.5221034288406372\n",
            "Loss:0.521533191204071\n",
            "Loss:0.5209629535675049\n",
            "Epoch: 60 | Loss: 0.5209629535675049 | Test loss: 0.5467736124992371\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7528]])), ('linear_layer.bias', tensor([0.7998]))])\n",
            "Loss:0.520392656326294\n",
            "Loss:0.5198224782943726\n",
            "Loss:0.5192521810531616\n",
            "Loss:0.5186818838119507\n",
            "Loss:0.5181116461753845\n",
            "Loss:0.5175414085388184\n",
            "Loss:0.5169711709022522\n",
            "Loss:0.516400933265686\n",
            "Loss:0.5158306360244751\n",
            "Loss:0.5152603983879089\n",
            "Epoch: 70 | Loss: 0.5152603983879089 | Test loss: 0.5401058197021484\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7508]])), ('linear_layer.bias', tensor([0.7949]))])\n",
            "Loss:0.5146901607513428\n",
            "Loss:0.5141199231147766\n",
            "Loss:0.5135496258735657\n",
            "Loss:0.5129793882369995\n",
            "Loss:0.5124091506004333\n",
            "Loss:0.5118389129638672\n",
            "Loss:0.511268675327301\n",
            "Loss:0.5106984376907349\n",
            "Loss:0.5101282000541687\n",
            "Loss:0.5095579028129578\n",
            "Epoch: 80 | Loss: 0.5095579028129578 | Test loss: 0.533437967300415\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7489]])), ('linear_layer.bias', tensor([0.7899]))])\n",
            "Loss:0.5089876651763916\n",
            "Loss:0.5084174275398254\n",
            "Loss:0.5078471899032593\n",
            "Loss:0.5072768926620483\n",
            "Loss:0.5067066550254822\n",
            "Loss:0.506136417388916\n",
            "Loss:0.5055661797523499\n",
            "Loss:0.5049959421157837\n",
            "Loss:0.5044257044792175\n",
            "Loss:0.5038553476333618\n",
            "Epoch: 90 | Loss: 0.5038553476333618 | Test loss: 0.5267702341079712\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7470]])), ('linear_layer.bias', tensor([0.7850]))])\n",
            "Loss:0.5032851696014404\n",
            "Loss:0.5027149319648743\n",
            "Loss:0.5021446943283081\n",
            "Loss:0.5015743970870972\n",
            "Loss:0.5010042190551758\n",
            "Loss:0.5004339218139648\n",
            "Loss:0.4998636841773987\n",
            "Loss:0.49929341673851013\n",
            "Loss:0.49872320890426636\n",
            "Loss:0.4981529116630554\n",
            "Epoch: 100 | Loss: 0.4981529116630554 | Test loss: 0.5201024413108826\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7450]])), ('linear_layer.bias', tensor([0.7800]))])\n",
            "Loss:0.4975826144218445\n",
            "Loss:0.4970124363899231\n",
            "Loss:0.49644213914871216\n",
            "Loss:0.4958719313144684\n",
            "Loss:0.49530166387557983\n",
            "Loss:0.49473142623901367\n",
            "Loss:0.49416112899780273\n",
            "Loss:0.49359092116355896\n",
            "Loss:0.493020623922348\n",
            "Loss:0.49245041608810425\n",
            "Epoch: 110 | Loss: 0.49245041608810425 | Test loss: 0.513434648513794\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7431]])), ('linear_layer.bias', tensor([0.7751]))])\n",
            "Loss:0.4918801784515381\n",
            "Loss:0.4913099408149719\n",
            "Loss:0.490739643573761\n",
            "Loss:0.4901694357395172\n",
            "Loss:0.48959916830062866\n",
            "Loss:0.4890289306640625\n",
            "Loss:0.48845869302749634\n",
            "Loss:0.4878883957862854\n",
            "Loss:0.48731812834739685\n",
            "Loss:0.4867479205131531\n",
            "Epoch: 120 | Loss: 0.4867479205131531 | Test loss: 0.5067668557167053\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7412]])), ('linear_layer.bias', tensor([0.7701]))])\n",
            "Loss:0.48617762327194214\n",
            "Loss:0.48560744524002075\n",
            "Loss:0.4850371778011322\n",
            "Loss:0.48446688055992126\n",
            "Loss:0.4838966727256775\n",
            "Loss:0.48332643508911133\n",
            "Loss:0.48275619745254517\n",
            "Loss:0.4821859300136566\n",
            "Loss:0.4816156327724457\n",
            "Loss:0.4810453951358795\n",
            "Epoch: 130 | Loss: 0.4810453951358795 | Test loss: 0.5000990629196167\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7392]])), ('linear_layer.bias', tensor([0.7652]))])\n",
            "Loss:0.48047518730163574\n",
            "Loss:0.4799049496650696\n",
            "Loss:0.47933465242385864\n",
            "Loss:0.47876444458961487\n",
            "Loss:0.47819414734840393\n",
            "Loss:0.4776238799095154\n",
            "Loss:0.4770536422729492\n",
            "Loss:0.47648343443870544\n",
            "Loss:0.47591322660446167\n",
            "Loss:0.47534292936325073\n",
            "Epoch: 140 | Loss: 0.47534292936325073 | Test loss: 0.4934312403202057\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7373]])), ('linear_layer.bias', tensor([0.7602]))])\n",
            "Loss:0.4747726321220398\n",
            "Loss:0.4742024540901184\n",
            "Loss:0.47363215684890747\n",
            "Loss:0.4730618894100189\n",
            "Loss:0.47249168157577515\n",
            "Loss:0.4719213843345642\n",
            "Loss:0.4713512063026428\n",
            "Loss:0.4707809388637543\n",
            "Loss:0.47021064162254333\n",
            "Loss:0.4696404039859772\n",
            "Epoch: 150 | Loss: 0.4696404039859772 | Test loss: 0.4867633879184723\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7354]])), ('linear_layer.bias', tensor([0.7553]))])\n",
            "Loss:0.4690701961517334\n",
            "Loss:0.46849995851516724\n",
            "Loss:0.4679296612739563\n",
            "Loss:0.4673594534397125\n",
            "Loss:0.4667891561985016\n",
            "Loss:0.46621888875961304\n",
            "Loss:0.4656486511230469\n",
            "Loss:0.4650784134864807\n",
            "Loss:0.46450814604759216\n",
            "Loss:0.463937908411026\n",
            "Epoch: 160 | Loss: 0.463937908411026 | Test loss: 0.4800955653190613\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7335]])), ('linear_layer.bias', tensor([0.7503]))])\n",
            "Loss:0.4633677005767822\n",
            "Loss:0.4627973437309265\n",
            "Loss:0.4622271656990051\n",
            "Loss:0.4616568982601166\n",
            "Loss:0.4610866606235504\n",
            "Loss:0.46051639318466187\n",
            "Loss:0.4599461555480957\n",
            "Loss:0.45937585830688477\n",
            "Loss:0.458805650472641\n",
            "Loss:0.45823541283607483\n",
            "Epoch: 170 | Loss: 0.45823541283607483 | Test loss: 0.4734278619289398\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7315]])), ('linear_layer.bias', tensor([0.7454]))])\n",
            "Loss:0.4576651453971863"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 99%|| 99/100 [00:34<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loss:0.4570949077606201\n",
            "Loss:0.45652467012405396\n",
            "Loss:0.4559544026851654\n",
            "Loss:0.45538416504859924\n",
            "Loss:0.4548138976097107\n",
            "Loss:0.45424365997314453\n",
            "Loss:0.45367342233657837\n",
            "Loss:0.4531031548976898\n",
            "Loss:0.45253294706344604\n",
            "Epoch: 180 | Loss: 0.45253294706344604 | Test loss: 0.4667600095272064\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7296]])), ('linear_layer.bias', tensor([0.7404]))])\n",
            "Loss:0.4519626498222351\n",
            "Loss:0.45139241218566895\n",
            "Loss:0.4508221745491028\n",
            "Loss:0.45025187730789185\n",
            "Loss:0.44968166947364807\n",
            "Loss:0.44911137223243713\n",
            "Loss:0.44854116439819336\n",
            "Loss:0.4479708671569824\n",
            "Loss:0.44740065932273865\n",
            "Loss:0.4468304216861725\n",
            "Epoch: 190 | Loss: 0.4468304216861725 | Test loss: 0.4600922465324402\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7277]])), ('linear_layer.bias', tensor([0.7355]))])\n",
            "Loss:0.44626015424728394\n",
            "Loss:0.445689857006073\n",
            "Loss:0.4451196789741516\n",
            "Loss:0.4445493817329407\n",
            "Loss:0.4439791738986969\n",
            "Loss:0.44340890645980835\n",
            "Loss:0.4428386092185974\n",
            "Loss:0.442268431186676\n",
            "Loss:0.4416981637477875\n",
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5867735743522644\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8295]))])\n",
            "Loss:0.5546018481254578\n",
            "Loss:0.5540257692337036\n",
            "Loss:0.5534496903419495\n",
            "Loss:0.5528736114501953\n",
            "Loss:0.5522974729537964\n",
            "Loss:0.5517213940620422\n",
            "Loss:0.5511453747749329\n",
            "Loss:0.5505692958831787\n",
            "Loss:0.5499931573867798\n",
            "Loss:0.5494170784950256\n",
            "Epoch: 10 | Loss: 0.5494170784950256 | Test loss: 0.5800376534461975\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7624]])), ('linear_layer.bias', tensor([0.8245]))])\n",
            "Loss:0.5488409996032715\n",
            "Loss:0.5482649207115173\n",
            "Loss:0.5476888418197632\n",
            "Loss:0.547112762928009\n",
            "Loss:0.5465366244316101\n",
            "Loss:0.545960545539856\n",
            "Loss:0.5453845262527466\n",
            "Loss:0.5448085069656372\n",
            "Loss:0.5442323684692383\n",
            "Loss:0.5436562299728394\n",
            "Epoch: 20 | Loss: 0.5436562299728394 | Test loss: 0.5733016729354858\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7604]])), ('linear_layer.bias', tensor([0.8195]))])\n",
            "Loss:0.54308021068573\n",
            "Loss:0.5425041317939758\n",
            "Loss:0.5419279932975769\n",
            "Loss:0.5413519144058228\n",
            "Loss:0.5407758951187134\n",
            "Loss:0.5401997566223145\n",
            "Loss:0.5396236777305603\n",
            "Loss:0.5390475988388062\n",
            "Loss:0.5384715795516968\n",
            "Loss:0.5378954410552979\n",
            "Epoch: 30 | Loss: 0.5378954410552979 | Test loss: 0.5665656924247742\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7585]])), ('linear_layer.bias', tensor([0.8145]))])\n",
            "Loss:0.5373193025588989\n",
            "Loss:0.5367432236671448\n",
            "Loss:0.5361671447753906\n",
            "Loss:0.5355910658836365\n",
            "Loss:0.5350149869918823\n",
            "Loss:0.5344389081001282\n",
            "Loss:0.533862829208374\n",
            "Loss:0.5332867503166199\n",
            "Loss:0.5327106714248657\n",
            "Loss:0.5321345925331116\n",
            "Epoch: 40 | Loss: 0.5321345925331116 | Test loss: 0.5598297715187073\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7565]])), ('linear_layer.bias', tensor([0.8095]))])\n",
            "Loss:0.5315585136413574\n",
            "Loss:0.5309823751449585\n",
            "Loss:0.5304063558578491\n",
            "Loss:0.529830276966095\n",
            "Loss:0.529254138469696\n",
            "Loss:0.5286781191825867\n",
            "Loss:0.5281020402908325\n",
            "Loss:0.5275259613990784\n",
            "Loss:0.5269498229026794\n",
            "Loss:0.5263737440109253\n",
            "Epoch: 50 | Loss: 0.5263737440109253 | Test loss: 0.5530937910079956\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7546]])), ('linear_layer.bias', tensor([0.8045]))])\n",
            "Loss:0.5257977247238159\n",
            "Loss:0.5252216458320618\n",
            "Loss:0.5246454477310181\n",
            "Loss:0.5240694284439087\n",
            "Loss:0.5234933495521545\n",
            "Loss:0.5229172706604004\n",
            "Loss:0.5223411321640015\n",
            "Loss:0.5217651128768921\n",
            "Loss:0.5211889743804932\n",
            "Loss:0.520612895488739\n",
            "Epoch: 60 | Loss: 0.520612895488739 | Test loss: 0.5463577508926392\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7526]])), ('linear_layer.bias', tensor([0.7995]))])\n",
            "Loss:0.5200368165969849\n",
            "Loss:0.5194607377052307\n",
            "Loss:0.5188846588134766\n",
            "Loss:0.5183085203170776\n",
            "Loss:0.5177325010299683\n",
            "Loss:0.5171564221382141\n",
            "Loss:0.5165802836418152\n",
            "Loss:0.5160042643547058\n",
            "Loss:0.5154281854629517\n",
            "Loss:0.5148521661758423\n",
            "Epoch: 70 | Loss: 0.5148521661758423 | Test loss: 0.5396217703819275\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7507]])), ('linear_layer.bias', tensor([0.7945]))])\n",
            "Loss:0.5142759680747986\n",
            "Loss:0.5136998891830444\n",
            "Loss:0.5131238698959351\n",
            "Loss:0.5125477313995361\n",
            "Loss:0.511971652507782\n",
            "Loss:0.5113955736160278\n",
            "Loss:0.5108194351196289\n",
            "Loss:0.5102434158325195\n",
            "Loss:0.5096672773361206\n",
            "Loss:0.5090912580490112\n",
            "Epoch: 80 | Loss: 0.5090912580490112 | Test loss: 0.5328857898712158\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7487]])), ('linear_layer.bias', tensor([0.7895]))])\n",
            "Loss:0.5085151791572571\n",
            "Loss:0.5079390406608582\n",
            "Loss:0.507362961769104\n",
            "Loss:0.5067868828773499\n",
            "Loss:0.5062108635902405\n",
            "Loss:0.5056347250938416\n",
            "Loss:0.5050586462020874\n",
            "Loss:0.5044825673103333\n",
            "Loss:0.5039065480232239\n",
            "Loss:0.503330409526825\n",
            "Epoch: 90 | Loss: 0.503330409526825 | Test loss: 0.5261498689651489\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7468]])), ('linear_layer.bias', tensor([0.7845]))])\n",
            "Loss:0.5027543306350708\n",
            "Loss:0.5021782517433167\n",
            "Loss:0.5016021728515625\n",
            "Loss:0.5010260939598083\n",
            "Loss:0.5004500150680542\n",
            "Loss:0.49987393617630005\n",
            "Loss:0.4992977976799011\n",
            "Loss:0.49872174859046936\n",
            "Loss:0.49814572930336\n",
            "Loss:0.49756956100463867\n",
            "Epoch: 100 | Loss: 0.49756956100463867 | Test loss: 0.5194138884544373\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7448]])), ('linear_layer.bias', tensor([0.7795]))])\n",
            "Loss:0.4969934821128845\n",
            "Loss:0.49641743302345276\n",
            "Loss:0.4958413243293762\n",
            "Loss:0.4952651858329773\n",
            "Loss:0.4946891665458679\n",
            "Loss:0.4941130578517914\n",
            "Loss:0.4935370087623596\n",
            "Loss:0.4929608702659607\n",
            "Loss:0.49238482117652893\n",
            "Loss:0.4918087124824524\n",
            "Epoch: 110 | Loss: 0.4918087124824524 | Test loss: 0.5126779675483704\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7429]])), ('linear_layer.bias', tensor([0.7745]))])\n",
            "Loss:0.491232693195343\n",
            "Loss:0.4906565546989441\n",
            "Loss:0.49008044600486755\n",
            "Loss:0.4895044267177582\n",
            "Loss:0.48892831802368164\n",
            "Loss:0.48835229873657227\n",
            "Loss:0.4877761900424957\n",
            "Loss:0.4872000813484192\n",
            "Loss:0.48662400245666504\n",
            "Loss:0.4860479235649109\n",
            "Epoch: 120 | Loss: 0.4860479235649109 | Test loss: 0.5059419870376587\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7409]])), ('linear_layer.bias', tensor([0.7695]))])\n",
            "Loss:0.48547181487083435\n",
            "Loss:0.4848957657814026\n",
            "Loss:0.48431962728500366\n",
            "Loss:0.4837435781955719\n",
            "Loss:0.48316746950149536\n",
            "Loss:0.4825913906097412\n",
            "Loss:0.48201531171798706\n",
            "Loss:0.4814392030239105\n",
            "Loss:0.480863094329834\n",
            "Loss:0.4802870750427246\n",
            "Epoch: 130 | Loss: 0.4802870750427246 | Test loss: 0.499206006526947\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7390]])), ('linear_layer.bias', tensor([0.7645]))])\n",
            "Loss:0.47971096634864807\n",
            "Loss:0.4791348874568939\n",
            "Loss:0.47855883836746216\n",
            "Loss:0.47798269987106323\n",
            "Loss:0.47740668058395386\n",
            "Loss:0.47683048248291016\n",
            "Loss:0.4762544631958008\n",
            "Loss:0.47567835450172424\n",
            "Loss:0.47510233521461487\n",
            "Loss:0.4745262563228607\n",
            "Epoch: 140 | Loss: 0.4745262563228607 | Test loss: 0.4924700856208801\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7370]])), ('linear_layer.bias', tensor([0.7595]))])\n",
            "Loss:0.47395020723342896\n",
            "Loss:0.47337406873703003\n",
            "Loss:0.4727979600429535\n",
            "Loss:0.47222191095352173\n",
            "Loss:0.4716458320617676\n",
            "Loss:0.47106972336769104\n",
            "Loss:0.4704936146736145\n",
            "Loss:0.46991753578186035\n",
            "Loss:0.4693414568901062\n",
            "Loss:0.46876534819602966\n",
            "Epoch: 150 | Loss: 0.46876534819602966 | Test loss: 0.48573407530784607\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7351]])), ('linear_layer.bias', tensor([0.7545]))])\n",
            "Loss:0.4681892991065979\n",
            "Loss:0.46761322021484375\n",
            "Loss:0.4670371115207672\n",
            "Loss:0.4664610028266907\n",
            "Loss:0.4658849239349365\n",
            "Loss:0.4653088450431824\n",
            "Loss:0.4647327959537506\n",
            "Loss:0.46415671706199646\n",
            "Loss:0.4635806977748871\n",
            "Loss:0.46300458908081055\n",
            "Epoch: 160 | Loss: 0.46300458908081055 | Test loss: 0.4789981245994568\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7331]])), ('linear_layer.bias', tensor([0.7495]))])\n",
            "Loss:0.4624285101890564\n",
            "Loss:0.46185237169265747\n",
            "Loss:0.4612763524055481\n",
            "Loss:0.46070021390914917\n",
            "Loss:0.4601241648197174\n",
            "Loss:0.45954805612564087\n",
            "Loss:0.45897191762924194\n",
            "Loss:0.4583958685398102\n",
            "Loss:0.45781978964805603\n",
            "Loss:0.45724374055862427\n",
            "Epoch: 170 | Loss: 0.45724374055862427 | Test loss: 0.4722621440887451\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7312]])), ('linear_layer.bias', tensor([0.7445]))])\n",
            "Loss:0.45666760206222534\n",
            "Loss:0.4560915529727936\n",
            "Loss:0.45551547408103943\n",
            "Loss:0.4549393653869629\n",
            "Loss:0.45436328649520874\n",
            "Loss:0.453787237405777\n",
            "Loss:0.45321112871170044\n",
            "Loss:0.4526349902153015\n",
            "Loss:0.45205897092819214"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 100/100 [00:35<00:00,  2.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loss:0.4514828622341156\n",
            "Epoch: 180 | Loss: 0.4514828622341156 | Test loss: 0.46552616357803345\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7292]])), ('linear_layer.bias', tensor([0.7395]))])\n",
            "Loss:0.45090681314468384\n",
            "Loss:0.4503307342529297\n",
            "Loss:0.44975462555885315\n",
            "Loss:0.4491785168647766\n",
            "Loss:0.44860243797302246\n",
            "Loss:0.4480263590812683\n",
            "Loss:0.44745030999183655\n",
            "Loss:0.44687420129776\n",
            "Loss:0.44629812240600586\n",
            "Loss:0.4457220137119293\n",
            "Epoch: 190 | Loss: 0.4457220137119293 | Test loss: 0.45879021286964417\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7273]])), ('linear_layer.bias', tensor([0.7345]))])\n",
            "Loss:0.44514599442481995\n",
            "Loss:0.4445698857307434\n",
            "Loss:0.4439937472343445\n",
            "Loss:0.4434177279472351\n",
            "Loss:0.4428415894508362\n",
            "Loss:0.4422655701637268\n",
            "Loss:0.4416894316673279\n",
            "Loss:0.4411133825778961\n",
            "Loss:0.44053730368614197\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "torch.manual_seed(42)\n",
        "# Epochs (number of updates) at 200\n",
        "epochs = 200\n",
        "\n",
        "# X_train = X_train.to(device)\n",
        "# y_train = y_train_to(device)\n",
        "\n",
        "\n",
        "\n",
        "tmp = 1e9\n",
        "mapping = {}\n",
        "\n",
        "#Requirement\"numpy.linspace\" is here\n",
        "lr_list = list(np.linspace(0., 0.0005, 100))\n",
        "\n",
        "for lr in tqdm(lr_list):\n",
        "  torch.manual_seed(42)\n",
        "  model_0 = LinearRegressionModel()\n",
        "  optimizer = torch.optim.SGD(params = model_0.parameters(),\n",
        "                            lr = lr)\n",
        "  epoch_count = []\n",
        "  loss_values = []\n",
        "  test_loss_values = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    model_0.train()\n",
        "\n",
        "    y_pred = model_0(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    print(f\"Loss:{loss}\")\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    model_0.eval()\n",
        "    with torch.inference_mode():\n",
        "      test_pred = model_0(X_test)\n",
        "\n",
        "      test_loss = criterion(test_pred, y_test)\n",
        "    if epoch % 10 == 0:\n",
        "      epoch_count.append(epoch)\n",
        "      loss_values.append(loss)\n",
        "      test_loss_values.append(test_loss)\n",
        "\n",
        "      print(f\"Epoch: {epoch} | Loss: {loss} | Test loss: {test_loss}\")\n",
        "      print(model_0.state_dict())\n",
        "    \n",
        "  min_loss = min(tmp,loss)\n",
        "  tmp = loss\n",
        "  mapping[loss] = lr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDArZ2uJgaw2",
        "outputId": "620698e6-bf98-4380-db7d-c655112c0ec1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lr with lowest loss is 0.0005\n"
          ]
        }
      ],
      "source": [
        "print(f\"lr with lowest loss is {mapping[min_loss]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bi6DuTNkg73F"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "criterion = nn.L1Loss()\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model_0 = LinearRegressionModel()\n",
        "optimizer = torch.optim.SGD(params = model_0.parameters(),\n",
        "                            lr = 0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVqC40olg1AG",
        "outputId": "71be6151-914a-42b1-e663-a14baa6bcfb3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|      | 67/200 [00:00<00:00, 663.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.5551779866218567\n",
            "Epoch: 0 | Loss: 0.5551779866218567 | Test loss: 0.5867735743522644\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7643]])), ('linear_layer.bias', tensor([0.8295]))])\n",
            "Loss:0.5546018481254578\n",
            "Loss:0.5540257692337036\n",
            "Loss:0.5534496903419495\n",
            "Loss:0.5528736114501953\n",
            "Loss:0.5522974729537964\n",
            "Loss:0.5517213940620422\n",
            "Loss:0.5511453747749329\n",
            "Loss:0.5505692958831787\n",
            "Loss:0.5499931573867798\n",
            "Loss:0.5494170784950256\n",
            "Epoch: 10 | Loss: 0.5494170784950256 | Test loss: 0.5800376534461975\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7624]])), ('linear_layer.bias', tensor([0.8245]))])\n",
            "Loss:0.5488409996032715\n",
            "Loss:0.5482649207115173\n",
            "Loss:0.5476888418197632\n",
            "Loss:0.547112762928009\n",
            "Loss:0.5465366244316101\n",
            "Loss:0.545960545539856\n",
            "Loss:0.5453845262527466\n",
            "Loss:0.5448085069656372\n",
            "Loss:0.5442323684692383\n",
            "Loss:0.5436562299728394\n",
            "Epoch: 20 | Loss: 0.5436562299728394 | Test loss: 0.5733016729354858\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7604]])), ('linear_layer.bias', tensor([0.8195]))])\n",
            "Loss:0.54308021068573\n",
            "Loss:0.5425041317939758\n",
            "Loss:0.5419279932975769\n",
            "Loss:0.5413519144058228\n",
            "Loss:0.5407758951187134\n",
            "Loss:0.5401997566223145\n",
            "Loss:0.5396236777305603\n",
            "Loss:0.5390475988388062\n",
            "Loss:0.5384715795516968\n",
            "Loss:0.5378954410552979\n",
            "Epoch: 30 | Loss: 0.5378954410552979 | Test loss: 0.5665656924247742\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7585]])), ('linear_layer.bias', tensor([0.8145]))])\n",
            "Loss:0.5373193025588989\n",
            "Loss:0.5367432236671448\n",
            "Loss:0.5361671447753906\n",
            "Loss:0.5355910658836365\n",
            "Loss:0.5350149869918823\n",
            "Loss:0.5344389081001282\n",
            "Loss:0.533862829208374\n",
            "Loss:0.5332867503166199\n",
            "Loss:0.5327106714248657\n",
            "Loss:0.5321345925331116\n",
            "Epoch: 40 | Loss: 0.5321345925331116 | Test loss: 0.5598297715187073\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7565]])), ('linear_layer.bias', tensor([0.8095]))])\n",
            "Loss:0.5315585136413574\n",
            "Loss:0.5309823751449585\n",
            "Loss:0.5304063558578491\n",
            "Loss:0.529830276966095\n",
            "Loss:0.529254138469696\n",
            "Loss:0.5286781191825867\n",
            "Loss:0.5281020402908325\n",
            "Loss:0.5275259613990784\n",
            "Loss:0.5269498229026794\n",
            "Loss:0.5263737440109253\n",
            "Epoch: 50 | Loss: 0.5263737440109253 | Test loss: 0.5530937910079956\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7546]])), ('linear_layer.bias', tensor([0.8045]))])\n",
            "Loss:0.5257977247238159\n",
            "Loss:0.5252216458320618\n",
            "Loss:0.5246454477310181\n",
            "Loss:0.5240694284439087\n",
            "Loss:0.5234933495521545\n",
            "Loss:0.5229172706604004\n",
            "Loss:0.5223411321640015\n",
            "Loss:0.5217651128768921\n",
            "Loss:0.5211889743804932\n",
            "Loss:0.520612895488739\n",
            "Epoch: 60 | Loss: 0.520612895488739 | Test loss: 0.5463577508926392\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7526]])), ('linear_layer.bias', tensor([0.7995]))])\n",
            "Loss:0.5200368165969849\n",
            "Loss:0.5194607377052307\n",
            "Loss:0.5188846588134766\n",
            "Loss:0.5183085203170776\n",
            "Loss:0.5177325010299683\n",
            "Loss:0.5171564221382141\n",
            "Loss:0.5165802836418152\n",
            "Loss:0.5160042643547058\n",
            "Loss:0.5154281854629517\n",
            "Loss:0.5148521661758423\n",
            "Epoch: 70 | Loss: 0.5148521661758423 | Test loss: 0.5396217703819275\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7507]])), ('linear_layer.bias', tensor([0.7945]))])\n",
            "Loss:0.5142759680747986\n",
            "Loss:0.5136998891830444\n",
            "Loss:0.5131238698959351\n",
            "Loss:0.5125477313995361\n",
            "Loss:0.511971652507782\n",
            "Loss:0.5113955736160278\n",
            "Loss:0.5108194351196289\n",
            "Loss:0.5102434158325195\n",
            "Loss:0.5096672773361206\n",
            "Loss:0.5090912580490112\n",
            "Epoch: 80 | Loss: 0.5090912580490112 | Test loss: 0.5328857898712158\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7487]])), ('linear_layer.bias', tensor([0.7895]))])\n",
            "Loss:0.5085151791572571\n",
            "Loss:0.5079390406608582\n",
            "Loss:0.507362961769104\n",
            "Loss:0.5067868828773499\n",
            "Loss:0.5062108635902405\n",
            "Loss:0.5056347250938416\n",
            "Loss:0.5050586462020874\n",
            "Loss:0.5044825673103333\n",
            "Loss:0.5039065480232239\n",
            "Loss:0.503330409526825\n",
            "Epoch: 90 | Loss: 0.503330409526825 | Test loss: 0.5261498689651489\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7468]])), ('linear_layer.bias', tensor([0.7845]))])\n",
            "Loss:0.5027543306350708\n",
            "Loss:0.5021782517433167\n",
            "Loss:0.5016021728515625\n",
            "Loss:0.5010260939598083\n",
            "Loss:0.5004500150680542\n",
            "Loss:0.49987393617630005\n",
            "Loss:0.4992977976799011\n",
            "Loss:0.49872174859046936\n",
            "Loss:0.49814572930336\n",
            "Loss:0.49756956100463867\n",
            "Epoch: 100 | Loss: 0.49756956100463867 | Test loss: 0.5194138884544373\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7448]])), ('linear_layer.bias', tensor([0.7795]))])\n",
            "Loss:0.4969934821128845\n",
            "Loss:0.49641743302345276\n",
            "Loss:0.4958413243293762\n",
            "Loss:0.4952651858329773\n",
            "Loss:0.4946891665458679\n",
            "Loss:0.4941130578517914\n",
            "Loss:0.4935370087623596\n",
            "Loss:0.4929608702659607\n",
            "Loss:0.49238482117652893\n",
            "Loss:0.4918087124824524\n",
            "Epoch: 110 | Loss: 0.4918087124824524 | Test loss: 0.5126779675483704\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7429]])), ('linear_layer.bias', tensor([0.7745]))])\n",
            "Loss:0.491232693195343\n",
            "Loss:0.4906565546989441\n",
            "Loss:0.49008044600486755\n",
            "Loss:0.4895044267177582\n",
            "Loss:0.48892831802368164\n",
            "Loss:0.48835229873657227\n",
            "Loss:0.4877761900424957\n",
            "Loss:0.4872000813484192\n",
            "Loss:0.48662400245666504\n",
            "Loss:0.4860479235649109\n",
            "Epoch: 120 | Loss: 0.4860479235649109 | Test loss: 0.5059419870376587\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7409]])), ('linear_layer.bias', tensor([0.7695]))])\n",
            "Loss:0.48547181487083435\n",
            "Loss:0.4848957657814026\n",
            "Loss:0.48431962728500366\n",
            "Loss:0.4837435781955719\n",
            "Loss:0.48316746950149536\n",
            "Loss:0.4825913906097412\n",
            "Loss:0.48201531171798706\n",
            "Loss:0.4814392030239105\n",
            "Loss:0.480863094329834\n",
            "Loss:0.4802870750427246\n",
            "Epoch: 130 | Loss: 0.4802870750427246 | Test loss: 0.499206006526947\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7390]])), ('linear_layer.bias', tensor([0.7645]))])\n",
            "Loss:0.47971096634864807\n",
            "Loss:0.4791348874568939\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 200/200 [00:00<00:00, 619.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.47855883836746216\n",
            "Loss:0.47798269987106323\n",
            "Loss:0.47740668058395386\n",
            "Loss:0.47683048248291016\n",
            "Loss:0.4762544631958008\n",
            "Loss:0.47567835450172424\n",
            "Loss:0.47510233521461487\n",
            "Loss:0.4745262563228607\n",
            "Epoch: 140 | Loss: 0.4745262563228607 | Test loss: 0.4924700856208801\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7370]])), ('linear_layer.bias', tensor([0.7595]))])\n",
            "Loss:0.47395020723342896\n",
            "Loss:0.47337406873703003\n",
            "Loss:0.4727979600429535\n",
            "Loss:0.47222191095352173\n",
            "Loss:0.4716458320617676\n",
            "Loss:0.47106972336769104\n",
            "Loss:0.4704936146736145\n",
            "Loss:0.46991753578186035\n",
            "Loss:0.4693414568901062\n",
            "Loss:0.46876534819602966\n",
            "Epoch: 150 | Loss: 0.46876534819602966 | Test loss: 0.48573407530784607\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7351]])), ('linear_layer.bias', tensor([0.7545]))])\n",
            "Loss:0.4681892991065979\n",
            "Loss:0.46761322021484375\n",
            "Loss:0.4670371115207672\n",
            "Loss:0.4664610028266907\n",
            "Loss:0.4658849239349365\n",
            "Loss:0.4653088450431824\n",
            "Loss:0.4647327959537506\n",
            "Loss:0.46415671706199646\n",
            "Loss:0.4635806977748871\n",
            "Loss:0.46300458908081055\n",
            "Epoch: 160 | Loss: 0.46300458908081055 | Test loss: 0.4789981245994568\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7331]])), ('linear_layer.bias', tensor([0.7495]))])\n",
            "Loss:0.4624285101890564\n",
            "Loss:0.46185237169265747\n",
            "Loss:0.4612763524055481\n",
            "Loss:0.46070021390914917\n",
            "Loss:0.4601241648197174\n",
            "Loss:0.45954805612564087\n",
            "Loss:0.45897191762924194\n",
            "Loss:0.4583958685398102\n",
            "Loss:0.45781978964805603\n",
            "Loss:0.45724374055862427\n",
            "Epoch: 170 | Loss: 0.45724374055862427 | Test loss: 0.4722621440887451\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7312]])), ('linear_layer.bias', tensor([0.7445]))])\n",
            "Loss:0.45666760206222534\n",
            "Loss:0.4560915529727936\n",
            "Loss:0.45551547408103943\n",
            "Loss:0.4549393653869629\n",
            "Loss:0.45436328649520874\n",
            "Loss:0.453787237405777\n",
            "Loss:0.45321112871170044\n",
            "Loss:0.4526349902153015\n",
            "Loss:0.45205897092819214\n",
            "Loss:0.4514828622341156\n",
            "Epoch: 180 | Loss: 0.4514828622341156 | Test loss: 0.46552616357803345\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7292]])), ('linear_layer.bias', tensor([0.7395]))])\n",
            "Loss:0.45090681314468384\n",
            "Loss:0.4503307342529297\n",
            "Loss:0.44975462555885315\n",
            "Loss:0.4491785168647766\n",
            "Loss:0.44860243797302246\n",
            "Loss:0.4480263590812683\n",
            "Loss:0.44745030999183655\n",
            "Loss:0.44687420129776\n",
            "Loss:0.44629812240600586\n",
            "Loss:0.4457220137119293\n",
            "Epoch: 190 | Loss: 0.4457220137119293 | Test loss: 0.45879021286964417\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7273]])), ('linear_layer.bias', tensor([0.7345]))])\n",
            "Loss:0.44514599442481995\n",
            "Loss:0.4445698857307434\n",
            "Loss:0.4439937472343445\n",
            "Loss:0.4434177279472351\n",
            "Loss:0.4428415894508362\n",
            "Loss:0.4422655701637268\n",
            "Loss:0.4416894316673279\n",
            "Loss:0.4411133825778961\n",
            "Loss:0.44053730368614197\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "torch.manual_seed(42)\n",
        "epochs = 200\n",
        "\n",
        "# X_train = X_train.to(device)\n",
        "# y_train = y_train_to(device)\n",
        "\n",
        "epoch_count = []\n",
        "loss_values = []\n",
        "test_loss_values = []\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  model_0.train()\n",
        "\n",
        "  y_pred = model_0(X_train)\n",
        "  loss = criterion(y_pred, y_train)\n",
        "  print(f\"Loss:{loss}\")\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_pred = model_0(X_test)\n",
        "\n",
        "    test_loss = criterion(test_pred, y_test)\n",
        "  if epoch % 10 == 0:\n",
        "    epoch_count.append(epoch)\n",
        "    loss_values.append(loss)\n",
        "    test_loss_values.append(test_loss)\n",
        "\n",
        "    print(f\"Epoch: {epoch} | Loss: {loss} | Test loss: {test_loss}\")\n",
        "    print(model_0.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "5seJTXB2dPeH",
        "outputId": "14fc30e1-d684-42cc-df02-d0872bb8ddfb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epoch')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3gVZdrH8e+dhNA7oZcASUQUpAQQBaQEKatYsCEWXBVXpNl1XVfUdRXdVRBBxYJl7a762hAIELpAQIpBSUIgQGihhpZ+v3/M4MaYQICczElyf67rXJzznJkzdyYhv8wz8zwjqooxxhiTX4DXBRhjjPFPFhDGGGMKZAFhjDGmQBYQxhhjCmQBYYwxpkAWEMYYYwpkAWF8RkRmisitxb2sl0Rki4hE+UEdE0TkP17XYcq2IK8LMP5FRI7keVkFyABy3Nd3qeoHRf0sVR3ki2X9lYi8A2xX1b+d5eeEApuBCqqaffaVGXNmLCDM76hqtRPPRWQLcIeqRudfTkSC7JeXOR32M1P6WBeTKRIR6S0i20XkYRHZBcwQkdoi8q2IpIrIAfd50zzrxIjIHe7zESKyWET+5S67WUQGneGyLUVkoYgcFpFoEZlaWHdLEWt8WkSWuJ83W0Tq5Xn/ZhFJFpF9IvLYSfbPSGA48JCIHBGRb9z2xiLyX3f7m0VkbJ51uopIrIikichuEXnRfWuh++9B97O6F+H7M0RE4kTkoPs1nZvnvYdFJMX9+jaKSL9TbL+gz79CRNa4y24SkYFu+++63PJ2fYlIqIioiNwuIluBeW5X4uh8n71WRK52n7cRkTkist+t9bo8yw0WkQ3u15EiIg+car+Ys2MBYU5HQ6AO0AIYifPzM8N93Rw4DrxykvW7ARuBesDzwFsiImew7IfACqAuMAG4+STbLEqNNwK3AfWBYOABABFpC7zqfn5jd3tNKYCqTgc+AJ5X1WqqermIBADfAGuBJkA/YLyIDHBXmwxMVtUaQGvgU7e9l/tvLfezlp3k60NEIoCPgPFACPA98I2IBIvIOcBooIuqVgcGAFtOsf38n98VeA94EKjl1reloGULcQlwrrvtj4BheT67Lc735jsRqQrMwfn+1gduAKa5ywC8hdPNWR04H5h3GjWYM2ABYU5HLvCEqmao6nFV3aeq/1XVY6p6GHgG55dBYZJV9Q1VzQHeBRoBDU5nWRFpDnQB/q6qmaq6GPi6sA0WscYZqhqvqsdxfkl2cNuvAb5V1YWqmgE87u6DouoChKjqU26tScAbOL/4ALKAMBGpp6pHVPXH0/jsvK4HvlPVOaqaBfwLqAxchHP+qCLQVkQqqOoWVd10mtu/HXjb/fxcVU1R1V9Po74JqnrU3b9fAh1EpIX73nDgC3f/XgZsUdUZqpqtqj8B/wWuzVNvWxGpoaoHVHX1adRgzoAFhDkdqaqafuKFiFQRkdfdLpg0nK6RWiISWMj6u048UdVj7tNqp7lsY2B/njaAbYUVXMQad+V5fixPTY3zfraqHgX2FbatArQAGrvdPgdF5CDwV/4XircDEcCvIrJSRC47jc/OqzGQnKfOXLfuJqqaiHNkMQHYIyIfi0jj09x+M2BTIe8VRd59eBj4jv+F5DCcIy9w9le3fPtrOM6RK8BQYDCQLCILitL1Zs6OBYQ5Hfmn/r0fOAfo5nZTnOgaKazbqDjsBOqISJU8bc1OsvzZ1Lgz72e726x7kuXz759twGZVrZXnUV1VBwOoaoKqDsPpTpkIfO52s5zuFMs7cH65nqhT3LpT3O18qKo93GXU3dbJtp/fNpwuqIIcxbna7YSGBSyT/+v5CBjm/oKvBMzPs50F+fZXNVW92613pape4db7FYV0iZniYwFhzkZ1nD79gyJSB3jC1xtU1WQgFpjg9rF3By73UY2fA5eJSA8RCQae4uT/Z3YDrfK8XgEcdk8SVxaRQBE5X0S6AIjITSIS4v7Ff9BdJxdIdf/N+1kn8ynwJxHpJyIVcEIxA1gqIueISF8RqQik4+yL3FNsP7+3gNvczw8QkSYi0sZ9bw1wg4hUEJFInG65U/keJ6yeAj5xtw/wLRAhzoUBFdxHFxE51/1eDxeRmm43WlohtZpiZAFhzsYknL7uvcCPwA8ltN3hQHec7p5/AJ/g/EIsyBnXqKpxwD04J013AgeA7SdZ5S2cPvKDIvKVe/7kMpxzGpvdGt4EarrLDwTixBl7Mhm4wT23cwznXMkS97MuPEWdG4GbgCnuNi4HLlfVTJzzD8+57btw/vp+9GTbL+DzV+CcxH8JOAQs4H9HLI/jHF0cAJ5099VJuecbvgCi8i7vdj9ditP9tMOtd6L7NYBzscAWt6vwLzg/B8aHxG4YZEo7EfkE+FVVfX4EY0x5YkcQptRxux1au90dA4ErcPqkjTHFyEZSm9KoIU4XRV2cLp+73UsijTHFyLqYjDHGFMi6mIwxxhSozHQx1atXT0NDQ70uwxhjSpVVq1btVdWQgt4rMwERGhpKbGys12UYY0ypIiLJhb1nXUzGGGMKZAFhjDGmQBYQxhhjCmQBYYwxpkAWEMYYYwpkAWGMMaZAFhDGGGMKZAGhCrMeg9SNXldijDF+xQJi3yb46X149SInKNLTvK7IGGP8ggVEvTAYsxo63AjLpsKUzrDmQ8i1m1UZY8o3CwiAqvVgyBS4cx7Uag5f3Q1vXwo7bAZpY0z5ZQGRV5NOcPscuPJVOJAM0/vA12Ph6F6vKzPGmBJnAZFfQIDT3TQmFrrfA2s+gCmdYPnrkJPtdXXGGFNiLCAKU6kmDHgG7l4KjTvCzIfg9V6wZbHXlRljTImwgDiVkHPg5q/guvch4zC88yf47DY4lOJ1ZcYY41M+DQgRGSgiG0UkUUQeKeD9ESKSKiJr3Mcded57XkTiROQXEXlZRMSXtZ6UCLQdAqNXQO9HYeP38EokLPwXZGd4VpYxxviSzwJCRAKBqcAgoC0wTETaFrDoJ6rawX286a57EXAx0B44H+gCXOKrWousQmXo/QjcswLC+sG8p2FqN9j4g9eVGWNMsfPlEURXIFFVk1Q1E/gYuKKI6ypQCQgGKgIVgN0+qfJM1G4B1//H6XoKDIaProcPrnUG3RljTBnhy4BoAmzL83q725bfUBFZJyKfi0gzAFVdBswHdrqPWar6S/4VRWSkiMSKSGxqamrxfwWn0roP3L0ELn0Gkpc5RxNznoCMIyVfizHGFDOvT1J/A4SqantgDvAugIiEAecCTXFCpa+I9My/sqpOV9VIVY0MCSnwntu+F1gBLhoNY1ZB++tgySTn/MS6z5x5nowxppTyZUCkAM3yvG7qtv1GVfep6omzvG8Cnd3nVwE/quoRVT0CzAS6+7DWs1e9AVw5DW6PhuoN4Ys7YMZg2LXe68qMMeaM+DIgVgLhItJSRIKBG4Cv8y4gIo3yvBwCnOhG2gpcIiJBIlIB5wT1H7qY/FKzLnDHPLj8Zdi70Rk78e19cGy/15UZY8xp8VlAqGo2MBqYhfPL/VNVjRORp0RkiLvYWPdS1rXAWGCE2/45sAlYD6wF1qrqN76qtdgFBEDnW51upy53wqp3nNHYK9+C3ByvqzPGmCIRLSP95JGRkRobG+t1GQXbHQffPwTJi6Fhexj8AjS/0OuqjDEGEVmlqpEFvef1SeryocF5MOJbuGYGHNsHbw+AL0ZC2k6vKzPGmEJZQJQUETj/ahi9Eno+AHFfOlc7LZ4E2ZleV2eMMX9gAVHSgqtCv8fhnuUQ2hOin4BXu0NCtNeVGWPM71hAeKVOK7jxYxj+uTNe4oOh8NEw2L/Z68qMMQawgPBeeH8YtQyiJkDSAmc09rx/QOZRryszxpRzFhD+IKgi9LjXuUlR2yGw8AV4pSv8/IWNxjbGeMYCwp/UaAxD34TbfoAqteHz2+Ddy2H3Bq8rM8aUQxYQ/qhFdxi5AP70b9j9M7zWA2Y+DMcPel2ZMaYcsYDwVwGB0OUOGLPaGZW9/HVnNPaqdyE31+vqjDHlgAWEv6tSBy57Ce5aAHXD4Zux8GY/2O6no8aNMWWGBURp0egC+PMPcPUbkLbDCYmvRsGRPV5XZowpoywgShMR554TY2Lh4nGw7lOY0hmWTYWcLK+rM8aUMRYQpVHF6tD/KWf8RLOuMOuvzonspBivKzPGlCEWEKVZvXBnJPYNH0F2Orx3BXxyExzc6nVlxpgywAKitBOBNoNh1HLo+zdnTqdXukDMc5B13OvqjDGlmAVEWVGhEvR60Dk/cc4giHkWpnaFX76x0djGmDNiAVHW1GwK174Dt34DwdWcLqf3r4LUjV5XZowpZSwgyqqWveCuRTDoedixGl69CGY9BulpXldmjCklLCDKssAg6HaXMxq7w43O5bBTOsOaD200tjHmlHwaECIyUEQ2ikiiiDxSwPsjRCRVRNa4jzvyvNdcRGaLyC8iskFEQn1Za5lWtR4MmQJ3zoVazeGru+HtS2HHT15XZozxYz4LCBEJBKYCg4C2wDARaVvAop+oagf38Wae9veAF1T1XKArYEOGz1aTznD7HLhiGhzYAtP7wNdj4eheryszxvghXx5BdAUSVTVJVTOBj4ErirKiGyRBqjoHQFWPqOox35VajgQEQMfhMGYVdL8H1nzgTAK4/HXIyfa6OmOMH/FlQDQBtuV5vd1ty2+oiKwTkc9FpJnbFgEcFJEvROQnEXnBPSL5HREZKSKxIhKbmppa/F9BWVapJgx4Bu5eCo07wsyH4PVesHmR15UZY/yE1yepvwFCVbU9MAd4120PAnoCDwBdgFbAiPwrq+p0VY1U1ciQkJCSqbisCTkHbv4KrnsfMg7Du5fBZyPg0HavKzPGeMyXAZECNMvzuqnb9htV3aeqGe7LN4HO7vPtwBq3eyob+Aro5MNayzcR51ano1dA70dh40xnNPbCFyAr3evqjDEe8WVArATCRaSliAQDNwBf511ARBrleTkE+CXPurVE5MRhQV/A7rvpaxUqQ+9H4J4VENYP5v0DpnVzAsNGYxtT7vgsINy//EcDs3B+8X+qqnEi8pSIDHEXGysicSKyFhiL242kqjk43UtzRWQ9IMAbvqrV5FO7BVz/H7j5SwisCB/dAB9cC3sTva7MGFOCRMvIX4aRkZEaG3tmd1lbGJ/Kha3qEhzk9SkZP5ST5VzhFPOcM2Ns93ug1wPOlOPGmFJPRFapamRB75X734ib9x7l1hkr6POvGD5asZWsHBth/DuBFeCi0c5lse2uhSWTnPMT6z61bidjyrhyHxChdaswY0QX6lWvyKNfrKfPv2L4ZKUFxR9UbwBXveoMtKvWAL64E2YMgp3rvK7MGOMj1sXkUlViNqbyUnQ867YfonmdKozuG8bVHZsQFFjuc/T3cnPhp/dh7pNw/AB0vs25F0WVOl5XZow5TSfrYrKAyEdVmffrHiZFJ7A+5RAt6lZhTN9wruzQ2IIiv+MHYP6zsPINZ+Bd38eh8wgI+MOYRmOMn7KAOAOqSvQve5gUHU/cjjRa1qvKmL5hDLnAguIPdsfB9w9B8mJo2B4GvwDNL/S6KmNMEVhAnAVVZfaG3UyKTuCXnWm0qleVsf3CufyCxgQGSLFvr9RShbgvYPbjkJYC7a+HqCehRqNTr2uM8YwFRDHIzVVmb9jFpOgEft11mNYhTlBc1t6C4ncyj8KiF2HpyxAY7NwG9cJREBTsdWXGmAJYQBSj3Fzlh7hdTI5OYOPuw4TVr8a4fuH8qV0jAiwo/md/EvzwV4ifCXXDYOBECI/yuipjTD4WED6Qm6vM/HkXk+fGE7/7CBENqjGuXwSDzm9oQZFXwhyY+TDs3wTnDIYB/4Q6Lb2uyhjjsoDwodxc5bv1O5k8N4HEPUdo07A64/qFM+A8C4rfZGfAj9NgwQuQmw0Xj4Ue90FwFa8rM6bcs4AoATm5yrfrdjB5bgJJqUdp07A646MiGHBeA0QsKABI2wFz/g7rP4MaTeHSp+G8q5zZZI0xnrCAKEE5ucrXa1N4eW4im/cepW2jGoyPCqd/WwuK3yQvdS6L3b0eQnvCoOehQUF3ozXG+JoFhAeyc3L5vzU7mDIvgS37jnF+kxqM7xdBv3PrW1AA5ObAqhnOlOLpadD1TudeFJVreV2ZMeWKBYSHsnNy+fKnFKbMS2Tr/mO0b1qT8VHh9DnHggKAY/th3tMQOwOq1IWoJ6DDTc69s40xPmcB4QeycnL5cnUKL89LYPuB41zQrBbjo8LpHRFiQQGwc63T7bTtR+ce2YP/BU0L/Jk1xhQjCwg/kpWTy39XbWfKvERSDh6nQ7Na3Ns/gl7h9SwoVJ0T2LMfhyO7oMNwiJoA1ep7XZkxZZYFhB/KzM7l81XbmTrfCYpOzZ2g6BFmQUHGYed+2Mum/e82qF1HOvemMMYUKwsIP5aRncNnsU5Q7DyUTpfQ2oyPiuCi1nUtKPYmwA+PQGI01DsHBk2E1n28rsqYMsUCohTIyM7h05XbmDp/E7vS0unasg73RkXQvXVdr0vzlipsnAmzHoUDW+Dcy+HSZ5z7ZhtjzppntxwVkYEislFEEkXkkQLeHyEiqSKyxn3cke/9GiKyXURe8WWd/qBiUCA3dw8l5sHePDnkPJL3HWXYGz9yw/RlLE/a53V53hGBNoNh1HLnpkQJ0TC1q3OP7KzjXldnTJnmsyMIEQkE4oH+wHZgJTBMVTfkWWYEEKmqowv5jMlACLC/sGVOKO1HEPmlZ+Xw0YqtTIvZROrhDC5qXZd7+0fQJbSc37Xt0HaY/TeI+xJqNXfmdmpzmY3GNuYMeXUE0RVIVNUkVc0EPgauKOrKItIZaADM9lF9fq1ShUBuu7glix7qw+OXtSV+9xGufW0ZN725nFXJ+70uzzs1m8K178Ct30JwNfjkJnj/Skjd6HVlxpQ5vgyIJsC2PK+3u235DRWRdSLyuYg0AxCRAODfwAMn24CIjBSRWBGJTU1NLa66/UqlCoHc3sMJiscGn8svO9MY+uoybn5rOau3HvC6PO+07Al3LXKm6djxE7x6Ecx6zBmVbYwpFl4PV/0GCFXV9sAc4F23fRTwvapuP9nKqjpdVSNVNTIkJMTHpXqrcnAgd/ZqxaKH+/DooDbE7Ujj6mlLufXtFazZdtDr8rwRGATd7oIxq6HDjbBsKkzpDGs+hNxcr6szptTz5TmI7sAEVR3gvn4UQFWfLWT5QJxzDTVF5AOgJ5ALVAOCgWmq+ocT3SeUtXMQp3I0I5v3liUzfeEmDhzLos85IYyPiuCCZuV4LqOUVc5o7JRYaNrFuTd2445eV2WMX/PkMlcRCcI5Sd0PSME5SX2jqsblWaaRqu50n18FPKyqF+b7nBGc5ET2CeUtIE44kpHNu0u38MaiJA4ey6Jfm/qMj4qgXdOaXpfmjdxcWPsRRD8BR/dCp1ug39+haj2vKzPGL3lyklpVs4HRwCzgF+BTVY0TkadEZIi72FgRiRORtcBYYISv6imrqlUM4p4+YSx6qA8PXBpBbPIBLn9lMXe8G8vPKYe8Lq/kBQRAx+EwZhV0vwfWfABTOsHy1yEn2+vqjClVbKBcGZOWnsU7S7bw5qIk0tKzubRtA8ZHRdC2cQ2vS/NG6kaY+RAkxUD985zR2C17el2VMX7DRlKXQ4eOZzFjyWbeWryZw+nZDDyvIeOiwjm3UTkMClX45RvnKqdDW5272F36D+eSWWPKOQuIcuzQ8SzeWryZGYs3czgjm8HtGjKuXwTnNKzudWklL/MYLJkMSyaBBEDP+6D7GKhQyevKjPGMBYTh0LEs3lycxIwlWziamc3gdo0Y3y+c8AblMCgOJMPsx5yjitotYeCzEDHQRmObcskCwvzm4LFM3liUxDtLtnAsK4fL2jdmXL8wwuqXw6DYNA9mPgx74yGsPwx8DuqFeV2VMSXKAsL8wYGjblAs3cLxrByGXNCYsf3CaR1SzevSSlZOlnOFU8xzkJ3uXPnU60GoWM72gym3LCBMofYdyWD6oiTeW5pMRnYOV3Rowpi+YbQqb0FxeDdET4C1H0L1RtD/aWh3jXU7mTLPAsKc0t4jGUxfmMR7y7aQmZ3LlR2bMLZvOKH1qnpdWsnatgK+fxB2roHm3Z25nhq197oqY3zGAsIUWerhDF5fsIn/LE8mK0e5qqNzRNGibjkKitxc+Ol9mPskHD8AnW9z7kVRpZxPtW7KJAsIc9r2HE7ntZgkPlieTHauMrRTE8b0DadZnSpel1Zyjh+A+c/CyjehUg3o+zh0HgEBgV5XZkyxsYAwZ2xPWjrTYjbx4Yqt5OYq13Ruyj19wspXUOyOc6522rIIGrZ3JgFsfuGp1zOmFLCAMGdt16F0Xo1J5KMV28hV5drIZozuG0aTWpW9Lq1kqDp3sZv9N0hLgfbXQ9STUKOR15UZc1YsIEyx2XnoONPmb+KTldtQlOsim3FPnzAal5egyDwKi16EpS9DYLBzSeyFoyAo2OvKjDkjFhCm2O04eJyp8xP5NHYbgnB9l2aM6tOaRjXLSVDsT4If/grxM6FuGAycCOFRXldlzGmzgDA+s/3AMabO38RnsdsIEGFY12aM6hNGgxrlZH6jhDnwwyOwLxHOGQwD/gl1WnpdlTFFZgFhfG7b/mNMnZ/I56u2ExAg3Ni1OaN6t6Z+eQiK7Ez4cRosfMEZmX3xWOhxHwSXoxP5ptSygDAlZtv+Y0yZl8B/V6cQFCAM79aCv/RuRf3q5SAo0nbCnL/D+k+hRlO49GlnanEbjW38mAWEKXHJ+44yZV4iX/6UQoVA4aZuLbjrktaEVK/odWm+l7wMZj4Iu9ZDaE9nNHaDtl5XZUyBLCCMZ7bsPcrL8xL46qcUgoMCuKV7KCN7taJetTIeFLk5sOodmPc0pKdB1zuh96NQuZbXlRnzOxYQxnNJqUeYMi+R/1uTQsWgQG65qAV39WpNnapl/PLQY/th3j9g1QyoXBv6PQEdb3bunW2MHzhZQBTpp1REqopIgPs8QkSGiEiFIqw3UEQ2ikiiiDxSwPsjRCRVRNa4jzvc9g4iskxE4kRknYhcX5Q6jf9qFVKNl67vwOx7L+HS8xowfWESPSbOY+IPv3LgaKbX5flOlTpw2YswMgbqRcA3Y+HNvrDd/pgx/q9IRxAisgroCdQGlgArgUxVHX6SdQKBeKA/sN1dZ5iqbsizzAggUlVH51s3AlBVTRCRxsAq4FxVPVjY9uwIonRJ3HOYyXMT+XbdDqpUCGTExaHc2bMVtaqU4SMKVVj/Gcx+HI7sgg7DIWoCVKvvdWWmHDvrIwicIDkGXA1MU9VrgfNOsU5XIFFVk1Q1E/gYuKIoG1PVeFVNcJ/vAPYAIUWs1ZQCYfWrM2VYR2aN70XvNvWZOn8TPSbO59+zN3LoWJbX5fmGCLS/DsbEwsXjYd2nMKUzLH3FuTzWGD9T5IAQke7AcOA7t+1UU1o2Abbleb3dbctvqNuN9LmINCtgw12BYGBTAe+NFJFYEYlNTU0tytdh/ExEg+pMvbETs8b3oldEPabMS6THxHm8OCeeQ8fL6C/NitWh/5Mw6kdo1s25P/arF8Om+V5XZszvFDUgxgOPAl+qapyItAKK46f5GyBUVdsDc4B3874pIo2A94HbVDU3/8qqOl1VI1U1MiTEDjBKs3MaVmfa8M7MHNeTi8Pq8fLcBHpMnMfk6ATS0stoUNQLg+GfwbCPIScD3r8SPrkJDiR7XZkxwBlcxeSerK6mqmmnWK47MEFVB7ivHwVQ1WcLWT4Q2K+qNd3XNYAY4J+q+vmp6rJzEGVL3I5DTI5OYPaG3dSoFMSdPVsx4uJQqlc65bURpVNWOiybAgv/DSj0uBcuHgcVysncVsYzxXEV04ciUkNEqgI/AxtE5MFTrLYSCBeRliISDNwAfJ3vc/POlTwE+MVtDwa+BN4rSjiYsue8xjWZfksk347pQdeWdfn3nHh6Pj+fqfMTOZKR7XV5xa9CJWdm2DGxcM4giHkWpnaFX75xTm4b44GiXsW0RlU7iMhwoBPwCLDK7Ro62XqDgUk45yveVtVnROQpIFZVvxaRZ3GCIRvYD9ytqr+KyE3ADCAuz8eNUNU1hW3LjiDKtvXbDzEpOp65v+6hdpUK3NmrFbd2D6VqxSCvS/ONzQudmxTt2QCt+jijsUMivK7KlEFnPVBOROKADsCHwCuqukBE1qrqBcVb6pmzgCgf1mw7yKToeGI2plKnajAje7Xilu4tqBJcBoMiJ9u53en8f0LWUej2F7jkYef2p8YUk+K4zPV1YAtQFVgoIi2Ak56DMMYXOjSrxTu3deWLURdxfpOaPDfzV3pOnM/0hZs4llnGup4Cg+DCv8CYVdDhRlg21bksds2HkPuHazaMKXZnPNWGiASpqt/8j7QjiPJpVfIBJkXHsyhhL/WqBfOXS1ozvFsLKgef6irsUihlFXz/EKTEQtOuMPh5aNzR66pMKVccXUw1gSeAXm7TAuApVT1UbFWeJQuI8i12y34mRSewOHEv9apV5O7erRnerTmVKpSxoMjNhbUfQfQTcHQvdLoF+v0dqtbzujJTShVHQPwX5+qlE+MUbgYuUNWri63Ks2QBYQBWbN7PpOh4lm7aR/3qTlAM61oGgyL9EMRMhOWvQcVq0OdvEPlnp1vKmNNQHAGxRlU7nKrNSxYQJq8fk/YxKTqeH5P206BGRUb1DuP6Ls3KXlDs+RVmPgSbF0D985xup9AeXldlSpHiOEl9XER++6kTkYuB48VRnDG+cGGrunw8sjsf3tmNFnWq8sTXcfR+IYb3l20hIzvH6/KKT/02cMv/wXXvQUYavPMn+PzPcCjF68pMGVDUI4gLgPeAmm7TAeBWVV3nw9pOix1BmMKoKks37eOlOfHEJh+gcc1KjOoTxnWRzQgOKkP3Zcg8Bksmw5JJIAHQ837oPtoZhGdMIYrthkHu9BeoapqIjFfVScVU41mzgDCnoqosTtzLS3PiWb31IE1qVeaePmFc07lp2QqKA8kw66/w67dQuyUMfA7OGeh1VcZP+eSOciKyVVWbn1VlxcgCwhSVqrIwwQmKNdsO0rR2ZUb3CWNo56ZUCCxDQbFpnjMae288hF8KA551Jgg0Jg9fBcQ2VaQRY9QAABzBSURBVP3D9NxesYAwp0tVWRCfykvRCazddpBmdSozpk84V3VqUnaCIicLlr8OMc9Bdjp0v8eZ86liNa8rM37CjiCMOQlVJWZjKi9Fx7Nu+yGa16nCmL5hXNWxCUFlJSgO74boCbD2Q6jeCPo/De2ucW5iZMq1Mw4IETkMFLSAAJVV1W8uuraAMGdLVZn36x5eio7n55Q0QutWYUzfcK7o0LjsBMW2FfD9g7BzDTTv7kwC2Oikc26aMs4nRxD+xgLCFBdVZc6G3UyKTmDDzjRa1qvK2H5hDLmgCYEBZeAv7twc+Ok/MPdJOH4AOt8Gff8GVep4XZnxgAWEMWdAVZkVt5tJ0fH8uuswrUKqMq5fOJe1b1w2guL4AZj/rDNjbKUa0Pdx6DwCAsrYYEJzUhYQxpyF3FxlVtwuJkUnsHH3YcLqV2Nsv3D+1K5R2QiK3XHOJIDJi6FhOxj0ArTo7nVVpoRYQBhTDHJzlZk/72Ly3Hjidx8hvH41xkWFM/j8RgSU9qBQhbgvYPbjkJYC7a6D/k9BjUanXteUahYQxhSj3Fzlu/U7mTw3gcQ9R4hoUI1x/SIYdH7D0h8UmUdh0Yuw9GUIDHYuib1wFAQFe12Z8RELCGN8ICdX+XbdDl6em8Cm1KO0aVid8VHhXNq2DATF/iT44a8QPxPqhsHAiRAe5XVVxgcsIIzxoZxc5Zu1TlAk7T3KuY1quEHRACnt4wwS5jijsfdvgnMGw4B/Qp2WXldlilFxzOZ6phseKCIbRSRRRB4p4P0RIpIqImvcxx153rtVRBLcx62+rNOYsxEYIFzZsQmz7+3Fi9ddwPHMbO56fxWXTVnMnA27KdV/hIX3h1HLIGoCJC2Aqd1g3j+ciQFNmeezIwgRCQTigf7AdmAlMExVN+RZZgQQqaqj861bB4gFInEG6q0COqvqgcK2Z0cQxl9k5+Ty1ZodTJmXQPK+Y7RrUpPxUeH0bVO/dB9RpO2AOX+H9Z9BjaZw6dNw3lU2GruU8+oIoiuQqKpJqpoJfAxcUcR1BwBzVHW/GwpzAJuO0pQKQYEBXNO5KdH3XcLz17Tn4PFMbn83liunLmH+r3tK7xFFjcYw9E24bSZUrg2f3wbvXg67N5x6XVMq+TIgmgDb8rze7rblN1RE1onI5yJyYvK/Iq0rIiNFJFZEYlNTU4urbmOKRYXAAK6LbMa8+3szcWg79h3N5LZ3VnLVtKXEbCzFQdHiIrhrAfzp37D7Z3ith3Oe4vhBryszxczrCWa+AUJVtT3OUcK7p1j+d1R1uqpGqmpkSEiITwo05mxVCAzg+i7NmXd/b569uh2phzMYMWMlV7+6lIXxqaUzKAICocsdMGY1dL7VmTF2SmdY/R7k5npdnSkmvgyIFCDvdOBN3bbfqOo+Vc1wX74JdC7qusaUNsFBAQzr2pz5D/TmH1eez65D6dzy9gqueW0ZixP2ls6gqFIHLnvJOaKoGwZfj4E3+8F2Ox9YFvjyJHUQzknqfji/3FcCN6pqXJ5lGqnqTvf5VcDDqnqhe5J6FdDJXXQ1zknq/YVtz05Sm9ImIzuHT1duY+r8TexKS6dLaG3ujYqge+u6pfNktqpzAnv243BkF3QY7lz9VK2+15WZk/BsHISIDAYmAYHA26r6jIg8BcSq6tci8iwwBMgG9gN3q+qv7rp/Bv7qftQzqjrjZNuygDClVXpWDp+s3Ma0mER2p2XQtWWd34KiVMo4DAtfgGXToEJl6P0IdB0JgRW8rswUwAbKGVMKpGfl8NGKrUyL2UTq4QwubOUERbdWpTQo9ibAD49AYjSEtIFBE6FVb6+rMvlYQBhTiqRn5fDB8q28GrOJvUcyuDisLvdGRRAZWgrv16AKG2fCrEfhwBY4dwgMeAZq+c3NKMs9CwhjSqHjmTl8sDyZ1xZsYu+RTHqG12N8VASdW9T2urTTl5UOy6Y4EwFqLvS4Fy4e53RBGU9ZQBhTih3LzOY/Pybz+oIk9h3NpFdECPdGhdOxeSkMikPbYfbfIO5L5yhiwD+hzWU2GttDFhDGlAHHMrN5b1ky0xcmsf9oJr3PCeHeqAguaFbL69JO3+ZFMPMh2LMBWvd1ZosNifC6qnLJAsKYMuRoRjbvLtvC9IVJHDyWRd829bk3KoJ2TWt6XdrpycmG2Ldg/jPOfSi6/QUuedi5/akpMRYQxpRBRzKyeXfpFt5Y5ARF1Ln1GR8VwflNSllQHN0Lc5+E1e87YyainoT210OA1xM9lA8WEMaUYYfTs3hniRMUaenZ9G/bgPFR4ZzXuJQFRcpq+P5BSImFpl1h8PPQuKPXVZV5FhDGlANp6VnMWLyFNxcncTg9mwHnNWB8VATnNipFXTa5ubD2I4h+wjmy6HQL9Ps7VK3ndWVllgWEMeXIoeNZvL14M28v3szhjGwGnd+QcVHhtGlYioIi/RAseB6WvwbBVaHP3yDyzxAY5HVlZY4FhDHl0KFjWby1OIm3l2zhSEY2f2rXiHFR4UQ0qO51aUWXutG52ikpBuqf53Q7hfbwuqoyxQLCmHLs4LFM3ly0mRlLNnMsK4c/tWvE+KhwwuqXkqBQhV++gVmPwaGtcN7Vzt3sajb1urIywQLCGMP+o5m8sSiJd5du4XhWDpe3b8zYfuGE1a/mdWlFk3kMlkyGJZNAAqDnfdB9DFSo5HVlpZoFhDHmN/uOZDB9URLvLU0mIzuHIRc4QdEqpJQExYFkmP2Yc1RRuyUMfBYiBtpo7DNkAWGM+YO9RzKYvjCJ95ZtITM7lys7NmFM33Ba1qvqdWlFs2mec6vTvfEQ1h8GPgf1wryuqtSxgDDGFCr1cAbTF27i/R+TycpRruzQhLH9wmhRtxQERU6Wc7vTmOcgOx263wO9HoSKpeRoyA9YQBhjTmnP4XRei0nig+XJZOcqV7tHFM3rVvG6tFM7vBuiJ8DaD6F6I+j/NLS7xrqdisACwhhTZHvS0pkWs4kPV2wlN1cZ2qkpo/uG0axOKQiKbSuc0dg710Dz7jDoeWjU3uuq/JoFhDHmtO06lM6rMYl8tGIbuapcG9mUe/qE0bS2nwdFbg789B9nfqfjB6DzbdD3b1ClFN5wqQRYQBhjztjOQ8d5NWYTH6/YhqJcG9mMe/qE0aSWn9/s5/gBmP8srHwDKtWEvo9D5xEQEOh1ZX7Fs4AQkYHAZCAQeFNVnytkuaHA50AXVY0VkQrAm0AnIAh4T1WfPdm2LCCM8a0dB48zLSaRT1ZuA+D6Lk5QNKrp50GxOw6+fwiSF0PD9jD4BWh+oddV+Q1PAkJEAoF4oD+wHVgJDFPVDfmWqw58BwQDo92AuBEYoqo3iEgVYAPQW1W3FLY9CwhjSkbKweNMnZ/IZ7HbEIQbujZjVO8wGtb04wFrqhD3Bcx+HNJSnOnEo56EGo28rsxzJwsIX0643hVIVNUkVc0EPgauKGC5p4GJQHqeNgWqikgQUBnIBNJ8WKsxpoia1KrMP69qx/wHejO0cxM+XL6VXi/MZ8LXcexOSz/1B3hBBM4fCqNXQs/7nVuevhIJiydBdqbX1fktXwZEE2Bbntfb3bbfiEgnoJmqfpdv3c+Bo8BOYCvwL1Xdn38DIjJSRGJFJDY1NbVYizfGnFzT2lV49ur2zH+gN1d1aML7PybT6/n5PPlNHHv8NSiCqzrTh9+zHEJ7OtOKv9odEqK9rswveXbLJhEJAF4E7i/g7a5ADtAYaAncLyKt8i+kqtNVNVJVI0NCQnxarzGmYM3qVGHiNe2Zf39vhlzQmPeWJdPz+fk8/e0GUg9neF1eweq0ghs/huGfO91PHwyFj4bB/s1eV+ZXfBkQKUCzPK+bum0nVAfOB2JEZAtwIfC1iEQCNwI/qGqWqu4BlgAF9pEZY/xD87pVeOHaC5h73yVc1r4xM5Zspufz83jmuw3sPeKnQRHeH0Ytg6gJkLQApnaDef9wJgY0Pj1JHYRzkrofTjCsBG5U1bhClo8BHnBPUj8MtFHV20SkqrvuDaq6rrDt2UlqY/zL5r1HmTI3ga/WpFAxKJBburdgZK9W1K1W0evSCpa2A+b8HdZ/BjWawoB/QNsry/xobE9OUqtqNjAamAX8AnyqqnEi8pSIDDnF6lOBaiIShxMOM04WDsYY/9OyXlVevL4Dc+67hAHnNWD6oiR6Pj+f52b+yv6jfnhiuEZjGPom3PYDVKkNn42Ady+H3RtOuWpZZQPljDElInHPEV6em8A363ZQpUIgt14Uyp09W1G7arDXpf1Rbg6smuF0N6WnQdc7ofejULmW15UVOxtJbYzxGwm7DzNpbgLfr99J1eAgRlwUyh09W1Krih8GxbH9TkismgGV60DUE9DhJgjw7PqeYmcBYYzxOxt3HWby3Hi+X7+L6hWDuK1HS27v0ZKalSt4Xdof7VzrjMbe9iM07uSMxm5aNq6bsYAwxvitX3amMTk6gR/idlG9UhC392jJn3u0pEYlPwsKVecE9uzH4cgu50gi6gmoVt/rys6KBYQxxu/F7TjE5OgEZm/YTY1KQdzRsxW3XRxKdX8LiozDsPAFWDYNKlSG3o9A15EQ6Gd1FpEFhDGm1Pg55RCTohOI/mU3NStX4M6eLbn1Ij8Mir0J8MMjkBgNIW1g0ERo1dvrqk6bBYQxptRZv/0Qk6LjmfvrHmpVqcCdPVtx60WhVKsY5HVp/6MK8T84QXFgC5w7BAY8A7Wae11ZkVlAGGNKrbXbDjIpOp75G1OpXaUCI3u15pbuLajqT0GRlQ7LpsCiF0Fzoce9cPE4pwvKz1lAGGNKvZ+2HmBSdAIL4lOpUzWYu3q14ubuLagS7EdBcWg7zP6bM1tsreYw4J/Q5jK/Ho1tAWGMKTNWJR9gUnQ8ixL2Uq9aMHf1as1NF7agcrAf3Slu80KY+TDs2QCt+jj3xg6J8LqqAllAGGPKnFXJ+3lpTgKLE/dSr1pF/nJJK266sAWVKvhJUORkQ+xbMP8ZyDwK3f4ClzwMlWp4XdnvWEAYY8qslVv289KceJZu2kdI9YrcfUlrbuzW3H+C4uhemPskrH4fqoZA/yeh/Q1+MxrbAsIYU+YtT9rHS9Hx/Ji0n/rVKzKqd2tu6OpHQZGyyhmNnRILTbvC4OehcUevq7KAMMaUH8s2OUGxYvN+GtaoxKg+rbm+SzMqBvlBUOTmwtqPnDvZHd0LnW5x7nBXtZ5nJVlAGGPKFVVl6aZ9vDQnntjkAzSqWYlRfcK4LrKpfwRF+iGImQgrXndug9rnMYi8HQJL/oosCwhjTLmkqixO3MtLc+JZvfUgjWtW4p6+YVzbuRnBQX5wDmDPr/DDw5AUA/XPc7qdQnuUaAkWEMaYck1VWZjgBMWabQdpUqsyo/uGcU3nplQI9DgoVOGXb2DWY3BoK5x3NVz6NNRsWiKbt4AwxhicoIiJT2XSnHjWbj9E09qVGdM3jKs7+UFQZB6DJZNhySSQAOh5H3QfAxUq+XSzFhDGGJOHqjJ/4x4mRSewbvshmtepwui+YVzdsQlBXgfFgWSY/ZhzVFG7JQx8FiIG+mw0tgWEMcYUQFWZ+8seJs2N5+eUNFrUrcLYvuFc0aGx90GxaZ4zGntvPIT1h4HPQb2wYt/MyQLCp3tARAaKyEYRSRSRR06y3FARURGJzNPWXkSWiUiciKwXEd8eZxljyh0RIaptA74Z3YPpN3emanAQ93+2lv4vLeTLn7aTk+vhH9Ct+8LdS+HSZ2DrjzDtQpjzBGQcKbESfHYEISKBQDzQH9gOrASGqeqGfMtVB74DgoHRqhorIkHAauBmVV0rInWBg6qaU9j27AjCGHO2VJVZcbuZFB3Pr7sO0yqkKuP6hXNZ+8YEBng44d7h3RA9AdZ+CNUbQf+nod01xdLt5NURRFcgUVWTVDUT+Bi4ooDlngYmAul52i4F1qnqWgBV3XeycDDGmOIgIgw8vyHfj+3Jazd1IjgwgHEfr2HApIV8vXaHd0cU1RvAVa/C7XOgWgP44g6YMQh2rvPpZn0ZEE2AbXleb3fbfiMinYBmqvpdvnUjABWRWSKyWkQeKmgDIjJSRGJFJDY1NbU4azfGlGMBAcLA8xvx/dieTBveiQCBsR/9xMBJC/l23Q5yvQqKZl3hznlw+cvOuYnpl8C398Gx/T7ZnGdnYUQkAHgRuL+At4OAHsBw99+rRKRf/oVUdbqqRqpqZEhIiE/rNcaUPwEBwuB2jfhhXC9eudGZN2n0hz8xaPIivl+/05ugCAiEzrfCmFXQ5U5YNQNmDHbGUxQzX47rTgGa5Xnd1G07oTpwPhAjTj9aQ+BrERmCc7SxUFX3AojI90AnYK4P6zXGmAIFBAiXtW/MoPMb8d36nUyOjmfUB6tp07A646PCubRtQwJK+hxF5drOyOvOt8LhnT65DNaXJ6mDcE5S98MJhpXAjaoaV8jyMcAD7knq2jhh0APIBH4AXiqgK+o3dpLaGFNScnKVb9ftYPLcBJJSj3JuoxpuUDRA/PjucQXx5CS1qmYDo4FZwC/Ap6oaJyJPuUcJJ1v3AE7300pgDbD6ZOFgjDElKTBAuKJDE+bcewkvXX8B6Vk53PX+Ki6bspg5G3ZTVsaX2UA5Y4w5S9k5ufzfmh28PC+B5H3HaNekJuOjwunbpr7fH1HYSGpjjCkB2Tm5fPlTClPmJbJ1/zEuaFqT8VER9D4nxG+DwgLCGGNKUFZOLl+uTuHleQlsP3CcC5rVYnxUOL0j/C8oLCCMMcYDWTm5/HfVdqbMSyTl4HE6Nq/F+KgIeoXX85ugsIAwxhgPZWbn8vmq7Uyd7wRF5xa1GR8VTo8w74PCAsIYY/xARnYOn8U6QbHzUDpdQmszPiqCi1rX9SwoLCCMMcaPZGTn8OnKbUydv4ldael0bVmHe6Mi6N66bonXYgFhjDF+KD0rh09WbmNaTCK70zK4sJUTFN1alVxQWEAYY4wfS8/K4aMVW5kWs4nUwxlc1Lou9/aPoEtoHZ9v2wLCGGNKgfSsHP7zYzKvLUhi75EMeoTV497+4XRu4bugsIAwxphS5HjmiaDYxL6jmfQMr8e9/SPo1Lx2sW/LAsIYY0qhY5nZvL8smdcXJrH/aCaXRIRwb/8IOjSrVWzbsIAwxphS7GhGNu8tS2b6wk0cOJZFn3OcoGjf9OyDwgLCGGPKgCMZ2by7dAtvLEri4LEsos6tz/ioCM5vUvOMP9MCwhhjypDD6VluUGzm0PEs/tS+Ea8M63hGg+1OFhC+vKOcMcYYH6heqQKj+4Zzy0WhvLNkCxnZOT4ZiW0BYYwxpVSNShUY2y/cZ5/vszvKGWOMKd0sIIwxxhTIAsIYY0yBfBoQIjJQRDaKSKKIPHKS5YaKiIpIZL725iJyREQe8GWdxhhj/shnASEigcBUYBDQFhgmIm0LWK46MA5YXsDHvAjM9FWNxhhjCufLI4iuQKKqJqlqJvAxcEUByz0NTATS8zaKyJXAZiDOhzUaY4wphC8DogmwLc/r7W7bb0SkE9BMVb/L114NeBh48mQbEJGRIhIrIrGpqanFU7UxxhjAw5PUIhKA04V0fwFvTwBeUtUjJ/sMVZ2uqpGqGhkSEuKDKo0xpvzy5UC5FKBZntdN3bYTqgPnAzHuCMCGwNciMgToBlwjIs8DtYBcEUlX1VcK29iqVav2ikjyWdRbD9h7Fuv7mtV3dqy+s2P1nR1/rq9FYW/4bC4mEQkC4oF+OMGwErhRVQs8pyAiMcADqhqbr30CcERV/+WTQv+3ndjC5iPxB1bf2bH6zo7Vd3b8vb7C+KyLSVWzgdHALOAX4FNVjRORp9yjBGOMMX7Mp3Mxqer3wPf52v5eyLK9C2mfUOyFGWOMOSUbSf0/070u4BSsvrNj9Z0dq+/s+Ht9BSoz94MwxhhTvOwIwhhjTIEsIIwxxhSo3AdEUScULMF6monIfBHZICJxIjLObZ8gIikissZ9DPawxi0ist6tI9ZtqyMic0Qkwf23tke1nZNnH60RkTQRGe/1/hORt0Vkj4j8nKetwH0mjpfdn8l17owDJV3bCyLyq7v9L0WkltseKiLH8+zH13xZ2ylqLPR7KiKPuvtvo4gM8Ki+T/LUtkVE1rjtnuzDM6Kq5fYBBAKbgFZAMLAWaOtxTY2ATu7z6jhjSdrijC5/wOt95ta1BaiXr+154BH3+SPARD+oMxDYhTMQyNP9B/QCOgE/n2qfAYNxJqkU4EJguQe1XQoEuc8n5qktNO9yHu+/Ar+n7v+XtUBFoKX7fzywpOvL9/6/gb97uQ/P5FHejyCKOqFgiVHVnaq62n1+GGcMSZOTr+UXrgDedZ+/C1zpYS0n9AM2qerZjLAvFqq6ENifr7mwfXYF8J46fgRqiUijkqxNVWerM5YJ4EecmRA8U8j+K8wVwMeqmqGqm4FEnP/rPnOy+sSZKuI64CNf1uAL5T0gTjmhoJdEJBToyP+mQh/tHvK/7VUXjkuB2SKySkRGum0NVHWn+3wX0MCb0n7nBn7/n9Jf9t8Jhe0zf/u5/DO/n3a/pYj8JCILRKSnV0W5Cvqe+tv+6wnsVtWEPG3+tA8LVd4Dwm+JM6Ptf4HxqpoGvAq0BjoAO3EOWb3SQ1U74dzr4x4R6ZX3TXWOoz29flpEgoEhwGdukz/tvz/wh31WEBF5DMgGPnCbdgLNVbUjcB/woYjU8Kg8v/6e5jGM3/+h4k/78KTKe0CcakJBT4hIBZxw+EBVvwBQ1d2qmqOqucAb+PiQ+WRUNcX9dw/wpVvL7hPdIO6/e7yqzzUIWK2qu8G/9l8ehe0zv/i5FJERwGXAcDfAcLtt9rnPV+H070eUdG3u9gv7nvrF/oPf5qS7GvjkRJs/7cNTKe8BsRIIF5GW7l+cNwBfe1mQ21/5FvCLqr6Ypz1vH/RVwM/51y0JIlJVnLsAIiJVcU5m/oyz3251F7sV+D8v6svjd3+1+cv+y6ewffY1cIt7NdOFwKE8XVElQkQGAg8BQ1T1WJ72EHHuFomItALCgaSSrC1PLYV9T78GbhCRiiLSEqfGFSVdnysK+FVVt59o8Kd9eEpenyX3+oFzxUg8Too/5gf19MDpalgHrHEfg4H3gfVu+9dAI4/qa4VzhchanLv9Pea21wXmAglANFDHw31YFdgH1MzT5un+wwmrnUAWTp/47YXtM5yrl6a6P5PrgUgPakvE6cc/8TP4mrvsUPf7vgZYDVzu4f4r9HsKPObuv43AIC/qc9vfAf6Sb1lP9uGZPGyqDWOMMQUq711MxhhjCmEBYYwxpkAWEMYYYwpkAWGMMaZAFhDGGGMKZAFhzGkQkRz5/WyxxTYDsDvLpz+MzzAG8PE9qY0pg46ragevizCmJNgRhDHFwJ3v/3lx7pOxQkTC3PZQEZnnTig3V0Sau+0N3PssrHUfF7kfFSgib4hzL5DZIlLZsy/KlHsWEMacnsr5upiuz/PeIVVtB7wCTHLbpgDvqmp7nAnvXnbbXwYWqOoFOPcRiHPbw4GpqnoecBBn1K0xnrCR1MacBhE5oqrVCmjfAvRV1SR3ssVdqlpXRPbiTAGR5bbvVNV6IpIKNFXVjDyfEQrMUdVw9/XDQAVV/YfvvzJj/siOIIwpPlrI89ORked5Dnae0HjIAsKY4nN9nn+Xuc+X4swSDDAcWOQ+nwvcDSAigSJSs6SKNKao7K8TY05P5RM3n3f9oKonLnWtLSLrcI4ChrltY4AZIvIgkArc5raPA6aLyO04Rwp348wGaozfsHMQxhQD9xxEpKru9boWY4qLdTEZY4wpkB1BGGOMKZAdQRhjjCmQBYQxxpgCWUAYY/6/vToQAAAAABDkb73ACCURLEEAsAQBwApZWg3tjA8rRAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "plt.plot(epoch_count,torch.tensor(loss_values).numpy(), label = \"Train loss\")\n",
        "plt.plot(epoch_count, test_loss_values, label = \"Test loss\")\n",
        "plt.title(\"Training and test loss curves\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "-ViX8XQedSxH",
        "outputId": "ffd06812-b671-4055-a0eb-6e6261c5cd0b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_predictions(predictions=test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qxFq6mS5hc_i"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
